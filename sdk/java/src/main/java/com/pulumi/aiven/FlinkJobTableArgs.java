// *** WARNING: this file was generated by pulumi-java-gen. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

package com.pulumi.aiven;

import com.pulumi.aiven.inputs.FlinkJobTableUpsertKafkaArgs;
import com.pulumi.core.Output;
import com.pulumi.core.annotations.Import;
import java.lang.String;
import java.util.List;
import java.util.Objects;
import java.util.Optional;
import javax.annotation.Nullable;


public final class FlinkJobTableArgs extends com.pulumi.resources.ResourceArgs {

    public static final FlinkJobTableArgs Empty = new FlinkJobTableArgs();

    /**
     * The id of the service integration that is used with this table. It must have the service integration type `flink`. To set up proper dependencies please refer to this variable as a reference. This property cannot be changed, doing so forces recreation of the resource.
     * 
     */
    @Import(name="integrationId", required=true)
    private Output<String> integrationId;

    /**
     * @return The id of the service integration that is used with this table. It must have the service integration type `flink`. To set up proper dependencies please refer to this variable as a reference. This property cannot be changed, doing so forces recreation of the resource.
     * 
     */
    public Output<String> integrationId() {
        return this.integrationId;
    }

    /**
     * Name of the jdbc table that is to be connected to this table. Valid if the service integration id refers to a mysql or postgres service. This property cannot be changed, doing so forces recreation of the resource.
     * 
     */
    @Import(name="jdbcTable")
    private @Nullable Output<String> jdbcTable;

    /**
     * @return Name of the jdbc table that is to be connected to this table. Valid if the service integration id refers to a mysql or postgres service. This property cannot be changed, doing so forces recreation of the resource.
     * 
     */
    public Optional<Output<String>> jdbcTable() {
        return Optional.ofNullable(this.jdbcTable);
    }

    /**
     * When used as a source, upsert Kafka connectors update values that use an existing key and delete values that are null. For sinks, the connector correspondingly writes update or delete messages in a compacted topic. If no matching key is found, the values are added as new entries. For more information, see the Apache Flink documentation The possible values are `kafka` and `upsert-kafka`. This property cannot be changed, doing so forces recreation of the resource.
     * 
     */
    @Import(name="kafkaConnectorType")
    private @Nullable Output<String> kafkaConnectorType;

    /**
     * @return When used as a source, upsert Kafka connectors update values that use an existing key and delete values that are null. For sinks, the connector correspondingly writes update or delete messages in a compacted topic. If no matching key is found, the values are added as new entries. For more information, see the Apache Flink documentation The possible values are `kafka` and `upsert-kafka`. This property cannot be changed, doing so forces recreation of the resource.
     * 
     */
    public Optional<Output<String>> kafkaConnectorType() {
        return Optional.ofNullable(this.kafkaConnectorType);
    }

    /**
     * Defines an explicit list of physical columns from the table schema that configure the data type for the key format. This property cannot be changed, doing so forces recreation of the resource.
     * 
     */
    @Import(name="kafkaKeyFields")
    private @Nullable Output<List<String>> kafkaKeyFields;

    /**
     * @return Defines an explicit list of physical columns from the table schema that configure the data type for the key format. This property cannot be changed, doing so forces recreation of the resource.
     * 
     */
    public Optional<Output<List<String>>> kafkaKeyFields() {
        return Optional.ofNullable(this.kafkaKeyFields);
    }

    /**
     * Kafka Key Format The possible values are `avro`, `avro-confluent`, `debezium-avro-confluent`, `debezium-json` and `json`. This property cannot be changed, doing so forces recreation of the resource.
     * 
     */
    @Import(name="kafkaKeyFormat")
    private @Nullable Output<String> kafkaKeyFormat;

    /**
     * @return Kafka Key Format The possible values are `avro`, `avro-confluent`, `debezium-avro-confluent`, `debezium-json` and `json`. This property cannot be changed, doing so forces recreation of the resource.
     * 
     */
    public Optional<Output<String>> kafkaKeyFormat() {
        return Optional.ofNullable(this.kafkaKeyFormat);
    }

    /**
     * Startup mode The possible values are `earliest-offset`, `latest-offset`, `group-offsets` and `timestamp`. This property cannot be changed, doing so forces recreation of the resource.
     * 
     */
    @Import(name="kafkaStartupMode")
    private @Nullable Output<String> kafkaStartupMode;

    /**
     * @return Startup mode The possible values are `earliest-offset`, `latest-offset`, `group-offsets` and `timestamp`. This property cannot be changed, doing so forces recreation of the resource.
     * 
     */
    public Optional<Output<String>> kafkaStartupMode() {
        return Optional.ofNullable(this.kafkaStartupMode);
    }

    /**
     * Name of the kafka topic that is to be connected to this table. Valid if the service integration id refers to a kafka service. This property cannot be changed, doing so forces recreation of the resource.
     * 
     */
    @Import(name="kafkaTopic")
    private @Nullable Output<String> kafkaTopic;

    /**
     * @return Name of the kafka topic that is to be connected to this table. Valid if the service integration id refers to a kafka service. This property cannot be changed, doing so forces recreation of the resource.
     * 
     */
    public Optional<Output<String>> kafkaTopic() {
        return Optional.ofNullable(this.kafkaTopic);
    }

    /**
     * Controls how key columns are handled in the message value. Select ALL to include the physical columns of the table schema in the message value. Select EXCEPT_KEY to exclude the physical columns of the table schema from the message value. This is the default for upsert Kafka connectors. The possible values are `[ALL EXCEPT_KEY]`. This property cannot be changed, doing so forces recreation of the resource.
     * 
     */
    @Import(name="kafkaValueFieldsInclude")
    private @Nullable Output<String> kafkaValueFieldsInclude;

    /**
     * @return Controls how key columns are handled in the message value. Select ALL to include the physical columns of the table schema in the message value. Select EXCEPT_KEY to exclude the physical columns of the table schema from the message value. This is the default for upsert Kafka connectors. The possible values are `[ALL EXCEPT_KEY]`. This property cannot be changed, doing so forces recreation of the resource.
     * 
     */
    public Optional<Output<String>> kafkaValueFieldsInclude() {
        return Optional.ofNullable(this.kafkaValueFieldsInclude);
    }

    /**
     * Kafka Value Format The possible values are `avro`, `avro-confluent`, `debezium-avro-confluent`, `debezium-json` and `json`. This property cannot be changed, doing so forces recreation of the resource.
     * 
     */
    @Import(name="kafkaValueFormat")
    private @Nullable Output<String> kafkaValueFormat;

    /**
     * @return Kafka Value Format The possible values are `avro`, `avro-confluent`, `debezium-avro-confluent`, `debezium-json` and `json`. This property cannot be changed, doing so forces recreation of the resource.
     * 
     */
    public Optional<Output<String>> kafkaValueFormat() {
        return Optional.ofNullable(this.kafkaValueFormat);
    }

    /**
     * [LIKE](https://nightlies.apache.org/flink/flink-docs-master/docs/dev/table/sql/create/#like) statement for table creation. This property cannot be changed, doing so forces recreation of the resource.
     * 
     */
    @Import(name="likeOptions")
    private @Nullable Output<String> likeOptions;

    /**
     * @return [LIKE](https://nightlies.apache.org/flink/flink-docs-master/docs/dev/table/sql/create/#like) statement for table creation. This property cannot be changed, doing so forces recreation of the resource.
     * 
     */
    public Optional<Output<String>> likeOptions() {
        return Optional.ofNullable(this.likeOptions);
    }

    /**
     * For an OpenSearch table, the OpenSearch index the table outputs to. This property cannot be changed, doing so forces recreation of the resource.
     * 
     */
    @Import(name="opensearchIndex")
    private @Nullable Output<String> opensearchIndex;

    /**
     * @return For an OpenSearch table, the OpenSearch index the table outputs to. This property cannot be changed, doing so forces recreation of the resource.
     * 
     */
    public Optional<Output<String>> opensearchIndex() {
        return Optional.ofNullable(this.opensearchIndex);
    }

    /**
     * Identifies the project this resource belongs to. To set up proper dependencies please refer to this variable as a reference. This property cannot be changed, doing so forces recreation of the resource.
     * 
     */
    @Import(name="project", required=true)
    private Output<String> project;

    /**
     * @return Identifies the project this resource belongs to. To set up proper dependencies please refer to this variable as a reference. This property cannot be changed, doing so forces recreation of the resource.
     * 
     */
    public Output<String> project() {
        return this.project;
    }

    /**
     * The SQL statement to create the table. This property cannot be changed, doing so forces recreation of the resource.
     * 
     */
    @Import(name="schemaSql", required=true)
    private Output<String> schemaSql;

    /**
     * @return The SQL statement to create the table. This property cannot be changed, doing so forces recreation of the resource.
     * 
     */
    public Output<String> schemaSql() {
        return this.schemaSql;
    }

    /**
     * Specifies the name of the service that this resource belongs to. To set up proper dependencies please refer to this variable as a reference. This property cannot be changed, doing so forces recreation of the resource.
     * 
     */
    @Import(name="serviceName", required=true)
    private Output<String> serviceName;

    /**
     * @return Specifies the name of the service that this resource belongs to. To set up proper dependencies please refer to this variable as a reference. This property cannot be changed, doing so forces recreation of the resource.
     * 
     */
    public Output<String> serviceName() {
        return this.serviceName;
    }

    /**
     * Specifies the name of the table. This property cannot be changed, doing so forces recreation of the resource.
     * 
     */
    @Import(name="tableName", required=true)
    private Output<String> tableName;

    /**
     * @return Specifies the name of the table. This property cannot be changed, doing so forces recreation of the resource.
     * 
     */
    public Output<String> tableName() {
        return this.tableName;
    }

    /**
     * Kafka upsert connector configuration.
     * 
     */
    @Import(name="upsertKafka")
    private @Nullable Output<FlinkJobTableUpsertKafkaArgs> upsertKafka;

    /**
     * @return Kafka upsert connector configuration.
     * 
     */
    public Optional<Output<FlinkJobTableUpsertKafkaArgs>> upsertKafka() {
        return Optional.ofNullable(this.upsertKafka);
    }

    private FlinkJobTableArgs() {}

    private FlinkJobTableArgs(FlinkJobTableArgs $) {
        this.integrationId = $.integrationId;
        this.jdbcTable = $.jdbcTable;
        this.kafkaConnectorType = $.kafkaConnectorType;
        this.kafkaKeyFields = $.kafkaKeyFields;
        this.kafkaKeyFormat = $.kafkaKeyFormat;
        this.kafkaStartupMode = $.kafkaStartupMode;
        this.kafkaTopic = $.kafkaTopic;
        this.kafkaValueFieldsInclude = $.kafkaValueFieldsInclude;
        this.kafkaValueFormat = $.kafkaValueFormat;
        this.likeOptions = $.likeOptions;
        this.opensearchIndex = $.opensearchIndex;
        this.project = $.project;
        this.schemaSql = $.schemaSql;
        this.serviceName = $.serviceName;
        this.tableName = $.tableName;
        this.upsertKafka = $.upsertKafka;
    }

    public static Builder builder() {
        return new Builder();
    }
    public static Builder builder(FlinkJobTableArgs defaults) {
        return new Builder(defaults);
    }

    public static final class Builder {
        private FlinkJobTableArgs $;

        public Builder() {
            $ = new FlinkJobTableArgs();
        }

        public Builder(FlinkJobTableArgs defaults) {
            $ = new FlinkJobTableArgs(Objects.requireNonNull(defaults));
        }

        /**
         * @param integrationId The id of the service integration that is used with this table. It must have the service integration type `flink`. To set up proper dependencies please refer to this variable as a reference. This property cannot be changed, doing so forces recreation of the resource.
         * 
         * @return builder
         * 
         */
        public Builder integrationId(Output<String> integrationId) {
            $.integrationId = integrationId;
            return this;
        }

        /**
         * @param integrationId The id of the service integration that is used with this table. It must have the service integration type `flink`. To set up proper dependencies please refer to this variable as a reference. This property cannot be changed, doing so forces recreation of the resource.
         * 
         * @return builder
         * 
         */
        public Builder integrationId(String integrationId) {
            return integrationId(Output.of(integrationId));
        }

        /**
         * @param jdbcTable Name of the jdbc table that is to be connected to this table. Valid if the service integration id refers to a mysql or postgres service. This property cannot be changed, doing so forces recreation of the resource.
         * 
         * @return builder
         * 
         */
        public Builder jdbcTable(@Nullable Output<String> jdbcTable) {
            $.jdbcTable = jdbcTable;
            return this;
        }

        /**
         * @param jdbcTable Name of the jdbc table that is to be connected to this table. Valid if the service integration id refers to a mysql or postgres service. This property cannot be changed, doing so forces recreation of the resource.
         * 
         * @return builder
         * 
         */
        public Builder jdbcTable(String jdbcTable) {
            return jdbcTable(Output.of(jdbcTable));
        }

        /**
         * @param kafkaConnectorType When used as a source, upsert Kafka connectors update values that use an existing key and delete values that are null. For sinks, the connector correspondingly writes update or delete messages in a compacted topic. If no matching key is found, the values are added as new entries. For more information, see the Apache Flink documentation The possible values are `kafka` and `upsert-kafka`. This property cannot be changed, doing so forces recreation of the resource.
         * 
         * @return builder
         * 
         */
        public Builder kafkaConnectorType(@Nullable Output<String> kafkaConnectorType) {
            $.kafkaConnectorType = kafkaConnectorType;
            return this;
        }

        /**
         * @param kafkaConnectorType When used as a source, upsert Kafka connectors update values that use an existing key and delete values that are null. For sinks, the connector correspondingly writes update or delete messages in a compacted topic. If no matching key is found, the values are added as new entries. For more information, see the Apache Flink documentation The possible values are `kafka` and `upsert-kafka`. This property cannot be changed, doing so forces recreation of the resource.
         * 
         * @return builder
         * 
         */
        public Builder kafkaConnectorType(String kafkaConnectorType) {
            return kafkaConnectorType(Output.of(kafkaConnectorType));
        }

        /**
         * @param kafkaKeyFields Defines an explicit list of physical columns from the table schema that configure the data type for the key format. This property cannot be changed, doing so forces recreation of the resource.
         * 
         * @return builder
         * 
         */
        public Builder kafkaKeyFields(@Nullable Output<List<String>> kafkaKeyFields) {
            $.kafkaKeyFields = kafkaKeyFields;
            return this;
        }

        /**
         * @param kafkaKeyFields Defines an explicit list of physical columns from the table schema that configure the data type for the key format. This property cannot be changed, doing so forces recreation of the resource.
         * 
         * @return builder
         * 
         */
        public Builder kafkaKeyFields(List<String> kafkaKeyFields) {
            return kafkaKeyFields(Output.of(kafkaKeyFields));
        }

        /**
         * @param kafkaKeyFields Defines an explicit list of physical columns from the table schema that configure the data type for the key format. This property cannot be changed, doing so forces recreation of the resource.
         * 
         * @return builder
         * 
         */
        public Builder kafkaKeyFields(String... kafkaKeyFields) {
            return kafkaKeyFields(List.of(kafkaKeyFields));
        }

        /**
         * @param kafkaKeyFormat Kafka Key Format The possible values are `avro`, `avro-confluent`, `debezium-avro-confluent`, `debezium-json` and `json`. This property cannot be changed, doing so forces recreation of the resource.
         * 
         * @return builder
         * 
         */
        public Builder kafkaKeyFormat(@Nullable Output<String> kafkaKeyFormat) {
            $.kafkaKeyFormat = kafkaKeyFormat;
            return this;
        }

        /**
         * @param kafkaKeyFormat Kafka Key Format The possible values are `avro`, `avro-confluent`, `debezium-avro-confluent`, `debezium-json` and `json`. This property cannot be changed, doing so forces recreation of the resource.
         * 
         * @return builder
         * 
         */
        public Builder kafkaKeyFormat(String kafkaKeyFormat) {
            return kafkaKeyFormat(Output.of(kafkaKeyFormat));
        }

        /**
         * @param kafkaStartupMode Startup mode The possible values are `earliest-offset`, `latest-offset`, `group-offsets` and `timestamp`. This property cannot be changed, doing so forces recreation of the resource.
         * 
         * @return builder
         * 
         */
        public Builder kafkaStartupMode(@Nullable Output<String> kafkaStartupMode) {
            $.kafkaStartupMode = kafkaStartupMode;
            return this;
        }

        /**
         * @param kafkaStartupMode Startup mode The possible values are `earliest-offset`, `latest-offset`, `group-offsets` and `timestamp`. This property cannot be changed, doing so forces recreation of the resource.
         * 
         * @return builder
         * 
         */
        public Builder kafkaStartupMode(String kafkaStartupMode) {
            return kafkaStartupMode(Output.of(kafkaStartupMode));
        }

        /**
         * @param kafkaTopic Name of the kafka topic that is to be connected to this table. Valid if the service integration id refers to a kafka service. This property cannot be changed, doing so forces recreation of the resource.
         * 
         * @return builder
         * 
         */
        public Builder kafkaTopic(@Nullable Output<String> kafkaTopic) {
            $.kafkaTopic = kafkaTopic;
            return this;
        }

        /**
         * @param kafkaTopic Name of the kafka topic that is to be connected to this table. Valid if the service integration id refers to a kafka service. This property cannot be changed, doing so forces recreation of the resource.
         * 
         * @return builder
         * 
         */
        public Builder kafkaTopic(String kafkaTopic) {
            return kafkaTopic(Output.of(kafkaTopic));
        }

        /**
         * @param kafkaValueFieldsInclude Controls how key columns are handled in the message value. Select ALL to include the physical columns of the table schema in the message value. Select EXCEPT_KEY to exclude the physical columns of the table schema from the message value. This is the default for upsert Kafka connectors. The possible values are `[ALL EXCEPT_KEY]`. This property cannot be changed, doing so forces recreation of the resource.
         * 
         * @return builder
         * 
         */
        public Builder kafkaValueFieldsInclude(@Nullable Output<String> kafkaValueFieldsInclude) {
            $.kafkaValueFieldsInclude = kafkaValueFieldsInclude;
            return this;
        }

        /**
         * @param kafkaValueFieldsInclude Controls how key columns are handled in the message value. Select ALL to include the physical columns of the table schema in the message value. Select EXCEPT_KEY to exclude the physical columns of the table schema from the message value. This is the default for upsert Kafka connectors. The possible values are `[ALL EXCEPT_KEY]`. This property cannot be changed, doing so forces recreation of the resource.
         * 
         * @return builder
         * 
         */
        public Builder kafkaValueFieldsInclude(String kafkaValueFieldsInclude) {
            return kafkaValueFieldsInclude(Output.of(kafkaValueFieldsInclude));
        }

        /**
         * @param kafkaValueFormat Kafka Value Format The possible values are `avro`, `avro-confluent`, `debezium-avro-confluent`, `debezium-json` and `json`. This property cannot be changed, doing so forces recreation of the resource.
         * 
         * @return builder
         * 
         */
        public Builder kafkaValueFormat(@Nullable Output<String> kafkaValueFormat) {
            $.kafkaValueFormat = kafkaValueFormat;
            return this;
        }

        /**
         * @param kafkaValueFormat Kafka Value Format The possible values are `avro`, `avro-confluent`, `debezium-avro-confluent`, `debezium-json` and `json`. This property cannot be changed, doing so forces recreation of the resource.
         * 
         * @return builder
         * 
         */
        public Builder kafkaValueFormat(String kafkaValueFormat) {
            return kafkaValueFormat(Output.of(kafkaValueFormat));
        }

        /**
         * @param likeOptions [LIKE](https://nightlies.apache.org/flink/flink-docs-master/docs/dev/table/sql/create/#like) statement for table creation. This property cannot be changed, doing so forces recreation of the resource.
         * 
         * @return builder
         * 
         */
        public Builder likeOptions(@Nullable Output<String> likeOptions) {
            $.likeOptions = likeOptions;
            return this;
        }

        /**
         * @param likeOptions [LIKE](https://nightlies.apache.org/flink/flink-docs-master/docs/dev/table/sql/create/#like) statement for table creation. This property cannot be changed, doing so forces recreation of the resource.
         * 
         * @return builder
         * 
         */
        public Builder likeOptions(String likeOptions) {
            return likeOptions(Output.of(likeOptions));
        }

        /**
         * @param opensearchIndex For an OpenSearch table, the OpenSearch index the table outputs to. This property cannot be changed, doing so forces recreation of the resource.
         * 
         * @return builder
         * 
         */
        public Builder opensearchIndex(@Nullable Output<String> opensearchIndex) {
            $.opensearchIndex = opensearchIndex;
            return this;
        }

        /**
         * @param opensearchIndex For an OpenSearch table, the OpenSearch index the table outputs to. This property cannot be changed, doing so forces recreation of the resource.
         * 
         * @return builder
         * 
         */
        public Builder opensearchIndex(String opensearchIndex) {
            return opensearchIndex(Output.of(opensearchIndex));
        }

        /**
         * @param project Identifies the project this resource belongs to. To set up proper dependencies please refer to this variable as a reference. This property cannot be changed, doing so forces recreation of the resource.
         * 
         * @return builder
         * 
         */
        public Builder project(Output<String> project) {
            $.project = project;
            return this;
        }

        /**
         * @param project Identifies the project this resource belongs to. To set up proper dependencies please refer to this variable as a reference. This property cannot be changed, doing so forces recreation of the resource.
         * 
         * @return builder
         * 
         */
        public Builder project(String project) {
            return project(Output.of(project));
        }

        /**
         * @param schemaSql The SQL statement to create the table. This property cannot be changed, doing so forces recreation of the resource.
         * 
         * @return builder
         * 
         */
        public Builder schemaSql(Output<String> schemaSql) {
            $.schemaSql = schemaSql;
            return this;
        }

        /**
         * @param schemaSql The SQL statement to create the table. This property cannot be changed, doing so forces recreation of the resource.
         * 
         * @return builder
         * 
         */
        public Builder schemaSql(String schemaSql) {
            return schemaSql(Output.of(schemaSql));
        }

        /**
         * @param serviceName Specifies the name of the service that this resource belongs to. To set up proper dependencies please refer to this variable as a reference. This property cannot be changed, doing so forces recreation of the resource.
         * 
         * @return builder
         * 
         */
        public Builder serviceName(Output<String> serviceName) {
            $.serviceName = serviceName;
            return this;
        }

        /**
         * @param serviceName Specifies the name of the service that this resource belongs to. To set up proper dependencies please refer to this variable as a reference. This property cannot be changed, doing so forces recreation of the resource.
         * 
         * @return builder
         * 
         */
        public Builder serviceName(String serviceName) {
            return serviceName(Output.of(serviceName));
        }

        /**
         * @param tableName Specifies the name of the table. This property cannot be changed, doing so forces recreation of the resource.
         * 
         * @return builder
         * 
         */
        public Builder tableName(Output<String> tableName) {
            $.tableName = tableName;
            return this;
        }

        /**
         * @param tableName Specifies the name of the table. This property cannot be changed, doing so forces recreation of the resource.
         * 
         * @return builder
         * 
         */
        public Builder tableName(String tableName) {
            return tableName(Output.of(tableName));
        }

        /**
         * @param upsertKafka Kafka upsert connector configuration.
         * 
         * @return builder
         * 
         */
        public Builder upsertKafka(@Nullable Output<FlinkJobTableUpsertKafkaArgs> upsertKafka) {
            $.upsertKafka = upsertKafka;
            return this;
        }

        /**
         * @param upsertKafka Kafka upsert connector configuration.
         * 
         * @return builder
         * 
         */
        public Builder upsertKafka(FlinkJobTableUpsertKafkaArgs upsertKafka) {
            return upsertKafka(Output.of(upsertKafka));
        }

        public FlinkJobTableArgs build() {
            $.integrationId = Objects.requireNonNull($.integrationId, "expected parameter 'integrationId' to be non-null");
            $.project = Objects.requireNonNull($.project, "expected parameter 'project' to be non-null");
            $.schemaSql = Objects.requireNonNull($.schemaSql, "expected parameter 'schemaSql' to be non-null");
            $.serviceName = Objects.requireNonNull($.serviceName, "expected parameter 'serviceName' to be non-null");
            $.tableName = Objects.requireNonNull($.tableName, "expected parameter 'tableName' to be non-null");
            return $;
        }
    }

}
