// *** WARNING: this file was generated by pulumi-java-gen. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

package com.pulumi.aiven.outputs;

import com.pulumi.aiven.outputs.GetServiceIntegrationClickhouseKafkaUserConfigTableColumn;
import com.pulumi.aiven.outputs.GetServiceIntegrationClickhouseKafkaUserConfigTableTopic;
import com.pulumi.core.annotations.CustomType;
import com.pulumi.exceptions.MissingRequiredPropertyException;
import java.lang.Boolean;
import java.lang.Integer;
import java.lang.String;
import java.util.List;
import java.util.Objects;
import java.util.Optional;
import javax.annotation.Nullable;

@CustomType
public final class GetServiceIntegrationClickhouseKafkaUserConfigTable {
    /**
     * @return Enum: `beginning`, `earliest`, `end`, `largest`, `latest`, `smallest`. Action to take when there is no initial offset in offset store or the desired offset is out of range. Default: `earliest`.
     * 
     */
    private @Nullable String autoOffsetReset;
    /**
     * @return Table columns
     * 
     */
    private List<GetServiceIntegrationClickhouseKafkaUserConfigTableColumn> columns;
    /**
     * @return Enum: `Avro`, `AvroConfluent`, `CSV`, `JSONAsString`, `JSONCompactEachRow`, `JSONCompactStringsEachRow`, `JSONEachRow`, `JSONStringsEachRow`, `MsgPack`, `Parquet`, `RawBLOB`, `TSKV`, `TSV`, `TabSeparated`. Message data format. Default: `JSONEachRow`.
     * 
     */
    private String dataFormat;
    /**
     * @return Enum: `basic`, `best_effort`, `best_effort_us`. Method to read DateTime from text input formats. Default: `basic`.
     * 
     */
    private @Nullable String dateTimeInputFormat;
    /**
     * @return Kafka consumers group. Default: `clickhouse`.
     * 
     */
    private String groupName;
    /**
     * @return Enum: `default`, `stream`. How to handle errors for Kafka engine. Default: `default`.
     * 
     */
    private @Nullable String handleErrorMode;
    /**
     * @return Number of row collected by poll(s) for flushing data from Kafka. Default: `0`.
     * 
     */
    private @Nullable Integer maxBlockSize;
    /**
     * @return The maximum number of rows produced in one kafka message for row-based formats. Default: `1`.
     * 
     */
    private @Nullable Integer maxRowsPerMessage;
    /**
     * @return Name of the table. Example: `events`.
     * 
     */
    private String name;
    /**
     * @return The number of consumers per table per replica. Default: `1`.
     * 
     */
    private @Nullable Integer numConsumers;
    /**
     * @return Maximum amount of messages to be polled in a single Kafka poll. Default: `0`.
     * 
     */
    private @Nullable Integer pollMaxBatchSize;
    /**
     * @return Timeout in milliseconds for a single poll from Kafka. Takes the value of the stream_flush_interval_ms server setting by default (500ms). Default: `0`.
     * 
     */
    private @Nullable Integer pollMaxTimeoutMs;
    /**
     * @return Skip at least this number of broken messages from Kafka topic per block. Default: `0`.
     * 
     */
    private @Nullable Integer skipBrokenMessages;
    /**
     * @return Provide an independent thread for each consumer. All consumers run in the same thread by default. Default: `false`.
     * 
     */
    private @Nullable Boolean threadPerConsumer;
    /**
     * @return Kafka topics
     * 
     */
    private List<GetServiceIntegrationClickhouseKafkaUserConfigTableTopic> topics;

    private GetServiceIntegrationClickhouseKafkaUserConfigTable() {}
    /**
     * @return Enum: `beginning`, `earliest`, `end`, `largest`, `latest`, `smallest`. Action to take when there is no initial offset in offset store or the desired offset is out of range. Default: `earliest`.
     * 
     */
    public Optional<String> autoOffsetReset() {
        return Optional.ofNullable(this.autoOffsetReset);
    }
    /**
     * @return Table columns
     * 
     */
    public List<GetServiceIntegrationClickhouseKafkaUserConfigTableColumn> columns() {
        return this.columns;
    }
    /**
     * @return Enum: `Avro`, `AvroConfluent`, `CSV`, `JSONAsString`, `JSONCompactEachRow`, `JSONCompactStringsEachRow`, `JSONEachRow`, `JSONStringsEachRow`, `MsgPack`, `Parquet`, `RawBLOB`, `TSKV`, `TSV`, `TabSeparated`. Message data format. Default: `JSONEachRow`.
     * 
     */
    public String dataFormat() {
        return this.dataFormat;
    }
    /**
     * @return Enum: `basic`, `best_effort`, `best_effort_us`. Method to read DateTime from text input formats. Default: `basic`.
     * 
     */
    public Optional<String> dateTimeInputFormat() {
        return Optional.ofNullable(this.dateTimeInputFormat);
    }
    /**
     * @return Kafka consumers group. Default: `clickhouse`.
     * 
     */
    public String groupName() {
        return this.groupName;
    }
    /**
     * @return Enum: `default`, `stream`. How to handle errors for Kafka engine. Default: `default`.
     * 
     */
    public Optional<String> handleErrorMode() {
        return Optional.ofNullable(this.handleErrorMode);
    }
    /**
     * @return Number of row collected by poll(s) for flushing data from Kafka. Default: `0`.
     * 
     */
    public Optional<Integer> maxBlockSize() {
        return Optional.ofNullable(this.maxBlockSize);
    }
    /**
     * @return The maximum number of rows produced in one kafka message for row-based formats. Default: `1`.
     * 
     */
    public Optional<Integer> maxRowsPerMessage() {
        return Optional.ofNullable(this.maxRowsPerMessage);
    }
    /**
     * @return Name of the table. Example: `events`.
     * 
     */
    public String name() {
        return this.name;
    }
    /**
     * @return The number of consumers per table per replica. Default: `1`.
     * 
     */
    public Optional<Integer> numConsumers() {
        return Optional.ofNullable(this.numConsumers);
    }
    /**
     * @return Maximum amount of messages to be polled in a single Kafka poll. Default: `0`.
     * 
     */
    public Optional<Integer> pollMaxBatchSize() {
        return Optional.ofNullable(this.pollMaxBatchSize);
    }
    /**
     * @return Timeout in milliseconds for a single poll from Kafka. Takes the value of the stream_flush_interval_ms server setting by default (500ms). Default: `0`.
     * 
     */
    public Optional<Integer> pollMaxTimeoutMs() {
        return Optional.ofNullable(this.pollMaxTimeoutMs);
    }
    /**
     * @return Skip at least this number of broken messages from Kafka topic per block. Default: `0`.
     * 
     */
    public Optional<Integer> skipBrokenMessages() {
        return Optional.ofNullable(this.skipBrokenMessages);
    }
    /**
     * @return Provide an independent thread for each consumer. All consumers run in the same thread by default. Default: `false`.
     * 
     */
    public Optional<Boolean> threadPerConsumer() {
        return Optional.ofNullable(this.threadPerConsumer);
    }
    /**
     * @return Kafka topics
     * 
     */
    public List<GetServiceIntegrationClickhouseKafkaUserConfigTableTopic> topics() {
        return this.topics;
    }

    public static Builder builder() {
        return new Builder();
    }

    public static Builder builder(GetServiceIntegrationClickhouseKafkaUserConfigTable defaults) {
        return new Builder(defaults);
    }
    @CustomType.Builder
    public static final class Builder {
        private @Nullable String autoOffsetReset;
        private List<GetServiceIntegrationClickhouseKafkaUserConfigTableColumn> columns;
        private String dataFormat;
        private @Nullable String dateTimeInputFormat;
        private String groupName;
        private @Nullable String handleErrorMode;
        private @Nullable Integer maxBlockSize;
        private @Nullable Integer maxRowsPerMessage;
        private String name;
        private @Nullable Integer numConsumers;
        private @Nullable Integer pollMaxBatchSize;
        private @Nullable Integer pollMaxTimeoutMs;
        private @Nullable Integer skipBrokenMessages;
        private @Nullable Boolean threadPerConsumer;
        private List<GetServiceIntegrationClickhouseKafkaUserConfigTableTopic> topics;
        public Builder() {}
        public Builder(GetServiceIntegrationClickhouseKafkaUserConfigTable defaults) {
    	      Objects.requireNonNull(defaults);
    	      this.autoOffsetReset = defaults.autoOffsetReset;
    	      this.columns = defaults.columns;
    	      this.dataFormat = defaults.dataFormat;
    	      this.dateTimeInputFormat = defaults.dateTimeInputFormat;
    	      this.groupName = defaults.groupName;
    	      this.handleErrorMode = defaults.handleErrorMode;
    	      this.maxBlockSize = defaults.maxBlockSize;
    	      this.maxRowsPerMessage = defaults.maxRowsPerMessage;
    	      this.name = defaults.name;
    	      this.numConsumers = defaults.numConsumers;
    	      this.pollMaxBatchSize = defaults.pollMaxBatchSize;
    	      this.pollMaxTimeoutMs = defaults.pollMaxTimeoutMs;
    	      this.skipBrokenMessages = defaults.skipBrokenMessages;
    	      this.threadPerConsumer = defaults.threadPerConsumer;
    	      this.topics = defaults.topics;
        }

        @CustomType.Setter
        public Builder autoOffsetReset(@Nullable String autoOffsetReset) {

            this.autoOffsetReset = autoOffsetReset;
            return this;
        }
        @CustomType.Setter
        public Builder columns(List<GetServiceIntegrationClickhouseKafkaUserConfigTableColumn> columns) {
            if (columns == null) {
              throw new MissingRequiredPropertyException("GetServiceIntegrationClickhouseKafkaUserConfigTable", "columns");
            }
            this.columns = columns;
            return this;
        }
        public Builder columns(GetServiceIntegrationClickhouseKafkaUserConfigTableColumn... columns) {
            return columns(List.of(columns));
        }
        @CustomType.Setter
        public Builder dataFormat(String dataFormat) {
            if (dataFormat == null) {
              throw new MissingRequiredPropertyException("GetServiceIntegrationClickhouseKafkaUserConfigTable", "dataFormat");
            }
            this.dataFormat = dataFormat;
            return this;
        }
        @CustomType.Setter
        public Builder dateTimeInputFormat(@Nullable String dateTimeInputFormat) {

            this.dateTimeInputFormat = dateTimeInputFormat;
            return this;
        }
        @CustomType.Setter
        public Builder groupName(String groupName) {
            if (groupName == null) {
              throw new MissingRequiredPropertyException("GetServiceIntegrationClickhouseKafkaUserConfigTable", "groupName");
            }
            this.groupName = groupName;
            return this;
        }
        @CustomType.Setter
        public Builder handleErrorMode(@Nullable String handleErrorMode) {

            this.handleErrorMode = handleErrorMode;
            return this;
        }
        @CustomType.Setter
        public Builder maxBlockSize(@Nullable Integer maxBlockSize) {

            this.maxBlockSize = maxBlockSize;
            return this;
        }
        @CustomType.Setter
        public Builder maxRowsPerMessage(@Nullable Integer maxRowsPerMessage) {

            this.maxRowsPerMessage = maxRowsPerMessage;
            return this;
        }
        @CustomType.Setter
        public Builder name(String name) {
            if (name == null) {
              throw new MissingRequiredPropertyException("GetServiceIntegrationClickhouseKafkaUserConfigTable", "name");
            }
            this.name = name;
            return this;
        }
        @CustomType.Setter
        public Builder numConsumers(@Nullable Integer numConsumers) {

            this.numConsumers = numConsumers;
            return this;
        }
        @CustomType.Setter
        public Builder pollMaxBatchSize(@Nullable Integer pollMaxBatchSize) {

            this.pollMaxBatchSize = pollMaxBatchSize;
            return this;
        }
        @CustomType.Setter
        public Builder pollMaxTimeoutMs(@Nullable Integer pollMaxTimeoutMs) {

            this.pollMaxTimeoutMs = pollMaxTimeoutMs;
            return this;
        }
        @CustomType.Setter
        public Builder skipBrokenMessages(@Nullable Integer skipBrokenMessages) {

            this.skipBrokenMessages = skipBrokenMessages;
            return this;
        }
        @CustomType.Setter
        public Builder threadPerConsumer(@Nullable Boolean threadPerConsumer) {

            this.threadPerConsumer = threadPerConsumer;
            return this;
        }
        @CustomType.Setter
        public Builder topics(List<GetServiceIntegrationClickhouseKafkaUserConfigTableTopic> topics) {
            if (topics == null) {
              throw new MissingRequiredPropertyException("GetServiceIntegrationClickhouseKafkaUserConfigTable", "topics");
            }
            this.topics = topics;
            return this;
        }
        public Builder topics(GetServiceIntegrationClickhouseKafkaUserConfigTableTopic... topics) {
            return topics(List.of(topics));
        }
        public GetServiceIntegrationClickhouseKafkaUserConfigTable build() {
            final var _resultValue = new GetServiceIntegrationClickhouseKafkaUserConfigTable();
            _resultValue.autoOffsetReset = autoOffsetReset;
            _resultValue.columns = columns;
            _resultValue.dataFormat = dataFormat;
            _resultValue.dateTimeInputFormat = dateTimeInputFormat;
            _resultValue.groupName = groupName;
            _resultValue.handleErrorMode = handleErrorMode;
            _resultValue.maxBlockSize = maxBlockSize;
            _resultValue.maxRowsPerMessage = maxRowsPerMessage;
            _resultValue.name = name;
            _resultValue.numConsumers = numConsumers;
            _resultValue.pollMaxBatchSize = pollMaxBatchSize;
            _resultValue.pollMaxTimeoutMs = pollMaxTimeoutMs;
            _resultValue.skipBrokenMessages = skipBrokenMessages;
            _resultValue.threadPerConsumer = threadPerConsumer;
            _resultValue.topics = topics;
            return _resultValue;
        }
    }
}
