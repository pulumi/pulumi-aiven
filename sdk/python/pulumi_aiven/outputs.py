# coding=utf-8
# *** WARNING: this file was generated by the Pulumi Terraform Bridge (tfgen) Tool. ***
# *** Do not edit by hand unless you're certain you know what you are doing! ***

import warnings
import pulumi
import pulumi.runtime
from typing import Any, Mapping, Optional, Sequence, Union, overload
from . import _utilities
from . import outputs

__all__ = [
    'CassandraCassandra',
    'CassandraCassandraUserConfig',
    'CassandraCassandraUserConfigCassandra',
    'CassandraCassandraUserConfigPrivateAccess',
    'CassandraCassandraUserConfigPublicAccess',
    'CassandraComponent',
    'CassandraServiceIntegration',
    'ElasticSearchAclAcl',
    'ElasticSearchAclAclRule',
    'ElasticSearchComponent',
    'ElasticSearchElasticsearch',
    'ElasticSearchElasticsearchUserConfig',
    'ElasticSearchElasticsearchUserConfigElasticsearch',
    'ElasticSearchElasticsearchUserConfigIndexPattern',
    'ElasticSearchElasticsearchUserConfigIndexTemplate',
    'ElasticSearchElasticsearchUserConfigKibana',
    'ElasticSearchElasticsearchUserConfigPrivateAccess',
    'ElasticSearchElasticsearchUserConfigPrivatelinkAccess',
    'ElasticSearchElasticsearchUserConfigPublicAccess',
    'ElasticSearchServiceIntegration',
    'GrafanaComponent',
    'GrafanaGrafana',
    'GrafanaGrafanaUserConfig',
    'GrafanaGrafanaUserConfigAuthGenericOauth',
    'GrafanaGrafanaUserConfigAuthGithub',
    'GrafanaGrafanaUserConfigAuthGitlab',
    'GrafanaGrafanaUserConfigAuthGoogle',
    'GrafanaGrafanaUserConfigExternalImageStorage',
    'GrafanaGrafanaUserConfigPrivateAccess',
    'GrafanaGrafanaUserConfigPrivatelinkAccess',
    'GrafanaGrafanaUserConfigPublicAccess',
    'GrafanaGrafanaUserConfigSmtpServer',
    'GrafanaServiceIntegration',
    'InfluxDbComponent',
    'InfluxDbInfluxdb',
    'InfluxDbInfluxdbUserConfig',
    'InfluxDbInfluxdbUserConfigInfluxdb',
    'InfluxDbInfluxdbUserConfigPrivateAccess',
    'InfluxDbInfluxdbUserConfigPrivatelinkAccess',
    'InfluxDbInfluxdbUserConfigPublicAccess',
    'InfluxDbServiceIntegration',
    'KafkaComponent',
    'KafkaConnectComponent',
    'KafkaConnectKafkaConnect',
    'KafkaConnectKafkaConnectUserConfig',
    'KafkaConnectKafkaConnectUserConfigKafkaConnect',
    'KafkaConnectKafkaConnectUserConfigPrivateAccess',
    'KafkaConnectKafkaConnectUserConfigPrivatelinkAccess',
    'KafkaConnectKafkaConnectUserConfigPublicAccess',
    'KafkaConnectServiceIntegration',
    'KafkaConnectorTask',
    'KafkaKafka',
    'KafkaKafkaUserConfig',
    'KafkaKafkaUserConfigKafka',
    'KafkaKafkaUserConfigKafkaAuthenticationMethods',
    'KafkaKafkaUserConfigKafkaConnectConfig',
    'KafkaKafkaUserConfigKafkaRestConfig',
    'KafkaKafkaUserConfigPrivateAccess',
    'KafkaKafkaUserConfigPrivatelinkAccess',
    'KafkaKafkaUserConfigPublicAccess',
    'KafkaKafkaUserConfigSchemaRegistryConfig',
    'KafkaMirrorMakerComponent',
    'KafkaMirrorMakerKafkaMirrormaker',
    'KafkaMirrorMakerKafkaMirrormakerUserConfig',
    'KafkaMirrorMakerKafkaMirrormakerUserConfigKafkaMirrormaker',
    'KafkaMirrorMakerServiceIntegration',
    'KafkaServiceIntegration',
    'KafkaTopicConfig',
    'KafkaTopicTag',
    'M3AggregatorComponent',
    'M3AggregatorM3aggregator',
    'M3AggregatorM3aggregatorUserConfig',
    'M3AggregatorServiceIntegration',
    'M3DbComponent',
    'M3DbM3db',
    'M3DbM3dbUserConfig',
    'M3DbM3dbUserConfigLimits',
    'M3DbM3dbUserConfigNamespace',
    'M3DbM3dbUserConfigNamespaceOptions',
    'M3DbM3dbUserConfigNamespaceOptionsRetentionOptions',
    'M3DbM3dbUserConfigPrivateAccess',
    'M3DbM3dbUserConfigPublicAccess',
    'M3DbM3dbUserConfigRules',
    'M3DbM3dbUserConfigRulesMapping',
    'M3DbM3dbUserConfigRulesMappingTag',
    'M3DbServiceIntegration',
    'MySqlComponent',
    'MySqlMysql',
    'MySqlMysqlUserConfig',
    'MySqlMysqlUserConfigMigration',
    'MySqlMysqlUserConfigMysql',
    'MySqlMysqlUserConfigPrivateAccess',
    'MySqlMysqlUserConfigPrivatelinkAccess',
    'MySqlMysqlUserConfigPublicAccess',
    'MySqlServiceIntegration',
    'PgComponent',
    'PgPg',
    'PgPgUserConfig',
    'PgPgUserConfigMigration',
    'PgPgUserConfigPg',
    'PgPgUserConfigPgbouncer',
    'PgPgUserConfigPglookout',
    'PgPgUserConfigPrivateAccess',
    'PgPgUserConfigPrivatelinkAccess',
    'PgPgUserConfigPublicAccess',
    'PgPgUserConfigTimescaledb',
    'PgServiceIntegration',
    'RedisComponent',
    'RedisRedis',
    'RedisRedisUserConfig',
    'RedisRedisUserConfigMigration',
    'RedisRedisUserConfigPrivateAccess',
    'RedisRedisUserConfigPrivatelinkAccess',
    'RedisRedisUserConfigPublicAccess',
    'RedisServiceIntegration',
    'ServiceCassandra',
    'ServiceCassandraUserConfig',
    'ServiceCassandraUserConfigCassandra',
    'ServiceCassandraUserConfigPrivateAccess',
    'ServiceCassandraUserConfigPublicAccess',
    'ServiceComponent',
    'ServiceElasticsearch',
    'ServiceElasticsearchUserConfig',
    'ServiceElasticsearchUserConfigElasticsearch',
    'ServiceElasticsearchUserConfigIndexPattern',
    'ServiceElasticsearchUserConfigIndexTemplate',
    'ServiceElasticsearchUserConfigKibana',
    'ServiceElasticsearchUserConfigPrivateAccess',
    'ServiceElasticsearchUserConfigPrivatelinkAccess',
    'ServiceElasticsearchUserConfigPublicAccess',
    'ServiceGrafana',
    'ServiceGrafanaUserConfig',
    'ServiceGrafanaUserConfigAuthGenericOauth',
    'ServiceGrafanaUserConfigAuthGithub',
    'ServiceGrafanaUserConfigAuthGitlab',
    'ServiceGrafanaUserConfigAuthGoogle',
    'ServiceGrafanaUserConfigExternalImageStorage',
    'ServiceGrafanaUserConfigPrivateAccess',
    'ServiceGrafanaUserConfigPrivatelinkAccess',
    'ServiceGrafanaUserConfigPublicAccess',
    'ServiceGrafanaUserConfigSmtpServer',
    'ServiceInfluxdb',
    'ServiceInfluxdbUserConfig',
    'ServiceInfluxdbUserConfigInfluxdb',
    'ServiceInfluxdbUserConfigPrivateAccess',
    'ServiceInfluxdbUserConfigPrivatelinkAccess',
    'ServiceInfluxdbUserConfigPublicAccess',
    'ServiceIntegrationDashboardUserConfig',
    'ServiceIntegrationDatadogUserConfig',
    'ServiceIntegrationDatadogUserConfigDatadogTag',
    'ServiceIntegrationEndpointDatadogUserConfig',
    'ServiceIntegrationEndpointDatadogUserConfigDatadogTag',
    'ServiceIntegrationEndpointExternalAwsCloudwatchLogsUserConfig',
    'ServiceIntegrationEndpointExternalAwsCloudwatchMetricsUserConfig',
    'ServiceIntegrationEndpointExternalElasticsearchLogsUserConfig',
    'ServiceIntegrationEndpointExternalGoogleCloudLoggingUserConfig',
    'ServiceIntegrationEndpointExternalKafkaUserConfig',
    'ServiceIntegrationEndpointExternalSchemaRegistryUserConfig',
    'ServiceIntegrationEndpointJolokiaUserConfig',
    'ServiceIntegrationEndpointPrometheusUserConfig',
    'ServiceIntegrationEndpointRsyslogUserConfig',
    'ServiceIntegrationEndpointSignalfxUserConfig',
    'ServiceIntegrationExternalAwsCloudwatchLogsUserConfig',
    'ServiceIntegrationExternalAwsCloudwatchMetricsUserConfig',
    'ServiceIntegrationExternalAwsCloudwatchMetricsUserConfigDroppedMetric',
    'ServiceIntegrationExternalAwsCloudwatchMetricsUserConfigExtraMetric',
    'ServiceIntegrationExternalElasticsearchLogsUserConfig',
    'ServiceIntegrationExternalGoogleCloudLoggingUserConfig',
    'ServiceIntegrationKafkaConnectUserConfig',
    'ServiceIntegrationKafkaConnectUserConfigKafkaConnect',
    'ServiceIntegrationKafkaLogsUserConfig',
    'ServiceIntegrationKafkaMirrormakerUserConfig',
    'ServiceIntegrationLogsUserConfig',
    'ServiceIntegrationM3aggregatorUserConfig',
    'ServiceIntegrationM3coordinatorUserConfig',
    'ServiceIntegrationMetricsUserConfig',
    'ServiceIntegrationMetricsUserConfigSourceMysql',
    'ServiceIntegrationMetricsUserConfigSourceMysqlTelegraf',
    'ServiceIntegrationMirrormakerUserConfig',
    'ServiceIntegrationPrometheusUserConfig',
    'ServiceIntegrationPrometheusUserConfigSourceMysql',
    'ServiceIntegrationPrometheusUserConfigSourceMysqlTelegraf',
    'ServiceIntegrationReadReplicaUserConfig',
    'ServiceIntegrationRsyslogUserConfig',
    'ServiceIntegrationSchemaRegistryProxyUserConfig',
    'ServiceIntegrationSignalfxUserConfig',
    'ServiceKafka',
    'ServiceKafkaConnect',
    'ServiceKafkaConnectUserConfig',
    'ServiceKafkaConnectUserConfigKafkaConnect',
    'ServiceKafkaConnectUserConfigPrivateAccess',
    'ServiceKafkaConnectUserConfigPrivatelinkAccess',
    'ServiceKafkaConnectUserConfigPublicAccess',
    'ServiceKafkaMirrormaker',
    'ServiceKafkaMirrormakerUserConfig',
    'ServiceKafkaMirrormakerUserConfigKafkaMirrormaker',
    'ServiceKafkaUserConfig',
    'ServiceKafkaUserConfigKafka',
    'ServiceKafkaUserConfigKafkaAuthenticationMethods',
    'ServiceKafkaUserConfigKafkaConnectConfig',
    'ServiceKafkaUserConfigKafkaRestConfig',
    'ServiceKafkaUserConfigPrivateAccess',
    'ServiceKafkaUserConfigPrivatelinkAccess',
    'ServiceKafkaUserConfigPublicAccess',
    'ServiceKafkaUserConfigSchemaRegistryConfig',
    'ServiceMysql',
    'ServiceMysqlUserConfig',
    'ServiceMysqlUserConfigMigration',
    'ServiceMysqlUserConfigMysql',
    'ServiceMysqlUserConfigPrivateAccess',
    'ServiceMysqlUserConfigPrivatelinkAccess',
    'ServiceMysqlUserConfigPublicAccess',
    'ServicePg',
    'ServicePgUserConfig',
    'ServicePgUserConfigMigration',
    'ServicePgUserConfigPg',
    'ServicePgUserConfigPgbouncer',
    'ServicePgUserConfigPglookout',
    'ServicePgUserConfigPrivateAccess',
    'ServicePgUserConfigPrivatelinkAccess',
    'ServicePgUserConfigPublicAccess',
    'ServicePgUserConfigTimescaledb',
    'ServiceRedis',
    'ServiceRedisUserConfig',
    'ServiceRedisUserConfigMigration',
    'ServiceRedisUserConfigPrivateAccess',
    'ServiceRedisUserConfigPrivatelinkAccess',
    'ServiceRedisUserConfigPublicAccess',
    'ServiceServiceIntegration',
    'GetCassandaCassandraResult',
    'GetCassandaCassandraUserConfigResult',
    'GetCassandaCassandraUserConfigCassandraResult',
    'GetCassandaCassandraUserConfigPrivateAccessResult',
    'GetCassandaCassandraUserConfigPublicAccessResult',
    'GetCassandaComponentResult',
    'GetCassandaServiceIntegrationResult',
    'GetElasticSearchAclAclResult',
    'GetElasticSearchAclAclRuleResult',
    'GetElasticSearchComponentResult',
    'GetElasticSearchElasticsearchResult',
    'GetElasticSearchElasticsearchUserConfigResult',
    'GetElasticSearchElasticsearchUserConfigElasticsearchResult',
    'GetElasticSearchElasticsearchUserConfigIndexPatternResult',
    'GetElasticSearchElasticsearchUserConfigIndexTemplateResult',
    'GetElasticSearchElasticsearchUserConfigKibanaResult',
    'GetElasticSearchElasticsearchUserConfigPrivateAccessResult',
    'GetElasticSearchElasticsearchUserConfigPrivatelinkAccessResult',
    'GetElasticSearchElasticsearchUserConfigPublicAccessResult',
    'GetElasticSearchServiceIntegrationResult',
    'GetGrafanaComponentResult',
    'GetGrafanaGrafanaResult',
    'GetGrafanaGrafanaUserConfigResult',
    'GetGrafanaGrafanaUserConfigAuthGenericOauthResult',
    'GetGrafanaGrafanaUserConfigAuthGithubResult',
    'GetGrafanaGrafanaUserConfigAuthGitlabResult',
    'GetGrafanaGrafanaUserConfigAuthGoogleResult',
    'GetGrafanaGrafanaUserConfigExternalImageStorageResult',
    'GetGrafanaGrafanaUserConfigPrivateAccessResult',
    'GetGrafanaGrafanaUserConfigPrivatelinkAccessResult',
    'GetGrafanaGrafanaUserConfigPublicAccessResult',
    'GetGrafanaGrafanaUserConfigSmtpServerResult',
    'GetGrafanaServiceIntegrationResult',
    'GetInfluxDbComponentResult',
    'GetInfluxDbInfluxdbResult',
    'GetInfluxDbInfluxdbUserConfigResult',
    'GetInfluxDbInfluxdbUserConfigInfluxdbResult',
    'GetInfluxDbInfluxdbUserConfigPrivateAccessResult',
    'GetInfluxDbInfluxdbUserConfigPrivatelinkAccessResult',
    'GetInfluxDbInfluxdbUserConfigPublicAccessResult',
    'GetInfluxDbServiceIntegrationResult',
    'GetKafkaComponentResult',
    'GetKafkaConnectComponentResult',
    'GetKafkaConnectKafkaConnectResult',
    'GetKafkaConnectKafkaConnectUserConfigResult',
    'GetKafkaConnectKafkaConnectUserConfigKafkaConnectResult',
    'GetKafkaConnectKafkaConnectUserConfigPrivateAccessResult',
    'GetKafkaConnectKafkaConnectUserConfigPrivatelinkAccessResult',
    'GetKafkaConnectKafkaConnectUserConfigPublicAccessResult',
    'GetKafkaConnectServiceIntegrationResult',
    'GetKafkaConnectorTaskResult',
    'GetKafkaKafkaResult',
    'GetKafkaKafkaUserConfigResult',
    'GetKafkaKafkaUserConfigKafkaResult',
    'GetKafkaKafkaUserConfigKafkaAuthenticationMethodsResult',
    'GetKafkaKafkaUserConfigKafkaConnectConfigResult',
    'GetKafkaKafkaUserConfigKafkaRestConfigResult',
    'GetKafkaKafkaUserConfigPrivateAccessResult',
    'GetKafkaKafkaUserConfigPrivatelinkAccessResult',
    'GetKafkaKafkaUserConfigPublicAccessResult',
    'GetKafkaKafkaUserConfigSchemaRegistryConfigResult',
    'GetKafkaMirrorMakerComponentResult',
    'GetKafkaMirrorMakerKafkaMirrormakerResult',
    'GetKafkaMirrorMakerKafkaMirrormakerUserConfigResult',
    'GetKafkaMirrorMakerKafkaMirrormakerUserConfigKafkaMirrormakerResult',
    'GetKafkaMirrorMakerServiceIntegrationResult',
    'GetKafkaServiceIntegrationResult',
    'GetKafkaTopicConfigResult',
    'GetKafkaTopicTagResult',
    'GetM3AggregatorComponentResult',
    'GetM3AggregatorM3aggregatorResult',
    'GetM3AggregatorM3aggregatorUserConfigResult',
    'GetM3AggregatorServiceIntegrationResult',
    'GetM3DbComponentResult',
    'GetM3DbM3dbResult',
    'GetM3DbM3dbUserConfigResult',
    'GetM3DbM3dbUserConfigLimitsResult',
    'GetM3DbM3dbUserConfigNamespaceResult',
    'GetM3DbM3dbUserConfigNamespaceOptionsResult',
    'GetM3DbM3dbUserConfigNamespaceOptionsRetentionOptionsResult',
    'GetM3DbM3dbUserConfigPrivateAccessResult',
    'GetM3DbM3dbUserConfigPublicAccessResult',
    'GetM3DbM3dbUserConfigRulesResult',
    'GetM3DbM3dbUserConfigRulesMappingResult',
    'GetM3DbM3dbUserConfigRulesMappingTagResult',
    'GetM3DbServiceIntegrationResult',
    'GetMySqlComponentResult',
    'GetMySqlMysqlResult',
    'GetMySqlMysqlUserConfigResult',
    'GetMySqlMysqlUserConfigMigrationResult',
    'GetMySqlMysqlUserConfigMysqlResult',
    'GetMySqlMysqlUserConfigPrivateAccessResult',
    'GetMySqlMysqlUserConfigPrivatelinkAccessResult',
    'GetMySqlMysqlUserConfigPublicAccessResult',
    'GetMySqlServiceIntegrationResult',
    'GetPgComponentResult',
    'GetPgPgResult',
    'GetPgPgUserConfigResult',
    'GetPgPgUserConfigMigrationResult',
    'GetPgPgUserConfigPgResult',
    'GetPgPgUserConfigPgbouncerResult',
    'GetPgPgUserConfigPglookoutResult',
    'GetPgPgUserConfigPrivateAccessResult',
    'GetPgPgUserConfigPrivatelinkAccessResult',
    'GetPgPgUserConfigPublicAccessResult',
    'GetPgPgUserConfigTimescaledbResult',
    'GetPgServiceIntegrationResult',
    'GetRedisComponentResult',
    'GetRedisRedisResult',
    'GetRedisRedisUserConfigResult',
    'GetRedisRedisUserConfigMigrationResult',
    'GetRedisRedisUserConfigPrivateAccessResult',
    'GetRedisRedisUserConfigPrivatelinkAccessResult',
    'GetRedisRedisUserConfigPublicAccessResult',
    'GetRedisServiceIntegrationResult',
    'GetServiceCassandraResult',
    'GetServiceCassandraUserConfigResult',
    'GetServiceCassandraUserConfigCassandraResult',
    'GetServiceCassandraUserConfigPrivateAccessResult',
    'GetServiceCassandraUserConfigPublicAccessResult',
    'GetServiceComponentResult',
    'GetServiceElasticsearchResult',
    'GetServiceElasticsearchUserConfigResult',
    'GetServiceElasticsearchUserConfigElasticsearchResult',
    'GetServiceElasticsearchUserConfigIndexPatternResult',
    'GetServiceElasticsearchUserConfigIndexTemplateResult',
    'GetServiceElasticsearchUserConfigKibanaResult',
    'GetServiceElasticsearchUserConfigPrivateAccessResult',
    'GetServiceElasticsearchUserConfigPrivatelinkAccessResult',
    'GetServiceElasticsearchUserConfigPublicAccessResult',
    'GetServiceGrafanaResult',
    'GetServiceGrafanaUserConfigResult',
    'GetServiceGrafanaUserConfigAuthGenericOauthResult',
    'GetServiceGrafanaUserConfigAuthGithubResult',
    'GetServiceGrafanaUserConfigAuthGitlabResult',
    'GetServiceGrafanaUserConfigAuthGoogleResult',
    'GetServiceGrafanaUserConfigExternalImageStorageResult',
    'GetServiceGrafanaUserConfigPrivateAccessResult',
    'GetServiceGrafanaUserConfigPrivatelinkAccessResult',
    'GetServiceGrafanaUserConfigPublicAccessResult',
    'GetServiceGrafanaUserConfigSmtpServerResult',
    'GetServiceInfluxdbResult',
    'GetServiceInfluxdbUserConfigResult',
    'GetServiceInfluxdbUserConfigInfluxdbResult',
    'GetServiceInfluxdbUserConfigPrivateAccessResult',
    'GetServiceInfluxdbUserConfigPrivatelinkAccessResult',
    'GetServiceInfluxdbUserConfigPublicAccessResult',
    'GetServiceIntegrationDashboardUserConfigResult',
    'GetServiceIntegrationDatadogUserConfigResult',
    'GetServiceIntegrationDatadogUserConfigDatadogTagResult',
    'GetServiceIntegrationEndpointDatadogUserConfigResult',
    'GetServiceIntegrationEndpointDatadogUserConfigDatadogTagResult',
    'GetServiceIntegrationEndpointExternalAwsCloudwatchLogsUserConfigResult',
    'GetServiceIntegrationEndpointExternalAwsCloudwatchMetricsUserConfigResult',
    'GetServiceIntegrationEndpointExternalElasticsearchLogsUserConfigResult',
    'GetServiceIntegrationEndpointExternalGoogleCloudLoggingUserConfigResult',
    'GetServiceIntegrationEndpointExternalKafkaUserConfigResult',
    'GetServiceIntegrationEndpointExternalSchemaRegistryUserConfigResult',
    'GetServiceIntegrationEndpointJolokiaUserConfigResult',
    'GetServiceIntegrationEndpointPrometheusUserConfigResult',
    'GetServiceIntegrationEndpointRsyslogUserConfigResult',
    'GetServiceIntegrationEndpointSignalfxUserConfigResult',
    'GetServiceIntegrationExternalAwsCloudwatchLogsUserConfigResult',
    'GetServiceIntegrationExternalAwsCloudwatchMetricsUserConfigResult',
    'GetServiceIntegrationExternalAwsCloudwatchMetricsUserConfigDroppedMetricResult',
    'GetServiceIntegrationExternalAwsCloudwatchMetricsUserConfigExtraMetricResult',
    'GetServiceIntegrationExternalElasticsearchLogsUserConfigResult',
    'GetServiceIntegrationExternalGoogleCloudLoggingUserConfigResult',
    'GetServiceIntegrationKafkaConnectUserConfigResult',
    'GetServiceIntegrationKafkaConnectUserConfigKafkaConnectResult',
    'GetServiceIntegrationKafkaLogsUserConfigResult',
    'GetServiceIntegrationKafkaMirrormakerUserConfigResult',
    'GetServiceIntegrationLogsUserConfigResult',
    'GetServiceIntegrationM3aggregatorUserConfigResult',
    'GetServiceIntegrationM3coordinatorUserConfigResult',
    'GetServiceIntegrationMetricsUserConfigResult',
    'GetServiceIntegrationMetricsUserConfigSourceMysqlResult',
    'GetServiceIntegrationMetricsUserConfigSourceMysqlTelegrafResult',
    'GetServiceIntegrationMirrormakerUserConfigResult',
    'GetServiceIntegrationPrometheusUserConfigResult',
    'GetServiceIntegrationPrometheusUserConfigSourceMysqlResult',
    'GetServiceIntegrationPrometheusUserConfigSourceMysqlTelegrafResult',
    'GetServiceIntegrationReadReplicaUserConfigResult',
    'GetServiceIntegrationRsyslogUserConfigResult',
    'GetServiceIntegrationSchemaRegistryProxyUserConfigResult',
    'GetServiceIntegrationSignalfxUserConfigResult',
    'GetServiceKafkaResult',
    'GetServiceKafkaConnectResult',
    'GetServiceKafkaConnectUserConfigResult',
    'GetServiceKafkaConnectUserConfigKafkaConnectResult',
    'GetServiceKafkaConnectUserConfigPrivateAccessResult',
    'GetServiceKafkaConnectUserConfigPrivatelinkAccessResult',
    'GetServiceKafkaConnectUserConfigPublicAccessResult',
    'GetServiceKafkaMirrormakerResult',
    'GetServiceKafkaMirrormakerUserConfigResult',
    'GetServiceKafkaMirrormakerUserConfigKafkaMirrormakerResult',
    'GetServiceKafkaUserConfigResult',
    'GetServiceKafkaUserConfigKafkaResult',
    'GetServiceKafkaUserConfigKafkaAuthenticationMethodsResult',
    'GetServiceKafkaUserConfigKafkaConnectConfigResult',
    'GetServiceKafkaUserConfigKafkaRestConfigResult',
    'GetServiceKafkaUserConfigPrivateAccessResult',
    'GetServiceKafkaUserConfigPrivatelinkAccessResult',
    'GetServiceKafkaUserConfigPublicAccessResult',
    'GetServiceKafkaUserConfigSchemaRegistryConfigResult',
    'GetServiceMysqlResult',
    'GetServiceMysqlUserConfigResult',
    'GetServiceMysqlUserConfigMigrationResult',
    'GetServiceMysqlUserConfigMysqlResult',
    'GetServiceMysqlUserConfigPrivateAccessResult',
    'GetServiceMysqlUserConfigPrivatelinkAccessResult',
    'GetServiceMysqlUserConfigPublicAccessResult',
    'GetServicePgResult',
    'GetServicePgUserConfigResult',
    'GetServicePgUserConfigMigrationResult',
    'GetServicePgUserConfigPgResult',
    'GetServicePgUserConfigPgbouncerResult',
    'GetServicePgUserConfigPglookoutResult',
    'GetServicePgUserConfigPrivateAccessResult',
    'GetServicePgUserConfigPrivatelinkAccessResult',
    'GetServicePgUserConfigPublicAccessResult',
    'GetServicePgUserConfigTimescaledbResult',
    'GetServiceRedisResult',
    'GetServiceRedisUserConfigResult',
    'GetServiceRedisUserConfigMigrationResult',
    'GetServiceRedisUserConfigPrivateAccessResult',
    'GetServiceRedisUserConfigPrivatelinkAccessResult',
    'GetServiceRedisUserConfigPublicAccessResult',
    'GetServiceServiceIntegrationResult',
]

@pulumi.output_type
class CassandraCassandra(dict):
    def __init__(__self__):
        pass


@pulumi.output_type
class CassandraCassandraUserConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "ipFilters":
            suggest = "ip_filters"
        elif key == "migrateSstableloader":
            suggest = "migrate_sstableloader"
        elif key == "privateAccess":
            suggest = "private_access"
        elif key == "projectToForkFrom":
            suggest = "project_to_fork_from"
        elif key == "publicAccess":
            suggest = "public_access"
        elif key == "serviceToForkFrom":
            suggest = "service_to_fork_from"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in CassandraCassandraUserConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        CassandraCassandraUserConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        CassandraCassandraUserConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 cassandra: Optional['outputs.CassandraCassandraUserConfigCassandra'] = None,
                 ip_filters: Optional[Sequence[str]] = None,
                 migrate_sstableloader: Optional[str] = None,
                 private_access: Optional['outputs.CassandraCassandraUserConfigPrivateAccess'] = None,
                 project_to_fork_from: Optional[str] = None,
                 public_access: Optional['outputs.CassandraCassandraUserConfigPublicAccess'] = None,
                 service_to_fork_from: Optional[str] = None):
        """
        :param 'CassandraCassandraUserConfigCassandraArgs' cassandra: Cassandra configuration values
        :param Sequence[str] ip_filters: allow incoming connections from CIDR address block, e.g. `10.20.0.0/16`
        :param str migrate_sstableloader: sets the service into migration mode enabling the sstableloader 
               utility to be used to upload Cassandra data files. Available only on service create.
        :param 'CassandraCassandraUserConfigPrivateAccessArgs' private_access: Allow access to selected service ports from private networks.
        :param 'CassandraCassandraUserConfigPublicAccessArgs' public_access: Allow access to selected service ports from the public Internet
        :param str service_to_fork_from: Name of another service to fork from. This has effect only 
               when a new service is being created.
        """
        if cassandra is not None:
            pulumi.set(__self__, "cassandra", cassandra)
        if ip_filters is not None:
            pulumi.set(__self__, "ip_filters", ip_filters)
        if migrate_sstableloader is not None:
            pulumi.set(__self__, "migrate_sstableloader", migrate_sstableloader)
        if private_access is not None:
            pulumi.set(__self__, "private_access", private_access)
        if project_to_fork_from is not None:
            pulumi.set(__self__, "project_to_fork_from", project_to_fork_from)
        if public_access is not None:
            pulumi.set(__self__, "public_access", public_access)
        if service_to_fork_from is not None:
            pulumi.set(__self__, "service_to_fork_from", service_to_fork_from)

    @property
    @pulumi.getter
    def cassandra(self) -> Optional['outputs.CassandraCassandraUserConfigCassandra']:
        """
        Cassandra configuration values
        """
        return pulumi.get(self, "cassandra")

    @property
    @pulumi.getter(name="ipFilters")
    def ip_filters(self) -> Optional[Sequence[str]]:
        """
        allow incoming connections from CIDR address block, e.g. `10.20.0.0/16`
        """
        return pulumi.get(self, "ip_filters")

    @property
    @pulumi.getter(name="migrateSstableloader")
    def migrate_sstableloader(self) -> Optional[str]:
        """
        sets the service into migration mode enabling the sstableloader 
        utility to be used to upload Cassandra data files. Available only on service create.
        """
        return pulumi.get(self, "migrate_sstableloader")

    @property
    @pulumi.getter(name="privateAccess")
    def private_access(self) -> Optional['outputs.CassandraCassandraUserConfigPrivateAccess']:
        """
        Allow access to selected service ports from private networks.
        """
        return pulumi.get(self, "private_access")

    @property
    @pulumi.getter(name="projectToForkFrom")
    def project_to_fork_from(self) -> Optional[str]:
        return pulumi.get(self, "project_to_fork_from")

    @property
    @pulumi.getter(name="publicAccess")
    def public_access(self) -> Optional['outputs.CassandraCassandraUserConfigPublicAccess']:
        """
        Allow access to selected service ports from the public Internet
        """
        return pulumi.get(self, "public_access")

    @property
    @pulumi.getter(name="serviceToForkFrom")
    def service_to_fork_from(self) -> Optional[str]:
        """
        Name of another service to fork from. This has effect only 
        when a new service is being created.
        """
        return pulumi.get(self, "service_to_fork_from")


@pulumi.output_type
class CassandraCassandraUserConfigCassandra(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "batchSizeFailThresholdInKb":
            suggest = "batch_size_fail_threshold_in_kb"
        elif key == "batchSizeWarnThresholdInKb":
            suggest = "batch_size_warn_threshold_in_kb"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in CassandraCassandraUserConfigCassandra. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        CassandraCassandraUserConfigCassandra.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        CassandraCassandraUserConfigCassandra.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 batch_size_fail_threshold_in_kb: Optional[str] = None,
                 batch_size_warn_threshold_in_kb: Optional[str] = None):
        """
        :param str batch_size_fail_threshold_in_kb: Fail any multiple-partition batch exceeding this value. 
               50kb (10x warn threshold) by default.
        :param str batch_size_warn_threshold_in_kb: Log a warning message on any multiple-partition 
               batch size exceeding this value.5kb per batch by default.Caution should be taken on increasing
               the size of this thresholdas it can lead to node instability.
        """
        if batch_size_fail_threshold_in_kb is not None:
            pulumi.set(__self__, "batch_size_fail_threshold_in_kb", batch_size_fail_threshold_in_kb)
        if batch_size_warn_threshold_in_kb is not None:
            pulumi.set(__self__, "batch_size_warn_threshold_in_kb", batch_size_warn_threshold_in_kb)

    @property
    @pulumi.getter(name="batchSizeFailThresholdInKb")
    def batch_size_fail_threshold_in_kb(self) -> Optional[str]:
        """
        Fail any multiple-partition batch exceeding this value. 
        50kb (10x warn threshold) by default.
        """
        return pulumi.get(self, "batch_size_fail_threshold_in_kb")

    @property
    @pulumi.getter(name="batchSizeWarnThresholdInKb")
    def batch_size_warn_threshold_in_kb(self) -> Optional[str]:
        """
        Log a warning message on any multiple-partition 
        batch size exceeding this value.5kb per batch by default.Caution should be taken on increasing
        the size of this thresholdas it can lead to node instability.
        """
        return pulumi.get(self, "batch_size_warn_threshold_in_kb")


@pulumi.output_type
class CassandraCassandraUserConfigPrivateAccess(dict):
    def __init__(__self__, *,
                 prometheus: Optional[str] = None):
        """
        :param str prometheus: Allow clients to connect to prometheus from the public internet 
               for service nodes that are in a project VPC or another type of private network.
        """
        if prometheus is not None:
            pulumi.set(__self__, "prometheus", prometheus)

    @property
    @pulumi.getter
    def prometheus(self) -> Optional[str]:
        """
        Allow clients to connect to prometheus from the public internet 
        for service nodes that are in a project VPC or another type of private network.
        """
        return pulumi.get(self, "prometheus")


@pulumi.output_type
class CassandraCassandraUserConfigPublicAccess(dict):
    def __init__(__self__, *,
                 prometheus: Optional[str] = None):
        """
        :param str prometheus: Allow clients to connect to prometheus from the public internet 
               for service nodes that are in a project VPC or another type of private network.
        """
        if prometheus is not None:
            pulumi.set(__self__, "prometheus", prometheus)

    @property
    @pulumi.getter
    def prometheus(self) -> Optional[str]:
        """
        Allow clients to connect to prometheus from the public internet 
        for service nodes that are in a project VPC or another type of private network.
        """
        return pulumi.get(self, "prometheus")


@pulumi.output_type
class CassandraComponent(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "kafkaAuthenticationMethod":
            suggest = "kafka_authentication_method"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in CassandraComponent. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        CassandraComponent.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        CassandraComponent.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 component: Optional[str] = None,
                 host: Optional[str] = None,
                 kafka_authentication_method: Optional[str] = None,
                 port: Optional[int] = None,
                 route: Optional[str] = None,
                 ssl: Optional[bool] = None,
                 usage: Optional[str] = None):
        if component is not None:
            pulumi.set(__self__, "component", component)
        if host is not None:
            pulumi.set(__self__, "host", host)
        if kafka_authentication_method is not None:
            pulumi.set(__self__, "kafka_authentication_method", kafka_authentication_method)
        if port is not None:
            pulumi.set(__self__, "port", port)
        if route is not None:
            pulumi.set(__self__, "route", route)
        if ssl is not None:
            pulumi.set(__self__, "ssl", ssl)
        if usage is not None:
            pulumi.set(__self__, "usage", usage)

    @property
    @pulumi.getter
    def component(self) -> Optional[str]:
        return pulumi.get(self, "component")

    @property
    @pulumi.getter
    def host(self) -> Optional[str]:
        return pulumi.get(self, "host")

    @property
    @pulumi.getter(name="kafkaAuthenticationMethod")
    def kafka_authentication_method(self) -> Optional[str]:
        return pulumi.get(self, "kafka_authentication_method")

    @property
    @pulumi.getter
    def port(self) -> Optional[int]:
        return pulumi.get(self, "port")

    @property
    @pulumi.getter
    def route(self) -> Optional[str]:
        return pulumi.get(self, "route")

    @property
    @pulumi.getter
    def ssl(self) -> Optional[bool]:
        return pulumi.get(self, "ssl")

    @property
    @pulumi.getter
    def usage(self) -> Optional[str]:
        return pulumi.get(self, "usage")


@pulumi.output_type
class CassandraServiceIntegration(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "integrationType":
            suggest = "integration_type"
        elif key == "sourceServiceName":
            suggest = "source_service_name"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in CassandraServiceIntegration. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        CassandraServiceIntegration.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        CassandraServiceIntegration.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 integration_type: str,
                 source_service_name: str):
        pulumi.set(__self__, "integration_type", integration_type)
        pulumi.set(__self__, "source_service_name", source_service_name)

    @property
    @pulumi.getter(name="integrationType")
    def integration_type(self) -> str:
        return pulumi.get(self, "integration_type")

    @property
    @pulumi.getter(name="sourceServiceName")
    def source_service_name(self) -> str:
        return pulumi.get(self, "source_service_name")


@pulumi.output_type
class ElasticSearchAclAcl(dict):
    def __init__(__self__, *,
                 rules: Sequence['outputs.ElasticSearchAclAclRule'],
                 username: str):
        pulumi.set(__self__, "rules", rules)
        pulumi.set(__self__, "username", username)

    @property
    @pulumi.getter
    def rules(self) -> Sequence['outputs.ElasticSearchAclAclRule']:
        return pulumi.get(self, "rules")

    @property
    @pulumi.getter
    def username(self) -> str:
        return pulumi.get(self, "username")


@pulumi.output_type
class ElasticSearchAclAclRule(dict):
    def __init__(__self__, *,
                 index: str,
                 permission: str):
        pulumi.set(__self__, "index", index)
        pulumi.set(__self__, "permission", permission)

    @property
    @pulumi.getter
    def index(self) -> str:
        return pulumi.get(self, "index")

    @property
    @pulumi.getter
    def permission(self) -> str:
        return pulumi.get(self, "permission")


@pulumi.output_type
class ElasticSearchComponent(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "kafkaAuthenticationMethod":
            suggest = "kafka_authentication_method"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ElasticSearchComponent. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ElasticSearchComponent.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ElasticSearchComponent.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 component: Optional[str] = None,
                 host: Optional[str] = None,
                 kafka_authentication_method: Optional[str] = None,
                 port: Optional[int] = None,
                 route: Optional[str] = None,
                 ssl: Optional[bool] = None,
                 usage: Optional[str] = None):
        if component is not None:
            pulumi.set(__self__, "component", component)
        if host is not None:
            pulumi.set(__self__, "host", host)
        if kafka_authentication_method is not None:
            pulumi.set(__self__, "kafka_authentication_method", kafka_authentication_method)
        if port is not None:
            pulumi.set(__self__, "port", port)
        if route is not None:
            pulumi.set(__self__, "route", route)
        if ssl is not None:
            pulumi.set(__self__, "ssl", ssl)
        if usage is not None:
            pulumi.set(__self__, "usage", usage)

    @property
    @pulumi.getter
    def component(self) -> Optional[str]:
        return pulumi.get(self, "component")

    @property
    @pulumi.getter
    def host(self) -> Optional[str]:
        return pulumi.get(self, "host")

    @property
    @pulumi.getter(name="kafkaAuthenticationMethod")
    def kafka_authentication_method(self) -> Optional[str]:
        return pulumi.get(self, "kafka_authentication_method")

    @property
    @pulumi.getter
    def port(self) -> Optional[int]:
        return pulumi.get(self, "port")

    @property
    @pulumi.getter
    def route(self) -> Optional[str]:
        return pulumi.get(self, "route")

    @property
    @pulumi.getter
    def ssl(self) -> Optional[bool]:
        return pulumi.get(self, "ssl")

    @property
    @pulumi.getter
    def usage(self) -> Optional[str]:
        return pulumi.get(self, "usage")


@pulumi.output_type
class ElasticSearchElasticsearch(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "kibanaUri":
            suggest = "kibana_uri"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ElasticSearchElasticsearch. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ElasticSearchElasticsearch.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ElasticSearchElasticsearch.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 kibana_uri: Optional[str] = None):
        """
        :param str kibana_uri: URI for Kibana frontend.
        """
        if kibana_uri is not None:
            pulumi.set(__self__, "kibana_uri", kibana_uri)

    @property
    @pulumi.getter(name="kibanaUri")
    def kibana_uri(self) -> Optional[str]:
        """
        URI for Kibana frontend.
        """
        return pulumi.get(self, "kibana_uri")


@pulumi.output_type
class ElasticSearchElasticsearchUserConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "customDomain":
            suggest = "custom_domain"
        elif key == "disableReplicationFactorAdjustment":
            suggest = "disable_replication_factor_adjustment"
        elif key == "elasticsearchVersion":
            suggest = "elasticsearch_version"
        elif key == "indexPatterns":
            suggest = "index_patterns"
        elif key == "indexTemplate":
            suggest = "index_template"
        elif key == "ipFilters":
            suggest = "ip_filters"
        elif key == "maxIndexCount":
            suggest = "max_index_count"
        elif key == "privateAccess":
            suggest = "private_access"
        elif key == "privatelinkAccess":
            suggest = "privatelink_access"
        elif key == "projectToForkFrom":
            suggest = "project_to_fork_from"
        elif key == "publicAccess":
            suggest = "public_access"
        elif key == "recoveryBasebackupName":
            suggest = "recovery_basebackup_name"
        elif key == "serviceToForkFrom":
            suggest = "service_to_fork_from"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ElasticSearchElasticsearchUserConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ElasticSearchElasticsearchUserConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ElasticSearchElasticsearchUserConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 custom_domain: Optional[str] = None,
                 disable_replication_factor_adjustment: Optional[str] = None,
                 elasticsearch: Optional['outputs.ElasticSearchElasticsearchUserConfigElasticsearch'] = None,
                 elasticsearch_version: Optional[str] = None,
                 index_patterns: Optional[Sequence['outputs.ElasticSearchElasticsearchUserConfigIndexPattern']] = None,
                 index_template: Optional['outputs.ElasticSearchElasticsearchUserConfigIndexTemplate'] = None,
                 ip_filters: Optional[Sequence[str]] = None,
                 kibana: Optional['outputs.ElasticSearchElasticsearchUserConfigKibana'] = None,
                 max_index_count: Optional[str] = None,
                 private_access: Optional['outputs.ElasticSearchElasticsearchUserConfigPrivateAccess'] = None,
                 privatelink_access: Optional['outputs.ElasticSearchElasticsearchUserConfigPrivatelinkAccess'] = None,
                 project_to_fork_from: Optional[str] = None,
                 public_access: Optional['outputs.ElasticSearchElasticsearchUserConfigPublicAccess'] = None,
                 recovery_basebackup_name: Optional[str] = None,
                 service_to_fork_from: Optional[str] = None):
        """
        :param str custom_domain: Serve the web frontend using a custom CNAME pointing to the 
               Aiven DNS name.
        :param str disable_replication_factor_adjustment: Disable automatic replication factor 
               adjustment for multi-node services. By default, Aiven ensures all indexes are replicated at
               least to two nodes. Note: setting this to true increases a risk of data loss in case of
               virtual machine failure.
        :param 'ElasticSearchElasticsearchUserConfigElasticsearchArgs' elasticsearch: Allow clients to connect to elasticsearch from the public 
               internet for service nodes that are in a project VPC or another type of private network.
        :param str elasticsearch_version: Elasticsearch major version.
        :param Sequence['ElasticSearchElasticsearchUserConfigIndexPatternArgs'] index_patterns: Glob pattern and number of indexes matching that pattern to 
               be kept.
        :param 'ElasticSearchElasticsearchUserConfigIndexTemplateArgs' index_template: Template settings for all new indexe.
        :param Sequence[str] ip_filters: allow incoming connections from CIDR address block, e.g. `10.20.0.0/16`
        :param 'ElasticSearchElasticsearchUserConfigKibanaArgs' kibana: Allow clients to connect to kibana from the public internet for 
               service nodes that are in a project VPC or another type of private network.
        :param str max_index_count: Maximum number of indexes to keep before deleting the oldest one.
        :param 'ElasticSearchElasticsearchUserConfigPrivateAccessArgs' private_access: Allow access to selected service ports from private networks.
        :param 'ElasticSearchElasticsearchUserConfigPrivatelinkAccessArgs' privatelink_access: Allow access to selected service components through Privatelink
        :param str project_to_fork_from: Name of another project to fork a service from. This has 
               effect only when a new service is being created.
        :param 'ElasticSearchElasticsearchUserConfigPublicAccessArgs' public_access: Allow access to selected service ports from the public Internet.
        :param str recovery_basebackup_name: Name of the basebackup to restore in forked service.
        :param str service_to_fork_from: Name of another service to fork from. This has effect 
               only when a new service is being created.
        """
        if custom_domain is not None:
            pulumi.set(__self__, "custom_domain", custom_domain)
        if disable_replication_factor_adjustment is not None:
            pulumi.set(__self__, "disable_replication_factor_adjustment", disable_replication_factor_adjustment)
        if elasticsearch is not None:
            pulumi.set(__self__, "elasticsearch", elasticsearch)
        if elasticsearch_version is not None:
            pulumi.set(__self__, "elasticsearch_version", elasticsearch_version)
        if index_patterns is not None:
            pulumi.set(__self__, "index_patterns", index_patterns)
        if index_template is not None:
            pulumi.set(__self__, "index_template", index_template)
        if ip_filters is not None:
            pulumi.set(__self__, "ip_filters", ip_filters)
        if kibana is not None:
            pulumi.set(__self__, "kibana", kibana)
        if max_index_count is not None:
            pulumi.set(__self__, "max_index_count", max_index_count)
        if private_access is not None:
            pulumi.set(__self__, "private_access", private_access)
        if privatelink_access is not None:
            pulumi.set(__self__, "privatelink_access", privatelink_access)
        if project_to_fork_from is not None:
            pulumi.set(__self__, "project_to_fork_from", project_to_fork_from)
        if public_access is not None:
            pulumi.set(__self__, "public_access", public_access)
        if recovery_basebackup_name is not None:
            pulumi.set(__self__, "recovery_basebackup_name", recovery_basebackup_name)
        if service_to_fork_from is not None:
            pulumi.set(__self__, "service_to_fork_from", service_to_fork_from)

    @property
    @pulumi.getter(name="customDomain")
    def custom_domain(self) -> Optional[str]:
        """
        Serve the web frontend using a custom CNAME pointing to the 
        Aiven DNS name.
        """
        return pulumi.get(self, "custom_domain")

    @property
    @pulumi.getter(name="disableReplicationFactorAdjustment")
    def disable_replication_factor_adjustment(self) -> Optional[str]:
        """
        Disable automatic replication factor 
        adjustment for multi-node services. By default, Aiven ensures all indexes are replicated at
        least to two nodes. Note: setting this to true increases a risk of data loss in case of
        virtual machine failure.
        """
        return pulumi.get(self, "disable_replication_factor_adjustment")

    @property
    @pulumi.getter
    def elasticsearch(self) -> Optional['outputs.ElasticSearchElasticsearchUserConfigElasticsearch']:
        """
        Allow clients to connect to elasticsearch from the public 
        internet for service nodes that are in a project VPC or another type of private network.
        """
        return pulumi.get(self, "elasticsearch")

    @property
    @pulumi.getter(name="elasticsearchVersion")
    def elasticsearch_version(self) -> Optional[str]:
        """
        Elasticsearch major version.
        """
        return pulumi.get(self, "elasticsearch_version")

    @property
    @pulumi.getter(name="indexPatterns")
    def index_patterns(self) -> Optional[Sequence['outputs.ElasticSearchElasticsearchUserConfigIndexPattern']]:
        """
        Glob pattern and number of indexes matching that pattern to 
        be kept.
        """
        return pulumi.get(self, "index_patterns")

    @property
    @pulumi.getter(name="indexTemplate")
    def index_template(self) -> Optional['outputs.ElasticSearchElasticsearchUserConfigIndexTemplate']:
        """
        Template settings for all new indexe.
        """
        return pulumi.get(self, "index_template")

    @property
    @pulumi.getter(name="ipFilters")
    def ip_filters(self) -> Optional[Sequence[str]]:
        """
        allow incoming connections from CIDR address block, e.g. `10.20.0.0/16`
        """
        return pulumi.get(self, "ip_filters")

    @property
    @pulumi.getter
    def kibana(self) -> Optional['outputs.ElasticSearchElasticsearchUserConfigKibana']:
        """
        Allow clients to connect to kibana from the public internet for 
        service nodes that are in a project VPC or another type of private network.
        """
        return pulumi.get(self, "kibana")

    @property
    @pulumi.getter(name="maxIndexCount")
    def max_index_count(self) -> Optional[str]:
        """
        Maximum number of indexes to keep before deleting the oldest one.
        """
        return pulumi.get(self, "max_index_count")

    @property
    @pulumi.getter(name="privateAccess")
    def private_access(self) -> Optional['outputs.ElasticSearchElasticsearchUserConfigPrivateAccess']:
        """
        Allow access to selected service ports from private networks.
        """
        return pulumi.get(self, "private_access")

    @property
    @pulumi.getter(name="privatelinkAccess")
    def privatelink_access(self) -> Optional['outputs.ElasticSearchElasticsearchUserConfigPrivatelinkAccess']:
        """
        Allow access to selected service components through Privatelink
        """
        return pulumi.get(self, "privatelink_access")

    @property
    @pulumi.getter(name="projectToForkFrom")
    def project_to_fork_from(self) -> Optional[str]:
        """
        Name of another project to fork a service from. This has 
        effect only when a new service is being created.
        """
        return pulumi.get(self, "project_to_fork_from")

    @property
    @pulumi.getter(name="publicAccess")
    def public_access(self) -> Optional['outputs.ElasticSearchElasticsearchUserConfigPublicAccess']:
        """
        Allow access to selected service ports from the public Internet.
        """
        return pulumi.get(self, "public_access")

    @property
    @pulumi.getter(name="recoveryBasebackupName")
    def recovery_basebackup_name(self) -> Optional[str]:
        """
        Name of the basebackup to restore in forked service.
        """
        return pulumi.get(self, "recovery_basebackup_name")

    @property
    @pulumi.getter(name="serviceToForkFrom")
    def service_to_fork_from(self) -> Optional[str]:
        """
        Name of another service to fork from. This has effect 
        only when a new service is being created.
        """
        return pulumi.get(self, "service_to_fork_from")


@pulumi.output_type
class ElasticSearchElasticsearchUserConfigElasticsearch(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "actionAutoCreateIndexEnabled":
            suggest = "action_auto_create_index_enabled"
        elif key == "actionDestructiveRequiresName":
            suggest = "action_destructive_requires_name"
        elif key == "clusterMaxShardsPerNode":
            suggest = "cluster_max_shards_per_node"
        elif key == "httpMaxContentLength":
            suggest = "http_max_content_length"
        elif key == "httpMaxHeaderSize":
            suggest = "http_max_header_size"
        elif key == "httpMaxInitialLineLength":
            suggest = "http_max_initial_line_length"
        elif key == "indicesFielddataCacheSize":
            suggest = "indices_fielddata_cache_size"
        elif key == "indicesMemoryIndexBufferSize":
            suggest = "indices_memory_index_buffer_size"
        elif key == "indicesQueriesCacheSize":
            suggest = "indices_queries_cache_size"
        elif key == "indicesQueryBoolMaxClauseCount":
            suggest = "indices_query_bool_max_clause_count"
        elif key == "reindexRemoteWhitelists":
            suggest = "reindex_remote_whitelists"
        elif key == "searchMaxBuckets":
            suggest = "search_max_buckets"
        elif key == "threadPoolAnalyzeQueueSize":
            suggest = "thread_pool_analyze_queue_size"
        elif key == "threadPoolAnalyzeSize":
            suggest = "thread_pool_analyze_size"
        elif key == "threadPoolForceMergeSize":
            suggest = "thread_pool_force_merge_size"
        elif key == "threadPoolGetQueueSize":
            suggest = "thread_pool_get_queue_size"
        elif key == "threadPoolGetSize":
            suggest = "thread_pool_get_size"
        elif key == "threadPoolIndexQueueSize":
            suggest = "thread_pool_index_queue_size"
        elif key == "threadPoolIndexSize":
            suggest = "thread_pool_index_size"
        elif key == "threadPoolSearchQueueSize":
            suggest = "thread_pool_search_queue_size"
        elif key == "threadPoolSearchSize":
            suggest = "thread_pool_search_size"
        elif key == "threadPoolSearchThrottledQueueSize":
            suggest = "thread_pool_search_throttled_queue_size"
        elif key == "threadPoolSearchThrottledSize":
            suggest = "thread_pool_search_throttled_size"
        elif key == "threadPoolWriteQueueSize":
            suggest = "thread_pool_write_queue_size"
        elif key == "threadPoolWriteSize":
            suggest = "thread_pool_write_size"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ElasticSearchElasticsearchUserConfigElasticsearch. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ElasticSearchElasticsearchUserConfigElasticsearch.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ElasticSearchElasticsearchUserConfigElasticsearch.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 action_auto_create_index_enabled: Optional[str] = None,
                 action_destructive_requires_name: Optional[str] = None,
                 cluster_max_shards_per_node: Optional[str] = None,
                 http_max_content_length: Optional[str] = None,
                 http_max_header_size: Optional[str] = None,
                 http_max_initial_line_length: Optional[str] = None,
                 indices_fielddata_cache_size: Optional[str] = None,
                 indices_memory_index_buffer_size: Optional[str] = None,
                 indices_queries_cache_size: Optional[str] = None,
                 indices_query_bool_max_clause_count: Optional[str] = None,
                 reindex_remote_whitelists: Optional[Sequence[str]] = None,
                 search_max_buckets: Optional[str] = None,
                 thread_pool_analyze_queue_size: Optional[str] = None,
                 thread_pool_analyze_size: Optional[str] = None,
                 thread_pool_force_merge_size: Optional[str] = None,
                 thread_pool_get_queue_size: Optional[str] = None,
                 thread_pool_get_size: Optional[str] = None,
                 thread_pool_index_queue_size: Optional[str] = None,
                 thread_pool_index_size: Optional[str] = None,
                 thread_pool_search_queue_size: Optional[str] = None,
                 thread_pool_search_size: Optional[str] = None,
                 thread_pool_search_throttled_queue_size: Optional[str] = None,
                 thread_pool_search_throttled_size: Optional[str] = None,
                 thread_pool_write_queue_size: Optional[str] = None,
                 thread_pool_write_size: Optional[str] = None):
        """
        :param str action_auto_create_index_enabled: Explicitly allow or block automatic 
               creation of indices. Defaults to true
        :param str action_destructive_requires_name: Require explicit index names when deleting
        :param str cluster_max_shards_per_node: Controls the number of shards allowed in the
               cluster per data node.
        :param str http_max_content_length: Maximum content length for HTTP requests to 
               the Elasticsearch HTTP API, in bytes.
        :param str http_max_header_size: The max size of allowed headers, in bytes.
        :param str http_max_initial_line_length: The max length of an HTTP URL, in bytes.
        :param str indices_fielddata_cache_size: Relative amount. Maximum amount of 
               heap memory used for field data cache. This is an expert setting; decreasing the
               value too much will increase overhead of loading field data; too much memory used
               for field data cache will decrease amount of heap available for other operations.
        :param str indices_memory_index_buffer_size: Percentage value. Default is 10%. 
               Total amount of heap used for indexing buffer, before writing segments to disk.
               This is an expert setting. Too low value will slow down indexing; too high value
               will increase indexing performance but causes performance issues for query performance.
        :param str indices_queries_cache_size: Percentage value. Default is 10%. 
               Maximum amount of heap used for query cache. This is an expert setting.
               Too low value will decrease query performance and increase performance for other
               operations; too high value will cause issues with other Elasticsearch functionality.
        :param str indices_query_bool_max_clause_count: Maximum number of clauses Lucene 
               BooleanQuery can have. The default value (1024) is relatively high, and increasing it
               may cause performance issues. Investigate other approaches first before increasing this value.
        :param Sequence[str] reindex_remote_whitelists: Whitelisted addresses for reindexing. 
               Changing this value will cause all Elasticsearch instances to restart.
        :param str search_max_buckets: Maximum number of aggregation buckets allowed 
               in a single response. Elasticsearch default value is used when this is not defined.
        :param str thread_pool_analyze_queue_size: Size for the thread pool queue. 
               See documentation for exact details.
        :param str thread_pool_analyze_size: Size for the thread pool. See documentation 
               for exact details. Do note this may have maximum value depending on CPU count -
               value is automatically lowered if set to higher than maximum value.
        :param str thread_pool_force_merge_size: Size for the thread pool. See 
               documentation for exact details. Do note this may have maximum value depending on
               CPU count - value is automatically lowered if set to higher than maximum value.
        :param str thread_pool_get_queue_size: Size for the thread pool queue. See 
               documentation for exact details.
        :param str thread_pool_get_size: Size for the thread pool. See documentation 
               for exact details. Do note this may have maximum value depending on CPU count -
               value is automatically lowered if set to higher than maximum value.
        :param str thread_pool_index_queue_size: Size for the thread pool queue. 
               See documentation for exact details.
        :param str thread_pool_index_size: Size for the thread pool. See documentation 
               for exact details. Do note this may have maximum value depending on CPU count -
               value is automatically lowered if set to higher than maximum value.
        :param str thread_pool_search_queue_size: Size for the thread pool queue. See 
               documentation for exact details.
        :param str thread_pool_search_size: Size for the thread pool. See documentation 
               for exact details. Do note this may have maximum value depending on CPU count - value
               is automatically lowered if set to higher than maximum value.
        :param str thread_pool_search_throttled_queue_size: Size for the thread pool queue. 
               See documentation for exact details.
        :param str thread_pool_search_throttled_size: Size for the thread pool. See 
               documentation for exact details. Do note this may have maximum value depending on
               CPU count - value is automatically lowered if set to higher than maximum value.
        :param str thread_pool_write_queue_size: Size for the thread pool queue. See 
               documentation for exact details.
        :param str thread_pool_write_size: Size for the thread pool. See documentation 
               for exact details. Do note this may have maximum value depending on CPU count - value
               is automatically lowered if set to higher than maximum value.
        """
        if action_auto_create_index_enabled is not None:
            pulumi.set(__self__, "action_auto_create_index_enabled", action_auto_create_index_enabled)
        if action_destructive_requires_name is not None:
            pulumi.set(__self__, "action_destructive_requires_name", action_destructive_requires_name)
        if cluster_max_shards_per_node is not None:
            pulumi.set(__self__, "cluster_max_shards_per_node", cluster_max_shards_per_node)
        if http_max_content_length is not None:
            pulumi.set(__self__, "http_max_content_length", http_max_content_length)
        if http_max_header_size is not None:
            pulumi.set(__self__, "http_max_header_size", http_max_header_size)
        if http_max_initial_line_length is not None:
            pulumi.set(__self__, "http_max_initial_line_length", http_max_initial_line_length)
        if indices_fielddata_cache_size is not None:
            pulumi.set(__self__, "indices_fielddata_cache_size", indices_fielddata_cache_size)
        if indices_memory_index_buffer_size is not None:
            pulumi.set(__self__, "indices_memory_index_buffer_size", indices_memory_index_buffer_size)
        if indices_queries_cache_size is not None:
            pulumi.set(__self__, "indices_queries_cache_size", indices_queries_cache_size)
        if indices_query_bool_max_clause_count is not None:
            pulumi.set(__self__, "indices_query_bool_max_clause_count", indices_query_bool_max_clause_count)
        if reindex_remote_whitelists is not None:
            pulumi.set(__self__, "reindex_remote_whitelists", reindex_remote_whitelists)
        if search_max_buckets is not None:
            pulumi.set(__self__, "search_max_buckets", search_max_buckets)
        if thread_pool_analyze_queue_size is not None:
            pulumi.set(__self__, "thread_pool_analyze_queue_size", thread_pool_analyze_queue_size)
        if thread_pool_analyze_size is not None:
            pulumi.set(__self__, "thread_pool_analyze_size", thread_pool_analyze_size)
        if thread_pool_force_merge_size is not None:
            pulumi.set(__self__, "thread_pool_force_merge_size", thread_pool_force_merge_size)
        if thread_pool_get_queue_size is not None:
            pulumi.set(__self__, "thread_pool_get_queue_size", thread_pool_get_queue_size)
        if thread_pool_get_size is not None:
            pulumi.set(__self__, "thread_pool_get_size", thread_pool_get_size)
        if thread_pool_index_queue_size is not None:
            pulumi.set(__self__, "thread_pool_index_queue_size", thread_pool_index_queue_size)
        if thread_pool_index_size is not None:
            pulumi.set(__self__, "thread_pool_index_size", thread_pool_index_size)
        if thread_pool_search_queue_size is not None:
            pulumi.set(__self__, "thread_pool_search_queue_size", thread_pool_search_queue_size)
        if thread_pool_search_size is not None:
            pulumi.set(__self__, "thread_pool_search_size", thread_pool_search_size)
        if thread_pool_search_throttled_queue_size is not None:
            pulumi.set(__self__, "thread_pool_search_throttled_queue_size", thread_pool_search_throttled_queue_size)
        if thread_pool_search_throttled_size is not None:
            pulumi.set(__self__, "thread_pool_search_throttled_size", thread_pool_search_throttled_size)
        if thread_pool_write_queue_size is not None:
            pulumi.set(__self__, "thread_pool_write_queue_size", thread_pool_write_queue_size)
        if thread_pool_write_size is not None:
            pulumi.set(__self__, "thread_pool_write_size", thread_pool_write_size)

    @property
    @pulumi.getter(name="actionAutoCreateIndexEnabled")
    def action_auto_create_index_enabled(self) -> Optional[str]:
        """
        Explicitly allow or block automatic 
        creation of indices. Defaults to true
        """
        return pulumi.get(self, "action_auto_create_index_enabled")

    @property
    @pulumi.getter(name="actionDestructiveRequiresName")
    def action_destructive_requires_name(self) -> Optional[str]:
        """
        Require explicit index names when deleting
        """
        return pulumi.get(self, "action_destructive_requires_name")

    @property
    @pulumi.getter(name="clusterMaxShardsPerNode")
    def cluster_max_shards_per_node(self) -> Optional[str]:
        """
        Controls the number of shards allowed in the
        cluster per data node.
        """
        return pulumi.get(self, "cluster_max_shards_per_node")

    @property
    @pulumi.getter(name="httpMaxContentLength")
    def http_max_content_length(self) -> Optional[str]:
        """
        Maximum content length for HTTP requests to 
        the Elasticsearch HTTP API, in bytes.
        """
        return pulumi.get(self, "http_max_content_length")

    @property
    @pulumi.getter(name="httpMaxHeaderSize")
    def http_max_header_size(self) -> Optional[str]:
        """
        The max size of allowed headers, in bytes.
        """
        return pulumi.get(self, "http_max_header_size")

    @property
    @pulumi.getter(name="httpMaxInitialLineLength")
    def http_max_initial_line_length(self) -> Optional[str]:
        """
        The max length of an HTTP URL, in bytes.
        """
        return pulumi.get(self, "http_max_initial_line_length")

    @property
    @pulumi.getter(name="indicesFielddataCacheSize")
    def indices_fielddata_cache_size(self) -> Optional[str]:
        """
        Relative amount. Maximum amount of 
        heap memory used for field data cache. This is an expert setting; decreasing the
        value too much will increase overhead of loading field data; too much memory used
        for field data cache will decrease amount of heap available for other operations.
        """
        return pulumi.get(self, "indices_fielddata_cache_size")

    @property
    @pulumi.getter(name="indicesMemoryIndexBufferSize")
    def indices_memory_index_buffer_size(self) -> Optional[str]:
        """
        Percentage value. Default is 10%. 
        Total amount of heap used for indexing buffer, before writing segments to disk.
        This is an expert setting. Too low value will slow down indexing; too high value
        will increase indexing performance but causes performance issues for query performance.
        """
        return pulumi.get(self, "indices_memory_index_buffer_size")

    @property
    @pulumi.getter(name="indicesQueriesCacheSize")
    def indices_queries_cache_size(self) -> Optional[str]:
        """
        Percentage value. Default is 10%. 
        Maximum amount of heap used for query cache. This is an expert setting.
        Too low value will decrease query performance and increase performance for other
        operations; too high value will cause issues with other Elasticsearch functionality.
        """
        return pulumi.get(self, "indices_queries_cache_size")

    @property
    @pulumi.getter(name="indicesQueryBoolMaxClauseCount")
    def indices_query_bool_max_clause_count(self) -> Optional[str]:
        """
        Maximum number of clauses Lucene 
        BooleanQuery can have. The default value (1024) is relatively high, and increasing it
        may cause performance issues. Investigate other approaches first before increasing this value.
        """
        return pulumi.get(self, "indices_query_bool_max_clause_count")

    @property
    @pulumi.getter(name="reindexRemoteWhitelists")
    def reindex_remote_whitelists(self) -> Optional[Sequence[str]]:
        """
        Whitelisted addresses for reindexing. 
        Changing this value will cause all Elasticsearch instances to restart.
        """
        return pulumi.get(self, "reindex_remote_whitelists")

    @property
    @pulumi.getter(name="searchMaxBuckets")
    def search_max_buckets(self) -> Optional[str]:
        """
        Maximum number of aggregation buckets allowed 
        in a single response. Elasticsearch default value is used when this is not defined.
        """
        return pulumi.get(self, "search_max_buckets")

    @property
    @pulumi.getter(name="threadPoolAnalyzeQueueSize")
    def thread_pool_analyze_queue_size(self) -> Optional[str]:
        """
        Size for the thread pool queue. 
        See documentation for exact details.
        """
        return pulumi.get(self, "thread_pool_analyze_queue_size")

    @property
    @pulumi.getter(name="threadPoolAnalyzeSize")
    def thread_pool_analyze_size(self) -> Optional[str]:
        """
        Size for the thread pool. See documentation 
        for exact details. Do note this may have maximum value depending on CPU count -
        value is automatically lowered if set to higher than maximum value.
        """
        return pulumi.get(self, "thread_pool_analyze_size")

    @property
    @pulumi.getter(name="threadPoolForceMergeSize")
    def thread_pool_force_merge_size(self) -> Optional[str]:
        """
        Size for the thread pool. See 
        documentation for exact details. Do note this may have maximum value depending on
        CPU count - value is automatically lowered if set to higher than maximum value.
        """
        return pulumi.get(self, "thread_pool_force_merge_size")

    @property
    @pulumi.getter(name="threadPoolGetQueueSize")
    def thread_pool_get_queue_size(self) -> Optional[str]:
        """
        Size for the thread pool queue. See 
        documentation for exact details.
        """
        return pulumi.get(self, "thread_pool_get_queue_size")

    @property
    @pulumi.getter(name="threadPoolGetSize")
    def thread_pool_get_size(self) -> Optional[str]:
        """
        Size for the thread pool. See documentation 
        for exact details. Do note this may have maximum value depending on CPU count -
        value is automatically lowered if set to higher than maximum value.
        """
        return pulumi.get(self, "thread_pool_get_size")

    @property
    @pulumi.getter(name="threadPoolIndexQueueSize")
    def thread_pool_index_queue_size(self) -> Optional[str]:
        """
        Size for the thread pool queue. 
        See documentation for exact details.
        """
        return pulumi.get(self, "thread_pool_index_queue_size")

    @property
    @pulumi.getter(name="threadPoolIndexSize")
    def thread_pool_index_size(self) -> Optional[str]:
        """
        Size for the thread pool. See documentation 
        for exact details. Do note this may have maximum value depending on CPU count -
        value is automatically lowered if set to higher than maximum value.
        """
        return pulumi.get(self, "thread_pool_index_size")

    @property
    @pulumi.getter(name="threadPoolSearchQueueSize")
    def thread_pool_search_queue_size(self) -> Optional[str]:
        """
        Size for the thread pool queue. See 
        documentation for exact details.
        """
        return pulumi.get(self, "thread_pool_search_queue_size")

    @property
    @pulumi.getter(name="threadPoolSearchSize")
    def thread_pool_search_size(self) -> Optional[str]:
        """
        Size for the thread pool. See documentation 
        for exact details. Do note this may have maximum value depending on CPU count - value
        is automatically lowered if set to higher than maximum value.
        """
        return pulumi.get(self, "thread_pool_search_size")

    @property
    @pulumi.getter(name="threadPoolSearchThrottledQueueSize")
    def thread_pool_search_throttled_queue_size(self) -> Optional[str]:
        """
        Size for the thread pool queue. 
        See documentation for exact details.
        """
        return pulumi.get(self, "thread_pool_search_throttled_queue_size")

    @property
    @pulumi.getter(name="threadPoolSearchThrottledSize")
    def thread_pool_search_throttled_size(self) -> Optional[str]:
        """
        Size for the thread pool. See 
        documentation for exact details. Do note this may have maximum value depending on
        CPU count - value is automatically lowered if set to higher than maximum value.
        """
        return pulumi.get(self, "thread_pool_search_throttled_size")

    @property
    @pulumi.getter(name="threadPoolWriteQueueSize")
    def thread_pool_write_queue_size(self) -> Optional[str]:
        """
        Size for the thread pool queue. See 
        documentation for exact details.
        """
        return pulumi.get(self, "thread_pool_write_queue_size")

    @property
    @pulumi.getter(name="threadPoolWriteSize")
    def thread_pool_write_size(self) -> Optional[str]:
        """
        Size for the thread pool. See documentation 
        for exact details. Do note this may have maximum value depending on CPU count - value
        is automatically lowered if set to higher than maximum value.
        """
        return pulumi.get(self, "thread_pool_write_size")


@pulumi.output_type
class ElasticSearchElasticsearchUserConfigIndexPattern(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "maxIndexCount":
            suggest = "max_index_count"
        elif key == "sortingAlgorithm":
            suggest = "sorting_algorithm"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ElasticSearchElasticsearchUserConfigIndexPattern. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ElasticSearchElasticsearchUserConfigIndexPattern.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ElasticSearchElasticsearchUserConfigIndexPattern.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 max_index_count: Optional[str] = None,
                 pattern: Optional[str] = None,
                 sorting_algorithm: Optional[str] = None):
        """
        :param str max_index_count: Maximum number of indexes to keep before deleting the oldest one.
        :param str pattern: Must consist of alpha-numeric characters, dashes, underscores, 
               dots and glob characters (* and ?)
        :param str sorting_algorithm: Deletion sorting algorithm
        """
        if max_index_count is not None:
            pulumi.set(__self__, "max_index_count", max_index_count)
        if pattern is not None:
            pulumi.set(__self__, "pattern", pattern)
        if sorting_algorithm is not None:
            pulumi.set(__self__, "sorting_algorithm", sorting_algorithm)

    @property
    @pulumi.getter(name="maxIndexCount")
    def max_index_count(self) -> Optional[str]:
        """
        Maximum number of indexes to keep before deleting the oldest one.
        """
        return pulumi.get(self, "max_index_count")

    @property
    @pulumi.getter
    def pattern(self) -> Optional[str]:
        """
        Must consist of alpha-numeric characters, dashes, underscores, 
        dots and glob characters (* and ?)
        """
        return pulumi.get(self, "pattern")

    @property
    @pulumi.getter(name="sortingAlgorithm")
    def sorting_algorithm(self) -> Optional[str]:
        """
        Deletion sorting algorithm
        """
        return pulumi.get(self, "sorting_algorithm")


@pulumi.output_type
class ElasticSearchElasticsearchUserConfigIndexTemplate(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "mappingNestedObjectsLimit":
            suggest = "mapping_nested_objects_limit"
        elif key == "numberOfReplicas":
            suggest = "number_of_replicas"
        elif key == "numberOfShards":
            suggest = "number_of_shards"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ElasticSearchElasticsearchUserConfigIndexTemplate. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ElasticSearchElasticsearchUserConfigIndexTemplate.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ElasticSearchElasticsearchUserConfigIndexTemplate.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 mapping_nested_objects_limit: Optional[str] = None,
                 number_of_replicas: Optional[str] = None,
                 number_of_shards: Optional[str] = None):
        """
        :param str mapping_nested_objects_limit: The maximum number of nested JSON objects that 
               a single document can contain across all nested types. This limit helps to prevent out of
               memory errors when a document contains too many nested objects. Default is 10000.
        :param str number_of_replicas: The number of replicas each primary shard has.
        :param str number_of_shards: The number of primary shards that an index should have.
        """
        if mapping_nested_objects_limit is not None:
            pulumi.set(__self__, "mapping_nested_objects_limit", mapping_nested_objects_limit)
        if number_of_replicas is not None:
            pulumi.set(__self__, "number_of_replicas", number_of_replicas)
        if number_of_shards is not None:
            pulumi.set(__self__, "number_of_shards", number_of_shards)

    @property
    @pulumi.getter(name="mappingNestedObjectsLimit")
    def mapping_nested_objects_limit(self) -> Optional[str]:
        """
        The maximum number of nested JSON objects that 
        a single document can contain across all nested types. This limit helps to prevent out of
        memory errors when a document contains too many nested objects. Default is 10000.
        """
        return pulumi.get(self, "mapping_nested_objects_limit")

    @property
    @pulumi.getter(name="numberOfReplicas")
    def number_of_replicas(self) -> Optional[str]:
        """
        The number of replicas each primary shard has.
        """
        return pulumi.get(self, "number_of_replicas")

    @property
    @pulumi.getter(name="numberOfShards")
    def number_of_shards(self) -> Optional[str]:
        """
        The number of primary shards that an index should have.
        """
        return pulumi.get(self, "number_of_shards")


@pulumi.output_type
class ElasticSearchElasticsearchUserConfigKibana(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "elasticsearchRequestTimeout":
            suggest = "elasticsearch_request_timeout"
        elif key == "maxOldSpaceSize":
            suggest = "max_old_space_size"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ElasticSearchElasticsearchUserConfigKibana. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ElasticSearchElasticsearchUserConfigKibana.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ElasticSearchElasticsearchUserConfigKibana.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 elasticsearch_request_timeout: Optional[str] = None,
                 enabled: Optional[str] = None,
                 max_old_space_size: Optional[str] = None):
        """
        :param str elasticsearch_request_timeout: Timeout in milliseconds for requests 
               made by Kibana towards Elasticsearch.
        :param str enabled: Enable or disable Kibana.
        :param str max_old_space_size: Limits the maximum amount of memory (in MiB) the 
               Kibana process can use. This sets the max_old_space_size option of the nodejs running
               the Kibana. Note: the memory reserved by Kibana is not available for Elasticsearch.
        """
        if elasticsearch_request_timeout is not None:
            pulumi.set(__self__, "elasticsearch_request_timeout", elasticsearch_request_timeout)
        if enabled is not None:
            pulumi.set(__self__, "enabled", enabled)
        if max_old_space_size is not None:
            pulumi.set(__self__, "max_old_space_size", max_old_space_size)

    @property
    @pulumi.getter(name="elasticsearchRequestTimeout")
    def elasticsearch_request_timeout(self) -> Optional[str]:
        """
        Timeout in milliseconds for requests 
        made by Kibana towards Elasticsearch.
        """
        return pulumi.get(self, "elasticsearch_request_timeout")

    @property
    @pulumi.getter
    def enabled(self) -> Optional[str]:
        """
        Enable or disable Kibana.
        """
        return pulumi.get(self, "enabled")

    @property
    @pulumi.getter(name="maxOldSpaceSize")
    def max_old_space_size(self) -> Optional[str]:
        """
        Limits the maximum amount of memory (in MiB) the 
        Kibana process can use. This sets the max_old_space_size option of the nodejs running
        the Kibana. Note: the memory reserved by Kibana is not available for Elasticsearch.
        """
        return pulumi.get(self, "max_old_space_size")


@pulumi.output_type
class ElasticSearchElasticsearchUserConfigPrivateAccess(dict):
    def __init__(__self__, *,
                 elasticsearch: Optional[str] = None,
                 kibana: Optional[str] = None,
                 prometheus: Optional[str] = None):
        """
        :param str elasticsearch: Allow clients to connect to elasticsearch from the public 
               internet for service nodes that are in a project VPC or another type of private network.
        :param str kibana: Allow clients to connect to kibana from the public internet for 
               service nodes that are in a project VPC or another type of private network.
        :param str prometheus: Allow clients to connect to prometheus from the public 
               internet for service nodes that are in a project VPC or another type of private network.
        """
        if elasticsearch is not None:
            pulumi.set(__self__, "elasticsearch", elasticsearch)
        if kibana is not None:
            pulumi.set(__self__, "kibana", kibana)
        if prometheus is not None:
            pulumi.set(__self__, "prometheus", prometheus)

    @property
    @pulumi.getter
    def elasticsearch(self) -> Optional[str]:
        """
        Allow clients to connect to elasticsearch from the public 
        internet for service nodes that are in a project VPC or another type of private network.
        """
        return pulumi.get(self, "elasticsearch")

    @property
    @pulumi.getter
    def kibana(self) -> Optional[str]:
        """
        Allow clients to connect to kibana from the public internet for 
        service nodes that are in a project VPC or another type of private network.
        """
        return pulumi.get(self, "kibana")

    @property
    @pulumi.getter
    def prometheus(self) -> Optional[str]:
        """
        Allow clients to connect to prometheus from the public 
        internet for service nodes that are in a project VPC or another type of private network.
        """
        return pulumi.get(self, "prometheus")


@pulumi.output_type
class ElasticSearchElasticsearchUserConfigPrivatelinkAccess(dict):
    def __init__(__self__, *,
                 elasticsearch: Optional[str] = None,
                 kibana: Optional[str] = None):
        """
        :param str elasticsearch: Allow clients to connect to elasticsearch from the public 
               internet for service nodes that are in a project VPC or another type of private network.
        :param str kibana: Allow clients to connect to kibana from the public internet for 
               service nodes that are in a project VPC or another type of private network.
        """
        if elasticsearch is not None:
            pulumi.set(__self__, "elasticsearch", elasticsearch)
        if kibana is not None:
            pulumi.set(__self__, "kibana", kibana)

    @property
    @pulumi.getter
    def elasticsearch(self) -> Optional[str]:
        """
        Allow clients to connect to elasticsearch from the public 
        internet for service nodes that are in a project VPC or another type of private network.
        """
        return pulumi.get(self, "elasticsearch")

    @property
    @pulumi.getter
    def kibana(self) -> Optional[str]:
        """
        Allow clients to connect to kibana from the public internet for 
        service nodes that are in a project VPC or another type of private network.
        """
        return pulumi.get(self, "kibana")


@pulumi.output_type
class ElasticSearchElasticsearchUserConfigPublicAccess(dict):
    def __init__(__self__, *,
                 elasticsearch: Optional[str] = None,
                 kibana: Optional[str] = None,
                 prometheus: Optional[str] = None):
        """
        :param str elasticsearch: Allow clients to connect to elasticsearch from the public 
               internet for service nodes that are in a project VPC or another type of private network.
        :param str kibana: Allow clients to connect to kibana from the public internet for 
               service nodes that are in a project VPC or another type of private network.
        :param str prometheus: Allow clients to connect to prometheus from the public 
               internet for service nodes that are in a project VPC or another type of private network.
        """
        if elasticsearch is not None:
            pulumi.set(__self__, "elasticsearch", elasticsearch)
        if kibana is not None:
            pulumi.set(__self__, "kibana", kibana)
        if prometheus is not None:
            pulumi.set(__self__, "prometheus", prometheus)

    @property
    @pulumi.getter
    def elasticsearch(self) -> Optional[str]:
        """
        Allow clients to connect to elasticsearch from the public 
        internet for service nodes that are in a project VPC or another type of private network.
        """
        return pulumi.get(self, "elasticsearch")

    @property
    @pulumi.getter
    def kibana(self) -> Optional[str]:
        """
        Allow clients to connect to kibana from the public internet for 
        service nodes that are in a project VPC or another type of private network.
        """
        return pulumi.get(self, "kibana")

    @property
    @pulumi.getter
    def prometheus(self) -> Optional[str]:
        """
        Allow clients to connect to prometheus from the public 
        internet for service nodes that are in a project VPC or another type of private network.
        """
        return pulumi.get(self, "prometheus")


@pulumi.output_type
class ElasticSearchServiceIntegration(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "integrationType":
            suggest = "integration_type"
        elif key == "sourceServiceName":
            suggest = "source_service_name"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ElasticSearchServiceIntegration. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ElasticSearchServiceIntegration.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ElasticSearchServiceIntegration.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 integration_type: str,
                 source_service_name: str):
        pulumi.set(__self__, "integration_type", integration_type)
        pulumi.set(__self__, "source_service_name", source_service_name)

    @property
    @pulumi.getter(name="integrationType")
    def integration_type(self) -> str:
        return pulumi.get(self, "integration_type")

    @property
    @pulumi.getter(name="sourceServiceName")
    def source_service_name(self) -> str:
        return pulumi.get(self, "source_service_name")


@pulumi.output_type
class GrafanaComponent(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "kafkaAuthenticationMethod":
            suggest = "kafka_authentication_method"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in GrafanaComponent. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        GrafanaComponent.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        GrafanaComponent.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 component: Optional[str] = None,
                 host: Optional[str] = None,
                 kafka_authentication_method: Optional[str] = None,
                 port: Optional[int] = None,
                 route: Optional[str] = None,
                 ssl: Optional[bool] = None,
                 usage: Optional[str] = None):
        """
        :param str host: Server hostname or IP
        :param int port: SMTP server port
        """
        if component is not None:
            pulumi.set(__self__, "component", component)
        if host is not None:
            pulumi.set(__self__, "host", host)
        if kafka_authentication_method is not None:
            pulumi.set(__self__, "kafka_authentication_method", kafka_authentication_method)
        if port is not None:
            pulumi.set(__self__, "port", port)
        if route is not None:
            pulumi.set(__self__, "route", route)
        if ssl is not None:
            pulumi.set(__self__, "ssl", ssl)
        if usage is not None:
            pulumi.set(__self__, "usage", usage)

    @property
    @pulumi.getter
    def component(self) -> Optional[str]:
        return pulumi.get(self, "component")

    @property
    @pulumi.getter
    def host(self) -> Optional[str]:
        """
        Server hostname or IP
        """
        return pulumi.get(self, "host")

    @property
    @pulumi.getter(name="kafkaAuthenticationMethod")
    def kafka_authentication_method(self) -> Optional[str]:
        return pulumi.get(self, "kafka_authentication_method")

    @property
    @pulumi.getter
    def port(self) -> Optional[int]:
        """
        SMTP server port
        """
        return pulumi.get(self, "port")

    @property
    @pulumi.getter
    def route(self) -> Optional[str]:
        return pulumi.get(self, "route")

    @property
    @pulumi.getter
    def ssl(self) -> Optional[bool]:
        return pulumi.get(self, "ssl")

    @property
    @pulumi.getter
    def usage(self) -> Optional[str]:
        return pulumi.get(self, "usage")


@pulumi.output_type
class GrafanaGrafana(dict):
    def __init__(__self__):
        pass


@pulumi.output_type
class GrafanaGrafanaUserConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "alertingEnabled":
            suggest = "alerting_enabled"
        elif key == "alertingErrorOrTimeout":
            suggest = "alerting_error_or_timeout"
        elif key == "alertingNodataOrNullvalues":
            suggest = "alerting_nodata_or_nullvalues"
        elif key == "allowEmbedding":
            suggest = "allow_embedding"
        elif key == "authBasicEnabled":
            suggest = "auth_basic_enabled"
        elif key == "authGenericOauth":
            suggest = "auth_generic_oauth"
        elif key == "authGithub":
            suggest = "auth_github"
        elif key == "authGitlab":
            suggest = "auth_gitlab"
        elif key == "authGoogle":
            suggest = "auth_google"
        elif key == "cookieSamesite":
            suggest = "cookie_samesite"
        elif key == "customDomain":
            suggest = "custom_domain"
        elif key == "dashboardsMinRefreshInterval":
            suggest = "dashboards_min_refresh_interval"
        elif key == "dashboardsVersionsToKeep":
            suggest = "dashboards_versions_to_keep"
        elif key == "dataproxySendUserHeader":
            suggest = "dataproxy_send_user_header"
        elif key == "dataproxyTimeout":
            suggest = "dataproxy_timeout"
        elif key == "disableGravatar":
            suggest = "disable_gravatar"
        elif key == "editorsCanAdmin":
            suggest = "editors_can_admin"
        elif key == "externalImageStorage":
            suggest = "external_image_storage"
        elif key == "googleAnalyticsUaId":
            suggest = "google_analytics_ua_id"
        elif key == "ipFilters":
            suggest = "ip_filters"
        elif key == "metricsEnabled":
            suggest = "metrics_enabled"
        elif key == "privateAccess":
            suggest = "private_access"
        elif key == "privatelinkAccess":
            suggest = "privatelink_access"
        elif key == "projectToForkFrom":
            suggest = "project_to_fork_from"
        elif key == "publicAccess":
            suggest = "public_access"
        elif key == "recoveryBasebackupName":
            suggest = "recovery_basebackup_name"
        elif key == "serviceToForkFrom":
            suggest = "service_to_fork_from"
        elif key == "smtpServer":
            suggest = "smtp_server"
        elif key == "userAutoAssignOrg":
            suggest = "user_auto_assign_org"
        elif key == "userAutoAssignOrgRole":
            suggest = "user_auto_assign_org_role"
        elif key == "viewersCanEdit":
            suggest = "viewers_can_edit"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in GrafanaGrafanaUserConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        GrafanaGrafanaUserConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        GrafanaGrafanaUserConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 alerting_enabled: Optional[str] = None,
                 alerting_error_or_timeout: Optional[str] = None,
                 alerting_nodata_or_nullvalues: Optional[str] = None,
                 allow_embedding: Optional[str] = None,
                 auth_basic_enabled: Optional[str] = None,
                 auth_generic_oauth: Optional['outputs.GrafanaGrafanaUserConfigAuthGenericOauth'] = None,
                 auth_github: Optional['outputs.GrafanaGrafanaUserConfigAuthGithub'] = None,
                 auth_gitlab: Optional['outputs.GrafanaGrafanaUserConfigAuthGitlab'] = None,
                 auth_google: Optional['outputs.GrafanaGrafanaUserConfigAuthGoogle'] = None,
                 cookie_samesite: Optional[str] = None,
                 custom_domain: Optional[str] = None,
                 dashboards_min_refresh_interval: Optional[str] = None,
                 dashboards_versions_to_keep: Optional[str] = None,
                 dataproxy_send_user_header: Optional[str] = None,
                 dataproxy_timeout: Optional[str] = None,
                 disable_gravatar: Optional[str] = None,
                 editors_can_admin: Optional[str] = None,
                 external_image_storage: Optional['outputs.GrafanaGrafanaUserConfigExternalImageStorage'] = None,
                 google_analytics_ua_id: Optional[str] = None,
                 ip_filters: Optional[Sequence[str]] = None,
                 metrics_enabled: Optional[str] = None,
                 private_access: Optional['outputs.GrafanaGrafanaUserConfigPrivateAccess'] = None,
                 privatelink_access: Optional['outputs.GrafanaGrafanaUserConfigPrivatelinkAccess'] = None,
                 project_to_fork_from: Optional[str] = None,
                 public_access: Optional['outputs.GrafanaGrafanaUserConfigPublicAccess'] = None,
                 recovery_basebackup_name: Optional[str] = None,
                 service_to_fork_from: Optional[str] = None,
                 smtp_server: Optional['outputs.GrafanaGrafanaUserConfigSmtpServer'] = None,
                 user_auto_assign_org: Optional[str] = None,
                 user_auto_assign_org_role: Optional[str] = None,
                 viewers_can_edit: Optional[str] = None):
        """
        :param str alerting_enabled: Enable or disable Grafana alerting functionality
        :param str alerting_error_or_timeout: Default error or timeout setting for new alerting rules
        :param str alerting_nodata_or_nullvalues: Default value for 'no data or null values' for
               new alerting rules
        :param str allow_embedding: Allow embedding Grafana dashboards with iframe/frame/object/embed 
               tags. Disabled by default to limit impact of clickjacking
        :param str auth_basic_enabled: Enable or disable basic authentication form, used by Grafana 
               built-in login.
        :param 'GrafanaGrafanaUserConfigAuthGenericOauthArgs' auth_generic_oauth: Generic OAuth integration.
        :param 'GrafanaGrafanaUserConfigAuthGithubArgs' auth_github: Automatically sign-up users on successful sign-in
        :param 'GrafanaGrafanaUserConfigAuthGitlabArgs' auth_gitlab: GitLab Auth integration.
        :param 'GrafanaGrafanaUserConfigAuthGoogleArgs' auth_google: Google Auth integration
        :param str cookie_samesite: Cookie SameSite attribute: 'strict' prevents sending cookie for 
               cross-site requests, effectively disabling direct linking from other sites to Grafana. 'lax' is the default value.
        :param str custom_domain: Serve the web frontend using a custom CNAME pointing to the Aiven DNS name.
        :param str dashboards_min_refresh_interval: Signed sequence of decimal numbers, followed 
               by a unit suffix (ms, s, m, h, d), e.g. 30s, 1h.
        :param str dashboards_versions_to_keep: Dashboard versions to keep per dashboard.
        :param str dataproxy_send_user_header: Send 'X-Grafana-User' header to data source.
        :param str dataproxy_timeout: Timeout for data proxy requests in seconds.
        :param str disable_gravatar: Set to true to disable gravatar. Defaults to false 
               (gravatar is enabled).
        :param str editors_can_admin: Editors can manage folders, teams and dashboards created by them.
        :param 'GrafanaGrafanaUserConfigExternalImageStorageArgs' external_image_storage: External image store settings
        :param str google_analytics_ua_id: Google Analytics Universal Analytics ID for tracking Grafana usage
        :param Sequence[str] ip_filters: Allow incoming connections from CIDR address block, e.g. '10.20.0.0/16'
        :param str metrics_enabled: Enable Grafana /metrics endpoint
        :param 'GrafanaGrafanaUserConfigPrivatelinkAccessArgs' privatelink_access: Allow access to selected service components through Privatelink
        :param str project_to_fork_from: Name of another project to fork a service from. This has 
               effect only when a new service is being created.
        :param 'GrafanaGrafanaUserConfigPublicAccessArgs' public_access: Allow access to selected service ports from the public Internet.
        :param str recovery_basebackup_name: Name of the basebackup to restore in forked service.
        :param str service_to_fork_from: Name of another service to fork from. This has effect only 
               when a new service is being created.
        :param 'GrafanaGrafanaUserConfigSmtpServerArgs' smtp_server: SMTP server settings.
        :param str user_auto_assign_org: Auto-assign new users on signup to main organization. 
               Defaults to false.
        :param str user_auto_assign_org_role: Set role for new signups. Defaults to Viewer.
        :param str viewers_can_edit: Users with view-only permission can edit but not save dashboards.
        """
        if alerting_enabled is not None:
            pulumi.set(__self__, "alerting_enabled", alerting_enabled)
        if alerting_error_or_timeout is not None:
            pulumi.set(__self__, "alerting_error_or_timeout", alerting_error_or_timeout)
        if alerting_nodata_or_nullvalues is not None:
            pulumi.set(__self__, "alerting_nodata_or_nullvalues", alerting_nodata_or_nullvalues)
        if allow_embedding is not None:
            pulumi.set(__self__, "allow_embedding", allow_embedding)
        if auth_basic_enabled is not None:
            pulumi.set(__self__, "auth_basic_enabled", auth_basic_enabled)
        if auth_generic_oauth is not None:
            pulumi.set(__self__, "auth_generic_oauth", auth_generic_oauth)
        if auth_github is not None:
            pulumi.set(__self__, "auth_github", auth_github)
        if auth_gitlab is not None:
            pulumi.set(__self__, "auth_gitlab", auth_gitlab)
        if auth_google is not None:
            pulumi.set(__self__, "auth_google", auth_google)
        if cookie_samesite is not None:
            pulumi.set(__self__, "cookie_samesite", cookie_samesite)
        if custom_domain is not None:
            pulumi.set(__self__, "custom_domain", custom_domain)
        if dashboards_min_refresh_interval is not None:
            pulumi.set(__self__, "dashboards_min_refresh_interval", dashboards_min_refresh_interval)
        if dashboards_versions_to_keep is not None:
            pulumi.set(__self__, "dashboards_versions_to_keep", dashboards_versions_to_keep)
        if dataproxy_send_user_header is not None:
            pulumi.set(__self__, "dataproxy_send_user_header", dataproxy_send_user_header)
        if dataproxy_timeout is not None:
            pulumi.set(__self__, "dataproxy_timeout", dataproxy_timeout)
        if disable_gravatar is not None:
            pulumi.set(__self__, "disable_gravatar", disable_gravatar)
        if editors_can_admin is not None:
            pulumi.set(__self__, "editors_can_admin", editors_can_admin)
        if external_image_storage is not None:
            pulumi.set(__self__, "external_image_storage", external_image_storage)
        if google_analytics_ua_id is not None:
            pulumi.set(__self__, "google_analytics_ua_id", google_analytics_ua_id)
        if ip_filters is not None:
            pulumi.set(__self__, "ip_filters", ip_filters)
        if metrics_enabled is not None:
            pulumi.set(__self__, "metrics_enabled", metrics_enabled)
        if private_access is not None:
            pulumi.set(__self__, "private_access", private_access)
        if privatelink_access is not None:
            pulumi.set(__self__, "privatelink_access", privatelink_access)
        if project_to_fork_from is not None:
            pulumi.set(__self__, "project_to_fork_from", project_to_fork_from)
        if public_access is not None:
            pulumi.set(__self__, "public_access", public_access)
        if recovery_basebackup_name is not None:
            pulumi.set(__self__, "recovery_basebackup_name", recovery_basebackup_name)
        if service_to_fork_from is not None:
            pulumi.set(__self__, "service_to_fork_from", service_to_fork_from)
        if smtp_server is not None:
            pulumi.set(__self__, "smtp_server", smtp_server)
        if user_auto_assign_org is not None:
            pulumi.set(__self__, "user_auto_assign_org", user_auto_assign_org)
        if user_auto_assign_org_role is not None:
            pulumi.set(__self__, "user_auto_assign_org_role", user_auto_assign_org_role)
        if viewers_can_edit is not None:
            pulumi.set(__self__, "viewers_can_edit", viewers_can_edit)

    @property
    @pulumi.getter(name="alertingEnabled")
    def alerting_enabled(self) -> Optional[str]:
        """
        Enable or disable Grafana alerting functionality
        """
        return pulumi.get(self, "alerting_enabled")

    @property
    @pulumi.getter(name="alertingErrorOrTimeout")
    def alerting_error_or_timeout(self) -> Optional[str]:
        """
        Default error or timeout setting for new alerting rules
        """
        return pulumi.get(self, "alerting_error_or_timeout")

    @property
    @pulumi.getter(name="alertingNodataOrNullvalues")
    def alerting_nodata_or_nullvalues(self) -> Optional[str]:
        """
        Default value for 'no data or null values' for
        new alerting rules
        """
        return pulumi.get(self, "alerting_nodata_or_nullvalues")

    @property
    @pulumi.getter(name="allowEmbedding")
    def allow_embedding(self) -> Optional[str]:
        """
        Allow embedding Grafana dashboards with iframe/frame/object/embed 
        tags. Disabled by default to limit impact of clickjacking
        """
        return pulumi.get(self, "allow_embedding")

    @property
    @pulumi.getter(name="authBasicEnabled")
    def auth_basic_enabled(self) -> Optional[str]:
        """
        Enable or disable basic authentication form, used by Grafana 
        built-in login.
        """
        return pulumi.get(self, "auth_basic_enabled")

    @property
    @pulumi.getter(name="authGenericOauth")
    def auth_generic_oauth(self) -> Optional['outputs.GrafanaGrafanaUserConfigAuthGenericOauth']:
        """
        Generic OAuth integration.
        """
        return pulumi.get(self, "auth_generic_oauth")

    @property
    @pulumi.getter(name="authGithub")
    def auth_github(self) -> Optional['outputs.GrafanaGrafanaUserConfigAuthGithub']:
        """
        Automatically sign-up users on successful sign-in
        """
        return pulumi.get(self, "auth_github")

    @property
    @pulumi.getter(name="authGitlab")
    def auth_gitlab(self) -> Optional['outputs.GrafanaGrafanaUserConfigAuthGitlab']:
        """
        GitLab Auth integration.
        """
        return pulumi.get(self, "auth_gitlab")

    @property
    @pulumi.getter(name="authGoogle")
    def auth_google(self) -> Optional['outputs.GrafanaGrafanaUserConfigAuthGoogle']:
        """
        Google Auth integration
        """
        return pulumi.get(self, "auth_google")

    @property
    @pulumi.getter(name="cookieSamesite")
    def cookie_samesite(self) -> Optional[str]:
        """
        Cookie SameSite attribute: 'strict' prevents sending cookie for 
        cross-site requests, effectively disabling direct linking from other sites to Grafana. 'lax' is the default value.
        """
        return pulumi.get(self, "cookie_samesite")

    @property
    @pulumi.getter(name="customDomain")
    def custom_domain(self) -> Optional[str]:
        """
        Serve the web frontend using a custom CNAME pointing to the Aiven DNS name.
        """
        return pulumi.get(self, "custom_domain")

    @property
    @pulumi.getter(name="dashboardsMinRefreshInterval")
    def dashboards_min_refresh_interval(self) -> Optional[str]:
        """
        Signed sequence of decimal numbers, followed 
        by a unit suffix (ms, s, m, h, d), e.g. 30s, 1h.
        """
        return pulumi.get(self, "dashboards_min_refresh_interval")

    @property
    @pulumi.getter(name="dashboardsVersionsToKeep")
    def dashboards_versions_to_keep(self) -> Optional[str]:
        """
        Dashboard versions to keep per dashboard.
        """
        return pulumi.get(self, "dashboards_versions_to_keep")

    @property
    @pulumi.getter(name="dataproxySendUserHeader")
    def dataproxy_send_user_header(self) -> Optional[str]:
        """
        Send 'X-Grafana-User' header to data source.
        """
        return pulumi.get(self, "dataproxy_send_user_header")

    @property
    @pulumi.getter(name="dataproxyTimeout")
    def dataproxy_timeout(self) -> Optional[str]:
        """
        Timeout for data proxy requests in seconds.
        """
        return pulumi.get(self, "dataproxy_timeout")

    @property
    @pulumi.getter(name="disableGravatar")
    def disable_gravatar(self) -> Optional[str]:
        """
        Set to true to disable gravatar. Defaults to false 
        (gravatar is enabled).
        """
        return pulumi.get(self, "disable_gravatar")

    @property
    @pulumi.getter(name="editorsCanAdmin")
    def editors_can_admin(self) -> Optional[str]:
        """
        Editors can manage folders, teams and dashboards created by them.
        """
        return pulumi.get(self, "editors_can_admin")

    @property
    @pulumi.getter(name="externalImageStorage")
    def external_image_storage(self) -> Optional['outputs.GrafanaGrafanaUserConfigExternalImageStorage']:
        """
        External image store settings
        """
        return pulumi.get(self, "external_image_storage")

    @property
    @pulumi.getter(name="googleAnalyticsUaId")
    def google_analytics_ua_id(self) -> Optional[str]:
        """
        Google Analytics Universal Analytics ID for tracking Grafana usage
        """
        return pulumi.get(self, "google_analytics_ua_id")

    @property
    @pulumi.getter(name="ipFilters")
    def ip_filters(self) -> Optional[Sequence[str]]:
        """
        Allow incoming connections from CIDR address block, e.g. '10.20.0.0/16'
        """
        return pulumi.get(self, "ip_filters")

    @property
    @pulumi.getter(name="metricsEnabled")
    def metrics_enabled(self) -> Optional[str]:
        """
        Enable Grafana /metrics endpoint
        """
        return pulumi.get(self, "metrics_enabled")

    @property
    @pulumi.getter(name="privateAccess")
    def private_access(self) -> Optional['outputs.GrafanaGrafanaUserConfigPrivateAccess']:
        return pulumi.get(self, "private_access")

    @property
    @pulumi.getter(name="privatelinkAccess")
    def privatelink_access(self) -> Optional['outputs.GrafanaGrafanaUserConfigPrivatelinkAccess']:
        """
        Allow access to selected service components through Privatelink
        """
        return pulumi.get(self, "privatelink_access")

    @property
    @pulumi.getter(name="projectToForkFrom")
    def project_to_fork_from(self) -> Optional[str]:
        """
        Name of another project to fork a service from. This has 
        effect only when a new service is being created.
        """
        return pulumi.get(self, "project_to_fork_from")

    @property
    @pulumi.getter(name="publicAccess")
    def public_access(self) -> Optional['outputs.GrafanaGrafanaUserConfigPublicAccess']:
        """
        Allow access to selected service ports from the public Internet.
        """
        return pulumi.get(self, "public_access")

    @property
    @pulumi.getter(name="recoveryBasebackupName")
    def recovery_basebackup_name(self) -> Optional[str]:
        """
        Name of the basebackup to restore in forked service.
        """
        return pulumi.get(self, "recovery_basebackup_name")

    @property
    @pulumi.getter(name="serviceToForkFrom")
    def service_to_fork_from(self) -> Optional[str]:
        """
        Name of another service to fork from. This has effect only 
        when a new service is being created.
        """
        return pulumi.get(self, "service_to_fork_from")

    @property
    @pulumi.getter(name="smtpServer")
    def smtp_server(self) -> Optional['outputs.GrafanaGrafanaUserConfigSmtpServer']:
        """
        SMTP server settings.
        """
        return pulumi.get(self, "smtp_server")

    @property
    @pulumi.getter(name="userAutoAssignOrg")
    def user_auto_assign_org(self) -> Optional[str]:
        """
        Auto-assign new users on signup to main organization. 
        Defaults to false.
        """
        return pulumi.get(self, "user_auto_assign_org")

    @property
    @pulumi.getter(name="userAutoAssignOrgRole")
    def user_auto_assign_org_role(self) -> Optional[str]:
        """
        Set role for new signups. Defaults to Viewer.
        """
        return pulumi.get(self, "user_auto_assign_org_role")

    @property
    @pulumi.getter(name="viewersCanEdit")
    def viewers_can_edit(self) -> Optional[str]:
        """
        Users with view-only permission can edit but not save dashboards.
        """
        return pulumi.get(self, "viewers_can_edit")


@pulumi.output_type
class GrafanaGrafanaUserConfigAuthGenericOauth(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "allowSignUp":
            suggest = "allow_sign_up"
        elif key == "allowedDomains":
            suggest = "allowed_domains"
        elif key == "allowedOrganizations":
            suggest = "allowed_organizations"
        elif key == "apiUrl":
            suggest = "api_url"
        elif key == "authUrl":
            suggest = "auth_url"
        elif key == "clientId":
            suggest = "client_id"
        elif key == "clientSecret":
            suggest = "client_secret"
        elif key == "tokenUrl":
            suggest = "token_url"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in GrafanaGrafanaUserConfigAuthGenericOauth. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        GrafanaGrafanaUserConfigAuthGenericOauth.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        GrafanaGrafanaUserConfigAuthGenericOauth.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 allow_sign_up: Optional[str] = None,
                 allowed_domains: Optional[Sequence[str]] = None,
                 allowed_organizations: Optional[Sequence[str]] = None,
                 api_url: Optional[str] = None,
                 auth_url: Optional[str] = None,
                 client_id: Optional[str] = None,
                 client_secret: Optional[str] = None,
                 name: Optional[str] = None,
                 scopes: Optional[Sequence[str]] = None,
                 token_url: Optional[str] = None):
        """
        :param str allow_sign_up: Automatically sign-up users on successful sign-in
        :param Sequence[str] allowed_domains: Allowed domain
        :param Sequence[str] allowed_organizations: Must consist of alpha-numeric characters and dashes"
        :param str api_url: API URL. This only needs to be set when using self hosted GitLab
        :param str auth_url: Authorization URL. This only needs to be set when using self hosted GitLab
        :param str client_id: Client ID from provider
        :param str client_secret: Client secret from provider
        :param str name: Name of the OAuth integration
        :param Sequence[str] scopes: Scope must be non-empty string without whitespace
        :param str token_url: Token URL. This only needs to be set when using self hosted GitLab
        """
        if allow_sign_up is not None:
            pulumi.set(__self__, "allow_sign_up", allow_sign_up)
        if allowed_domains is not None:
            pulumi.set(__self__, "allowed_domains", allowed_domains)
        if allowed_organizations is not None:
            pulumi.set(__self__, "allowed_organizations", allowed_organizations)
        if api_url is not None:
            pulumi.set(__self__, "api_url", api_url)
        if auth_url is not None:
            pulumi.set(__self__, "auth_url", auth_url)
        if client_id is not None:
            pulumi.set(__self__, "client_id", client_id)
        if client_secret is not None:
            pulumi.set(__self__, "client_secret", client_secret)
        if name is not None:
            pulumi.set(__self__, "name", name)
        if scopes is not None:
            pulumi.set(__self__, "scopes", scopes)
        if token_url is not None:
            pulumi.set(__self__, "token_url", token_url)

    @property
    @pulumi.getter(name="allowSignUp")
    def allow_sign_up(self) -> Optional[str]:
        """
        Automatically sign-up users on successful sign-in
        """
        return pulumi.get(self, "allow_sign_up")

    @property
    @pulumi.getter(name="allowedDomains")
    def allowed_domains(self) -> Optional[Sequence[str]]:
        """
        Allowed domain
        """
        return pulumi.get(self, "allowed_domains")

    @property
    @pulumi.getter(name="allowedOrganizations")
    def allowed_organizations(self) -> Optional[Sequence[str]]:
        """
        Must consist of alpha-numeric characters and dashes"
        """
        return pulumi.get(self, "allowed_organizations")

    @property
    @pulumi.getter(name="apiUrl")
    def api_url(self) -> Optional[str]:
        """
        API URL. This only needs to be set when using self hosted GitLab
        """
        return pulumi.get(self, "api_url")

    @property
    @pulumi.getter(name="authUrl")
    def auth_url(self) -> Optional[str]:
        """
        Authorization URL. This only needs to be set when using self hosted GitLab
        """
        return pulumi.get(self, "auth_url")

    @property
    @pulumi.getter(name="clientId")
    def client_id(self) -> Optional[str]:
        """
        Client ID from provider
        """
        return pulumi.get(self, "client_id")

    @property
    @pulumi.getter(name="clientSecret")
    def client_secret(self) -> Optional[str]:
        """
        Client secret from provider
        """
        return pulumi.get(self, "client_secret")

    @property
    @pulumi.getter
    def name(self) -> Optional[str]:
        """
        Name of the OAuth integration
        """
        return pulumi.get(self, "name")

    @property
    @pulumi.getter
    def scopes(self) -> Optional[Sequence[str]]:
        """
        Scope must be non-empty string without whitespace
        """
        return pulumi.get(self, "scopes")

    @property
    @pulumi.getter(name="tokenUrl")
    def token_url(self) -> Optional[str]:
        """
        Token URL. This only needs to be set when using self hosted GitLab
        """
        return pulumi.get(self, "token_url")


@pulumi.output_type
class GrafanaGrafanaUserConfigAuthGithub(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "allowSignUp":
            suggest = "allow_sign_up"
        elif key == "allowedOrganizations":
            suggest = "allowed_organizations"
        elif key == "clientId":
            suggest = "client_id"
        elif key == "clientSecret":
            suggest = "client_secret"
        elif key == "teamIds":
            suggest = "team_ids"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in GrafanaGrafanaUserConfigAuthGithub. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        GrafanaGrafanaUserConfigAuthGithub.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        GrafanaGrafanaUserConfigAuthGithub.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 allow_sign_up: Optional[str] = None,
                 allowed_organizations: Optional[Sequence[str]] = None,
                 client_id: Optional[str] = None,
                 client_secret: Optional[str] = None,
                 team_ids: Optional[Sequence[str]] = None):
        """
        :param str allow_sign_up: Automatically sign-up users on successful sign-in
        :param Sequence[str] allowed_organizations: Must consist of alpha-numeric characters and dashes"
        :param str client_id: Client ID from provider
        :param str client_secret: Client secret from provider
        :param Sequence[str] team_ids: Require users to belong to one of given team IDs
        """
        if allow_sign_up is not None:
            pulumi.set(__self__, "allow_sign_up", allow_sign_up)
        if allowed_organizations is not None:
            pulumi.set(__self__, "allowed_organizations", allowed_organizations)
        if client_id is not None:
            pulumi.set(__self__, "client_id", client_id)
        if client_secret is not None:
            pulumi.set(__self__, "client_secret", client_secret)
        if team_ids is not None:
            pulumi.set(__self__, "team_ids", team_ids)

    @property
    @pulumi.getter(name="allowSignUp")
    def allow_sign_up(self) -> Optional[str]:
        """
        Automatically sign-up users on successful sign-in
        """
        return pulumi.get(self, "allow_sign_up")

    @property
    @pulumi.getter(name="allowedOrganizations")
    def allowed_organizations(self) -> Optional[Sequence[str]]:
        """
        Must consist of alpha-numeric characters and dashes"
        """
        return pulumi.get(self, "allowed_organizations")

    @property
    @pulumi.getter(name="clientId")
    def client_id(self) -> Optional[str]:
        """
        Client ID from provider
        """
        return pulumi.get(self, "client_id")

    @property
    @pulumi.getter(name="clientSecret")
    def client_secret(self) -> Optional[str]:
        """
        Client secret from provider
        """
        return pulumi.get(self, "client_secret")

    @property
    @pulumi.getter(name="teamIds")
    def team_ids(self) -> Optional[Sequence[str]]:
        """
        Require users to belong to one of given team IDs
        """
        return pulumi.get(self, "team_ids")


@pulumi.output_type
class GrafanaGrafanaUserConfigAuthGitlab(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "allowSignUp":
            suggest = "allow_sign_up"
        elif key == "allowedGroups":
            suggest = "allowed_groups"
        elif key == "apiUrl":
            suggest = "api_url"
        elif key == "authUrl":
            suggest = "auth_url"
        elif key == "clientId":
            suggest = "client_id"
        elif key == "clientSecret":
            suggest = "client_secret"
        elif key == "tokenUrl":
            suggest = "token_url"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in GrafanaGrafanaUserConfigAuthGitlab. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        GrafanaGrafanaUserConfigAuthGitlab.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        GrafanaGrafanaUserConfigAuthGitlab.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 allow_sign_up: Optional[str] = None,
                 allowed_groups: Optional[Sequence[str]] = None,
                 api_url: Optional[str] = None,
                 auth_url: Optional[str] = None,
                 client_id: Optional[str] = None,
                 client_secret: Optional[str] = None,
                 token_url: Optional[str] = None):
        """
        :param str allow_sign_up: Automatically sign-up users on successful sign-in
        :param Sequence[str] allowed_groups: Require users to belong to one of given groups
        :param str api_url: API URL. This only needs to be set when using self hosted GitLab
        :param str auth_url: Authorization URL. This only needs to be set when using self hosted GitLab
        :param str client_id: Client ID from provider
        :param str client_secret: Client secret from provider
        :param str token_url: Token URL. This only needs to be set when using self hosted GitLab
        """
        if allow_sign_up is not None:
            pulumi.set(__self__, "allow_sign_up", allow_sign_up)
        if allowed_groups is not None:
            pulumi.set(__self__, "allowed_groups", allowed_groups)
        if api_url is not None:
            pulumi.set(__self__, "api_url", api_url)
        if auth_url is not None:
            pulumi.set(__self__, "auth_url", auth_url)
        if client_id is not None:
            pulumi.set(__self__, "client_id", client_id)
        if client_secret is not None:
            pulumi.set(__self__, "client_secret", client_secret)
        if token_url is not None:
            pulumi.set(__self__, "token_url", token_url)

    @property
    @pulumi.getter(name="allowSignUp")
    def allow_sign_up(self) -> Optional[str]:
        """
        Automatically sign-up users on successful sign-in
        """
        return pulumi.get(self, "allow_sign_up")

    @property
    @pulumi.getter(name="allowedGroups")
    def allowed_groups(self) -> Optional[Sequence[str]]:
        """
        Require users to belong to one of given groups
        """
        return pulumi.get(self, "allowed_groups")

    @property
    @pulumi.getter(name="apiUrl")
    def api_url(self) -> Optional[str]:
        """
        API URL. This only needs to be set when using self hosted GitLab
        """
        return pulumi.get(self, "api_url")

    @property
    @pulumi.getter(name="authUrl")
    def auth_url(self) -> Optional[str]:
        """
        Authorization URL. This only needs to be set when using self hosted GitLab
        """
        return pulumi.get(self, "auth_url")

    @property
    @pulumi.getter(name="clientId")
    def client_id(self) -> Optional[str]:
        """
        Client ID from provider
        """
        return pulumi.get(self, "client_id")

    @property
    @pulumi.getter(name="clientSecret")
    def client_secret(self) -> Optional[str]:
        """
        Client secret from provider
        """
        return pulumi.get(self, "client_secret")

    @property
    @pulumi.getter(name="tokenUrl")
    def token_url(self) -> Optional[str]:
        """
        Token URL. This only needs to be set when using self hosted GitLab
        """
        return pulumi.get(self, "token_url")


@pulumi.output_type
class GrafanaGrafanaUserConfigAuthGoogle(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "allowSignUp":
            suggest = "allow_sign_up"
        elif key == "allowedDomains":
            suggest = "allowed_domains"
        elif key == "clientId":
            suggest = "client_id"
        elif key == "clientSecret":
            suggest = "client_secret"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in GrafanaGrafanaUserConfigAuthGoogle. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        GrafanaGrafanaUserConfigAuthGoogle.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        GrafanaGrafanaUserConfigAuthGoogle.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 allow_sign_up: Optional[str] = None,
                 allowed_domains: Optional[Sequence[str]] = None,
                 client_id: Optional[str] = None,
                 client_secret: Optional[str] = None):
        """
        :param str allow_sign_up: Automatically sign-up users on successful sign-in
        :param Sequence[str] allowed_domains: Allowed domain
        :param str client_id: Client ID from provider
        :param str client_secret: Client secret from provider
        """
        if allow_sign_up is not None:
            pulumi.set(__self__, "allow_sign_up", allow_sign_up)
        if allowed_domains is not None:
            pulumi.set(__self__, "allowed_domains", allowed_domains)
        if client_id is not None:
            pulumi.set(__self__, "client_id", client_id)
        if client_secret is not None:
            pulumi.set(__self__, "client_secret", client_secret)

    @property
    @pulumi.getter(name="allowSignUp")
    def allow_sign_up(self) -> Optional[str]:
        """
        Automatically sign-up users on successful sign-in
        """
        return pulumi.get(self, "allow_sign_up")

    @property
    @pulumi.getter(name="allowedDomains")
    def allowed_domains(self) -> Optional[Sequence[str]]:
        """
        Allowed domain
        """
        return pulumi.get(self, "allowed_domains")

    @property
    @pulumi.getter(name="clientId")
    def client_id(self) -> Optional[str]:
        """
        Client ID from provider
        """
        return pulumi.get(self, "client_id")

    @property
    @pulumi.getter(name="clientSecret")
    def client_secret(self) -> Optional[str]:
        """
        Client secret from provider
        """
        return pulumi.get(self, "client_secret")


@pulumi.output_type
class GrafanaGrafanaUserConfigExternalImageStorage(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "accessKey":
            suggest = "access_key"
        elif key == "bucketUrl":
            suggest = "bucket_url"
        elif key == "secretKey":
            suggest = "secret_key"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in GrafanaGrafanaUserConfigExternalImageStorage. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        GrafanaGrafanaUserConfigExternalImageStorage.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        GrafanaGrafanaUserConfigExternalImageStorage.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 access_key: Optional[str] = None,
                 bucket_url: Optional[str] = None,
                 provider: Optional[str] = None,
                 secret_key: Optional[str] = None):
        """
        :param str access_key: S3 access key. Requires permissions to the S3 bucket for the 
               s3:PutObject and s3:PutObjectAcl actions
        :param str bucket_url: Bucket URL for S3
        :param str provider: Provider type
        :param str secret_key: S3 secret key
        """
        if access_key is not None:
            pulumi.set(__self__, "access_key", access_key)
        if bucket_url is not None:
            pulumi.set(__self__, "bucket_url", bucket_url)
        if provider is not None:
            pulumi.set(__self__, "provider", provider)
        if secret_key is not None:
            pulumi.set(__self__, "secret_key", secret_key)

    @property
    @pulumi.getter(name="accessKey")
    def access_key(self) -> Optional[str]:
        """
        S3 access key. Requires permissions to the S3 bucket for the 
        s3:PutObject and s3:PutObjectAcl actions
        """
        return pulumi.get(self, "access_key")

    @property
    @pulumi.getter(name="bucketUrl")
    def bucket_url(self) -> Optional[str]:
        """
        Bucket URL for S3
        """
        return pulumi.get(self, "bucket_url")

    @property
    @pulumi.getter
    def provider(self) -> Optional[str]:
        """
        Provider type
        """
        return pulumi.get(self, "provider")

    @property
    @pulumi.getter(name="secretKey")
    def secret_key(self) -> Optional[str]:
        """
        S3 secret key
        """
        return pulumi.get(self, "secret_key")


@pulumi.output_type
class GrafanaGrafanaUserConfigPrivateAccess(dict):
    def __init__(__self__, *,
                 grafana: Optional[str] = None):
        """
        :param str grafana: Allow clients to connect to grafana from the public internet for service nodes that 
               are in a project VPC or another type of private network.
        """
        if grafana is not None:
            pulumi.set(__self__, "grafana", grafana)

    @property
    @pulumi.getter
    def grafana(self) -> Optional[str]:
        """
        Allow clients to connect to grafana from the public internet for service nodes that 
        are in a project VPC or another type of private network.
        """
        return pulumi.get(self, "grafana")


@pulumi.output_type
class GrafanaGrafanaUserConfigPrivatelinkAccess(dict):
    def __init__(__self__, *,
                 grafana: Optional[str] = None):
        """
        :param str grafana: Allow clients to connect to grafana from the public internet for service nodes that 
               are in a project VPC or another type of private network.
        """
        if grafana is not None:
            pulumi.set(__self__, "grafana", grafana)

    @property
    @pulumi.getter
    def grafana(self) -> Optional[str]:
        """
        Allow clients to connect to grafana from the public internet for service nodes that 
        are in a project VPC or another type of private network.
        """
        return pulumi.get(self, "grafana")


@pulumi.output_type
class GrafanaGrafanaUserConfigPublicAccess(dict):
    def __init__(__self__, *,
                 grafana: Optional[str] = None):
        """
        :param str grafana: Allow clients to connect to grafana from the public internet for service nodes that 
               are in a project VPC or another type of private network.
        """
        if grafana is not None:
            pulumi.set(__self__, "grafana", grafana)

    @property
    @pulumi.getter
    def grafana(self) -> Optional[str]:
        """
        Allow clients to connect to grafana from the public internet for service nodes that 
        are in a project VPC or another type of private network.
        """
        return pulumi.get(self, "grafana")


@pulumi.output_type
class GrafanaGrafanaUserConfigSmtpServer(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "fromAddress":
            suggest = "from_address"
        elif key == "fromName":
            suggest = "from_name"
        elif key == "skipVerify":
            suggest = "skip_verify"
        elif key == "starttlsPolicy":
            suggest = "starttls_policy"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in GrafanaGrafanaUserConfigSmtpServer. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        GrafanaGrafanaUserConfigSmtpServer.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        GrafanaGrafanaUserConfigSmtpServer.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 from_address: Optional[str] = None,
                 from_name: Optional[str] = None,
                 host: Optional[str] = None,
                 password: Optional[str] = None,
                 port: Optional[str] = None,
                 skip_verify: Optional[str] = None,
                 starttls_policy: Optional[str] = None,
                 username: Optional[str] = None):
        """
        :param str from_address: Address used for sending emails
        :param str from_name: Name used in outgoing emails, defaults to Grafana
        :param str host: Server hostname or IP
        :param str password: Password for SMTP authentication
        :param str port: SMTP server port
        :param str skip_verify: Skip verifying server certificate. Defaults to false
        :param str starttls_policy: Either OpportunisticStartTLS, MandatoryStartTLS or NoStartTLS. 
               Default is OpportunisticStartTLS.
        :param str username: Username for SMTP authentication
        """
        if from_address is not None:
            pulumi.set(__self__, "from_address", from_address)
        if from_name is not None:
            pulumi.set(__self__, "from_name", from_name)
        if host is not None:
            pulumi.set(__self__, "host", host)
        if password is not None:
            pulumi.set(__self__, "password", password)
        if port is not None:
            pulumi.set(__self__, "port", port)
        if skip_verify is not None:
            pulumi.set(__self__, "skip_verify", skip_verify)
        if starttls_policy is not None:
            pulumi.set(__self__, "starttls_policy", starttls_policy)
        if username is not None:
            pulumi.set(__self__, "username", username)

    @property
    @pulumi.getter(name="fromAddress")
    def from_address(self) -> Optional[str]:
        """
        Address used for sending emails
        """
        return pulumi.get(self, "from_address")

    @property
    @pulumi.getter(name="fromName")
    def from_name(self) -> Optional[str]:
        """
        Name used in outgoing emails, defaults to Grafana
        """
        return pulumi.get(self, "from_name")

    @property
    @pulumi.getter
    def host(self) -> Optional[str]:
        """
        Server hostname or IP
        """
        return pulumi.get(self, "host")

    @property
    @pulumi.getter
    def password(self) -> Optional[str]:
        """
        Password for SMTP authentication
        """
        return pulumi.get(self, "password")

    @property
    @pulumi.getter
    def port(self) -> Optional[str]:
        """
        SMTP server port
        """
        return pulumi.get(self, "port")

    @property
    @pulumi.getter(name="skipVerify")
    def skip_verify(self) -> Optional[str]:
        """
        Skip verifying server certificate. Defaults to false
        """
        return pulumi.get(self, "skip_verify")

    @property
    @pulumi.getter(name="starttlsPolicy")
    def starttls_policy(self) -> Optional[str]:
        """
        Either OpportunisticStartTLS, MandatoryStartTLS or NoStartTLS. 
        Default is OpportunisticStartTLS.
        """
        return pulumi.get(self, "starttls_policy")

    @property
    @pulumi.getter
    def username(self) -> Optional[str]:
        """
        Username for SMTP authentication
        """
        return pulumi.get(self, "username")


@pulumi.output_type
class GrafanaServiceIntegration(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "integrationType":
            suggest = "integration_type"
        elif key == "sourceServiceName":
            suggest = "source_service_name"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in GrafanaServiceIntegration. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        GrafanaServiceIntegration.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        GrafanaServiceIntegration.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 integration_type: str,
                 source_service_name: str):
        pulumi.set(__self__, "integration_type", integration_type)
        pulumi.set(__self__, "source_service_name", source_service_name)

    @property
    @pulumi.getter(name="integrationType")
    def integration_type(self) -> str:
        return pulumi.get(self, "integration_type")

    @property
    @pulumi.getter(name="sourceServiceName")
    def source_service_name(self) -> str:
        return pulumi.get(self, "source_service_name")


@pulumi.output_type
class InfluxDbComponent(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "kafkaAuthenticationMethod":
            suggest = "kafka_authentication_method"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in InfluxDbComponent. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        InfluxDbComponent.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        InfluxDbComponent.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 component: Optional[str] = None,
                 host: Optional[str] = None,
                 kafka_authentication_method: Optional[str] = None,
                 port: Optional[int] = None,
                 route: Optional[str] = None,
                 ssl: Optional[bool] = None,
                 usage: Optional[str] = None):
        if component is not None:
            pulumi.set(__self__, "component", component)
        if host is not None:
            pulumi.set(__self__, "host", host)
        if kafka_authentication_method is not None:
            pulumi.set(__self__, "kafka_authentication_method", kafka_authentication_method)
        if port is not None:
            pulumi.set(__self__, "port", port)
        if route is not None:
            pulumi.set(__self__, "route", route)
        if ssl is not None:
            pulumi.set(__self__, "ssl", ssl)
        if usage is not None:
            pulumi.set(__self__, "usage", usage)

    @property
    @pulumi.getter
    def component(self) -> Optional[str]:
        return pulumi.get(self, "component")

    @property
    @pulumi.getter
    def host(self) -> Optional[str]:
        return pulumi.get(self, "host")

    @property
    @pulumi.getter(name="kafkaAuthenticationMethod")
    def kafka_authentication_method(self) -> Optional[str]:
        return pulumi.get(self, "kafka_authentication_method")

    @property
    @pulumi.getter
    def port(self) -> Optional[int]:
        return pulumi.get(self, "port")

    @property
    @pulumi.getter
    def route(self) -> Optional[str]:
        return pulumi.get(self, "route")

    @property
    @pulumi.getter
    def ssl(self) -> Optional[bool]:
        return pulumi.get(self, "ssl")

    @property
    @pulumi.getter
    def usage(self) -> Optional[str]:
        return pulumi.get(self, "usage")


@pulumi.output_type
class InfluxDbInfluxdb(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "databaseName":
            suggest = "database_name"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in InfluxDbInfluxdb. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        InfluxDbInfluxdb.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        InfluxDbInfluxdb.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 database_name: Optional[str] = None):
        if database_name is not None:
            pulumi.set(__self__, "database_name", database_name)

    @property
    @pulumi.getter(name="databaseName")
    def database_name(self) -> Optional[str]:
        return pulumi.get(self, "database_name")


@pulumi.output_type
class InfluxDbInfluxdbUserConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "customDomain":
            suggest = "custom_domain"
        elif key == "ipFilters":
            suggest = "ip_filters"
        elif key == "privateAccess":
            suggest = "private_access"
        elif key == "privatelinkAccess":
            suggest = "privatelink_access"
        elif key == "projectToForkFrom":
            suggest = "project_to_fork_from"
        elif key == "publicAccess":
            suggest = "public_access"
        elif key == "recoveryBasebackupName":
            suggest = "recovery_basebackup_name"
        elif key == "serviceToForkFrom":
            suggest = "service_to_fork_from"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in InfluxDbInfluxdbUserConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        InfluxDbInfluxdbUserConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        InfluxDbInfluxdbUserConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 custom_domain: Optional[str] = None,
                 influxdb: Optional['outputs.InfluxDbInfluxdbUserConfigInfluxdb'] = None,
                 ip_filters: Optional[Sequence[str]] = None,
                 private_access: Optional['outputs.InfluxDbInfluxdbUserConfigPrivateAccess'] = None,
                 privatelink_access: Optional['outputs.InfluxDbInfluxdbUserConfigPrivatelinkAccess'] = None,
                 project_to_fork_from: Optional[str] = None,
                 public_access: Optional['outputs.InfluxDbInfluxdbUserConfigPublicAccess'] = None,
                 recovery_basebackup_name: Optional[str] = None,
                 service_to_fork_from: Optional[str] = None):
        """
        :param str custom_domain: Serve the web frontend using a custom CNAME pointing to the Aiven DNS name
        :param 'InfluxDbInfluxdbUserConfigInfluxdbArgs' influxdb: influxdb.conf configuration values
        :param Sequence[str] ip_filters: allow incoming connections from CIDR address block, e.g. `10.20.0.0/16`
        :param 'InfluxDbInfluxdbUserConfigPrivateAccessArgs' private_access: Allow access to selected service ports from private networks
        :param 'InfluxDbInfluxdbUserConfigPrivatelinkAccessArgs' privatelink_access: Allow access to selected service components through Privatelink
        :param str project_to_fork_from: Name of another project to fork a service from. This has 
               effect only when a new service is being created.
        :param 'InfluxDbInfluxdbUserConfigPublicAccessArgs' public_access: Allow access to selected service ports from the public Internet
        :param str recovery_basebackup_name: Name of the basebackup to restore in forked service
        :param str service_to_fork_from: Name of another service to fork from. This has effect 
               only when a new service is being created.
        """
        if custom_domain is not None:
            pulumi.set(__self__, "custom_domain", custom_domain)
        if influxdb is not None:
            pulumi.set(__self__, "influxdb", influxdb)
        if ip_filters is not None:
            pulumi.set(__self__, "ip_filters", ip_filters)
        if private_access is not None:
            pulumi.set(__self__, "private_access", private_access)
        if privatelink_access is not None:
            pulumi.set(__self__, "privatelink_access", privatelink_access)
        if project_to_fork_from is not None:
            pulumi.set(__self__, "project_to_fork_from", project_to_fork_from)
        if public_access is not None:
            pulumi.set(__self__, "public_access", public_access)
        if recovery_basebackup_name is not None:
            pulumi.set(__self__, "recovery_basebackup_name", recovery_basebackup_name)
        if service_to_fork_from is not None:
            pulumi.set(__self__, "service_to_fork_from", service_to_fork_from)

    @property
    @pulumi.getter(name="customDomain")
    def custom_domain(self) -> Optional[str]:
        """
        Serve the web frontend using a custom CNAME pointing to the Aiven DNS name
        """
        return pulumi.get(self, "custom_domain")

    @property
    @pulumi.getter
    def influxdb(self) -> Optional['outputs.InfluxDbInfluxdbUserConfigInfluxdb']:
        """
        influxdb.conf configuration values
        """
        return pulumi.get(self, "influxdb")

    @property
    @pulumi.getter(name="ipFilters")
    def ip_filters(self) -> Optional[Sequence[str]]:
        """
        allow incoming connections from CIDR address block, e.g. `10.20.0.0/16`
        """
        return pulumi.get(self, "ip_filters")

    @property
    @pulumi.getter(name="privateAccess")
    def private_access(self) -> Optional['outputs.InfluxDbInfluxdbUserConfigPrivateAccess']:
        """
        Allow access to selected service ports from private networks
        """
        return pulumi.get(self, "private_access")

    @property
    @pulumi.getter(name="privatelinkAccess")
    def privatelink_access(self) -> Optional['outputs.InfluxDbInfluxdbUserConfigPrivatelinkAccess']:
        """
        Allow access to selected service components through Privatelink
        """
        return pulumi.get(self, "privatelink_access")

    @property
    @pulumi.getter(name="projectToForkFrom")
    def project_to_fork_from(self) -> Optional[str]:
        """
        Name of another project to fork a service from. This has 
        effect only when a new service is being created.
        """
        return pulumi.get(self, "project_to_fork_from")

    @property
    @pulumi.getter(name="publicAccess")
    def public_access(self) -> Optional['outputs.InfluxDbInfluxdbUserConfigPublicAccess']:
        """
        Allow access to selected service ports from the public Internet
        """
        return pulumi.get(self, "public_access")

    @property
    @pulumi.getter(name="recoveryBasebackupName")
    def recovery_basebackup_name(self) -> Optional[str]:
        """
        Name of the basebackup to restore in forked service
        """
        return pulumi.get(self, "recovery_basebackup_name")

    @property
    @pulumi.getter(name="serviceToForkFrom")
    def service_to_fork_from(self) -> Optional[str]:
        """
        Name of another service to fork from. This has effect 
        only when a new service is being created.
        """
        return pulumi.get(self, "service_to_fork_from")


@pulumi.output_type
class InfluxDbInfluxdbUserConfigInfluxdb(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "logQueriesAfter":
            suggest = "log_queries_after"
        elif key == "maxRowLimit":
            suggest = "max_row_limit"
        elif key == "maxSelectBuckets":
            suggest = "max_select_buckets"
        elif key == "maxSelectPoint":
            suggest = "max_select_point"
        elif key == "queryTimeout":
            suggest = "query_timeout"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in InfluxDbInfluxdbUserConfigInfluxdb. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        InfluxDbInfluxdbUserConfigInfluxdb.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        InfluxDbInfluxdbUserConfigInfluxdb.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 log_queries_after: Optional[str] = None,
                 max_row_limit: Optional[str] = None,
                 max_select_buckets: Optional[str] = None,
                 max_select_point: Optional[str] = None,
                 query_timeout: Optional[str] = None):
        """
        :param str log_queries_after: The maximum duration in seconds before a query is 
               logged as a slow query. Setting this to 0 (the default) will never log slow queries.
        :param str max_row_limit: The maximum number of rows returned in a non-chunked query. 
               Setting this to 0 (the default) allows an unlimited number to be returned.
        :param str max_select_buckets: The maximum number of `GROUP BY time()` buckets that 
               can be processed in a query. Setting this to 0 (the default) allows an unlimited number to
               be processed.
        :param str max_select_point: The maximum number of points that can be processed in a 
               SELECT statement. Setting this to 0 (the default) allows an unlimited number to be processed.
        :param str query_timeout: The maximum duration in seconds before a query is killed. 
               Setting this to 0 (the default) will never kill slow queries.
        """
        if log_queries_after is not None:
            pulumi.set(__self__, "log_queries_after", log_queries_after)
        if max_row_limit is not None:
            pulumi.set(__self__, "max_row_limit", max_row_limit)
        if max_select_buckets is not None:
            pulumi.set(__self__, "max_select_buckets", max_select_buckets)
        if max_select_point is not None:
            pulumi.set(__self__, "max_select_point", max_select_point)
        if query_timeout is not None:
            pulumi.set(__self__, "query_timeout", query_timeout)

    @property
    @pulumi.getter(name="logQueriesAfter")
    def log_queries_after(self) -> Optional[str]:
        """
        The maximum duration in seconds before a query is 
        logged as a slow query. Setting this to 0 (the default) will never log slow queries.
        """
        return pulumi.get(self, "log_queries_after")

    @property
    @pulumi.getter(name="maxRowLimit")
    def max_row_limit(self) -> Optional[str]:
        """
        The maximum number of rows returned in a non-chunked query. 
        Setting this to 0 (the default) allows an unlimited number to be returned.
        """
        return pulumi.get(self, "max_row_limit")

    @property
    @pulumi.getter(name="maxSelectBuckets")
    def max_select_buckets(self) -> Optional[str]:
        """
        The maximum number of `GROUP BY time()` buckets that 
        can be processed in a query. Setting this to 0 (the default) allows an unlimited number to
        be processed.
        """
        return pulumi.get(self, "max_select_buckets")

    @property
    @pulumi.getter(name="maxSelectPoint")
    def max_select_point(self) -> Optional[str]:
        """
        The maximum number of points that can be processed in a 
        SELECT statement. Setting this to 0 (the default) allows an unlimited number to be processed.
        """
        return pulumi.get(self, "max_select_point")

    @property
    @pulumi.getter(name="queryTimeout")
    def query_timeout(self) -> Optional[str]:
        """
        The maximum duration in seconds before a query is killed. 
        Setting this to 0 (the default) will never kill slow queries.
        """
        return pulumi.get(self, "query_timeout")


@pulumi.output_type
class InfluxDbInfluxdbUserConfigPrivateAccess(dict):
    def __init__(__self__, *,
                 influxdb: Optional[str] = None):
        """
        :param str influxdb: influxdb.conf configuration values
        """
        if influxdb is not None:
            pulumi.set(__self__, "influxdb", influxdb)

    @property
    @pulumi.getter
    def influxdb(self) -> Optional[str]:
        """
        influxdb.conf configuration values
        """
        return pulumi.get(self, "influxdb")


@pulumi.output_type
class InfluxDbInfluxdbUserConfigPrivatelinkAccess(dict):
    def __init__(__self__, *,
                 influxdb: Optional[str] = None):
        """
        :param str influxdb: influxdb.conf configuration values
        """
        if influxdb is not None:
            pulumi.set(__self__, "influxdb", influxdb)

    @property
    @pulumi.getter
    def influxdb(self) -> Optional[str]:
        """
        influxdb.conf configuration values
        """
        return pulumi.get(self, "influxdb")


@pulumi.output_type
class InfluxDbInfluxdbUserConfigPublicAccess(dict):
    def __init__(__self__, *,
                 influxdb: Optional[str] = None):
        """
        :param str influxdb: influxdb.conf configuration values
        """
        if influxdb is not None:
            pulumi.set(__self__, "influxdb", influxdb)

    @property
    @pulumi.getter
    def influxdb(self) -> Optional[str]:
        """
        influxdb.conf configuration values
        """
        return pulumi.get(self, "influxdb")


@pulumi.output_type
class InfluxDbServiceIntegration(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "integrationType":
            suggest = "integration_type"
        elif key == "sourceServiceName":
            suggest = "source_service_name"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in InfluxDbServiceIntegration. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        InfluxDbServiceIntegration.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        InfluxDbServiceIntegration.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 integration_type: str,
                 source_service_name: str):
        pulumi.set(__self__, "integration_type", integration_type)
        pulumi.set(__self__, "source_service_name", source_service_name)

    @property
    @pulumi.getter(name="integrationType")
    def integration_type(self) -> str:
        return pulumi.get(self, "integration_type")

    @property
    @pulumi.getter(name="sourceServiceName")
    def source_service_name(self) -> str:
        return pulumi.get(self, "source_service_name")


@pulumi.output_type
class KafkaComponent(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "kafkaAuthenticationMethod":
            suggest = "kafka_authentication_method"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in KafkaComponent. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        KafkaComponent.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        KafkaComponent.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 component: Optional[str] = None,
                 host: Optional[str] = None,
                 kafka_authentication_method: Optional[str] = None,
                 port: Optional[int] = None,
                 route: Optional[str] = None,
                 ssl: Optional[bool] = None,
                 usage: Optional[str] = None):
        if component is not None:
            pulumi.set(__self__, "component", component)
        if host is not None:
            pulumi.set(__self__, "host", host)
        if kafka_authentication_method is not None:
            pulumi.set(__self__, "kafka_authentication_method", kafka_authentication_method)
        if port is not None:
            pulumi.set(__self__, "port", port)
        if route is not None:
            pulumi.set(__self__, "route", route)
        if ssl is not None:
            pulumi.set(__self__, "ssl", ssl)
        if usage is not None:
            pulumi.set(__self__, "usage", usage)

    @property
    @pulumi.getter
    def component(self) -> Optional[str]:
        return pulumi.get(self, "component")

    @property
    @pulumi.getter
    def host(self) -> Optional[str]:
        return pulumi.get(self, "host")

    @property
    @pulumi.getter(name="kafkaAuthenticationMethod")
    def kafka_authentication_method(self) -> Optional[str]:
        return pulumi.get(self, "kafka_authentication_method")

    @property
    @pulumi.getter
    def port(self) -> Optional[int]:
        return pulumi.get(self, "port")

    @property
    @pulumi.getter
    def route(self) -> Optional[str]:
        return pulumi.get(self, "route")

    @property
    @pulumi.getter
    def ssl(self) -> Optional[bool]:
        return pulumi.get(self, "ssl")

    @property
    @pulumi.getter
    def usage(self) -> Optional[str]:
        return pulumi.get(self, "usage")


@pulumi.output_type
class KafkaConnectComponent(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "kafkaAuthenticationMethod":
            suggest = "kafka_authentication_method"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in KafkaConnectComponent. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        KafkaConnectComponent.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        KafkaConnectComponent.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 component: Optional[str] = None,
                 host: Optional[str] = None,
                 kafka_authentication_method: Optional[str] = None,
                 port: Optional[int] = None,
                 route: Optional[str] = None,
                 ssl: Optional[bool] = None,
                 usage: Optional[str] = None):
        if component is not None:
            pulumi.set(__self__, "component", component)
        if host is not None:
            pulumi.set(__self__, "host", host)
        if kafka_authentication_method is not None:
            pulumi.set(__self__, "kafka_authentication_method", kafka_authentication_method)
        if port is not None:
            pulumi.set(__self__, "port", port)
        if route is not None:
            pulumi.set(__self__, "route", route)
        if ssl is not None:
            pulumi.set(__self__, "ssl", ssl)
        if usage is not None:
            pulumi.set(__self__, "usage", usage)

    @property
    @pulumi.getter
    def component(self) -> Optional[str]:
        return pulumi.get(self, "component")

    @property
    @pulumi.getter
    def host(self) -> Optional[str]:
        return pulumi.get(self, "host")

    @property
    @pulumi.getter(name="kafkaAuthenticationMethod")
    def kafka_authentication_method(self) -> Optional[str]:
        return pulumi.get(self, "kafka_authentication_method")

    @property
    @pulumi.getter
    def port(self) -> Optional[int]:
        return pulumi.get(self, "port")

    @property
    @pulumi.getter
    def route(self) -> Optional[str]:
        return pulumi.get(self, "route")

    @property
    @pulumi.getter
    def ssl(self) -> Optional[bool]:
        return pulumi.get(self, "ssl")

    @property
    @pulumi.getter
    def usage(self) -> Optional[str]:
        return pulumi.get(self, "usage")


@pulumi.output_type
class KafkaConnectKafkaConnect(dict):
    def __init__(__self__):
        pass


@pulumi.output_type
class KafkaConnectKafkaConnectUserConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "ipFilters":
            suggest = "ip_filters"
        elif key == "kafkaConnect":
            suggest = "kafka_connect"
        elif key == "privateAccess":
            suggest = "private_access"
        elif key == "privatelinkAccess":
            suggest = "privatelink_access"
        elif key == "publicAccess":
            suggest = "public_access"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in KafkaConnectKafkaConnectUserConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        KafkaConnectKafkaConnectUserConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        KafkaConnectKafkaConnectUserConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 ip_filters: Optional[Sequence[str]] = None,
                 kafka_connect: Optional['outputs.KafkaConnectKafkaConnectUserConfigKafkaConnect'] = None,
                 private_access: Optional['outputs.KafkaConnectKafkaConnectUserConfigPrivateAccess'] = None,
                 privatelink_access: Optional['outputs.KafkaConnectKafkaConnectUserConfigPrivatelinkAccess'] = None,
                 public_access: Optional['outputs.KafkaConnectKafkaConnectUserConfigPublicAccess'] = None):
        """
        :param Sequence[str] ip_filters: allow incoming connections from CIDR address block, e.g. `10.20.0.0/16`
        :param 'KafkaConnectKafkaConnectUserConfigKafkaConnectArgs' kafka_connect: Allow clients to connect to kafka_connect from the public internet for 
               service nodes that are in a project VPC or another type of private network.
        :param 'KafkaConnectKafkaConnectUserConfigPrivateAccessArgs' private_access: Allow access to selected service ports from private networks.
        :param 'KafkaConnectKafkaConnectUserConfigPrivatelinkAccessArgs' privatelink_access: Allow access to selected service components through Privatelink
        :param 'KafkaConnectKafkaConnectUserConfigPublicAccessArgs' public_access: Allow access to selected service ports from the public Internet.
        """
        if ip_filters is not None:
            pulumi.set(__self__, "ip_filters", ip_filters)
        if kafka_connect is not None:
            pulumi.set(__self__, "kafka_connect", kafka_connect)
        if private_access is not None:
            pulumi.set(__self__, "private_access", private_access)
        if privatelink_access is not None:
            pulumi.set(__self__, "privatelink_access", privatelink_access)
        if public_access is not None:
            pulumi.set(__self__, "public_access", public_access)

    @property
    @pulumi.getter(name="ipFilters")
    def ip_filters(self) -> Optional[Sequence[str]]:
        """
        allow incoming connections from CIDR address block, e.g. `10.20.0.0/16`
        """
        return pulumi.get(self, "ip_filters")

    @property
    @pulumi.getter(name="kafkaConnect")
    def kafka_connect(self) -> Optional['outputs.KafkaConnectKafkaConnectUserConfigKafkaConnect']:
        """
        Allow clients to connect to kafka_connect from the public internet for 
        service nodes that are in a project VPC or another type of private network.
        """
        return pulumi.get(self, "kafka_connect")

    @property
    @pulumi.getter(name="privateAccess")
    def private_access(self) -> Optional['outputs.KafkaConnectKafkaConnectUserConfigPrivateAccess']:
        """
        Allow access to selected service ports from private networks.
        """
        return pulumi.get(self, "private_access")

    @property
    @pulumi.getter(name="privatelinkAccess")
    def privatelink_access(self) -> Optional['outputs.KafkaConnectKafkaConnectUserConfigPrivatelinkAccess']:
        """
        Allow access to selected service components through Privatelink
        """
        return pulumi.get(self, "privatelink_access")

    @property
    @pulumi.getter(name="publicAccess")
    def public_access(self) -> Optional['outputs.KafkaConnectKafkaConnectUserConfigPublicAccess']:
        """
        Allow access to selected service ports from the public Internet.
        """
        return pulumi.get(self, "public_access")


@pulumi.output_type
class KafkaConnectKafkaConnectUserConfigKafkaConnect(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "connectorClientConfigOverridePolicy":
            suggest = "connector_client_config_override_policy"
        elif key == "consumerAutoOffsetReset":
            suggest = "consumer_auto_offset_reset"
        elif key == "consumerFetchMaxBytes":
            suggest = "consumer_fetch_max_bytes"
        elif key == "consumerIsolationLevel":
            suggest = "consumer_isolation_level"
        elif key == "consumerMaxPartitionFetchBytes":
            suggest = "consumer_max_partition_fetch_bytes"
        elif key == "consumerMaxPollIntervalMs":
            suggest = "consumer_max_poll_interval_ms"
        elif key == "consumerMaxPollRecords":
            suggest = "consumer_max_poll_records"
        elif key == "offsetFlushIntervalMs":
            suggest = "offset_flush_interval_ms"
        elif key == "offsetFlushTimeoutMs":
            suggest = "offset_flush_timeout_ms"
        elif key == "producerMaxRequestSize":
            suggest = "producer_max_request_size"
        elif key == "sessionTimeoutMs":
            suggest = "session_timeout_ms"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in KafkaConnectKafkaConnectUserConfigKafkaConnect. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        KafkaConnectKafkaConnectUserConfigKafkaConnect.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        KafkaConnectKafkaConnectUserConfigKafkaConnect.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 connector_client_config_override_policy: Optional[str] = None,
                 consumer_auto_offset_reset: Optional[str] = None,
                 consumer_fetch_max_bytes: Optional[str] = None,
                 consumer_isolation_level: Optional[str] = None,
                 consumer_max_partition_fetch_bytes: Optional[str] = None,
                 consumer_max_poll_interval_ms: Optional[str] = None,
                 consumer_max_poll_records: Optional[str] = None,
                 offset_flush_interval_ms: Optional[str] = None,
                 offset_flush_timeout_ms: Optional[str] = None,
                 producer_max_request_size: Optional[str] = None,
                 session_timeout_ms: Optional[str] = None):
        """
        :param str connector_client_config_override_policy: Defines what client configurations can be 
               overridden by the connector. Default is None.
        :param str consumer_auto_offset_reset: What to do when there is no initial offset in Kafka or 
               if the current offset does not exist any more on the server. Default is earliest.
        :param str consumer_fetch_max_bytes: Records are fetched in batches by the consumer, and if 
               the first record batch in the first non-empty partition of the fetch is larger than this value,
               the record batch will still be returned to ensure that the consumer can make progress. As such,
               this is not a absolute maximum.
        :param str consumer_isolation_level: Transaction read isolation level. read_uncommitted is 
               the default, but read_committed can be used if consume-exactly-once behavior is desired.
        :param str consumer_max_partition_fetch_bytes: Records are fetched in batches by the consumer.If 
               the first record batch in the first non-empty partition of the fetch is larger than this limit,
               the batch will still be returned to ensure that the consumer can make progress.
        :param str consumer_max_poll_interval_ms: The maximum delay in milliseconds between invocations 
               of poll() when using consumer group management (defaults to 300000).
        :param str consumer_max_poll_records: The maximum number of records returned by a single poll.
        :param str offset_flush_interval_ms: The interval at which to try committing offsets for tasks 
               (defaults to 60000).
        :param str offset_flush_timeout_ms: Maximum number of milliseconds to wait for records to flush 
               and partition offset data to be committed to offset storage before cancelling the process and restoring
               the offset data to be committed in a future attempt (defaults to 5000).
        :param str producer_max_request_size: This setting will limit the number of record batches the 
               producer will send in a single request to avoid sending huge requests.
        :param str session_timeout_ms: The timeout in milliseconds used to detect failures when using Kafkas 
               group management facilities (defaults to 10000).
        """
        if connector_client_config_override_policy is not None:
            pulumi.set(__self__, "connector_client_config_override_policy", connector_client_config_override_policy)
        if consumer_auto_offset_reset is not None:
            pulumi.set(__self__, "consumer_auto_offset_reset", consumer_auto_offset_reset)
        if consumer_fetch_max_bytes is not None:
            pulumi.set(__self__, "consumer_fetch_max_bytes", consumer_fetch_max_bytes)
        if consumer_isolation_level is not None:
            pulumi.set(__self__, "consumer_isolation_level", consumer_isolation_level)
        if consumer_max_partition_fetch_bytes is not None:
            pulumi.set(__self__, "consumer_max_partition_fetch_bytes", consumer_max_partition_fetch_bytes)
        if consumer_max_poll_interval_ms is not None:
            pulumi.set(__self__, "consumer_max_poll_interval_ms", consumer_max_poll_interval_ms)
        if consumer_max_poll_records is not None:
            pulumi.set(__self__, "consumer_max_poll_records", consumer_max_poll_records)
        if offset_flush_interval_ms is not None:
            pulumi.set(__self__, "offset_flush_interval_ms", offset_flush_interval_ms)
        if offset_flush_timeout_ms is not None:
            pulumi.set(__self__, "offset_flush_timeout_ms", offset_flush_timeout_ms)
        if producer_max_request_size is not None:
            pulumi.set(__self__, "producer_max_request_size", producer_max_request_size)
        if session_timeout_ms is not None:
            pulumi.set(__self__, "session_timeout_ms", session_timeout_ms)

    @property
    @pulumi.getter(name="connectorClientConfigOverridePolicy")
    def connector_client_config_override_policy(self) -> Optional[str]:
        """
        Defines what client configurations can be 
        overridden by the connector. Default is None.
        """
        return pulumi.get(self, "connector_client_config_override_policy")

    @property
    @pulumi.getter(name="consumerAutoOffsetReset")
    def consumer_auto_offset_reset(self) -> Optional[str]:
        """
        What to do when there is no initial offset in Kafka or 
        if the current offset does not exist any more on the server. Default is earliest.
        """
        return pulumi.get(self, "consumer_auto_offset_reset")

    @property
    @pulumi.getter(name="consumerFetchMaxBytes")
    def consumer_fetch_max_bytes(self) -> Optional[str]:
        """
        Records are fetched in batches by the consumer, and if 
        the first record batch in the first non-empty partition of the fetch is larger than this value,
        the record batch will still be returned to ensure that the consumer can make progress. As such,
        this is not a absolute maximum.
        """
        return pulumi.get(self, "consumer_fetch_max_bytes")

    @property
    @pulumi.getter(name="consumerIsolationLevel")
    def consumer_isolation_level(self) -> Optional[str]:
        """
        Transaction read isolation level. read_uncommitted is 
        the default, but read_committed can be used if consume-exactly-once behavior is desired.
        """
        return pulumi.get(self, "consumer_isolation_level")

    @property
    @pulumi.getter(name="consumerMaxPartitionFetchBytes")
    def consumer_max_partition_fetch_bytes(self) -> Optional[str]:
        """
        Records are fetched in batches by the consumer.If 
        the first record batch in the first non-empty partition of the fetch is larger than this limit,
        the batch will still be returned to ensure that the consumer can make progress.
        """
        return pulumi.get(self, "consumer_max_partition_fetch_bytes")

    @property
    @pulumi.getter(name="consumerMaxPollIntervalMs")
    def consumer_max_poll_interval_ms(self) -> Optional[str]:
        """
        The maximum delay in milliseconds between invocations 
        of poll() when using consumer group management (defaults to 300000).
        """
        return pulumi.get(self, "consumer_max_poll_interval_ms")

    @property
    @pulumi.getter(name="consumerMaxPollRecords")
    def consumer_max_poll_records(self) -> Optional[str]:
        """
        The maximum number of records returned by a single poll.
        """
        return pulumi.get(self, "consumer_max_poll_records")

    @property
    @pulumi.getter(name="offsetFlushIntervalMs")
    def offset_flush_interval_ms(self) -> Optional[str]:
        """
        The interval at which to try committing offsets for tasks 
        (defaults to 60000).
        """
        return pulumi.get(self, "offset_flush_interval_ms")

    @property
    @pulumi.getter(name="offsetFlushTimeoutMs")
    def offset_flush_timeout_ms(self) -> Optional[str]:
        """
        Maximum number of milliseconds to wait for records to flush 
        and partition offset data to be committed to offset storage before cancelling the process and restoring
        the offset data to be committed in a future attempt (defaults to 5000).
        """
        return pulumi.get(self, "offset_flush_timeout_ms")

    @property
    @pulumi.getter(name="producerMaxRequestSize")
    def producer_max_request_size(self) -> Optional[str]:
        """
        This setting will limit the number of record batches the 
        producer will send in a single request to avoid sending huge requests.
        """
        return pulumi.get(self, "producer_max_request_size")

    @property
    @pulumi.getter(name="sessionTimeoutMs")
    def session_timeout_ms(self) -> Optional[str]:
        """
        The timeout in milliseconds used to detect failures when using Kafkas 
        group management facilities (defaults to 10000).
        """
        return pulumi.get(self, "session_timeout_ms")


@pulumi.output_type
class KafkaConnectKafkaConnectUserConfigPrivateAccess(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "kafkaConnect":
            suggest = "kafka_connect"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in KafkaConnectKafkaConnectUserConfigPrivateAccess. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        KafkaConnectKafkaConnectUserConfigPrivateAccess.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        KafkaConnectKafkaConnectUserConfigPrivateAccess.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 kafka_connect: Optional[str] = None,
                 prometheus: Optional[str] = None):
        """
        :param str kafka_connect: Allow clients to connect to kafka_connect from the public internet for 
               service nodes that are in a project VPC or another type of private network.
        :param str prometheus: Allow clients to connect to prometheus from the public internet for service 
               nodes that are in a project VPC or another type of private network.
        """
        if kafka_connect is not None:
            pulumi.set(__self__, "kafka_connect", kafka_connect)
        if prometheus is not None:
            pulumi.set(__self__, "prometheus", prometheus)

    @property
    @pulumi.getter(name="kafkaConnect")
    def kafka_connect(self) -> Optional[str]:
        """
        Allow clients to connect to kafka_connect from the public internet for 
        service nodes that are in a project VPC or another type of private network.
        """
        return pulumi.get(self, "kafka_connect")

    @property
    @pulumi.getter
    def prometheus(self) -> Optional[str]:
        """
        Allow clients to connect to prometheus from the public internet for service 
        nodes that are in a project VPC or another type of private network.
        """
        return pulumi.get(self, "prometheus")


@pulumi.output_type
class KafkaConnectKafkaConnectUserConfigPrivatelinkAccess(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "kafkaConnect":
            suggest = "kafka_connect"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in KafkaConnectKafkaConnectUserConfigPrivatelinkAccess. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        KafkaConnectKafkaConnectUserConfigPrivatelinkAccess.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        KafkaConnectKafkaConnectUserConfigPrivatelinkAccess.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 kafka_connect: Optional[str] = None):
        """
        :param str kafka_connect: Allow clients to connect to kafka_connect from the public internet for 
               service nodes that are in a project VPC or another type of private network.
        """
        if kafka_connect is not None:
            pulumi.set(__self__, "kafka_connect", kafka_connect)

    @property
    @pulumi.getter(name="kafkaConnect")
    def kafka_connect(self) -> Optional[str]:
        """
        Allow clients to connect to kafka_connect from the public internet for 
        service nodes that are in a project VPC or another type of private network.
        """
        return pulumi.get(self, "kafka_connect")


@pulumi.output_type
class KafkaConnectKafkaConnectUserConfigPublicAccess(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "kafkaConnect":
            suggest = "kafka_connect"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in KafkaConnectKafkaConnectUserConfigPublicAccess. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        KafkaConnectKafkaConnectUserConfigPublicAccess.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        KafkaConnectKafkaConnectUserConfigPublicAccess.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 kafka_connect: Optional[str] = None,
                 prometheus: Optional[str] = None):
        """
        :param str kafka_connect: Allow clients to connect to kafka_connect from the public internet for 
               service nodes that are in a project VPC or another type of private network.
        :param str prometheus: Allow clients to connect to prometheus from the public internet for service 
               nodes that are in a project VPC or another type of private network.
        """
        if kafka_connect is not None:
            pulumi.set(__self__, "kafka_connect", kafka_connect)
        if prometheus is not None:
            pulumi.set(__self__, "prometheus", prometheus)

    @property
    @pulumi.getter(name="kafkaConnect")
    def kafka_connect(self) -> Optional[str]:
        """
        Allow clients to connect to kafka_connect from the public internet for 
        service nodes that are in a project VPC or another type of private network.
        """
        return pulumi.get(self, "kafka_connect")

    @property
    @pulumi.getter
    def prometheus(self) -> Optional[str]:
        """
        Allow clients to connect to prometheus from the public internet for service 
        nodes that are in a project VPC or another type of private network.
        """
        return pulumi.get(self, "prometheus")


@pulumi.output_type
class KafkaConnectServiceIntegration(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "integrationType":
            suggest = "integration_type"
        elif key == "sourceServiceName":
            suggest = "source_service_name"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in KafkaConnectServiceIntegration. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        KafkaConnectServiceIntegration.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        KafkaConnectServiceIntegration.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 integration_type: str,
                 source_service_name: str):
        pulumi.set(__self__, "integration_type", integration_type)
        pulumi.set(__self__, "source_service_name", source_service_name)

    @property
    @pulumi.getter(name="integrationType")
    def integration_type(self) -> str:
        return pulumi.get(self, "integration_type")

    @property
    @pulumi.getter(name="sourceServiceName")
    def source_service_name(self) -> str:
        return pulumi.get(self, "source_service_name")


@pulumi.output_type
class KafkaConnectorTask(dict):
    def __init__(__self__, *,
                 connector: Optional[str] = None,
                 task: Optional[int] = None):
        """
        :param int task: List of tasks of a connector, each element contains `connector` 
               (Related connector name) and `task` (Task id / number).
        """
        if connector is not None:
            pulumi.set(__self__, "connector", connector)
        if task is not None:
            pulumi.set(__self__, "task", task)

    @property
    @pulumi.getter
    def connector(self) -> Optional[str]:
        return pulumi.get(self, "connector")

    @property
    @pulumi.getter
    def task(self) -> Optional[int]:
        """
        List of tasks of a connector, each element contains `connector` 
        (Related connector name) and `task` (Task id / number).
        """
        return pulumi.get(self, "task")


@pulumi.output_type
class KafkaKafka(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "accessCert":
            suggest = "access_cert"
        elif key == "accessKey":
            suggest = "access_key"
        elif key == "connectUri":
            suggest = "connect_uri"
        elif key == "restUri":
            suggest = "rest_uri"
        elif key == "schemaRegistryUri":
            suggest = "schema_registry_uri"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in KafkaKafka. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        KafkaKafka.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        KafkaKafka.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 access_cert: Optional[str] = None,
                 access_key: Optional[str] = None,
                 connect_uri: Optional[str] = None,
                 rest_uri: Optional[str] = None,
                 schema_registry_uri: Optional[str] = None):
        """
        :param str access_cert: The Kafka client certificate
        :param str access_key: The Kafka client certificate key
        :param str connect_uri: The Kafka Connect URI, if any
        :param str rest_uri: The Kafka REST URI, if any
        :param str schema_registry_uri: The Schema Registry URI, if any
        """
        if access_cert is not None:
            pulumi.set(__self__, "access_cert", access_cert)
        if access_key is not None:
            pulumi.set(__self__, "access_key", access_key)
        if connect_uri is not None:
            pulumi.set(__self__, "connect_uri", connect_uri)
        if rest_uri is not None:
            pulumi.set(__self__, "rest_uri", rest_uri)
        if schema_registry_uri is not None:
            pulumi.set(__self__, "schema_registry_uri", schema_registry_uri)

    @property
    @pulumi.getter(name="accessCert")
    def access_cert(self) -> Optional[str]:
        """
        The Kafka client certificate
        """
        return pulumi.get(self, "access_cert")

    @property
    @pulumi.getter(name="accessKey")
    def access_key(self) -> Optional[str]:
        """
        The Kafka client certificate key
        """
        return pulumi.get(self, "access_key")

    @property
    @pulumi.getter(name="connectUri")
    def connect_uri(self) -> Optional[str]:
        """
        The Kafka Connect URI, if any
        """
        return pulumi.get(self, "connect_uri")

    @property
    @pulumi.getter(name="restUri")
    def rest_uri(self) -> Optional[str]:
        """
        The Kafka REST URI, if any
        """
        return pulumi.get(self, "rest_uri")

    @property
    @pulumi.getter(name="schemaRegistryUri")
    def schema_registry_uri(self) -> Optional[str]:
        """
        The Schema Registry URI, if any
        """
        return pulumi.get(self, "schema_registry_uri")


@pulumi.output_type
class KafkaKafkaUserConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "customDomain":
            suggest = "custom_domain"
        elif key == "ipFilters":
            suggest = "ip_filters"
        elif key == "kafkaAuthenticationMethods":
            suggest = "kafka_authentication_methods"
        elif key == "kafkaConnect":
            suggest = "kafka_connect"
        elif key == "kafkaConnectConfig":
            suggest = "kafka_connect_config"
        elif key == "kafkaRest":
            suggest = "kafka_rest"
        elif key == "kafkaRestConfig":
            suggest = "kafka_rest_config"
        elif key == "kafkaVersion":
            suggest = "kafka_version"
        elif key == "privateAccess":
            suggest = "private_access"
        elif key == "privatelinkAccess":
            suggest = "privatelink_access"
        elif key == "publicAccess":
            suggest = "public_access"
        elif key == "schemaRegistry":
            suggest = "schema_registry"
        elif key == "schemaRegistryConfig":
            suggest = "schema_registry_config"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in KafkaKafkaUserConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        KafkaKafkaUserConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        KafkaKafkaUserConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 custom_domain: Optional[str] = None,
                 ip_filters: Optional[Sequence[str]] = None,
                 kafka: Optional['outputs.KafkaKafkaUserConfigKafka'] = None,
                 kafka_authentication_methods: Optional['outputs.KafkaKafkaUserConfigKafkaAuthenticationMethods'] = None,
                 kafka_connect: Optional[str] = None,
                 kafka_connect_config: Optional['outputs.KafkaKafkaUserConfigKafkaConnectConfig'] = None,
                 kafka_rest: Optional[str] = None,
                 kafka_rest_config: Optional['outputs.KafkaKafkaUserConfigKafkaRestConfig'] = None,
                 kafka_version: Optional[str] = None,
                 private_access: Optional['outputs.KafkaKafkaUserConfigPrivateAccess'] = None,
                 privatelink_access: Optional['outputs.KafkaKafkaUserConfigPrivatelinkAccess'] = None,
                 public_access: Optional['outputs.KafkaKafkaUserConfigPublicAccess'] = None,
                 schema_registry: Optional[str] = None,
                 schema_registry_config: Optional['outputs.KafkaKafkaUserConfigSchemaRegistryConfig'] = None):
        """
        :param str custom_domain: Serve the web frontend using a custom CNAME pointing to the Aiven DNS name.
        :param Sequence[str] ip_filters: Allow incoming connections from CIDR address block, e.g. '10.20.0.0/16'.
        :param 'KafkaKafkaUserConfigKafkaArgs' kafka: Enable kafka
        :param 'KafkaKafkaUserConfigKafkaAuthenticationMethodsArgs' kafka_authentication_methods: Kafka authentication methods
        :param str kafka_connect: Enable kafka_connect
        :param 'KafkaKafkaUserConfigKafkaConnectConfigArgs' kafka_connect_config: Kafka Connect configuration values
        :param str kafka_rest: Enable kafka_rest
        :param 'KafkaKafkaUserConfigKafkaRestConfigArgs' kafka_rest_config: Kafka-REST configuration
        :param str kafka_version: Kafka major version
        :param 'KafkaKafkaUserConfigPrivateAccessArgs' private_access: Allow access to selected service ports from private networks
        :param 'KafkaKafkaUserConfigPrivatelinkAccessArgs' privatelink_access: Allow access to selected service components through Privatelink
        :param 'KafkaKafkaUserConfigPublicAccessArgs' public_access: Allow access to selected service ports from the public Internet
        :param str schema_registry: Enable Schema-Registry service
        :param 'KafkaKafkaUserConfigSchemaRegistryConfigArgs' schema_registry_config: Schema Registry configuration
        """
        if custom_domain is not None:
            pulumi.set(__self__, "custom_domain", custom_domain)
        if ip_filters is not None:
            pulumi.set(__self__, "ip_filters", ip_filters)
        if kafka is not None:
            pulumi.set(__self__, "kafka", kafka)
        if kafka_authentication_methods is not None:
            pulumi.set(__self__, "kafka_authentication_methods", kafka_authentication_methods)
        if kafka_connect is not None:
            pulumi.set(__self__, "kafka_connect", kafka_connect)
        if kafka_connect_config is not None:
            pulumi.set(__self__, "kafka_connect_config", kafka_connect_config)
        if kafka_rest is not None:
            pulumi.set(__self__, "kafka_rest", kafka_rest)
        if kafka_rest_config is not None:
            pulumi.set(__self__, "kafka_rest_config", kafka_rest_config)
        if kafka_version is not None:
            pulumi.set(__self__, "kafka_version", kafka_version)
        if private_access is not None:
            pulumi.set(__self__, "private_access", private_access)
        if privatelink_access is not None:
            pulumi.set(__self__, "privatelink_access", privatelink_access)
        if public_access is not None:
            pulumi.set(__self__, "public_access", public_access)
        if schema_registry is not None:
            pulumi.set(__self__, "schema_registry", schema_registry)
        if schema_registry_config is not None:
            pulumi.set(__self__, "schema_registry_config", schema_registry_config)

    @property
    @pulumi.getter(name="customDomain")
    def custom_domain(self) -> Optional[str]:
        """
        Serve the web frontend using a custom CNAME pointing to the Aiven DNS name.
        """
        return pulumi.get(self, "custom_domain")

    @property
    @pulumi.getter(name="ipFilters")
    def ip_filters(self) -> Optional[Sequence[str]]:
        """
        Allow incoming connections from CIDR address block, e.g. '10.20.0.0/16'.
        """
        return pulumi.get(self, "ip_filters")

    @property
    @pulumi.getter
    def kafka(self) -> Optional['outputs.KafkaKafkaUserConfigKafka']:
        """
        Enable kafka
        """
        return pulumi.get(self, "kafka")

    @property
    @pulumi.getter(name="kafkaAuthenticationMethods")
    def kafka_authentication_methods(self) -> Optional['outputs.KafkaKafkaUserConfigKafkaAuthenticationMethods']:
        """
        Kafka authentication methods
        """
        return pulumi.get(self, "kafka_authentication_methods")

    @property
    @pulumi.getter(name="kafkaConnect")
    def kafka_connect(self) -> Optional[str]:
        """
        Enable kafka_connect
        """
        return pulumi.get(self, "kafka_connect")

    @property
    @pulumi.getter(name="kafkaConnectConfig")
    def kafka_connect_config(self) -> Optional['outputs.KafkaKafkaUserConfigKafkaConnectConfig']:
        """
        Kafka Connect configuration values
        """
        return pulumi.get(self, "kafka_connect_config")

    @property
    @pulumi.getter(name="kafkaRest")
    def kafka_rest(self) -> Optional[str]:
        """
        Enable kafka_rest
        """
        return pulumi.get(self, "kafka_rest")

    @property
    @pulumi.getter(name="kafkaRestConfig")
    def kafka_rest_config(self) -> Optional['outputs.KafkaKafkaUserConfigKafkaRestConfig']:
        """
        Kafka-REST configuration
        """
        return pulumi.get(self, "kafka_rest_config")

    @property
    @pulumi.getter(name="kafkaVersion")
    def kafka_version(self) -> Optional[str]:
        """
        Kafka major version
        """
        return pulumi.get(self, "kafka_version")

    @property
    @pulumi.getter(name="privateAccess")
    def private_access(self) -> Optional['outputs.KafkaKafkaUserConfigPrivateAccess']:
        """
        Allow access to selected service ports from private networks
        """
        return pulumi.get(self, "private_access")

    @property
    @pulumi.getter(name="privatelinkAccess")
    def privatelink_access(self) -> Optional['outputs.KafkaKafkaUserConfigPrivatelinkAccess']:
        """
        Allow access to selected service components through Privatelink
        """
        return pulumi.get(self, "privatelink_access")

    @property
    @pulumi.getter(name="publicAccess")
    def public_access(self) -> Optional['outputs.KafkaKafkaUserConfigPublicAccess']:
        """
        Allow access to selected service ports from the public Internet
        """
        return pulumi.get(self, "public_access")

    @property
    @pulumi.getter(name="schemaRegistry")
    def schema_registry(self) -> Optional[str]:
        """
        Enable Schema-Registry service
        """
        return pulumi.get(self, "schema_registry")

    @property
    @pulumi.getter(name="schemaRegistryConfig")
    def schema_registry_config(self) -> Optional['outputs.KafkaKafkaUserConfigSchemaRegistryConfig']:
        """
        Schema Registry configuration
        """
        return pulumi.get(self, "schema_registry_config")


@pulumi.output_type
class KafkaKafkaUserConfigKafka(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "autoCreateTopicsEnable":
            suggest = "auto_create_topics_enable"
        elif key == "compressionType":
            suggest = "compression_type"
        elif key == "connectionsMaxIdleMs":
            suggest = "connections_max_idle_ms"
        elif key == "defaultReplicationFactor":
            suggest = "default_replication_factor"
        elif key == "groupInitialRebalanceDelayMs":
            suggest = "group_initial_rebalance_delay_ms"
        elif key == "groupMaxSessionTimeoutMs":
            suggest = "group_max_session_timeout_ms"
        elif key == "groupMinSessionTimeoutMs":
            suggest = "group_min_session_timeout_ms"
        elif key == "logCleanerDeleteRetentionMs":
            suggest = "log_cleaner_delete_retention_ms"
        elif key == "logCleanerMaxCompactionLagMs":
            suggest = "log_cleaner_max_compaction_lag_ms"
        elif key == "logCleanerMinCleanableRatio":
            suggest = "log_cleaner_min_cleanable_ratio"
        elif key == "logCleanerMinCompactionLagMs":
            suggest = "log_cleaner_min_compaction_lag_ms"
        elif key == "logCleanupPolicy":
            suggest = "log_cleanup_policy"
        elif key == "logFlushIntervalMessages":
            suggest = "log_flush_interval_messages"
        elif key == "logFlushIntervalMs":
            suggest = "log_flush_interval_ms"
        elif key == "logIndexIntervalBytes":
            suggest = "log_index_interval_bytes"
        elif key == "logIndexSizeMaxBytes":
            suggest = "log_index_size_max_bytes"
        elif key == "logMessageDownconversionEnable":
            suggest = "log_message_downconversion_enable"
        elif key == "logMessageTimestampDifferenceMaxMs":
            suggest = "log_message_timestamp_difference_max_ms"
        elif key == "logMessageTimestampType":
            suggest = "log_message_timestamp_type"
        elif key == "logPreallocate":
            suggest = "log_preallocate"
        elif key == "logRetentionBytes":
            suggest = "log_retention_bytes"
        elif key == "logRetentionHours":
            suggest = "log_retention_hours"
        elif key == "logRetentionMs":
            suggest = "log_retention_ms"
        elif key == "logRollJitterMs":
            suggest = "log_roll_jitter_ms"
        elif key == "logRollMs":
            suggest = "log_roll_ms"
        elif key == "logSegmentBytes":
            suggest = "log_segment_bytes"
        elif key == "logSegmentDeleteDelayMs":
            suggest = "log_segment_delete_delay_ms"
        elif key == "maxConnectionsPerIp":
            suggest = "max_connections_per_ip"
        elif key == "maxIncrementalFetchSessionCacheSlots":
            suggest = "max_incremental_fetch_session_cache_slots"
        elif key == "messageMaxBytes":
            suggest = "message_max_bytes"
        elif key == "minInsyncReplicas":
            suggest = "min_insync_replicas"
        elif key == "numPartitions":
            suggest = "num_partitions"
        elif key == "offsetsRetentionMinutes":
            suggest = "offsets_retention_minutes"
        elif key == "producerPurgatoryPurgeIntervalRequests":
            suggest = "producer_purgatory_purge_interval_requests"
        elif key == "replicaFetchMaxBytes":
            suggest = "replica_fetch_max_bytes"
        elif key == "replicaFetchResponseMaxBytes":
            suggest = "replica_fetch_response_max_bytes"
        elif key == "socketRequestMaxBytes":
            suggest = "socket_request_max_bytes"
        elif key == "transactionRemoveExpiredTransactionCleanupIntervalMs":
            suggest = "transaction_remove_expired_transaction_cleanup_interval_ms"
        elif key == "transactionStateLogSegmentBytes":
            suggest = "transaction_state_log_segment_bytes"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in KafkaKafkaUserConfigKafka. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        KafkaKafkaUserConfigKafka.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        KafkaKafkaUserConfigKafka.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 auto_create_topics_enable: Optional[str] = None,
                 compression_type: Optional[str] = None,
                 connections_max_idle_ms: Optional[str] = None,
                 default_replication_factor: Optional[str] = None,
                 group_initial_rebalance_delay_ms: Optional[str] = None,
                 group_max_session_timeout_ms: Optional[str] = None,
                 group_min_session_timeout_ms: Optional[str] = None,
                 log_cleaner_delete_retention_ms: Optional[str] = None,
                 log_cleaner_max_compaction_lag_ms: Optional[str] = None,
                 log_cleaner_min_cleanable_ratio: Optional[str] = None,
                 log_cleaner_min_compaction_lag_ms: Optional[str] = None,
                 log_cleanup_policy: Optional[str] = None,
                 log_flush_interval_messages: Optional[str] = None,
                 log_flush_interval_ms: Optional[str] = None,
                 log_index_interval_bytes: Optional[str] = None,
                 log_index_size_max_bytes: Optional[str] = None,
                 log_message_downconversion_enable: Optional[str] = None,
                 log_message_timestamp_difference_max_ms: Optional[str] = None,
                 log_message_timestamp_type: Optional[str] = None,
                 log_preallocate: Optional[str] = None,
                 log_retention_bytes: Optional[str] = None,
                 log_retention_hours: Optional[str] = None,
                 log_retention_ms: Optional[str] = None,
                 log_roll_jitter_ms: Optional[str] = None,
                 log_roll_ms: Optional[str] = None,
                 log_segment_bytes: Optional[str] = None,
                 log_segment_delete_delay_ms: Optional[str] = None,
                 max_connections_per_ip: Optional[str] = None,
                 max_incremental_fetch_session_cache_slots: Optional[str] = None,
                 message_max_bytes: Optional[str] = None,
                 min_insync_replicas: Optional[str] = None,
                 num_partitions: Optional[str] = None,
                 offsets_retention_minutes: Optional[str] = None,
                 producer_purgatory_purge_interval_requests: Optional[str] = None,
                 replica_fetch_max_bytes: Optional[str] = None,
                 replica_fetch_response_max_bytes: Optional[str] = None,
                 socket_request_max_bytes: Optional[str] = None,
                 transaction_remove_expired_transaction_cleanup_interval_ms: Optional[str] = None,
                 transaction_state_log_segment_bytes: Optional[str] = None):
        """
        :param str auto_create_topics_enable: Enable auto creation of topics
        :param str compression_type: Specify the final compression type for a given topic. This 
               configuration accepts the standard compression codecs ('gzip', 'snappy', 'lz4', 'zstd').
               It additionally accepts 'uncompressed' which is equivalent to no compression; and 'producer'
               which means retain the original compression codec set by the producer.
        :param str connections_max_idle_ms: Idle connections timeout: the server socket processor 
               threads close the connections that idle for longer than this.
        :param str default_replication_factor: Replication factor for autocreated topics
        :param str group_initial_rebalance_delay_ms: The amount of time, in milliseconds, the group 
               coordinator will wait for more consumers to join a new group before performing the first rebalance.
               A longer delay means potentially fewer rebalances, but increases the time until processing begins.
               The default value for this is 3 seconds. During development and testing it might be desirable to set
               this to 0 in order to not delay test execution time.
        :param str group_max_session_timeout_ms: The maximum allowed session timeout for registered 
               consumers. Longer timeouts give consumers more time to process messages in between heartbeats
               at the cost of a longer time to detect failures.
        :param str group_min_session_timeout_ms: The minimum allowed session timeout for registered 
               consumers. Longer timeouts give consumers more time to process messages in between heartbeats
               at the cost of a longer time to detect failures.
        :param str log_cleaner_max_compaction_lag_ms: The maximum amount of time message will 
               remain uncompacted. Only applicable for logs that are being compacted
        :param str log_cleaner_min_cleanable_ratio: Controls log compactor frequency. Larger 
               value means more frequent compactions but also more space wasted for logs. Consider setting
               log.cleaner.max.compaction.lag.ms to enforce compactions sooner, instead of setting a very
               high value for this option.
        :param str log_cleaner_min_compaction_lag_ms: The minimum time a message will remain 
               uncompacted in the log. Only applicable for logs that are being compacted.
        :param str log_cleanup_policy: The default cleanup policy for segments beyond the retention window.
        :param str log_flush_interval_messages: The number of messages accumulated on a log partition 
               before messages are flushed to disk.
        :param str log_flush_interval_ms: The maximum time in ms that a message in any topic is kept 
               in memory before flushed to disk. If not set, the value in log.flush.scheduler.interval.ms is used.
        :param str log_index_interval_bytes: The interval with which Kafka adds an entry to the offset index.
        :param str log_index_size_max_bytes: The maximum size in bytes of the offset index.
        :param str log_message_downconversion_enable: This configuration controls whether down-conversion 
               of message formats is enabled to satisfy consume requests.
        :param str log_message_timestamp_difference_max_ms: The maximum difference allowed between 
               the timestamp when a broker receives a message and the timestamp specified in the message
        :param str log_message_timestamp_type: Define whether the timestamp in the message is 
               message create time or log append time.
        :param str log_preallocate: Should pre allocate file when create new segment?
        :param str log_retention_bytes: The maximum size of the log before deleting messages
        :param str log_retention_hours: The number of hours to keep a log file before deleting it.
        :param str log_retention_ms: The number of milliseconds to keep a log file before deleting it 
               (in milliseconds), If not set, the value in log.retention.minutes is used. If set to -1, no
               time limit is applied.
        :param str log_roll_jitter_ms: The maximum jitter to subtract from logRollTimeMillis 
               (in milliseconds). If not set, the value in log.roll.jitter.hours is used.
        :param str log_roll_ms: The maximum time before a new log segment is rolled out (in milliseconds).
        :param str log_segment_bytes: The maximum size of a single log file
        :param str log_segment_delete_delay_ms: The amount of time to wait before deleting a file 
               from the filesystem.
        :param str max_connections_per_ip: The maximum number of connections allowed from each ip 
               address (defaults to 2147483647).
        :param str max_incremental_fetch_session_cache_slots: The maximum number of incremental fetch 
               sessions that the broker will maintain.
        :param str message_max_bytes: The maximum size of message that the server can receive.
        :param str min_insync_replicas: When a producer sets acks to 'all' (or '-1'), 
               min.insync.replicas specifies the minimum number of replicas that must acknowledge a write for
               the write to be considered successful.
        :param str num_partitions: Number of partitions for autocreated topics
        :param str offsets_retention_minutes: Log retention window in minutes for offsets topic.
        :param str producer_purgatory_purge_interval_requests: The purge interval (in number of 
               requests) of the producer request purgatory(defaults to 1000).
        :param str replica_fetch_max_bytes: The number of bytes of messages to attempt to fetch 
               for each partition (defaults to 1048576). This is not an absolute maximum, if the first record
               batch in the first non-empty partition of the fetch is larger than this value, the record batch
               will still be returned to ensure that progress can be made.
        :param str replica_fetch_response_max_bytes: Maximum bytes expected for the entire fetch 
               response (defaults to 10485760). Records are fetched in batches, and if the first record batch
               in the first non-empty partition of the fetch is larger than this value, the record batch will
               still be returned to ensure that progress can be made. As such, this is not an absolute maximum.
        :param str socket_request_max_bytes: The maximum number of bytes in a socket request 
               (defaults to 104857600).
        :param str transaction_remove_expired_transaction_cleanup_interval_ms: The interval at which 
               to remove transactions that have expired due to transactional.id.expiration.ms passing (defaults
               to 3600000 (1 hour)).
        :param str transaction_state_log_segment_bytes: The transaction topic segment bytes should 
               be kept relatively small in order to facilitate faster log compaction and cache loads (defaults
               to 104857600 (100 mebibytes)).
        """
        if auto_create_topics_enable is not None:
            pulumi.set(__self__, "auto_create_topics_enable", auto_create_topics_enable)
        if compression_type is not None:
            pulumi.set(__self__, "compression_type", compression_type)
        if connections_max_idle_ms is not None:
            pulumi.set(__self__, "connections_max_idle_ms", connections_max_idle_ms)
        if default_replication_factor is not None:
            pulumi.set(__self__, "default_replication_factor", default_replication_factor)
        if group_initial_rebalance_delay_ms is not None:
            pulumi.set(__self__, "group_initial_rebalance_delay_ms", group_initial_rebalance_delay_ms)
        if group_max_session_timeout_ms is not None:
            pulumi.set(__self__, "group_max_session_timeout_ms", group_max_session_timeout_ms)
        if group_min_session_timeout_ms is not None:
            pulumi.set(__self__, "group_min_session_timeout_ms", group_min_session_timeout_ms)
        if log_cleaner_delete_retention_ms is not None:
            pulumi.set(__self__, "log_cleaner_delete_retention_ms", log_cleaner_delete_retention_ms)
        if log_cleaner_max_compaction_lag_ms is not None:
            pulumi.set(__self__, "log_cleaner_max_compaction_lag_ms", log_cleaner_max_compaction_lag_ms)
        if log_cleaner_min_cleanable_ratio is not None:
            pulumi.set(__self__, "log_cleaner_min_cleanable_ratio", log_cleaner_min_cleanable_ratio)
        if log_cleaner_min_compaction_lag_ms is not None:
            pulumi.set(__self__, "log_cleaner_min_compaction_lag_ms", log_cleaner_min_compaction_lag_ms)
        if log_cleanup_policy is not None:
            pulumi.set(__self__, "log_cleanup_policy", log_cleanup_policy)
        if log_flush_interval_messages is not None:
            pulumi.set(__self__, "log_flush_interval_messages", log_flush_interval_messages)
        if log_flush_interval_ms is not None:
            pulumi.set(__self__, "log_flush_interval_ms", log_flush_interval_ms)
        if log_index_interval_bytes is not None:
            pulumi.set(__self__, "log_index_interval_bytes", log_index_interval_bytes)
        if log_index_size_max_bytes is not None:
            pulumi.set(__self__, "log_index_size_max_bytes", log_index_size_max_bytes)
        if log_message_downconversion_enable is not None:
            pulumi.set(__self__, "log_message_downconversion_enable", log_message_downconversion_enable)
        if log_message_timestamp_difference_max_ms is not None:
            pulumi.set(__self__, "log_message_timestamp_difference_max_ms", log_message_timestamp_difference_max_ms)
        if log_message_timestamp_type is not None:
            pulumi.set(__self__, "log_message_timestamp_type", log_message_timestamp_type)
        if log_preallocate is not None:
            pulumi.set(__self__, "log_preallocate", log_preallocate)
        if log_retention_bytes is not None:
            pulumi.set(__self__, "log_retention_bytes", log_retention_bytes)
        if log_retention_hours is not None:
            pulumi.set(__self__, "log_retention_hours", log_retention_hours)
        if log_retention_ms is not None:
            pulumi.set(__self__, "log_retention_ms", log_retention_ms)
        if log_roll_jitter_ms is not None:
            pulumi.set(__self__, "log_roll_jitter_ms", log_roll_jitter_ms)
        if log_roll_ms is not None:
            pulumi.set(__self__, "log_roll_ms", log_roll_ms)
        if log_segment_bytes is not None:
            pulumi.set(__self__, "log_segment_bytes", log_segment_bytes)
        if log_segment_delete_delay_ms is not None:
            pulumi.set(__self__, "log_segment_delete_delay_ms", log_segment_delete_delay_ms)
        if max_connections_per_ip is not None:
            pulumi.set(__self__, "max_connections_per_ip", max_connections_per_ip)
        if max_incremental_fetch_session_cache_slots is not None:
            pulumi.set(__self__, "max_incremental_fetch_session_cache_slots", max_incremental_fetch_session_cache_slots)
        if message_max_bytes is not None:
            pulumi.set(__self__, "message_max_bytes", message_max_bytes)
        if min_insync_replicas is not None:
            pulumi.set(__self__, "min_insync_replicas", min_insync_replicas)
        if num_partitions is not None:
            pulumi.set(__self__, "num_partitions", num_partitions)
        if offsets_retention_minutes is not None:
            pulumi.set(__self__, "offsets_retention_minutes", offsets_retention_minutes)
        if producer_purgatory_purge_interval_requests is not None:
            pulumi.set(__self__, "producer_purgatory_purge_interval_requests", producer_purgatory_purge_interval_requests)
        if replica_fetch_max_bytes is not None:
            pulumi.set(__self__, "replica_fetch_max_bytes", replica_fetch_max_bytes)
        if replica_fetch_response_max_bytes is not None:
            pulumi.set(__self__, "replica_fetch_response_max_bytes", replica_fetch_response_max_bytes)
        if socket_request_max_bytes is not None:
            pulumi.set(__self__, "socket_request_max_bytes", socket_request_max_bytes)
        if transaction_remove_expired_transaction_cleanup_interval_ms is not None:
            pulumi.set(__self__, "transaction_remove_expired_transaction_cleanup_interval_ms", transaction_remove_expired_transaction_cleanup_interval_ms)
        if transaction_state_log_segment_bytes is not None:
            pulumi.set(__self__, "transaction_state_log_segment_bytes", transaction_state_log_segment_bytes)

    @property
    @pulumi.getter(name="autoCreateTopicsEnable")
    def auto_create_topics_enable(self) -> Optional[str]:
        """
        Enable auto creation of topics
        """
        return pulumi.get(self, "auto_create_topics_enable")

    @property
    @pulumi.getter(name="compressionType")
    def compression_type(self) -> Optional[str]:
        """
        Specify the final compression type for a given topic. This 
        configuration accepts the standard compression codecs ('gzip', 'snappy', 'lz4', 'zstd').
        It additionally accepts 'uncompressed' which is equivalent to no compression; and 'producer'
        which means retain the original compression codec set by the producer.
        """
        return pulumi.get(self, "compression_type")

    @property
    @pulumi.getter(name="connectionsMaxIdleMs")
    def connections_max_idle_ms(self) -> Optional[str]:
        """
        Idle connections timeout: the server socket processor 
        threads close the connections that idle for longer than this.
        """
        return pulumi.get(self, "connections_max_idle_ms")

    @property
    @pulumi.getter(name="defaultReplicationFactor")
    def default_replication_factor(self) -> Optional[str]:
        """
        Replication factor for autocreated topics
        """
        return pulumi.get(self, "default_replication_factor")

    @property
    @pulumi.getter(name="groupInitialRebalanceDelayMs")
    def group_initial_rebalance_delay_ms(self) -> Optional[str]:
        """
        The amount of time, in milliseconds, the group 
        coordinator will wait for more consumers to join a new group before performing the first rebalance.
        A longer delay means potentially fewer rebalances, but increases the time until processing begins.
        The default value for this is 3 seconds. During development and testing it might be desirable to set
        this to 0 in order to not delay test execution time.
        """
        return pulumi.get(self, "group_initial_rebalance_delay_ms")

    @property
    @pulumi.getter(name="groupMaxSessionTimeoutMs")
    def group_max_session_timeout_ms(self) -> Optional[str]:
        """
        The maximum allowed session timeout for registered 
        consumers. Longer timeouts give consumers more time to process messages in between heartbeats
        at the cost of a longer time to detect failures.
        """
        return pulumi.get(self, "group_max_session_timeout_ms")

    @property
    @pulumi.getter(name="groupMinSessionTimeoutMs")
    def group_min_session_timeout_ms(self) -> Optional[str]:
        """
        The minimum allowed session timeout for registered 
        consumers. Longer timeouts give consumers more time to process messages in between heartbeats
        at the cost of a longer time to detect failures.
        """
        return pulumi.get(self, "group_min_session_timeout_ms")

    @property
    @pulumi.getter(name="logCleanerDeleteRetentionMs")
    def log_cleaner_delete_retention_ms(self) -> Optional[str]:
        return pulumi.get(self, "log_cleaner_delete_retention_ms")

    @property
    @pulumi.getter(name="logCleanerMaxCompactionLagMs")
    def log_cleaner_max_compaction_lag_ms(self) -> Optional[str]:
        """
        The maximum amount of time message will 
        remain uncompacted. Only applicable for logs that are being compacted
        """
        return pulumi.get(self, "log_cleaner_max_compaction_lag_ms")

    @property
    @pulumi.getter(name="logCleanerMinCleanableRatio")
    def log_cleaner_min_cleanable_ratio(self) -> Optional[str]:
        """
        Controls log compactor frequency. Larger 
        value means more frequent compactions but also more space wasted for logs. Consider setting
        log.cleaner.max.compaction.lag.ms to enforce compactions sooner, instead of setting a very
        high value for this option.
        """
        return pulumi.get(self, "log_cleaner_min_cleanable_ratio")

    @property
    @pulumi.getter(name="logCleanerMinCompactionLagMs")
    def log_cleaner_min_compaction_lag_ms(self) -> Optional[str]:
        """
        The minimum time a message will remain 
        uncompacted in the log. Only applicable for logs that are being compacted.
        """
        return pulumi.get(self, "log_cleaner_min_compaction_lag_ms")

    @property
    @pulumi.getter(name="logCleanupPolicy")
    def log_cleanup_policy(self) -> Optional[str]:
        """
        The default cleanup policy for segments beyond the retention window.
        """
        return pulumi.get(self, "log_cleanup_policy")

    @property
    @pulumi.getter(name="logFlushIntervalMessages")
    def log_flush_interval_messages(self) -> Optional[str]:
        """
        The number of messages accumulated on a log partition 
        before messages are flushed to disk.
        """
        return pulumi.get(self, "log_flush_interval_messages")

    @property
    @pulumi.getter(name="logFlushIntervalMs")
    def log_flush_interval_ms(self) -> Optional[str]:
        """
        The maximum time in ms that a message in any topic is kept 
        in memory before flushed to disk. If not set, the value in log.flush.scheduler.interval.ms is used.
        """
        return pulumi.get(self, "log_flush_interval_ms")

    @property
    @pulumi.getter(name="logIndexIntervalBytes")
    def log_index_interval_bytes(self) -> Optional[str]:
        """
        The interval with which Kafka adds an entry to the offset index.
        """
        return pulumi.get(self, "log_index_interval_bytes")

    @property
    @pulumi.getter(name="logIndexSizeMaxBytes")
    def log_index_size_max_bytes(self) -> Optional[str]:
        """
        The maximum size in bytes of the offset index.
        """
        return pulumi.get(self, "log_index_size_max_bytes")

    @property
    @pulumi.getter(name="logMessageDownconversionEnable")
    def log_message_downconversion_enable(self) -> Optional[str]:
        """
        This configuration controls whether down-conversion 
        of message formats is enabled to satisfy consume requests.
        """
        return pulumi.get(self, "log_message_downconversion_enable")

    @property
    @pulumi.getter(name="logMessageTimestampDifferenceMaxMs")
    def log_message_timestamp_difference_max_ms(self) -> Optional[str]:
        """
        The maximum difference allowed between 
        the timestamp when a broker receives a message and the timestamp specified in the message
        """
        return pulumi.get(self, "log_message_timestamp_difference_max_ms")

    @property
    @pulumi.getter(name="logMessageTimestampType")
    def log_message_timestamp_type(self) -> Optional[str]:
        """
        Define whether the timestamp in the message is 
        message create time or log append time.
        """
        return pulumi.get(self, "log_message_timestamp_type")

    @property
    @pulumi.getter(name="logPreallocate")
    def log_preallocate(self) -> Optional[str]:
        """
        Should pre allocate file when create new segment?
        """
        return pulumi.get(self, "log_preallocate")

    @property
    @pulumi.getter(name="logRetentionBytes")
    def log_retention_bytes(self) -> Optional[str]:
        """
        The maximum size of the log before deleting messages
        """
        return pulumi.get(self, "log_retention_bytes")

    @property
    @pulumi.getter(name="logRetentionHours")
    def log_retention_hours(self) -> Optional[str]:
        """
        The number of hours to keep a log file before deleting it.
        """
        return pulumi.get(self, "log_retention_hours")

    @property
    @pulumi.getter(name="logRetentionMs")
    def log_retention_ms(self) -> Optional[str]:
        """
        The number of milliseconds to keep a log file before deleting it 
        (in milliseconds), If not set, the value in log.retention.minutes is used. If set to -1, no
        time limit is applied.
        """
        return pulumi.get(self, "log_retention_ms")

    @property
    @pulumi.getter(name="logRollJitterMs")
    def log_roll_jitter_ms(self) -> Optional[str]:
        """
        The maximum jitter to subtract from logRollTimeMillis 
        (in milliseconds). If not set, the value in log.roll.jitter.hours is used.
        """
        return pulumi.get(self, "log_roll_jitter_ms")

    @property
    @pulumi.getter(name="logRollMs")
    def log_roll_ms(self) -> Optional[str]:
        """
        The maximum time before a new log segment is rolled out (in milliseconds).
        """
        return pulumi.get(self, "log_roll_ms")

    @property
    @pulumi.getter(name="logSegmentBytes")
    def log_segment_bytes(self) -> Optional[str]:
        """
        The maximum size of a single log file
        """
        return pulumi.get(self, "log_segment_bytes")

    @property
    @pulumi.getter(name="logSegmentDeleteDelayMs")
    def log_segment_delete_delay_ms(self) -> Optional[str]:
        """
        The amount of time to wait before deleting a file 
        from the filesystem.
        """
        return pulumi.get(self, "log_segment_delete_delay_ms")

    @property
    @pulumi.getter(name="maxConnectionsPerIp")
    def max_connections_per_ip(self) -> Optional[str]:
        """
        The maximum number of connections allowed from each ip 
        address (defaults to 2147483647).
        """
        return pulumi.get(self, "max_connections_per_ip")

    @property
    @pulumi.getter(name="maxIncrementalFetchSessionCacheSlots")
    def max_incremental_fetch_session_cache_slots(self) -> Optional[str]:
        """
        The maximum number of incremental fetch 
        sessions that the broker will maintain.
        """
        return pulumi.get(self, "max_incremental_fetch_session_cache_slots")

    @property
    @pulumi.getter(name="messageMaxBytes")
    def message_max_bytes(self) -> Optional[str]:
        """
        The maximum size of message that the server can receive.
        """
        return pulumi.get(self, "message_max_bytes")

    @property
    @pulumi.getter(name="minInsyncReplicas")
    def min_insync_replicas(self) -> Optional[str]:
        """
        When a producer sets acks to 'all' (or '-1'), 
        min.insync.replicas specifies the minimum number of replicas that must acknowledge a write for
        the write to be considered successful.
        """
        return pulumi.get(self, "min_insync_replicas")

    @property
    @pulumi.getter(name="numPartitions")
    def num_partitions(self) -> Optional[str]:
        """
        Number of partitions for autocreated topics
        """
        return pulumi.get(self, "num_partitions")

    @property
    @pulumi.getter(name="offsetsRetentionMinutes")
    def offsets_retention_minutes(self) -> Optional[str]:
        """
        Log retention window in minutes for offsets topic.
        """
        return pulumi.get(self, "offsets_retention_minutes")

    @property
    @pulumi.getter(name="producerPurgatoryPurgeIntervalRequests")
    def producer_purgatory_purge_interval_requests(self) -> Optional[str]:
        """
        The purge interval (in number of 
        requests) of the producer request purgatory(defaults to 1000).
        """
        return pulumi.get(self, "producer_purgatory_purge_interval_requests")

    @property
    @pulumi.getter(name="replicaFetchMaxBytes")
    def replica_fetch_max_bytes(self) -> Optional[str]:
        """
        The number of bytes of messages to attempt to fetch 
        for each partition (defaults to 1048576). This is not an absolute maximum, if the first record
        batch in the first non-empty partition of the fetch is larger than this value, the record batch
        will still be returned to ensure that progress can be made.
        """
        return pulumi.get(self, "replica_fetch_max_bytes")

    @property
    @pulumi.getter(name="replicaFetchResponseMaxBytes")
    def replica_fetch_response_max_bytes(self) -> Optional[str]:
        """
        Maximum bytes expected for the entire fetch 
        response (defaults to 10485760). Records are fetched in batches, and if the first record batch
        in the first non-empty partition of the fetch is larger than this value, the record batch will
        still be returned to ensure that progress can be made. As such, this is not an absolute maximum.
        """
        return pulumi.get(self, "replica_fetch_response_max_bytes")

    @property
    @pulumi.getter(name="socketRequestMaxBytes")
    def socket_request_max_bytes(self) -> Optional[str]:
        """
        The maximum number of bytes in a socket request 
        (defaults to 104857600).
        """
        return pulumi.get(self, "socket_request_max_bytes")

    @property
    @pulumi.getter(name="transactionRemoveExpiredTransactionCleanupIntervalMs")
    def transaction_remove_expired_transaction_cleanup_interval_ms(self) -> Optional[str]:
        """
        The interval at which 
        to remove transactions that have expired due to transactional.id.expiration.ms passing (defaults
        to 3600000 (1 hour)).
        """
        return pulumi.get(self, "transaction_remove_expired_transaction_cleanup_interval_ms")

    @property
    @pulumi.getter(name="transactionStateLogSegmentBytes")
    def transaction_state_log_segment_bytes(self) -> Optional[str]:
        """
        The transaction topic segment bytes should 
        be kept relatively small in order to facilitate faster log compaction and cache loads (defaults
        to 104857600 (100 mebibytes)).
        """
        return pulumi.get(self, "transaction_state_log_segment_bytes")


@pulumi.output_type
class KafkaKafkaUserConfigKafkaAuthenticationMethods(dict):
    def __init__(__self__, *,
                 certificate: Optional[str] = None,
                 sasl: Optional[str] = None):
        """
        :param str certificate: Enable certificate/SSL authentication
        :param str sasl: Enable SASL authentication
        """
        if certificate is not None:
            pulumi.set(__self__, "certificate", certificate)
        if sasl is not None:
            pulumi.set(__self__, "sasl", sasl)

    @property
    @pulumi.getter
    def certificate(self) -> Optional[str]:
        """
        Enable certificate/SSL authentication
        """
        return pulumi.get(self, "certificate")

    @property
    @pulumi.getter
    def sasl(self) -> Optional[str]:
        """
        Enable SASL authentication
        """
        return pulumi.get(self, "sasl")


@pulumi.output_type
class KafkaKafkaUserConfigKafkaConnectConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "connectorClientConfigOverridePolicy":
            suggest = "connector_client_config_override_policy"
        elif key == "consumerAutoOffsetReset":
            suggest = "consumer_auto_offset_reset"
        elif key == "consumerFetchMaxBytes":
            suggest = "consumer_fetch_max_bytes"
        elif key == "consumerIsolationLevel":
            suggest = "consumer_isolation_level"
        elif key == "consumerMaxPartitionFetchBytes":
            suggest = "consumer_max_partition_fetch_bytes"
        elif key == "consumerMaxPollIntervalMs":
            suggest = "consumer_max_poll_interval_ms"
        elif key == "consumerMaxPollRecords":
            suggest = "consumer_max_poll_records"
        elif key == "offsetFlushIntervalMs":
            suggest = "offset_flush_interval_ms"
        elif key == "offsetFlushTimeoutMs":
            suggest = "offset_flush_timeout_ms"
        elif key == "producerMaxRequestSize":
            suggest = "producer_max_request_size"
        elif key == "sessionTimeoutMs":
            suggest = "session_timeout_ms"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in KafkaKafkaUserConfigKafkaConnectConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        KafkaKafkaUserConfigKafkaConnectConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        KafkaKafkaUserConfigKafkaConnectConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 connector_client_config_override_policy: Optional[str] = None,
                 consumer_auto_offset_reset: Optional[str] = None,
                 consumer_fetch_max_bytes: Optional[str] = None,
                 consumer_isolation_level: Optional[str] = None,
                 consumer_max_partition_fetch_bytes: Optional[str] = None,
                 consumer_max_poll_interval_ms: Optional[str] = None,
                 consumer_max_poll_records: Optional[str] = None,
                 offset_flush_interval_ms: Optional[str] = None,
                 offset_flush_timeout_ms: Optional[str] = None,
                 producer_max_request_size: Optional[str] = None,
                 session_timeout_ms: Optional[str] = None):
        """
        :param str connector_client_config_override_policy: Defines what client configurations can 
               be overridden by the connector. Default is None
        :param str consumer_auto_offset_reset: What to do when there is no initial offset in Kafka or 
               if the current offset does not exist any more on the server. Default is earliest.
        :param str consumer_fetch_max_bytes: Records are fetched in batches by the consumer, and 
               if the first record batch in the first non-empty partition of the fetch is larger than this value,
               the record batch will still be returned to ensure that the consumer can make progress. As such,
               this is not a absolute maximum.
        :param str consumer_isolation_level: Transaction read isolation level. read_uncommitted is 
               the default, but read_committed can be used if consume-exactly-once behavior is desired.
        :param str consumer_max_partition_fetch_bytes: Records are fetched in batches by the consumer.If 
               the first record batch in the first non-empty partition of the fetch is larger than this limit,
               the batch will still be returned to ensure that the consumer can make progress.
        :param str consumer_max_poll_interval_ms: The maximum delay in milliseconds between invocations 
               of poll() when using consumer group management (defaults to 300000).
        :param str consumer_max_poll_records: The maximum number of records returned in a single call 
               to poll() (defaults to 500).
        :param str offset_flush_interval_ms: The interval at which to try committing offsets for 
               tasks (defaults to 60000).
        :param str offset_flush_timeout_ms: Maximum number of milliseconds to wait for records to 
               flush and partition offset data to be committed to offset storage before cancelling the process
               and restoring the offset data to be committed in a future attempt (defaults to 5000).
        :param str producer_max_request_size: This setting will limit the number of record batches 
               the producer will send in a single request to avoid sending huge requests.
        :param str session_timeout_ms: The timeout in milliseconds used to detect failures when 
               using Kafkas group management facilities (defaults to 10000).
        """
        if connector_client_config_override_policy is not None:
            pulumi.set(__self__, "connector_client_config_override_policy", connector_client_config_override_policy)
        if consumer_auto_offset_reset is not None:
            pulumi.set(__self__, "consumer_auto_offset_reset", consumer_auto_offset_reset)
        if consumer_fetch_max_bytes is not None:
            pulumi.set(__self__, "consumer_fetch_max_bytes", consumer_fetch_max_bytes)
        if consumer_isolation_level is not None:
            pulumi.set(__self__, "consumer_isolation_level", consumer_isolation_level)
        if consumer_max_partition_fetch_bytes is not None:
            pulumi.set(__self__, "consumer_max_partition_fetch_bytes", consumer_max_partition_fetch_bytes)
        if consumer_max_poll_interval_ms is not None:
            pulumi.set(__self__, "consumer_max_poll_interval_ms", consumer_max_poll_interval_ms)
        if consumer_max_poll_records is not None:
            pulumi.set(__self__, "consumer_max_poll_records", consumer_max_poll_records)
        if offset_flush_interval_ms is not None:
            pulumi.set(__self__, "offset_flush_interval_ms", offset_flush_interval_ms)
        if offset_flush_timeout_ms is not None:
            pulumi.set(__self__, "offset_flush_timeout_ms", offset_flush_timeout_ms)
        if producer_max_request_size is not None:
            pulumi.set(__self__, "producer_max_request_size", producer_max_request_size)
        if session_timeout_ms is not None:
            pulumi.set(__self__, "session_timeout_ms", session_timeout_ms)

    @property
    @pulumi.getter(name="connectorClientConfigOverridePolicy")
    def connector_client_config_override_policy(self) -> Optional[str]:
        """
        Defines what client configurations can 
        be overridden by the connector. Default is None
        """
        return pulumi.get(self, "connector_client_config_override_policy")

    @property
    @pulumi.getter(name="consumerAutoOffsetReset")
    def consumer_auto_offset_reset(self) -> Optional[str]:
        """
        What to do when there is no initial offset in Kafka or 
        if the current offset does not exist any more on the server. Default is earliest.
        """
        return pulumi.get(self, "consumer_auto_offset_reset")

    @property
    @pulumi.getter(name="consumerFetchMaxBytes")
    def consumer_fetch_max_bytes(self) -> Optional[str]:
        """
        Records are fetched in batches by the consumer, and 
        if the first record batch in the first non-empty partition of the fetch is larger than this value,
        the record batch will still be returned to ensure that the consumer can make progress. As such,
        this is not a absolute maximum.
        """
        return pulumi.get(self, "consumer_fetch_max_bytes")

    @property
    @pulumi.getter(name="consumerIsolationLevel")
    def consumer_isolation_level(self) -> Optional[str]:
        """
        Transaction read isolation level. read_uncommitted is 
        the default, but read_committed can be used if consume-exactly-once behavior is desired.
        """
        return pulumi.get(self, "consumer_isolation_level")

    @property
    @pulumi.getter(name="consumerMaxPartitionFetchBytes")
    def consumer_max_partition_fetch_bytes(self) -> Optional[str]:
        """
        Records are fetched in batches by the consumer.If 
        the first record batch in the first non-empty partition of the fetch is larger than this limit,
        the batch will still be returned to ensure that the consumer can make progress.
        """
        return pulumi.get(self, "consumer_max_partition_fetch_bytes")

    @property
    @pulumi.getter(name="consumerMaxPollIntervalMs")
    def consumer_max_poll_interval_ms(self) -> Optional[str]:
        """
        The maximum delay in milliseconds between invocations 
        of poll() when using consumer group management (defaults to 300000).
        """
        return pulumi.get(self, "consumer_max_poll_interval_ms")

    @property
    @pulumi.getter(name="consumerMaxPollRecords")
    def consumer_max_poll_records(self) -> Optional[str]:
        """
        The maximum number of records returned in a single call 
        to poll() (defaults to 500).
        """
        return pulumi.get(self, "consumer_max_poll_records")

    @property
    @pulumi.getter(name="offsetFlushIntervalMs")
    def offset_flush_interval_ms(self) -> Optional[str]:
        """
        The interval at which to try committing offsets for 
        tasks (defaults to 60000).
        """
        return pulumi.get(self, "offset_flush_interval_ms")

    @property
    @pulumi.getter(name="offsetFlushTimeoutMs")
    def offset_flush_timeout_ms(self) -> Optional[str]:
        """
        Maximum number of milliseconds to wait for records to 
        flush and partition offset data to be committed to offset storage before cancelling the process
        and restoring the offset data to be committed in a future attempt (defaults to 5000).
        """
        return pulumi.get(self, "offset_flush_timeout_ms")

    @property
    @pulumi.getter(name="producerMaxRequestSize")
    def producer_max_request_size(self) -> Optional[str]:
        """
        This setting will limit the number of record batches 
        the producer will send in a single request to avoid sending huge requests.
        """
        return pulumi.get(self, "producer_max_request_size")

    @property
    @pulumi.getter(name="sessionTimeoutMs")
    def session_timeout_ms(self) -> Optional[str]:
        """
        The timeout in milliseconds used to detect failures when 
        using Kafkas group management facilities (defaults to 10000).
        """
        return pulumi.get(self, "session_timeout_ms")


@pulumi.output_type
class KafkaKafkaUserConfigKafkaRestConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "consumerEnableAutoCommit":
            suggest = "consumer_enable_auto_commit"
        elif key == "consumerRequestMaxBytes":
            suggest = "consumer_request_max_bytes"
        elif key == "consumerRequestTimeoutMs":
            suggest = "consumer_request_timeout_ms"
        elif key == "producerAcks":
            suggest = "producer_acks"
        elif key == "producerLingerMs":
            suggest = "producer_linger_ms"
        elif key == "simpleconsumerPoolSizeMax":
            suggest = "simpleconsumer_pool_size_max"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in KafkaKafkaUserConfigKafkaRestConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        KafkaKafkaUserConfigKafkaRestConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        KafkaKafkaUserConfigKafkaRestConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 consumer_enable_auto_commit: Optional[str] = None,
                 consumer_request_max_bytes: Optional[str] = None,
                 consumer_request_timeout_ms: Optional[str] = None,
                 producer_acks: Optional[str] = None,
                 producer_linger_ms: Optional[str] = None,
                 simpleconsumer_pool_size_max: Optional[str] = None):
        """
        :param str consumer_enable_auto_commit: If true the consumer's offset will be periodically 
               committed to Kafka in the background
        :param str consumer_request_max_bytes: Maximum number of bytes in unencoded message keys and 
               values by a single request
        :param str consumer_request_timeout_ms: The maximum total time to wait for messages for a 
               request if the maximum number of messages has not yet been reached
        :param str producer_acks: The number of acknowledgments the producer requires the leader to 
               have received before considering a request complete. If set to 'all' or '-1', the leader will wait
               for the full set of in-sync replicas to acknowledge the record.
        :param str producer_linger_ms: Wait for up to the given delay to allow batching records together
        :param str simpleconsumer_pool_size_max: Maximum number of SimpleConsumers that can be 
               instantiated per broker.
        """
        if consumer_enable_auto_commit is not None:
            pulumi.set(__self__, "consumer_enable_auto_commit", consumer_enable_auto_commit)
        if consumer_request_max_bytes is not None:
            pulumi.set(__self__, "consumer_request_max_bytes", consumer_request_max_bytes)
        if consumer_request_timeout_ms is not None:
            pulumi.set(__self__, "consumer_request_timeout_ms", consumer_request_timeout_ms)
        if producer_acks is not None:
            pulumi.set(__self__, "producer_acks", producer_acks)
        if producer_linger_ms is not None:
            pulumi.set(__self__, "producer_linger_ms", producer_linger_ms)
        if simpleconsumer_pool_size_max is not None:
            pulumi.set(__self__, "simpleconsumer_pool_size_max", simpleconsumer_pool_size_max)

    @property
    @pulumi.getter(name="consumerEnableAutoCommit")
    def consumer_enable_auto_commit(self) -> Optional[str]:
        """
        If true the consumer's offset will be periodically 
        committed to Kafka in the background
        """
        return pulumi.get(self, "consumer_enable_auto_commit")

    @property
    @pulumi.getter(name="consumerRequestMaxBytes")
    def consumer_request_max_bytes(self) -> Optional[str]:
        """
        Maximum number of bytes in unencoded message keys and 
        values by a single request
        """
        return pulumi.get(self, "consumer_request_max_bytes")

    @property
    @pulumi.getter(name="consumerRequestTimeoutMs")
    def consumer_request_timeout_ms(self) -> Optional[str]:
        """
        The maximum total time to wait for messages for a 
        request if the maximum number of messages has not yet been reached
        """
        return pulumi.get(self, "consumer_request_timeout_ms")

    @property
    @pulumi.getter(name="producerAcks")
    def producer_acks(self) -> Optional[str]:
        """
        The number of acknowledgments the producer requires the leader to 
        have received before considering a request complete. If set to 'all' or '-1', the leader will wait
        for the full set of in-sync replicas to acknowledge the record.
        """
        return pulumi.get(self, "producer_acks")

    @property
    @pulumi.getter(name="producerLingerMs")
    def producer_linger_ms(self) -> Optional[str]:
        """
        Wait for up to the given delay to allow batching records together
        """
        return pulumi.get(self, "producer_linger_ms")

    @property
    @pulumi.getter(name="simpleconsumerPoolSizeMax")
    def simpleconsumer_pool_size_max(self) -> Optional[str]:
        """
        Maximum number of SimpleConsumers that can be 
        instantiated per broker.
        """
        return pulumi.get(self, "simpleconsumer_pool_size_max")


@pulumi.output_type
class KafkaKafkaUserConfigPrivateAccess(dict):
    def __init__(__self__, *,
                 prometheus: Optional[str] = None):
        """
        :param str prometheus: Allow clients to connect to prometheus from the public internet for 
               service nodes that are in a project VPC or another type of private network
        """
        if prometheus is not None:
            pulumi.set(__self__, "prometheus", prometheus)

    @property
    @pulumi.getter
    def prometheus(self) -> Optional[str]:
        """
        Allow clients to connect to prometheus from the public internet for 
        service nodes that are in a project VPC or another type of private network
        """
        return pulumi.get(self, "prometheus")


@pulumi.output_type
class KafkaKafkaUserConfigPrivatelinkAccess(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "kafkaConnect":
            suggest = "kafka_connect"
        elif key == "kafkaRest":
            suggest = "kafka_rest"
        elif key == "schemaRegistry":
            suggest = "schema_registry"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in KafkaKafkaUserConfigPrivatelinkAccess. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        KafkaKafkaUserConfigPrivatelinkAccess.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        KafkaKafkaUserConfigPrivatelinkAccess.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 kafka: Optional[str] = None,
                 kafka_connect: Optional[str] = None,
                 kafka_rest: Optional[str] = None,
                 schema_registry: Optional[str] = None):
        """
        :param str kafka: Enable kafka
        :param str kafka_connect: Enable kafka_connect
        :param str kafka_rest: Enable kafka_rest
        :param str schema_registry: Enable Schema-Registry service
        """
        if kafka is not None:
            pulumi.set(__self__, "kafka", kafka)
        if kafka_connect is not None:
            pulumi.set(__self__, "kafka_connect", kafka_connect)
        if kafka_rest is not None:
            pulumi.set(__self__, "kafka_rest", kafka_rest)
        if schema_registry is not None:
            pulumi.set(__self__, "schema_registry", schema_registry)

    @property
    @pulumi.getter
    def kafka(self) -> Optional[str]:
        """
        Enable kafka
        """
        return pulumi.get(self, "kafka")

    @property
    @pulumi.getter(name="kafkaConnect")
    def kafka_connect(self) -> Optional[str]:
        """
        Enable kafka_connect
        """
        return pulumi.get(self, "kafka_connect")

    @property
    @pulumi.getter(name="kafkaRest")
    def kafka_rest(self) -> Optional[str]:
        """
        Enable kafka_rest
        """
        return pulumi.get(self, "kafka_rest")

    @property
    @pulumi.getter(name="schemaRegistry")
    def schema_registry(self) -> Optional[str]:
        """
        Enable Schema-Registry service
        """
        return pulumi.get(self, "schema_registry")


@pulumi.output_type
class KafkaKafkaUserConfigPublicAccess(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "kafkaConnect":
            suggest = "kafka_connect"
        elif key == "kafkaRest":
            suggest = "kafka_rest"
        elif key == "schemaRegistry":
            suggest = "schema_registry"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in KafkaKafkaUserConfigPublicAccess. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        KafkaKafkaUserConfigPublicAccess.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        KafkaKafkaUserConfigPublicAccess.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 kafka: Optional[str] = None,
                 kafka_connect: Optional[str] = None,
                 kafka_rest: Optional[str] = None,
                 prometheus: Optional[str] = None,
                 schema_registry: Optional[str] = None):
        """
        :param str kafka: Enable kafka
        :param str kafka_connect: Enable kafka_connect
        :param str kafka_rest: Enable kafka_rest
        :param str prometheus: Allow clients to connect to prometheus from the public internet for 
               service nodes that are in a project VPC or another type of private network
        :param str schema_registry: Enable Schema-Registry service
        """
        if kafka is not None:
            pulumi.set(__self__, "kafka", kafka)
        if kafka_connect is not None:
            pulumi.set(__self__, "kafka_connect", kafka_connect)
        if kafka_rest is not None:
            pulumi.set(__self__, "kafka_rest", kafka_rest)
        if prometheus is not None:
            pulumi.set(__self__, "prometheus", prometheus)
        if schema_registry is not None:
            pulumi.set(__self__, "schema_registry", schema_registry)

    @property
    @pulumi.getter
    def kafka(self) -> Optional[str]:
        """
        Enable kafka
        """
        return pulumi.get(self, "kafka")

    @property
    @pulumi.getter(name="kafkaConnect")
    def kafka_connect(self) -> Optional[str]:
        """
        Enable kafka_connect
        """
        return pulumi.get(self, "kafka_connect")

    @property
    @pulumi.getter(name="kafkaRest")
    def kafka_rest(self) -> Optional[str]:
        """
        Enable kafka_rest
        """
        return pulumi.get(self, "kafka_rest")

    @property
    @pulumi.getter
    def prometheus(self) -> Optional[str]:
        """
        Allow clients to connect to prometheus from the public internet for 
        service nodes that are in a project VPC or another type of private network
        """
        return pulumi.get(self, "prometheus")

    @property
    @pulumi.getter(name="schemaRegistry")
    def schema_registry(self) -> Optional[str]:
        """
        Enable Schema-Registry service
        """
        return pulumi.get(self, "schema_registry")


@pulumi.output_type
class KafkaKafkaUserConfigSchemaRegistryConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "leaderEligibility":
            suggest = "leader_eligibility"
        elif key == "topicName":
            suggest = "topic_name"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in KafkaKafkaUserConfigSchemaRegistryConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        KafkaKafkaUserConfigSchemaRegistryConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        KafkaKafkaUserConfigSchemaRegistryConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 leader_eligibility: Optional[str] = None,
                 topic_name: Optional[str] = None):
        """
        :param str leader_eligibility: If true, Karapace / Schema Registry on the service nodes can 
               participate in leader election. It might be needed to disable this when the schemas topic is replicated
               to a secondary cluster and Karapace / Schema Registry there must not participate in leader election.
               Defaults to 'true'.
        :param str topic_name: The durable single partition topic that acts as the durable log for the 
               data. This topic must be compacted to avoid losing data due to retention policy. Please note that
               changing this configuration in an existing Schema Registry / Karapace setup leads to previous
               schemas being inaccessible, data encoded with them potentially unreadable and schema ID sequence
               put out of order. It's only possible to do the switch while Schema Registry / Karapace is disabled.
               Defaults to '_schemas'.
        """
        if leader_eligibility is not None:
            pulumi.set(__self__, "leader_eligibility", leader_eligibility)
        if topic_name is not None:
            pulumi.set(__self__, "topic_name", topic_name)

    @property
    @pulumi.getter(name="leaderEligibility")
    def leader_eligibility(self) -> Optional[str]:
        """
        If true, Karapace / Schema Registry on the service nodes can 
        participate in leader election. It might be needed to disable this when the schemas topic is replicated
        to a secondary cluster and Karapace / Schema Registry there must not participate in leader election.
        Defaults to 'true'.
        """
        return pulumi.get(self, "leader_eligibility")

    @property
    @pulumi.getter(name="topicName")
    def topic_name(self) -> Optional[str]:
        """
        The durable single partition topic that acts as the durable log for the 
        data. This topic must be compacted to avoid losing data due to retention policy. Please note that
        changing this configuration in an existing Schema Registry / Karapace setup leads to previous
        schemas being inaccessible, data encoded with them potentially unreadable and schema ID sequence
        put out of order. It's only possible to do the switch while Schema Registry / Karapace is disabled.
        Defaults to '_schemas'.
        """
        return pulumi.get(self, "topic_name")


@pulumi.output_type
class KafkaMirrorMakerComponent(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "kafkaAuthenticationMethod":
            suggest = "kafka_authentication_method"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in KafkaMirrorMakerComponent. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        KafkaMirrorMakerComponent.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        KafkaMirrorMakerComponent.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 component: Optional[str] = None,
                 host: Optional[str] = None,
                 kafka_authentication_method: Optional[str] = None,
                 port: Optional[int] = None,
                 route: Optional[str] = None,
                 ssl: Optional[bool] = None,
                 usage: Optional[str] = None):
        if component is not None:
            pulumi.set(__self__, "component", component)
        if host is not None:
            pulumi.set(__self__, "host", host)
        if kafka_authentication_method is not None:
            pulumi.set(__self__, "kafka_authentication_method", kafka_authentication_method)
        if port is not None:
            pulumi.set(__self__, "port", port)
        if route is not None:
            pulumi.set(__self__, "route", route)
        if ssl is not None:
            pulumi.set(__self__, "ssl", ssl)
        if usage is not None:
            pulumi.set(__self__, "usage", usage)

    @property
    @pulumi.getter
    def component(self) -> Optional[str]:
        return pulumi.get(self, "component")

    @property
    @pulumi.getter
    def host(self) -> Optional[str]:
        return pulumi.get(self, "host")

    @property
    @pulumi.getter(name="kafkaAuthenticationMethod")
    def kafka_authentication_method(self) -> Optional[str]:
        return pulumi.get(self, "kafka_authentication_method")

    @property
    @pulumi.getter
    def port(self) -> Optional[int]:
        return pulumi.get(self, "port")

    @property
    @pulumi.getter
    def route(self) -> Optional[str]:
        return pulumi.get(self, "route")

    @property
    @pulumi.getter
    def ssl(self) -> Optional[bool]:
        return pulumi.get(self, "ssl")

    @property
    @pulumi.getter
    def usage(self) -> Optional[str]:
        return pulumi.get(self, "usage")


@pulumi.output_type
class KafkaMirrorMakerKafkaMirrormaker(dict):
    def __init__(__self__):
        pass


@pulumi.output_type
class KafkaMirrorMakerKafkaMirrormakerUserConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "ipFilters":
            suggest = "ip_filters"
        elif key == "kafkaMirrormaker":
            suggest = "kafka_mirrormaker"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in KafkaMirrorMakerKafkaMirrormakerUserConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        KafkaMirrorMakerKafkaMirrormakerUserConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        KafkaMirrorMakerKafkaMirrormakerUserConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 ip_filters: Optional[Sequence[str]] = None,
                 kafka_mirrormaker: Optional['outputs.KafkaMirrorMakerKafkaMirrormakerUserConfigKafkaMirrormaker'] = None):
        """
        :param Sequence[str] ip_filters: allow incoming connections from CIDR address block, e.g. `10.20.0.0/16`
        :param 'KafkaMirrorMakerKafkaMirrormakerUserConfigKafkaMirrormakerArgs' kafka_mirrormaker: Kafka MirrorMaker configuration values
        """
        if ip_filters is not None:
            pulumi.set(__self__, "ip_filters", ip_filters)
        if kafka_mirrormaker is not None:
            pulumi.set(__self__, "kafka_mirrormaker", kafka_mirrormaker)

    @property
    @pulumi.getter(name="ipFilters")
    def ip_filters(self) -> Optional[Sequence[str]]:
        """
        allow incoming connections from CIDR address block, e.g. `10.20.0.0/16`
        """
        return pulumi.get(self, "ip_filters")

    @property
    @pulumi.getter(name="kafkaMirrormaker")
    def kafka_mirrormaker(self) -> Optional['outputs.KafkaMirrorMakerKafkaMirrormakerUserConfigKafkaMirrormaker']:
        """
        Kafka MirrorMaker configuration values
        """
        return pulumi.get(self, "kafka_mirrormaker")


@pulumi.output_type
class KafkaMirrorMakerKafkaMirrormakerUserConfigKafkaMirrormaker(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "emitCheckpointsEnabled":
            suggest = "emit_checkpoints_enabled"
        elif key == "emitCheckpointsIntervalSeconds":
            suggest = "emit_checkpoints_interval_seconds"
        elif key == "refreshGroupsEnabled":
            suggest = "refresh_groups_enabled"
        elif key == "refreshGroupsIntervalSeconds":
            suggest = "refresh_groups_interval_seconds"
        elif key == "refreshTopicsEnabled":
            suggest = "refresh_topics_enabled"
        elif key == "refreshTopicsIntervalSeconds":
            suggest = "refresh_topics_interval_seconds"
        elif key == "syncGroupOffsetsEnabled":
            suggest = "sync_group_offsets_enabled"
        elif key == "syncGroupOffsetsIntervalSeconds":
            suggest = "sync_group_offsets_interval_seconds"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in KafkaMirrorMakerKafkaMirrormakerUserConfigKafkaMirrormaker. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        KafkaMirrorMakerKafkaMirrormakerUserConfigKafkaMirrormaker.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        KafkaMirrorMakerKafkaMirrormakerUserConfigKafkaMirrormaker.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 emit_checkpoints_enabled: Optional[str] = None,
                 emit_checkpoints_interval_seconds: Optional[str] = None,
                 refresh_groups_enabled: Optional[str] = None,
                 refresh_groups_interval_seconds: Optional[str] = None,
                 refresh_topics_enabled: Optional[str] = None,
                 refresh_topics_interval_seconds: Optional[str] = None,
                 sync_group_offsets_enabled: Optional[str] = None,
                 sync_group_offsets_interval_seconds: Optional[str] = None):
        """
        :param str emit_checkpoints_enabled: Whether to periodically write the translated offsets
               of replicated consumer groups (in the source cluster) to __consumer_offsets topic in target cluster,
               as long as no active consumers in that group are connected to the target cluster.
        :param str refresh_groups_enabled: Whether to periodically check for new consumer groups.
               Defaults to 'true'.
        :param str refresh_groups_interval_seconds: Frequency of consumer group refresh in seconds.
               Defaults to 600 seconds (10 minutes).
        :param str refresh_topics_enabled: Whether to periodically check for new topics and
               partitions. Defaults to 'true'.
        :param str refresh_topics_interval_seconds: Frequency of topic and partitions refresh in
               seconds. Defaults to 600 seconds (10 minutes).
        :param str sync_group_offsets_enabled: Whether to periodically write the translated offsets of replicated consumer groups (in the source cluster) to __consumer_offsets topic in target cluster, as long as no active consumers in that group are connected to the target cluster. Defaults to 'false'.
        :param str sync_group_offsets_interval_seconds: Frequency at which consumer group offsets
               are synced (default: 60, every minute).
        """
        if emit_checkpoints_enabled is not None:
            pulumi.set(__self__, "emit_checkpoints_enabled", emit_checkpoints_enabled)
        if emit_checkpoints_interval_seconds is not None:
            pulumi.set(__self__, "emit_checkpoints_interval_seconds", emit_checkpoints_interval_seconds)
        if refresh_groups_enabled is not None:
            pulumi.set(__self__, "refresh_groups_enabled", refresh_groups_enabled)
        if refresh_groups_interval_seconds is not None:
            pulumi.set(__self__, "refresh_groups_interval_seconds", refresh_groups_interval_seconds)
        if refresh_topics_enabled is not None:
            pulumi.set(__self__, "refresh_topics_enabled", refresh_topics_enabled)
        if refresh_topics_interval_seconds is not None:
            pulumi.set(__self__, "refresh_topics_interval_seconds", refresh_topics_interval_seconds)
        if sync_group_offsets_enabled is not None:
            pulumi.set(__self__, "sync_group_offsets_enabled", sync_group_offsets_enabled)
        if sync_group_offsets_interval_seconds is not None:
            pulumi.set(__self__, "sync_group_offsets_interval_seconds", sync_group_offsets_interval_seconds)

    @property
    @pulumi.getter(name="emitCheckpointsEnabled")
    def emit_checkpoints_enabled(self) -> Optional[str]:
        """
        Whether to periodically write the translated offsets
        of replicated consumer groups (in the source cluster) to __consumer_offsets topic in target cluster,
        as long as no active consumers in that group are connected to the target cluster.
        """
        return pulumi.get(self, "emit_checkpoints_enabled")

    @property
    @pulumi.getter(name="emitCheckpointsIntervalSeconds")
    def emit_checkpoints_interval_seconds(self) -> Optional[str]:
        return pulumi.get(self, "emit_checkpoints_interval_seconds")

    @property
    @pulumi.getter(name="refreshGroupsEnabled")
    def refresh_groups_enabled(self) -> Optional[str]:
        """
        Whether to periodically check for new consumer groups.
        Defaults to 'true'.
        """
        return pulumi.get(self, "refresh_groups_enabled")

    @property
    @pulumi.getter(name="refreshGroupsIntervalSeconds")
    def refresh_groups_interval_seconds(self) -> Optional[str]:
        """
        Frequency of consumer group refresh in seconds.
        Defaults to 600 seconds (10 minutes).
        """
        return pulumi.get(self, "refresh_groups_interval_seconds")

    @property
    @pulumi.getter(name="refreshTopicsEnabled")
    def refresh_topics_enabled(self) -> Optional[str]:
        """
        Whether to periodically check for new topics and
        partitions. Defaults to 'true'.
        """
        return pulumi.get(self, "refresh_topics_enabled")

    @property
    @pulumi.getter(name="refreshTopicsIntervalSeconds")
    def refresh_topics_interval_seconds(self) -> Optional[str]:
        """
        Frequency of topic and partitions refresh in
        seconds. Defaults to 600 seconds (10 minutes).
        """
        return pulumi.get(self, "refresh_topics_interval_seconds")

    @property
    @pulumi.getter(name="syncGroupOffsetsEnabled")
    def sync_group_offsets_enabled(self) -> Optional[str]:
        """
        Whether to periodically write the translated offsets of replicated consumer groups (in the source cluster) to __consumer_offsets topic in target cluster, as long as no active consumers in that group are connected to the target cluster. Defaults to 'false'.
        """
        return pulumi.get(self, "sync_group_offsets_enabled")

    @property
    @pulumi.getter(name="syncGroupOffsetsIntervalSeconds")
    def sync_group_offsets_interval_seconds(self) -> Optional[str]:
        """
        Frequency at which consumer group offsets
        are synced (default: 60, every minute).
        """
        return pulumi.get(self, "sync_group_offsets_interval_seconds")


@pulumi.output_type
class KafkaMirrorMakerServiceIntegration(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "integrationType":
            suggest = "integration_type"
        elif key == "sourceServiceName":
            suggest = "source_service_name"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in KafkaMirrorMakerServiceIntegration. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        KafkaMirrorMakerServiceIntegration.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        KafkaMirrorMakerServiceIntegration.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 integration_type: str,
                 source_service_name: str):
        pulumi.set(__self__, "integration_type", integration_type)
        pulumi.set(__self__, "source_service_name", source_service_name)

    @property
    @pulumi.getter(name="integrationType")
    def integration_type(self) -> str:
        return pulumi.get(self, "integration_type")

    @property
    @pulumi.getter(name="sourceServiceName")
    def source_service_name(self) -> str:
        return pulumi.get(self, "source_service_name")


@pulumi.output_type
class KafkaServiceIntegration(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "integrationType":
            suggest = "integration_type"
        elif key == "sourceServiceName":
            suggest = "source_service_name"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in KafkaServiceIntegration. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        KafkaServiceIntegration.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        KafkaServiceIntegration.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 integration_type: str,
                 source_service_name: str):
        pulumi.set(__self__, "integration_type", integration_type)
        pulumi.set(__self__, "source_service_name", source_service_name)

    @property
    @pulumi.getter(name="integrationType")
    def integration_type(self) -> str:
        return pulumi.get(self, "integration_type")

    @property
    @pulumi.getter(name="sourceServiceName")
    def source_service_name(self) -> str:
        return pulumi.get(self, "source_service_name")


@pulumi.output_type
class KafkaTopicConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "cleanupPolicy":
            suggest = "cleanup_policy"
        elif key == "compressionType":
            suggest = "compression_type"
        elif key == "deleteRetentionMs":
            suggest = "delete_retention_ms"
        elif key == "fileDeleteDelayMs":
            suggest = "file_delete_delay_ms"
        elif key == "flushMessages":
            suggest = "flush_messages"
        elif key == "flushMs":
            suggest = "flush_ms"
        elif key == "indexIntervalBytes":
            suggest = "index_interval_bytes"
        elif key == "maxCompactionLagMs":
            suggest = "max_compaction_lag_ms"
        elif key == "maxMessageBytes":
            suggest = "max_message_bytes"
        elif key == "messageDownconversionEnable":
            suggest = "message_downconversion_enable"
        elif key == "messageFormatVersion":
            suggest = "message_format_version"
        elif key == "messageTimestampDifferenceMaxMs":
            suggest = "message_timestamp_difference_max_ms"
        elif key == "messageTimestampType":
            suggest = "message_timestamp_type"
        elif key == "minCleanableDirtyRatio":
            suggest = "min_cleanable_dirty_ratio"
        elif key == "minCompactionLagMs":
            suggest = "min_compaction_lag_ms"
        elif key == "minInsyncReplicas":
            suggest = "min_insync_replicas"
        elif key == "retentionBytes":
            suggest = "retention_bytes"
        elif key == "retentionMs":
            suggest = "retention_ms"
        elif key == "segmentBytes":
            suggest = "segment_bytes"
        elif key == "segmentIndexBytes":
            suggest = "segment_index_bytes"
        elif key == "segmentJitterMs":
            suggest = "segment_jitter_ms"
        elif key == "segmentMs":
            suggest = "segment_ms"
        elif key == "uncleanLeaderElectionEnable":
            suggest = "unclean_leader_election_enable"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in KafkaTopicConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        KafkaTopicConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        KafkaTopicConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 cleanup_policy: Optional[str] = None,
                 compression_type: Optional[str] = None,
                 delete_retention_ms: Optional[str] = None,
                 file_delete_delay_ms: Optional[str] = None,
                 flush_messages: Optional[str] = None,
                 flush_ms: Optional[str] = None,
                 index_interval_bytes: Optional[str] = None,
                 max_compaction_lag_ms: Optional[str] = None,
                 max_message_bytes: Optional[str] = None,
                 message_downconversion_enable: Optional[str] = None,
                 message_format_version: Optional[str] = None,
                 message_timestamp_difference_max_ms: Optional[str] = None,
                 message_timestamp_type: Optional[str] = None,
                 min_cleanable_dirty_ratio: Optional[str] = None,
                 min_compaction_lag_ms: Optional[str] = None,
                 min_insync_replicas: Optional[str] = None,
                 preallocate: Optional[str] = None,
                 retention_bytes: Optional[str] = None,
                 retention_ms: Optional[str] = None,
                 segment_bytes: Optional[str] = None,
                 segment_index_bytes: Optional[str] = None,
                 segment_jitter_ms: Optional[str] = None,
                 segment_ms: Optional[str] = None,
                 unclean_leader_election_enable: Optional[str] = None):
        """
        :param str cleanup_policy: cleanup.policy value, can be `create`, `delete` or `compact,delete`
        :param str compression_type: compression.type value
        :param str delete_retention_ms: delete.retention.ms value
        :param str file_delete_delay_ms: file.delete.delay.ms value
        :param str flush_messages: flush.messages value
        :param str flush_ms: flush.ms value
        :param str index_interval_bytes: index.interval.bytes value
        :param str max_compaction_lag_ms: max.compaction.lag.ms value
        :param str max_message_bytes: max.message.bytes value
        :param str message_downconversion_enable: message.downconversion.enable value
        :param str message_format_version: message.format.version value
        :param str message_timestamp_difference_max_ms: message.timestamp.difference.max.ms value
        :param str message_timestamp_type: message.timestamp.type value
        :param str min_cleanable_dirty_ratio: min.cleanable.dirty.ratio value
        :param str min_compaction_lag_ms: min.compaction.lag.ms value
        :param str min_insync_replicas: min.insync.replicas value
        :param str preallocate: preallocate value
        :param str retention_bytes: retention.bytes value
        :param str retention_ms: retention.ms value
        :param str segment_bytes: segment.bytes value
        :param str segment_index_bytes: segment.index.bytes value
        :param str segment_jitter_ms: segment.jitter.ms value
        :param str segment_ms: segment.ms value
        :param str unclean_leader_election_enable: unclean.leader.election.enable value
        """
        if cleanup_policy is not None:
            pulumi.set(__self__, "cleanup_policy", cleanup_policy)
        if compression_type is not None:
            pulumi.set(__self__, "compression_type", compression_type)
        if delete_retention_ms is not None:
            pulumi.set(__self__, "delete_retention_ms", delete_retention_ms)
        if file_delete_delay_ms is not None:
            pulumi.set(__self__, "file_delete_delay_ms", file_delete_delay_ms)
        if flush_messages is not None:
            pulumi.set(__self__, "flush_messages", flush_messages)
        if flush_ms is not None:
            pulumi.set(__self__, "flush_ms", flush_ms)
        if index_interval_bytes is not None:
            pulumi.set(__self__, "index_interval_bytes", index_interval_bytes)
        if max_compaction_lag_ms is not None:
            pulumi.set(__self__, "max_compaction_lag_ms", max_compaction_lag_ms)
        if max_message_bytes is not None:
            pulumi.set(__self__, "max_message_bytes", max_message_bytes)
        if message_downconversion_enable is not None:
            pulumi.set(__self__, "message_downconversion_enable", message_downconversion_enable)
        if message_format_version is not None:
            pulumi.set(__self__, "message_format_version", message_format_version)
        if message_timestamp_difference_max_ms is not None:
            pulumi.set(__self__, "message_timestamp_difference_max_ms", message_timestamp_difference_max_ms)
        if message_timestamp_type is not None:
            pulumi.set(__self__, "message_timestamp_type", message_timestamp_type)
        if min_cleanable_dirty_ratio is not None:
            pulumi.set(__self__, "min_cleanable_dirty_ratio", min_cleanable_dirty_ratio)
        if min_compaction_lag_ms is not None:
            pulumi.set(__self__, "min_compaction_lag_ms", min_compaction_lag_ms)
        if min_insync_replicas is not None:
            pulumi.set(__self__, "min_insync_replicas", min_insync_replicas)
        if preallocate is not None:
            pulumi.set(__self__, "preallocate", preallocate)
        if retention_bytes is not None:
            pulumi.set(__self__, "retention_bytes", retention_bytes)
        if retention_ms is not None:
            pulumi.set(__self__, "retention_ms", retention_ms)
        if segment_bytes is not None:
            pulumi.set(__self__, "segment_bytes", segment_bytes)
        if segment_index_bytes is not None:
            pulumi.set(__self__, "segment_index_bytes", segment_index_bytes)
        if segment_jitter_ms is not None:
            pulumi.set(__self__, "segment_jitter_ms", segment_jitter_ms)
        if segment_ms is not None:
            pulumi.set(__self__, "segment_ms", segment_ms)
        if unclean_leader_election_enable is not None:
            pulumi.set(__self__, "unclean_leader_election_enable", unclean_leader_election_enable)

    @property
    @pulumi.getter(name="cleanupPolicy")
    def cleanup_policy(self) -> Optional[str]:
        """
        cleanup.policy value, can be `create`, `delete` or `compact,delete`
        """
        return pulumi.get(self, "cleanup_policy")

    @property
    @pulumi.getter(name="compressionType")
    def compression_type(self) -> Optional[str]:
        """
        compression.type value
        """
        return pulumi.get(self, "compression_type")

    @property
    @pulumi.getter(name="deleteRetentionMs")
    def delete_retention_ms(self) -> Optional[str]:
        """
        delete.retention.ms value
        """
        return pulumi.get(self, "delete_retention_ms")

    @property
    @pulumi.getter(name="fileDeleteDelayMs")
    def file_delete_delay_ms(self) -> Optional[str]:
        """
        file.delete.delay.ms value
        """
        return pulumi.get(self, "file_delete_delay_ms")

    @property
    @pulumi.getter(name="flushMessages")
    def flush_messages(self) -> Optional[str]:
        """
        flush.messages value
        """
        return pulumi.get(self, "flush_messages")

    @property
    @pulumi.getter(name="flushMs")
    def flush_ms(self) -> Optional[str]:
        """
        flush.ms value
        """
        return pulumi.get(self, "flush_ms")

    @property
    @pulumi.getter(name="indexIntervalBytes")
    def index_interval_bytes(self) -> Optional[str]:
        """
        index.interval.bytes value
        """
        return pulumi.get(self, "index_interval_bytes")

    @property
    @pulumi.getter(name="maxCompactionLagMs")
    def max_compaction_lag_ms(self) -> Optional[str]:
        """
        max.compaction.lag.ms value
        """
        return pulumi.get(self, "max_compaction_lag_ms")

    @property
    @pulumi.getter(name="maxMessageBytes")
    def max_message_bytes(self) -> Optional[str]:
        """
        max.message.bytes value
        """
        return pulumi.get(self, "max_message_bytes")

    @property
    @pulumi.getter(name="messageDownconversionEnable")
    def message_downconversion_enable(self) -> Optional[str]:
        """
        message.downconversion.enable value
        """
        return pulumi.get(self, "message_downconversion_enable")

    @property
    @pulumi.getter(name="messageFormatVersion")
    def message_format_version(self) -> Optional[str]:
        """
        message.format.version value
        """
        return pulumi.get(self, "message_format_version")

    @property
    @pulumi.getter(name="messageTimestampDifferenceMaxMs")
    def message_timestamp_difference_max_ms(self) -> Optional[str]:
        """
        message.timestamp.difference.max.ms value
        """
        return pulumi.get(self, "message_timestamp_difference_max_ms")

    @property
    @pulumi.getter(name="messageTimestampType")
    def message_timestamp_type(self) -> Optional[str]:
        """
        message.timestamp.type value
        """
        return pulumi.get(self, "message_timestamp_type")

    @property
    @pulumi.getter(name="minCleanableDirtyRatio")
    def min_cleanable_dirty_ratio(self) -> Optional[str]:
        """
        min.cleanable.dirty.ratio value
        """
        return pulumi.get(self, "min_cleanable_dirty_ratio")

    @property
    @pulumi.getter(name="minCompactionLagMs")
    def min_compaction_lag_ms(self) -> Optional[str]:
        """
        min.compaction.lag.ms value
        """
        return pulumi.get(self, "min_compaction_lag_ms")

    @property
    @pulumi.getter(name="minInsyncReplicas")
    def min_insync_replicas(self) -> Optional[str]:
        """
        min.insync.replicas value
        """
        return pulumi.get(self, "min_insync_replicas")

    @property
    @pulumi.getter
    def preallocate(self) -> Optional[str]:
        """
        preallocate value
        """
        return pulumi.get(self, "preallocate")

    @property
    @pulumi.getter(name="retentionBytes")
    def retention_bytes(self) -> Optional[str]:
        """
        retention.bytes value
        """
        return pulumi.get(self, "retention_bytes")

    @property
    @pulumi.getter(name="retentionMs")
    def retention_ms(self) -> Optional[str]:
        """
        retention.ms value
        """
        return pulumi.get(self, "retention_ms")

    @property
    @pulumi.getter(name="segmentBytes")
    def segment_bytes(self) -> Optional[str]:
        """
        segment.bytes value
        """
        return pulumi.get(self, "segment_bytes")

    @property
    @pulumi.getter(name="segmentIndexBytes")
    def segment_index_bytes(self) -> Optional[str]:
        """
        segment.index.bytes value
        """
        return pulumi.get(self, "segment_index_bytes")

    @property
    @pulumi.getter(name="segmentJitterMs")
    def segment_jitter_ms(self) -> Optional[str]:
        """
        segment.jitter.ms value
        """
        return pulumi.get(self, "segment_jitter_ms")

    @property
    @pulumi.getter(name="segmentMs")
    def segment_ms(self) -> Optional[str]:
        """
        segment.ms value
        """
        return pulumi.get(self, "segment_ms")

    @property
    @pulumi.getter(name="uncleanLeaderElectionEnable")
    def unclean_leader_election_enable(self) -> Optional[str]:
        """
        unclean.leader.election.enable value
        """
        return pulumi.get(self, "unclean_leader_election_enable")


@pulumi.output_type
class KafkaTopicTag(dict):
    def __init__(__self__, *,
                 key: str,
                 value: Optional[str] = None):
        pulumi.set(__self__, "key", key)
        if value is not None:
            pulumi.set(__self__, "value", value)

    @property
    @pulumi.getter
    def key(self) -> str:
        return pulumi.get(self, "key")

    @property
    @pulumi.getter
    def value(self) -> Optional[str]:
        return pulumi.get(self, "value")


@pulumi.output_type
class M3AggregatorComponent(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "kafkaAuthenticationMethod":
            suggest = "kafka_authentication_method"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in M3AggregatorComponent. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        M3AggregatorComponent.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        M3AggregatorComponent.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 component: Optional[str] = None,
                 host: Optional[str] = None,
                 kafka_authentication_method: Optional[str] = None,
                 port: Optional[int] = None,
                 route: Optional[str] = None,
                 ssl: Optional[bool] = None,
                 usage: Optional[str] = None):
        if component is not None:
            pulumi.set(__self__, "component", component)
        if host is not None:
            pulumi.set(__self__, "host", host)
        if kafka_authentication_method is not None:
            pulumi.set(__self__, "kafka_authentication_method", kafka_authentication_method)
        if port is not None:
            pulumi.set(__self__, "port", port)
        if route is not None:
            pulumi.set(__self__, "route", route)
        if ssl is not None:
            pulumi.set(__self__, "ssl", ssl)
        if usage is not None:
            pulumi.set(__self__, "usage", usage)

    @property
    @pulumi.getter
    def component(self) -> Optional[str]:
        return pulumi.get(self, "component")

    @property
    @pulumi.getter
    def host(self) -> Optional[str]:
        return pulumi.get(self, "host")

    @property
    @pulumi.getter(name="kafkaAuthenticationMethod")
    def kafka_authentication_method(self) -> Optional[str]:
        return pulumi.get(self, "kafka_authentication_method")

    @property
    @pulumi.getter
    def port(self) -> Optional[int]:
        return pulumi.get(self, "port")

    @property
    @pulumi.getter
    def route(self) -> Optional[str]:
        return pulumi.get(self, "route")

    @property
    @pulumi.getter
    def ssl(self) -> Optional[bool]:
        return pulumi.get(self, "ssl")

    @property
    @pulumi.getter
    def usage(self) -> Optional[str]:
        return pulumi.get(self, "usage")


@pulumi.output_type
class M3AggregatorM3aggregator(dict):
    def __init__(__self__):
        pass


@pulumi.output_type
class M3AggregatorM3aggregatorUserConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "customDomain":
            suggest = "custom_domain"
        elif key == "ipFilters":
            suggest = "ip_filters"
        elif key == "m3Version":
            suggest = "m3_version"
        elif key == "m3aggregatorVersion":
            suggest = "m3aggregator_version"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in M3AggregatorM3aggregatorUserConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        M3AggregatorM3aggregatorUserConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        M3AggregatorM3aggregatorUserConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 custom_domain: Optional[str] = None,
                 ip_filters: Optional[Sequence[str]] = None,
                 m3_version: Optional[str] = None,
                 m3aggregator_version: Optional[str] = None):
        """
        :param str custom_domain: Serve the web frontend using a custom CNAME pointing to the Aiven DNS name.
        :param Sequence[str] ip_filters: Allow incoming connections from CIDR address block, e.g. '10.20.0.0/16'
        :param str m3aggregator_version: M3 major version
        """
        if custom_domain is not None:
            pulumi.set(__self__, "custom_domain", custom_domain)
        if ip_filters is not None:
            pulumi.set(__self__, "ip_filters", ip_filters)
        if m3_version is not None:
            pulumi.set(__self__, "m3_version", m3_version)
        if m3aggregator_version is not None:
            pulumi.set(__self__, "m3aggregator_version", m3aggregator_version)

    @property
    @pulumi.getter(name="customDomain")
    def custom_domain(self) -> Optional[str]:
        """
        Serve the web frontend using a custom CNAME pointing to the Aiven DNS name.
        """
        return pulumi.get(self, "custom_domain")

    @property
    @pulumi.getter(name="ipFilters")
    def ip_filters(self) -> Optional[Sequence[str]]:
        """
        Allow incoming connections from CIDR address block, e.g. '10.20.0.0/16'
        """
        return pulumi.get(self, "ip_filters")

    @property
    @pulumi.getter(name="m3Version")
    def m3_version(self) -> Optional[str]:
        return pulumi.get(self, "m3_version")

    @property
    @pulumi.getter(name="m3aggregatorVersion")
    def m3aggregator_version(self) -> Optional[str]:
        """
        M3 major version
        """
        return pulumi.get(self, "m3aggregator_version")


@pulumi.output_type
class M3AggregatorServiceIntegration(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "integrationType":
            suggest = "integration_type"
        elif key == "sourceServiceName":
            suggest = "source_service_name"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in M3AggregatorServiceIntegration. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        M3AggregatorServiceIntegration.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        M3AggregatorServiceIntegration.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 integration_type: str,
                 source_service_name: str):
        pulumi.set(__self__, "integration_type", integration_type)
        pulumi.set(__self__, "source_service_name", source_service_name)

    @property
    @pulumi.getter(name="integrationType")
    def integration_type(self) -> str:
        return pulumi.get(self, "integration_type")

    @property
    @pulumi.getter(name="sourceServiceName")
    def source_service_name(self) -> str:
        return pulumi.get(self, "source_service_name")


@pulumi.output_type
class M3DbComponent(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "kafkaAuthenticationMethod":
            suggest = "kafka_authentication_method"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in M3DbComponent. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        M3DbComponent.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        M3DbComponent.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 component: Optional[str] = None,
                 host: Optional[str] = None,
                 kafka_authentication_method: Optional[str] = None,
                 port: Optional[int] = None,
                 route: Optional[str] = None,
                 ssl: Optional[bool] = None,
                 usage: Optional[str] = None):
        if component is not None:
            pulumi.set(__self__, "component", component)
        if host is not None:
            pulumi.set(__self__, "host", host)
        if kafka_authentication_method is not None:
            pulumi.set(__self__, "kafka_authentication_method", kafka_authentication_method)
        if port is not None:
            pulumi.set(__self__, "port", port)
        if route is not None:
            pulumi.set(__self__, "route", route)
        if ssl is not None:
            pulumi.set(__self__, "ssl", ssl)
        if usage is not None:
            pulumi.set(__self__, "usage", usage)

    @property
    @pulumi.getter
    def component(self) -> Optional[str]:
        return pulumi.get(self, "component")

    @property
    @pulumi.getter
    def host(self) -> Optional[str]:
        return pulumi.get(self, "host")

    @property
    @pulumi.getter(name="kafkaAuthenticationMethod")
    def kafka_authentication_method(self) -> Optional[str]:
        return pulumi.get(self, "kafka_authentication_method")

    @property
    @pulumi.getter
    def port(self) -> Optional[int]:
        return pulumi.get(self, "port")

    @property
    @pulumi.getter
    def route(self) -> Optional[str]:
        return pulumi.get(self, "route")

    @property
    @pulumi.getter
    def ssl(self) -> Optional[bool]:
        return pulumi.get(self, "ssl")

    @property
    @pulumi.getter
    def usage(self) -> Optional[str]:
        return pulumi.get(self, "usage")


@pulumi.output_type
class M3DbM3db(dict):
    def __init__(__self__):
        pass


@pulumi.output_type
class M3DbM3dbUserConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "customDomain":
            suggest = "custom_domain"
        elif key == "ipFilters":
            suggest = "ip_filters"
        elif key == "m3Version":
            suggest = "m3_version"
        elif key == "m3coordinatorEnableGraphiteCarbonIngest":
            suggest = "m3coordinator_enable_graphite_carbon_ingest"
        elif key == "m3dbVersion":
            suggest = "m3db_version"
        elif key == "privateAccess":
            suggest = "private_access"
        elif key == "projectToForkFrom":
            suggest = "project_to_fork_from"
        elif key == "publicAccess":
            suggest = "public_access"
        elif key == "serviceToForkFrom":
            suggest = "service_to_fork_from"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in M3DbM3dbUserConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        M3DbM3dbUserConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        M3DbM3dbUserConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 custom_domain: Optional[str] = None,
                 ip_filters: Optional[Sequence[str]] = None,
                 limits: Optional['outputs.M3DbM3dbUserConfigLimits'] = None,
                 m3_version: Optional[str] = None,
                 m3coordinator_enable_graphite_carbon_ingest: Optional[str] = None,
                 m3db_version: Optional[str] = None,
                 namespaces: Optional[Sequence['outputs.M3DbM3dbUserConfigNamespace']] = None,
                 private_access: Optional['outputs.M3DbM3dbUserConfigPrivateAccess'] = None,
                 project_to_fork_from: Optional[str] = None,
                 public_access: Optional['outputs.M3DbM3dbUserConfigPublicAccess'] = None,
                 rules: Optional['outputs.M3DbM3dbUserConfigRules'] = None,
                 service_to_fork_from: Optional[str] = None):
        """
        :param str custom_domain: Serve the web frontend using a custom CNAME pointing to the Aiven DNS name.
        :param Sequence[str] ip_filters: Allow incoming connections from CIDR address block, e.g. '10.20.0.0/16'
        :param 'M3DbM3dbUserConfigLimitsArgs' limits: M3 limits
        :param str m3coordinator_enable_graphite_carbon_ingest: Enables access to Graphite Carbon 
               plaintext metrics ingestion. It can be enabled only for services inside VPCs. The
               metrics are written to aggregated namespaces only.
        :param str m3db_version: M3 major version
        :param Sequence['M3DbM3dbUserConfigNamespaceArgs'] namespaces: List of M3 namespaces
        :param 'M3DbM3dbUserConfigPrivateAccessArgs' private_access: Allow access to selected service ports from private networks.
        :param str project_to_fork_from: Name of another project to fork a service from. This has
               effect only when a new service is being created.
        :param 'M3DbM3dbUserConfigPublicAccessArgs' public_access: Allow access to selected service ports from the public Internet.
        :param 'M3DbM3dbUserConfigRulesArgs' rules: Mapping rules allow more granular use of aggregation, not simply sending 
               everything to a namespace. If mapping rules exist that target a namespace, only data matching mapping
               rules will be sent to it and nothing else.
        :param str service_to_fork_from: Name of another service to fork from. This has effect only 
               when a new service is being created.
        """
        if custom_domain is not None:
            pulumi.set(__self__, "custom_domain", custom_domain)
        if ip_filters is not None:
            pulumi.set(__self__, "ip_filters", ip_filters)
        if limits is not None:
            pulumi.set(__self__, "limits", limits)
        if m3_version is not None:
            pulumi.set(__self__, "m3_version", m3_version)
        if m3coordinator_enable_graphite_carbon_ingest is not None:
            pulumi.set(__self__, "m3coordinator_enable_graphite_carbon_ingest", m3coordinator_enable_graphite_carbon_ingest)
        if m3db_version is not None:
            pulumi.set(__self__, "m3db_version", m3db_version)
        if namespaces is not None:
            pulumi.set(__self__, "namespaces", namespaces)
        if private_access is not None:
            pulumi.set(__self__, "private_access", private_access)
        if project_to_fork_from is not None:
            pulumi.set(__self__, "project_to_fork_from", project_to_fork_from)
        if public_access is not None:
            pulumi.set(__self__, "public_access", public_access)
        if rules is not None:
            pulumi.set(__self__, "rules", rules)
        if service_to_fork_from is not None:
            pulumi.set(__self__, "service_to_fork_from", service_to_fork_from)

    @property
    @pulumi.getter(name="customDomain")
    def custom_domain(self) -> Optional[str]:
        """
        Serve the web frontend using a custom CNAME pointing to the Aiven DNS name.
        """
        return pulumi.get(self, "custom_domain")

    @property
    @pulumi.getter(name="ipFilters")
    def ip_filters(self) -> Optional[Sequence[str]]:
        """
        Allow incoming connections from CIDR address block, e.g. '10.20.0.0/16'
        """
        return pulumi.get(self, "ip_filters")

    @property
    @pulumi.getter
    def limits(self) -> Optional['outputs.M3DbM3dbUserConfigLimits']:
        """
        M3 limits
        """
        return pulumi.get(self, "limits")

    @property
    @pulumi.getter(name="m3Version")
    def m3_version(self) -> Optional[str]:
        return pulumi.get(self, "m3_version")

    @property
    @pulumi.getter(name="m3coordinatorEnableGraphiteCarbonIngest")
    def m3coordinator_enable_graphite_carbon_ingest(self) -> Optional[str]:
        """
        Enables access to Graphite Carbon 
        plaintext metrics ingestion. It can be enabled only for services inside VPCs. The
        metrics are written to aggregated namespaces only.
        """
        return pulumi.get(self, "m3coordinator_enable_graphite_carbon_ingest")

    @property
    @pulumi.getter(name="m3dbVersion")
    def m3db_version(self) -> Optional[str]:
        """
        M3 major version
        """
        return pulumi.get(self, "m3db_version")

    @property
    @pulumi.getter
    def namespaces(self) -> Optional[Sequence['outputs.M3DbM3dbUserConfigNamespace']]:
        """
        List of M3 namespaces
        """
        return pulumi.get(self, "namespaces")

    @property
    @pulumi.getter(name="privateAccess")
    def private_access(self) -> Optional['outputs.M3DbM3dbUserConfigPrivateAccess']:
        """
        Allow access to selected service ports from private networks.
        """
        return pulumi.get(self, "private_access")

    @property
    @pulumi.getter(name="projectToForkFrom")
    def project_to_fork_from(self) -> Optional[str]:
        """
        Name of another project to fork a service from. This has
        effect only when a new service is being created.
        """
        return pulumi.get(self, "project_to_fork_from")

    @property
    @pulumi.getter(name="publicAccess")
    def public_access(self) -> Optional['outputs.M3DbM3dbUserConfigPublicAccess']:
        """
        Allow access to selected service ports from the public Internet.
        """
        return pulumi.get(self, "public_access")

    @property
    @pulumi.getter
    def rules(self) -> Optional['outputs.M3DbM3dbUserConfigRules']:
        """
        Mapping rules allow more granular use of aggregation, not simply sending 
        everything to a namespace. If mapping rules exist that target a namespace, only data matching mapping
        rules will be sent to it and nothing else.
        """
        return pulumi.get(self, "rules")

    @property
    @pulumi.getter(name="serviceToForkFrom")
    def service_to_fork_from(self) -> Optional[str]:
        """
        Name of another service to fork from. This has effect only 
        when a new service is being created.
        """
        return pulumi.get(self, "service_to_fork_from")


@pulumi.output_type
class M3DbM3dbUserConfigLimits(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "globalDatapoints":
            suggest = "global_datapoints"
        elif key == "queryDatapoints":
            suggest = "query_datapoints"
        elif key == "queryRequireExhaustive":
            suggest = "query_require_exhaustive"
        elif key == "querySeries":
            suggest = "query_series"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in M3DbM3dbUserConfigLimits. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        M3DbM3dbUserConfigLimits.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        M3DbM3dbUserConfigLimits.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 global_datapoints: Optional[str] = None,
                 query_datapoints: Optional[str] = None,
                 query_require_exhaustive: Optional[str] = None,
                 query_series: Optional[str] = None):
        """
        :param str global_datapoints: The maximum number of data points fetched during request
        :param str query_datapoints: The maximum number of data points fetched in single query
        :param str query_require_exhaustive: When query limits are exceeded, whether to return error 
               (if True) or return partial results (False)
        :param str query_series: The maximum number of series fetched in single query
        """
        if global_datapoints is not None:
            pulumi.set(__self__, "global_datapoints", global_datapoints)
        if query_datapoints is not None:
            pulumi.set(__self__, "query_datapoints", query_datapoints)
        if query_require_exhaustive is not None:
            pulumi.set(__self__, "query_require_exhaustive", query_require_exhaustive)
        if query_series is not None:
            pulumi.set(__self__, "query_series", query_series)

    @property
    @pulumi.getter(name="globalDatapoints")
    def global_datapoints(self) -> Optional[str]:
        """
        The maximum number of data points fetched during request
        """
        return pulumi.get(self, "global_datapoints")

    @property
    @pulumi.getter(name="queryDatapoints")
    def query_datapoints(self) -> Optional[str]:
        """
        The maximum number of data points fetched in single query
        """
        return pulumi.get(self, "query_datapoints")

    @property
    @pulumi.getter(name="queryRequireExhaustive")
    def query_require_exhaustive(self) -> Optional[str]:
        """
        When query limits are exceeded, whether to return error 
        (if True) or return partial results (False)
        """
        return pulumi.get(self, "query_require_exhaustive")

    @property
    @pulumi.getter(name="querySeries")
    def query_series(self) -> Optional[str]:
        """
        The maximum number of series fetched in single query
        """
        return pulumi.get(self, "query_series")


@pulumi.output_type
class M3DbM3dbUserConfigNamespace(dict):
    def __init__(__self__, *,
                 name: Optional[str] = None,
                 options: Optional['outputs.M3DbM3dbUserConfigNamespaceOptions'] = None,
                 resolution: Optional[str] = None,
                 type: Optional[str] = None):
        """
        :param str name: The name of the namespace
        :param 'M3DbM3dbUserConfigNamespaceOptionsArgs' options: Namespace options
        :param str resolution: The resolution for an aggregated namespace
        :param str type: The type of aggregation (aggregated/unaggregated)
        """
        if name is not None:
            pulumi.set(__self__, "name", name)
        if options is not None:
            pulumi.set(__self__, "options", options)
        if resolution is not None:
            pulumi.set(__self__, "resolution", resolution)
        if type is not None:
            pulumi.set(__self__, "type", type)

    @property
    @pulumi.getter
    def name(self) -> Optional[str]:
        """
        The name of the namespace
        """
        return pulumi.get(self, "name")

    @property
    @pulumi.getter
    def options(self) -> Optional['outputs.M3DbM3dbUserConfigNamespaceOptions']:
        """
        Namespace options
        """
        return pulumi.get(self, "options")

    @property
    @pulumi.getter
    def resolution(self) -> Optional[str]:
        """
        The resolution for an aggregated namespace
        """
        return pulumi.get(self, "resolution")

    @property
    @pulumi.getter
    def type(self) -> Optional[str]:
        """
        The type of aggregation (aggregated/unaggregated)
        """
        return pulumi.get(self, "type")


@pulumi.output_type
class M3DbM3dbUserConfigNamespaceOptions(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "retentionOptions":
            suggest = "retention_options"
        elif key == "snapshotEnabled":
            suggest = "snapshot_enabled"
        elif key == "writesToCommitlog":
            suggest = "writes_to_commitlog"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in M3DbM3dbUserConfigNamespaceOptions. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        M3DbM3dbUserConfigNamespaceOptions.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        M3DbM3dbUserConfigNamespaceOptions.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 retention_options: Optional['outputs.M3DbM3dbUserConfigNamespaceOptionsRetentionOptions'] = None,
                 snapshot_enabled: Optional[str] = None,
                 writes_to_commitlog: Optional[str] = None):
        """
        :param 'M3DbM3dbUserConfigNamespaceOptionsRetentionOptionsArgs' retention_options: Retention options
        :param str snapshot_enabled: Controls whether M3DB will create snapshot files for 
               this namespace
        :param str writes_to_commitlog: Controls whether M3DB will include writes to this 
               namespace in the commitlog.
        """
        if retention_options is not None:
            pulumi.set(__self__, "retention_options", retention_options)
        if snapshot_enabled is not None:
            pulumi.set(__self__, "snapshot_enabled", snapshot_enabled)
        if writes_to_commitlog is not None:
            pulumi.set(__self__, "writes_to_commitlog", writes_to_commitlog)

    @property
    @pulumi.getter(name="retentionOptions")
    def retention_options(self) -> Optional['outputs.M3DbM3dbUserConfigNamespaceOptionsRetentionOptions']:
        """
        Retention options
        """
        return pulumi.get(self, "retention_options")

    @property
    @pulumi.getter(name="snapshotEnabled")
    def snapshot_enabled(self) -> Optional[str]:
        """
        Controls whether M3DB will create snapshot files for 
        this namespace
        """
        return pulumi.get(self, "snapshot_enabled")

    @property
    @pulumi.getter(name="writesToCommitlog")
    def writes_to_commitlog(self) -> Optional[str]:
        """
        Controls whether M3DB will include writes to this 
        namespace in the commitlog.
        """
        return pulumi.get(self, "writes_to_commitlog")


@pulumi.output_type
class M3DbM3dbUserConfigNamespaceOptionsRetentionOptions(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "blockDataExpiryDuration":
            suggest = "block_data_expiry_duration"
        elif key == "blocksizeDuration":
            suggest = "blocksize_duration"
        elif key == "bufferFutureDuration":
            suggest = "buffer_future_duration"
        elif key == "bufferPastDuration":
            suggest = "buffer_past_duration"
        elif key == "retentionPeriodDuration":
            suggest = "retention_period_duration"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in M3DbM3dbUserConfigNamespaceOptionsRetentionOptions. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        M3DbM3dbUserConfigNamespaceOptionsRetentionOptions.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        M3DbM3dbUserConfigNamespaceOptionsRetentionOptions.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 block_data_expiry_duration: Optional[str] = None,
                 blocksize_duration: Optional[str] = None,
                 buffer_future_duration: Optional[str] = None,
                 buffer_past_duration: Optional[str] = None,
                 retention_period_duration: Optional[str] = None):
        """
        :param str block_data_expiry_duration: Controls how long we wait before expiring stale data
        :param str blocksize_duration: Controls how long to keep a block in memory before 
               flushing to a fileset on disk
        :param str buffer_future_duration: Controls how far into the future writes to 
               the namespace will be accepted
        :param str buffer_past_duration: Controls how far into the past writes to the 
               namespace will be accepted
        :param str retention_period_duration: Controls the duration of time that M3DB will 
               retain data for the namespace
        """
        if block_data_expiry_duration is not None:
            pulumi.set(__self__, "block_data_expiry_duration", block_data_expiry_duration)
        if blocksize_duration is not None:
            pulumi.set(__self__, "blocksize_duration", blocksize_duration)
        if buffer_future_duration is not None:
            pulumi.set(__self__, "buffer_future_duration", buffer_future_duration)
        if buffer_past_duration is not None:
            pulumi.set(__self__, "buffer_past_duration", buffer_past_duration)
        if retention_period_duration is not None:
            pulumi.set(__self__, "retention_period_duration", retention_period_duration)

    @property
    @pulumi.getter(name="blockDataExpiryDuration")
    def block_data_expiry_duration(self) -> Optional[str]:
        """
        Controls how long we wait before expiring stale data
        """
        return pulumi.get(self, "block_data_expiry_duration")

    @property
    @pulumi.getter(name="blocksizeDuration")
    def blocksize_duration(self) -> Optional[str]:
        """
        Controls how long to keep a block in memory before 
        flushing to a fileset on disk
        """
        return pulumi.get(self, "blocksize_duration")

    @property
    @pulumi.getter(name="bufferFutureDuration")
    def buffer_future_duration(self) -> Optional[str]:
        """
        Controls how far into the future writes to 
        the namespace will be accepted
        """
        return pulumi.get(self, "buffer_future_duration")

    @property
    @pulumi.getter(name="bufferPastDuration")
    def buffer_past_duration(self) -> Optional[str]:
        """
        Controls how far into the past writes to the 
        namespace will be accepted
        """
        return pulumi.get(self, "buffer_past_duration")

    @property
    @pulumi.getter(name="retentionPeriodDuration")
    def retention_period_duration(self) -> Optional[str]:
        """
        Controls the duration of time that M3DB will 
        retain data for the namespace
        """
        return pulumi.get(self, "retention_period_duration")


@pulumi.output_type
class M3DbM3dbUserConfigPrivateAccess(dict):
    def __init__(__self__, *,
                 m3coordinator: Optional[str] = None):
        """
        :param str m3coordinator: Allow clients to connect to m3coordinator from the public internet 
               for service nodes that are in a project VPC or another type of private network.
        """
        if m3coordinator is not None:
            pulumi.set(__self__, "m3coordinator", m3coordinator)

    @property
    @pulumi.getter
    def m3coordinator(self) -> Optional[str]:
        """
        Allow clients to connect to m3coordinator from the public internet 
        for service nodes that are in a project VPC or another type of private network.
        """
        return pulumi.get(self, "m3coordinator")


@pulumi.output_type
class M3DbM3dbUserConfigPublicAccess(dict):
    def __init__(__self__, *,
                 m3coordinator: Optional[str] = None):
        """
        :param str m3coordinator: Allow clients to connect to m3coordinator from the public internet 
               for service nodes that are in a project VPC or another type of private network.
        """
        if m3coordinator is not None:
            pulumi.set(__self__, "m3coordinator", m3coordinator)

    @property
    @pulumi.getter
    def m3coordinator(self) -> Optional[str]:
        """
        Allow clients to connect to m3coordinator from the public internet 
        for service nodes that are in a project VPC or another type of private network.
        """
        return pulumi.get(self, "m3coordinator")


@pulumi.output_type
class M3DbM3dbUserConfigRules(dict):
    def __init__(__self__, *,
                 mappings: Optional[Sequence['outputs.M3DbM3dbUserConfigRulesMapping']] = None):
        if mappings is not None:
            pulumi.set(__self__, "mappings", mappings)

    @property
    @pulumi.getter
    def mappings(self) -> Optional[Sequence['outputs.M3DbM3dbUserConfigRulesMapping']]:
        return pulumi.get(self, "mappings")


@pulumi.output_type
class M3DbM3dbUserConfigRulesMapping(dict):
    def __init__(__self__, *,
                 aggregations: Optional[Sequence[str]] = None,
                 drop: Optional[str] = None,
                 filter: Optional[str] = None,
                 name: Optional[str] = None,
                 tags: Optional[Sequence['outputs.M3DbM3dbUserConfigRulesMappingTag']] = None):
        """
        :param Sequence[str] aggregations: List of aggregations to be applied
        :param str drop: Drop the matching metric; Only store the derived metric (as specified in the roll-up rules), if any.
        :param str filter: The metrics to be used with this particular rule; Matching metric names with wildcards (using
               __name__:wildcard) or matching tags and their (optionally wildcarded) values. For value, !
               can be used at start of value for negation, and multiple filters can be supplied using space as separator.
        :param str name: The name of the namespace
        :param Sequence['M3DbM3dbUserConfigRulesMappingTagArgs'] tags: List of tags to be appended to matching metrics.
        """
        if aggregations is not None:
            pulumi.set(__self__, "aggregations", aggregations)
        if drop is not None:
            pulumi.set(__self__, "drop", drop)
        if filter is not None:
            pulumi.set(__self__, "filter", filter)
        if name is not None:
            pulumi.set(__self__, "name", name)
        if tags is not None:
            pulumi.set(__self__, "tags", tags)

    @property
    @pulumi.getter
    def aggregations(self) -> Optional[Sequence[str]]:
        """
        List of aggregations to be applied
        """
        return pulumi.get(self, "aggregations")

    @property
    @pulumi.getter
    def drop(self) -> Optional[str]:
        """
        Drop the matching metric; Only store the derived metric (as specified in the roll-up rules), if any.
        """
        return pulumi.get(self, "drop")

    @property
    @pulumi.getter
    def filter(self) -> Optional[str]:
        """
        The metrics to be used with this particular rule; Matching metric names with wildcards (using
        __name__:wildcard) or matching tags and their (optionally wildcarded) values. For value, !
        can be used at start of value for negation, and multiple filters can be supplied using space as separator.
        """
        return pulumi.get(self, "filter")

    @property
    @pulumi.getter
    def name(self) -> Optional[str]:
        """
        The name of the namespace
        """
        return pulumi.get(self, "name")

    @property
    @pulumi.getter
    def tags(self) -> Optional[Sequence['outputs.M3DbM3dbUserConfigRulesMappingTag']]:
        """
        List of tags to be appended to matching metrics.
        """
        return pulumi.get(self, "tags")


@pulumi.output_type
class M3DbM3dbUserConfigRulesMappingTag(dict):
    def __init__(__self__, *,
                 name: Optional[str] = None,
                 value: Optional[str] = None):
        """
        :param str name: The name of the namespace
        :param str value: Value of the tag.
        """
        if name is not None:
            pulumi.set(__self__, "name", name)
        if value is not None:
            pulumi.set(__self__, "value", value)

    @property
    @pulumi.getter
    def name(self) -> Optional[str]:
        """
        The name of the namespace
        """
        return pulumi.get(self, "name")

    @property
    @pulumi.getter
    def value(self) -> Optional[str]:
        """
        Value of the tag.
        """
        return pulumi.get(self, "value")


@pulumi.output_type
class M3DbServiceIntegration(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "integrationType":
            suggest = "integration_type"
        elif key == "sourceServiceName":
            suggest = "source_service_name"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in M3DbServiceIntegration. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        M3DbServiceIntegration.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        M3DbServiceIntegration.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 integration_type: str,
                 source_service_name: str):
        pulumi.set(__self__, "integration_type", integration_type)
        pulumi.set(__self__, "source_service_name", source_service_name)

    @property
    @pulumi.getter(name="integrationType")
    def integration_type(self) -> str:
        return pulumi.get(self, "integration_type")

    @property
    @pulumi.getter(name="sourceServiceName")
    def source_service_name(self) -> str:
        return pulumi.get(self, "source_service_name")


@pulumi.output_type
class MySqlComponent(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "kafkaAuthenticationMethod":
            suggest = "kafka_authentication_method"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in MySqlComponent. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        MySqlComponent.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        MySqlComponent.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 component: Optional[str] = None,
                 host: Optional[str] = None,
                 kafka_authentication_method: Optional[str] = None,
                 port: Optional[int] = None,
                 route: Optional[str] = None,
                 ssl: Optional[bool] = None,
                 usage: Optional[str] = None):
        """
        :param str host: Hostname or IP address of the server where to migrate data from
        :param int port: Port number of the server where to migrate data from
        :param bool ssl: The server where to migrate data from is secured with SSL
        """
        if component is not None:
            pulumi.set(__self__, "component", component)
        if host is not None:
            pulumi.set(__self__, "host", host)
        if kafka_authentication_method is not None:
            pulumi.set(__self__, "kafka_authentication_method", kafka_authentication_method)
        if port is not None:
            pulumi.set(__self__, "port", port)
        if route is not None:
            pulumi.set(__self__, "route", route)
        if ssl is not None:
            pulumi.set(__self__, "ssl", ssl)
        if usage is not None:
            pulumi.set(__self__, "usage", usage)

    @property
    @pulumi.getter
    def component(self) -> Optional[str]:
        return pulumi.get(self, "component")

    @property
    @pulumi.getter
    def host(self) -> Optional[str]:
        """
        Hostname or IP address of the server where to migrate data from
        """
        return pulumi.get(self, "host")

    @property
    @pulumi.getter(name="kafkaAuthenticationMethod")
    def kafka_authentication_method(self) -> Optional[str]:
        return pulumi.get(self, "kafka_authentication_method")

    @property
    @pulumi.getter
    def port(self) -> Optional[int]:
        """
        Port number of the server where to migrate data from
        """
        return pulumi.get(self, "port")

    @property
    @pulumi.getter
    def route(self) -> Optional[str]:
        return pulumi.get(self, "route")

    @property
    @pulumi.getter
    def ssl(self) -> Optional[bool]:
        """
        The server where to migrate data from is secured with SSL
        """
        return pulumi.get(self, "ssl")

    @property
    @pulumi.getter
    def usage(self) -> Optional[str]:
        return pulumi.get(self, "usage")


@pulumi.output_type
class MySqlMysql(dict):
    def __init__(__self__):
        pass


@pulumi.output_type
class MySqlMysqlUserConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "adminPassword":
            suggest = "admin_password"
        elif key == "adminUsername":
            suggest = "admin_username"
        elif key == "backupHour":
            suggest = "backup_hour"
        elif key == "backupMinute":
            suggest = "backup_minute"
        elif key == "binlogRetentionPeriod":
            suggest = "binlog_retention_period"
        elif key == "ipFilters":
            suggest = "ip_filters"
        elif key == "mysqlVersion":
            suggest = "mysql_version"
        elif key == "privateAccess":
            suggest = "private_access"
        elif key == "privatelinkAccess":
            suggest = "privatelink_access"
        elif key == "projectToForkFrom":
            suggest = "project_to_fork_from"
        elif key == "publicAccess":
            suggest = "public_access"
        elif key == "recoveryTargetTime":
            suggest = "recovery_target_time"
        elif key == "serviceToForkFrom":
            suggest = "service_to_fork_from"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in MySqlMysqlUserConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        MySqlMysqlUserConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        MySqlMysqlUserConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 admin_password: Optional[str] = None,
                 admin_username: Optional[str] = None,
                 backup_hour: Optional[str] = None,
                 backup_minute: Optional[str] = None,
                 binlog_retention_period: Optional[str] = None,
                 ip_filters: Optional[Sequence[str]] = None,
                 migration: Optional['outputs.MySqlMysqlUserConfigMigration'] = None,
                 mysql: Optional['outputs.MySqlMysqlUserConfigMysql'] = None,
                 mysql_version: Optional[str] = None,
                 private_access: Optional['outputs.MySqlMysqlUserConfigPrivateAccess'] = None,
                 privatelink_access: Optional['outputs.MySqlMysqlUserConfigPrivatelinkAccess'] = None,
                 project_to_fork_from: Optional[str] = None,
                 public_access: Optional['outputs.MySqlMysqlUserConfigPublicAccess'] = None,
                 recovery_target_time: Optional[str] = None,
                 service_to_fork_from: Optional[str] = None):
        """
        :param str admin_password: Custom password for admin user. Defaults to random string. 
               This must be set only when a new service is being created.
        :param str admin_username: Custom username for admin user. This must be set only when a 
               new service is being created.
        :param str backup_hour: The hour of day (in UTC) when backup for the service is started. 
               New backup is only started if previous backup has already completed.
        :param str backup_minute: The minute of an hour when backup for the service is started. 
               New backup is only started if previous backup has already completed.
        :param str binlog_retention_period: The minimum amount of time in seconds to keep binlog entries 
               before deletion. This may be extended for services that require binlog entries for longer than the
               default for example if using the MySQL Debezium Kafka connector.
        :param Sequence[str] ip_filters: Allow incoming connections from CIDR address block, e.g. '10.20.0.0/16'
        :param 'MySqlMysqlUserConfigMigrationArgs' migration: Migrate data from existing server
        :param 'MySqlMysqlUserConfigMysqlArgs' mysql: Allow clients to connect to mysql from the public internet for service 
               nodes that are in a project VPC or another type of private network
        :param str mysql_version: MySQL major version
        :param 'MySqlMysqlUserConfigPrivateAccessArgs' private_access: Allow access to selected service ports from private networks
        :param 'MySqlMysqlUserConfigPrivatelinkAccessArgs' privatelink_access: Allow access to selected service components through Privatelink
        :param str project_to_fork_from: Name of another project to fork a service from. This has
               effect only when a new service is being created.
        :param 'MySqlMysqlUserConfigPublicAccessArgs' public_access: Allow access to selected service ports from the public Internet
        :param str recovery_target_time: Recovery target time when forking a service. This has effect 
               only when a new service is being created.
        :param str service_to_fork_from: Name of another service to fork from. This has effect only when 
               a new service is being created.
        """
        if admin_password is not None:
            pulumi.set(__self__, "admin_password", admin_password)
        if admin_username is not None:
            pulumi.set(__self__, "admin_username", admin_username)
        if backup_hour is not None:
            pulumi.set(__self__, "backup_hour", backup_hour)
        if backup_minute is not None:
            pulumi.set(__self__, "backup_minute", backup_minute)
        if binlog_retention_period is not None:
            pulumi.set(__self__, "binlog_retention_period", binlog_retention_period)
        if ip_filters is not None:
            pulumi.set(__self__, "ip_filters", ip_filters)
        if migration is not None:
            pulumi.set(__self__, "migration", migration)
        if mysql is not None:
            pulumi.set(__self__, "mysql", mysql)
        if mysql_version is not None:
            pulumi.set(__self__, "mysql_version", mysql_version)
        if private_access is not None:
            pulumi.set(__self__, "private_access", private_access)
        if privatelink_access is not None:
            pulumi.set(__self__, "privatelink_access", privatelink_access)
        if project_to_fork_from is not None:
            pulumi.set(__self__, "project_to_fork_from", project_to_fork_from)
        if public_access is not None:
            pulumi.set(__self__, "public_access", public_access)
        if recovery_target_time is not None:
            pulumi.set(__self__, "recovery_target_time", recovery_target_time)
        if service_to_fork_from is not None:
            pulumi.set(__self__, "service_to_fork_from", service_to_fork_from)

    @property
    @pulumi.getter(name="adminPassword")
    def admin_password(self) -> Optional[str]:
        """
        Custom password for admin user. Defaults to random string. 
        This must be set only when a new service is being created.
        """
        return pulumi.get(self, "admin_password")

    @property
    @pulumi.getter(name="adminUsername")
    def admin_username(self) -> Optional[str]:
        """
        Custom username for admin user. This must be set only when a 
        new service is being created.
        """
        return pulumi.get(self, "admin_username")

    @property
    @pulumi.getter(name="backupHour")
    def backup_hour(self) -> Optional[str]:
        """
        The hour of day (in UTC) when backup for the service is started. 
        New backup is only started if previous backup has already completed.
        """
        return pulumi.get(self, "backup_hour")

    @property
    @pulumi.getter(name="backupMinute")
    def backup_minute(self) -> Optional[str]:
        """
        The minute of an hour when backup for the service is started. 
        New backup is only started if previous backup has already completed.
        """
        return pulumi.get(self, "backup_minute")

    @property
    @pulumi.getter(name="binlogRetentionPeriod")
    def binlog_retention_period(self) -> Optional[str]:
        """
        The minimum amount of time in seconds to keep binlog entries 
        before deletion. This may be extended for services that require binlog entries for longer than the
        default for example if using the MySQL Debezium Kafka connector.
        """
        return pulumi.get(self, "binlog_retention_period")

    @property
    @pulumi.getter(name="ipFilters")
    def ip_filters(self) -> Optional[Sequence[str]]:
        """
        Allow incoming connections from CIDR address block, e.g. '10.20.0.0/16'
        """
        return pulumi.get(self, "ip_filters")

    @property
    @pulumi.getter
    def migration(self) -> Optional['outputs.MySqlMysqlUserConfigMigration']:
        """
        Migrate data from existing server
        """
        return pulumi.get(self, "migration")

    @property
    @pulumi.getter
    def mysql(self) -> Optional['outputs.MySqlMysqlUserConfigMysql']:
        """
        Allow clients to connect to mysql from the public internet for service 
        nodes that are in a project VPC or another type of private network
        """
        return pulumi.get(self, "mysql")

    @property
    @pulumi.getter(name="mysqlVersion")
    def mysql_version(self) -> Optional[str]:
        """
        MySQL major version
        """
        return pulumi.get(self, "mysql_version")

    @property
    @pulumi.getter(name="privateAccess")
    def private_access(self) -> Optional['outputs.MySqlMysqlUserConfigPrivateAccess']:
        """
        Allow access to selected service ports from private networks
        """
        return pulumi.get(self, "private_access")

    @property
    @pulumi.getter(name="privatelinkAccess")
    def privatelink_access(self) -> Optional['outputs.MySqlMysqlUserConfigPrivatelinkAccess']:
        """
        Allow access to selected service components through Privatelink
        """
        return pulumi.get(self, "privatelink_access")

    @property
    @pulumi.getter(name="projectToForkFrom")
    def project_to_fork_from(self) -> Optional[str]:
        """
        Name of another project to fork a service from. This has
        effect only when a new service is being created.
        """
        return pulumi.get(self, "project_to_fork_from")

    @property
    @pulumi.getter(name="publicAccess")
    def public_access(self) -> Optional['outputs.MySqlMysqlUserConfigPublicAccess']:
        """
        Allow access to selected service ports from the public Internet
        """
        return pulumi.get(self, "public_access")

    @property
    @pulumi.getter(name="recoveryTargetTime")
    def recovery_target_time(self) -> Optional[str]:
        """
        Recovery target time when forking a service. This has effect 
        only when a new service is being created.
        """
        return pulumi.get(self, "recovery_target_time")

    @property
    @pulumi.getter(name="serviceToForkFrom")
    def service_to_fork_from(self) -> Optional[str]:
        """
        Name of another service to fork from. This has effect only when 
        a new service is being created.
        """
        return pulumi.get(self, "service_to_fork_from")


@pulumi.output_type
class MySqlMysqlUserConfigMigration(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "ignoreDbs":
            suggest = "ignore_dbs"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in MySqlMysqlUserConfigMigration. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        MySqlMysqlUserConfigMigration.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        MySqlMysqlUserConfigMigration.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 dbname: Optional[str] = None,
                 host: Optional[str] = None,
                 ignore_dbs: Optional[str] = None,
                 password: Optional[str] = None,
                 port: Optional[str] = None,
                 ssl: Optional[str] = None,
                 username: Optional[str] = None):
        """
        :param str dbname: Database name for bootstrapping the initial connection
        :param str host: Hostname or IP address of the server where to migrate data from
        :param str ignore_dbs: Comma-separated list of databases, which should be ignored 
               during migration (supported by MySQL only at the moment)
        :param str password: Password for authentication with the server where to migrate data from
        :param str port: Port number of the server where to migrate data from
        :param str ssl: The server where to migrate data from is secured with SSL
        :param str username: User name for authentication with the server where to migrate data from
        """
        if dbname is not None:
            pulumi.set(__self__, "dbname", dbname)
        if host is not None:
            pulumi.set(__self__, "host", host)
        if ignore_dbs is not None:
            pulumi.set(__self__, "ignore_dbs", ignore_dbs)
        if password is not None:
            pulumi.set(__self__, "password", password)
        if port is not None:
            pulumi.set(__self__, "port", port)
        if ssl is not None:
            pulumi.set(__self__, "ssl", ssl)
        if username is not None:
            pulumi.set(__self__, "username", username)

    @property
    @pulumi.getter
    def dbname(self) -> Optional[str]:
        """
        Database name for bootstrapping the initial connection
        """
        return pulumi.get(self, "dbname")

    @property
    @pulumi.getter
    def host(self) -> Optional[str]:
        """
        Hostname or IP address of the server where to migrate data from
        """
        return pulumi.get(self, "host")

    @property
    @pulumi.getter(name="ignoreDbs")
    def ignore_dbs(self) -> Optional[str]:
        """
        Comma-separated list of databases, which should be ignored 
        during migration (supported by MySQL only at the moment)
        """
        return pulumi.get(self, "ignore_dbs")

    @property
    @pulumi.getter
    def password(self) -> Optional[str]:
        """
        Password for authentication with the server where to migrate data from
        """
        return pulumi.get(self, "password")

    @property
    @pulumi.getter
    def port(self) -> Optional[str]:
        """
        Port number of the server where to migrate data from
        """
        return pulumi.get(self, "port")

    @property
    @pulumi.getter
    def ssl(self) -> Optional[str]:
        """
        The server where to migrate data from is secured with SSL
        """
        return pulumi.get(self, "ssl")

    @property
    @pulumi.getter
    def username(self) -> Optional[str]:
        """
        User name for authentication with the server where to migrate data from
        """
        return pulumi.get(self, "username")


@pulumi.output_type
class MySqlMysqlUserConfigMysql(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "connectTimeout":
            suggest = "connect_timeout"
        elif key == "defaultTimeZone":
            suggest = "default_time_zone"
        elif key == "groupConcatMaxLen":
            suggest = "group_concat_max_len"
        elif key == "informationSchemaStatsExpiry":
            suggest = "information_schema_stats_expiry"
        elif key == "innodbFtMinTokenSize":
            suggest = "innodb_ft_min_token_size"
        elif key == "innodbFtServerStopwordTable":
            suggest = "innodb_ft_server_stopword_table"
        elif key == "innodbLockWaitTimeout":
            suggest = "innodb_lock_wait_timeout"
        elif key == "innodbLogBufferSize":
            suggest = "innodb_log_buffer_size"
        elif key == "innodbOnlineAlterLogMaxSize":
            suggest = "innodb_online_alter_log_max_size"
        elif key == "innodbPrintAllDeadlocks":
            suggest = "innodb_print_all_deadlocks"
        elif key == "innodbRollbackOnTimeout":
            suggest = "innodb_rollback_on_timeout"
        elif key == "interactiveTimeout":
            suggest = "interactive_timeout"
        elif key == "longQueryTime":
            suggest = "long_query_time"
        elif key == "maxAllowedPacket":
            suggest = "max_allowed_packet"
        elif key == "maxHeapTableSize":
            suggest = "max_heap_table_size"
        elif key == "netReadTimeout":
            suggest = "net_read_timeout"
        elif key == "netWriteTimeout":
            suggest = "net_write_timeout"
        elif key == "slowQueryLog":
            suggest = "slow_query_log"
        elif key == "sortBufferSize":
            suggest = "sort_buffer_size"
        elif key == "sqlMode":
            suggest = "sql_mode"
        elif key == "sqlRequirePrimaryKey":
            suggest = "sql_require_primary_key"
        elif key == "tmpTableSize":
            suggest = "tmp_table_size"
        elif key == "waitTimeout":
            suggest = "wait_timeout"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in MySqlMysqlUserConfigMysql. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        MySqlMysqlUserConfigMysql.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        MySqlMysqlUserConfigMysql.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 connect_timeout: Optional[str] = None,
                 default_time_zone: Optional[str] = None,
                 group_concat_max_len: Optional[str] = None,
                 information_schema_stats_expiry: Optional[str] = None,
                 innodb_ft_min_token_size: Optional[str] = None,
                 innodb_ft_server_stopword_table: Optional[str] = None,
                 innodb_lock_wait_timeout: Optional[str] = None,
                 innodb_log_buffer_size: Optional[str] = None,
                 innodb_online_alter_log_max_size: Optional[str] = None,
                 innodb_print_all_deadlocks: Optional[str] = None,
                 innodb_rollback_on_timeout: Optional[str] = None,
                 interactive_timeout: Optional[str] = None,
                 long_query_time: Optional[str] = None,
                 max_allowed_packet: Optional[str] = None,
                 max_heap_table_size: Optional[str] = None,
                 net_read_timeout: Optional[str] = None,
                 net_write_timeout: Optional[str] = None,
                 slow_query_log: Optional[str] = None,
                 sort_buffer_size: Optional[str] = None,
                 sql_mode: Optional[str] = None,
                 sql_require_primary_key: Optional[str] = None,
                 tmp_table_size: Optional[str] = None,
                 wait_timeout: Optional[str] = None):
        """
        :param str connect_timeout: The number of seconds that the mysqld server waits for a 
               connect packet before responding with Bad handshake
        :param str default_time_zone: Default server time zone as an offset from UTC 
               (from -12:00 to +12:00), a time zone name, or 'SYSTEM' to use the MySQL server default.
        :param str group_concat_max_len: The maximum permitted result length in bytes for 
               the GROUP_CONCAT() function.
        :param str information_schema_stats_expiry: The time, in seconds, before cached 
               statistics expire
        :param str innodb_ft_min_token_size: Minimum length of words that are stored in 
               an InnoDB FULLTEXT index.
        :param str innodb_ft_server_stopword_table: This option is used to specify your 
               own InnoDB FULLTEXT index stopword list for all InnoDB tables.
        :param str innodb_lock_wait_timeout: The length of time in seconds an InnoDB 
               transaction waits for a row lock before giving up.
        :param str innodb_log_buffer_size: The size in bytes of the buffer that InnoDB 
               uses to write to the log files on disk.
        :param str innodb_online_alter_log_max_size: The upper limit in bytes on the 
               size of the temporary log files used during online DDL operations for InnoDB tables.
        :param str innodb_print_all_deadlocks: When enabled, information about all 
               deadlocks in InnoDB user transactions is recorded in the error log. Disabled by default.
        :param str innodb_rollback_on_timeout: When enabled a transaction timeout 
               causes InnoDB to abort and roll back the entire transaction.
        :param str interactive_timeout: The number of seconds the server waits for 
               activity on an interactive connection before closing it.
        :param str long_query_time: The slow_query_logs work as SQL statements that take 
               more than long_query_time seconds to execute. Default is 10s
        :param str max_allowed_packet: Size of the largest message in bytes that can 
               be received by the server. Default is 67108864 (64M)
        :param str max_heap_table_size: Limits the size of internal in-memory tables. 
               Also set tmp_table_size. Default is 16777216 (16M)
        :param str net_read_timeout: The number of seconds to wait for more data from 
               a connection before aborting the read.
        :param str net_write_timeout: The number of seconds to wait for a block to be 
               written to a connection before aborting the write.
        :param str slow_query_log: Slow query log enables capturing of slow queries. 
               Setting slow_query_log to false also truncates the mysql.slow_log table. Default is off
        :param str sort_buffer_size: Sort buffer size in bytes for ORDER BY optimization. 
               Default is 262144 (256K)
        :param str sql_mode: Global SQL mode. Set to empty to use MySQL server defaults. 
               When creating a new service and not setting this field Aiven default SQL mode (strict,
               SQL standard compliant) will be assigned.
        :param str sql_require_primary_key: Require primary key to be defined for new 
               tables or old tables modified with ALTER TABLE and fail if missing. It is recommended
               to always have primary keys because various functionality may break if any large table
               is missing them.
        :param str tmp_table_size: Limits the size of internal in-memory tables. Also set 
               max_heap_table_size. Default is 16777216 (16M)
        :param str wait_timeout: The number of seconds the server waits for activity on 
               a noninteractive connection before closing it.
        """
        if connect_timeout is not None:
            pulumi.set(__self__, "connect_timeout", connect_timeout)
        if default_time_zone is not None:
            pulumi.set(__self__, "default_time_zone", default_time_zone)
        if group_concat_max_len is not None:
            pulumi.set(__self__, "group_concat_max_len", group_concat_max_len)
        if information_schema_stats_expiry is not None:
            pulumi.set(__self__, "information_schema_stats_expiry", information_schema_stats_expiry)
        if innodb_ft_min_token_size is not None:
            pulumi.set(__self__, "innodb_ft_min_token_size", innodb_ft_min_token_size)
        if innodb_ft_server_stopword_table is not None:
            pulumi.set(__self__, "innodb_ft_server_stopword_table", innodb_ft_server_stopword_table)
        if innodb_lock_wait_timeout is not None:
            pulumi.set(__self__, "innodb_lock_wait_timeout", innodb_lock_wait_timeout)
        if innodb_log_buffer_size is not None:
            pulumi.set(__self__, "innodb_log_buffer_size", innodb_log_buffer_size)
        if innodb_online_alter_log_max_size is not None:
            pulumi.set(__self__, "innodb_online_alter_log_max_size", innodb_online_alter_log_max_size)
        if innodb_print_all_deadlocks is not None:
            pulumi.set(__self__, "innodb_print_all_deadlocks", innodb_print_all_deadlocks)
        if innodb_rollback_on_timeout is not None:
            pulumi.set(__self__, "innodb_rollback_on_timeout", innodb_rollback_on_timeout)
        if interactive_timeout is not None:
            pulumi.set(__self__, "interactive_timeout", interactive_timeout)
        if long_query_time is not None:
            pulumi.set(__self__, "long_query_time", long_query_time)
        if max_allowed_packet is not None:
            pulumi.set(__self__, "max_allowed_packet", max_allowed_packet)
        if max_heap_table_size is not None:
            pulumi.set(__self__, "max_heap_table_size", max_heap_table_size)
        if net_read_timeout is not None:
            pulumi.set(__self__, "net_read_timeout", net_read_timeout)
        if net_write_timeout is not None:
            pulumi.set(__self__, "net_write_timeout", net_write_timeout)
        if slow_query_log is not None:
            pulumi.set(__self__, "slow_query_log", slow_query_log)
        if sort_buffer_size is not None:
            pulumi.set(__self__, "sort_buffer_size", sort_buffer_size)
        if sql_mode is not None:
            pulumi.set(__self__, "sql_mode", sql_mode)
        if sql_require_primary_key is not None:
            pulumi.set(__self__, "sql_require_primary_key", sql_require_primary_key)
        if tmp_table_size is not None:
            pulumi.set(__self__, "tmp_table_size", tmp_table_size)
        if wait_timeout is not None:
            pulumi.set(__self__, "wait_timeout", wait_timeout)

    @property
    @pulumi.getter(name="connectTimeout")
    def connect_timeout(self) -> Optional[str]:
        """
        The number of seconds that the mysqld server waits for a 
        connect packet before responding with Bad handshake
        """
        return pulumi.get(self, "connect_timeout")

    @property
    @pulumi.getter(name="defaultTimeZone")
    def default_time_zone(self) -> Optional[str]:
        """
        Default server time zone as an offset from UTC 
        (from -12:00 to +12:00), a time zone name, or 'SYSTEM' to use the MySQL server default.
        """
        return pulumi.get(self, "default_time_zone")

    @property
    @pulumi.getter(name="groupConcatMaxLen")
    def group_concat_max_len(self) -> Optional[str]:
        """
        The maximum permitted result length in bytes for 
        the GROUP_CONCAT() function.
        """
        return pulumi.get(self, "group_concat_max_len")

    @property
    @pulumi.getter(name="informationSchemaStatsExpiry")
    def information_schema_stats_expiry(self) -> Optional[str]:
        """
        The time, in seconds, before cached 
        statistics expire
        """
        return pulumi.get(self, "information_schema_stats_expiry")

    @property
    @pulumi.getter(name="innodbFtMinTokenSize")
    def innodb_ft_min_token_size(self) -> Optional[str]:
        """
        Minimum length of words that are stored in 
        an InnoDB FULLTEXT index.
        """
        return pulumi.get(self, "innodb_ft_min_token_size")

    @property
    @pulumi.getter(name="innodbFtServerStopwordTable")
    def innodb_ft_server_stopword_table(self) -> Optional[str]:
        """
        This option is used to specify your 
        own InnoDB FULLTEXT index stopword list for all InnoDB tables.
        """
        return pulumi.get(self, "innodb_ft_server_stopword_table")

    @property
    @pulumi.getter(name="innodbLockWaitTimeout")
    def innodb_lock_wait_timeout(self) -> Optional[str]:
        """
        The length of time in seconds an InnoDB 
        transaction waits for a row lock before giving up.
        """
        return pulumi.get(self, "innodb_lock_wait_timeout")

    @property
    @pulumi.getter(name="innodbLogBufferSize")
    def innodb_log_buffer_size(self) -> Optional[str]:
        """
        The size in bytes of the buffer that InnoDB 
        uses to write to the log files on disk.
        """
        return pulumi.get(self, "innodb_log_buffer_size")

    @property
    @pulumi.getter(name="innodbOnlineAlterLogMaxSize")
    def innodb_online_alter_log_max_size(self) -> Optional[str]:
        """
        The upper limit in bytes on the 
        size of the temporary log files used during online DDL operations for InnoDB tables.
        """
        return pulumi.get(self, "innodb_online_alter_log_max_size")

    @property
    @pulumi.getter(name="innodbPrintAllDeadlocks")
    def innodb_print_all_deadlocks(self) -> Optional[str]:
        """
        When enabled, information about all 
        deadlocks in InnoDB user transactions is recorded in the error log. Disabled by default.
        """
        return pulumi.get(self, "innodb_print_all_deadlocks")

    @property
    @pulumi.getter(name="innodbRollbackOnTimeout")
    def innodb_rollback_on_timeout(self) -> Optional[str]:
        """
        When enabled a transaction timeout 
        causes InnoDB to abort and roll back the entire transaction.
        """
        return pulumi.get(self, "innodb_rollback_on_timeout")

    @property
    @pulumi.getter(name="interactiveTimeout")
    def interactive_timeout(self) -> Optional[str]:
        """
        The number of seconds the server waits for 
        activity on an interactive connection before closing it.
        """
        return pulumi.get(self, "interactive_timeout")

    @property
    @pulumi.getter(name="longQueryTime")
    def long_query_time(self) -> Optional[str]:
        """
        The slow_query_logs work as SQL statements that take 
        more than long_query_time seconds to execute. Default is 10s
        """
        return pulumi.get(self, "long_query_time")

    @property
    @pulumi.getter(name="maxAllowedPacket")
    def max_allowed_packet(self) -> Optional[str]:
        """
        Size of the largest message in bytes that can 
        be received by the server. Default is 67108864 (64M)
        """
        return pulumi.get(self, "max_allowed_packet")

    @property
    @pulumi.getter(name="maxHeapTableSize")
    def max_heap_table_size(self) -> Optional[str]:
        """
        Limits the size of internal in-memory tables. 
        Also set tmp_table_size. Default is 16777216 (16M)
        """
        return pulumi.get(self, "max_heap_table_size")

    @property
    @pulumi.getter(name="netReadTimeout")
    def net_read_timeout(self) -> Optional[str]:
        """
        The number of seconds to wait for more data from 
        a connection before aborting the read.
        """
        return pulumi.get(self, "net_read_timeout")

    @property
    @pulumi.getter(name="netWriteTimeout")
    def net_write_timeout(self) -> Optional[str]:
        """
        The number of seconds to wait for a block to be 
        written to a connection before aborting the write.
        """
        return pulumi.get(self, "net_write_timeout")

    @property
    @pulumi.getter(name="slowQueryLog")
    def slow_query_log(self) -> Optional[str]:
        """
        Slow query log enables capturing of slow queries. 
        Setting slow_query_log to false also truncates the mysql.slow_log table. Default is off
        """
        return pulumi.get(self, "slow_query_log")

    @property
    @pulumi.getter(name="sortBufferSize")
    def sort_buffer_size(self) -> Optional[str]:
        """
        Sort buffer size in bytes for ORDER BY optimization. 
        Default is 262144 (256K)
        """
        return pulumi.get(self, "sort_buffer_size")

    @property
    @pulumi.getter(name="sqlMode")
    def sql_mode(self) -> Optional[str]:
        """
        Global SQL mode. Set to empty to use MySQL server defaults. 
        When creating a new service and not setting this field Aiven default SQL mode (strict,
        SQL standard compliant) will be assigned.
        """
        return pulumi.get(self, "sql_mode")

    @property
    @pulumi.getter(name="sqlRequirePrimaryKey")
    def sql_require_primary_key(self) -> Optional[str]:
        """
        Require primary key to be defined for new 
        tables or old tables modified with ALTER TABLE and fail if missing. It is recommended
        to always have primary keys because various functionality may break if any large table
        is missing them.
        """
        return pulumi.get(self, "sql_require_primary_key")

    @property
    @pulumi.getter(name="tmpTableSize")
    def tmp_table_size(self) -> Optional[str]:
        """
        Limits the size of internal in-memory tables. Also set 
        max_heap_table_size. Default is 16777216 (16M)
        """
        return pulumi.get(self, "tmp_table_size")

    @property
    @pulumi.getter(name="waitTimeout")
    def wait_timeout(self) -> Optional[str]:
        """
        The number of seconds the server waits for activity on 
        a noninteractive connection before closing it.
        """
        return pulumi.get(self, "wait_timeout")


@pulumi.output_type
class MySqlMysqlUserConfigPrivateAccess(dict):
    def __init__(__self__, *,
                 mysql: Optional[str] = None,
                 mysqlx: Optional[str] = None,
                 prometheus: Optional[str] = None):
        """
        :param str mysql: Allow clients to connect to mysql from the public internet for service 
               nodes that are in a project VPC or another type of private network
        :param str mysqlx: Allow clients to connect to mysqlx from the public internet for service 
               nodes that are in a project VPC or another type of private network
        :param str prometheus: Allow clients to connect to prometheus from the public internet 
               for service nodes that are in a project VPC or another type of private network
        """
        if mysql is not None:
            pulumi.set(__self__, "mysql", mysql)
        if mysqlx is not None:
            pulumi.set(__self__, "mysqlx", mysqlx)
        if prometheus is not None:
            pulumi.set(__self__, "prometheus", prometheus)

    @property
    @pulumi.getter
    def mysql(self) -> Optional[str]:
        """
        Allow clients to connect to mysql from the public internet for service 
        nodes that are in a project VPC or another type of private network
        """
        return pulumi.get(self, "mysql")

    @property
    @pulumi.getter
    def mysqlx(self) -> Optional[str]:
        """
        Allow clients to connect to mysqlx from the public internet for service 
        nodes that are in a project VPC or another type of private network
        """
        return pulumi.get(self, "mysqlx")

    @property
    @pulumi.getter
    def prometheus(self) -> Optional[str]:
        """
        Allow clients to connect to prometheus from the public internet 
        for service nodes that are in a project VPC or another type of private network
        """
        return pulumi.get(self, "prometheus")


@pulumi.output_type
class MySqlMysqlUserConfigPrivatelinkAccess(dict):
    def __init__(__self__, *,
                 mysql: Optional[str] = None,
                 mysqlx: Optional[str] = None):
        """
        :param str mysql: Allow clients to connect to mysql from the public internet for service 
               nodes that are in a project VPC or another type of private network
        :param str mysqlx: Allow clients to connect to mysqlx from the public internet for service 
               nodes that are in a project VPC or another type of private network
        """
        if mysql is not None:
            pulumi.set(__self__, "mysql", mysql)
        if mysqlx is not None:
            pulumi.set(__self__, "mysqlx", mysqlx)

    @property
    @pulumi.getter
    def mysql(self) -> Optional[str]:
        """
        Allow clients to connect to mysql from the public internet for service 
        nodes that are in a project VPC or another type of private network
        """
        return pulumi.get(self, "mysql")

    @property
    @pulumi.getter
    def mysqlx(self) -> Optional[str]:
        """
        Allow clients to connect to mysqlx from the public internet for service 
        nodes that are in a project VPC or another type of private network
        """
        return pulumi.get(self, "mysqlx")


@pulumi.output_type
class MySqlMysqlUserConfigPublicAccess(dict):
    def __init__(__self__, *,
                 mysql: Optional[str] = None,
                 mysqlx: Optional[str] = None,
                 prometheus: Optional[str] = None):
        """
        :param str mysql: Allow clients to connect to mysql from the public internet for service 
               nodes that are in a project VPC or another type of private network
        :param str mysqlx: Allow clients to connect to mysqlx from the public internet for service 
               nodes that are in a project VPC or another type of private network
        :param str prometheus: Allow clients to connect to prometheus from the public internet 
               for service nodes that are in a project VPC or another type of private network
        """
        if mysql is not None:
            pulumi.set(__self__, "mysql", mysql)
        if mysqlx is not None:
            pulumi.set(__self__, "mysqlx", mysqlx)
        if prometheus is not None:
            pulumi.set(__self__, "prometheus", prometheus)

    @property
    @pulumi.getter
    def mysql(self) -> Optional[str]:
        """
        Allow clients to connect to mysql from the public internet for service 
        nodes that are in a project VPC or another type of private network
        """
        return pulumi.get(self, "mysql")

    @property
    @pulumi.getter
    def mysqlx(self) -> Optional[str]:
        """
        Allow clients to connect to mysqlx from the public internet for service 
        nodes that are in a project VPC or another type of private network
        """
        return pulumi.get(self, "mysqlx")

    @property
    @pulumi.getter
    def prometheus(self) -> Optional[str]:
        """
        Allow clients to connect to prometheus from the public internet 
        for service nodes that are in a project VPC or another type of private network
        """
        return pulumi.get(self, "prometheus")


@pulumi.output_type
class MySqlServiceIntegration(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "integrationType":
            suggest = "integration_type"
        elif key == "sourceServiceName":
            suggest = "source_service_name"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in MySqlServiceIntegration. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        MySqlServiceIntegration.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        MySqlServiceIntegration.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 integration_type: str,
                 source_service_name: str):
        pulumi.set(__self__, "integration_type", integration_type)
        pulumi.set(__self__, "source_service_name", source_service_name)

    @property
    @pulumi.getter(name="integrationType")
    def integration_type(self) -> str:
        return pulumi.get(self, "integration_type")

    @property
    @pulumi.getter(name="sourceServiceName")
    def source_service_name(self) -> str:
        return pulumi.get(self, "source_service_name")


@pulumi.output_type
class PgComponent(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "kafkaAuthenticationMethod":
            suggest = "kafka_authentication_method"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in PgComponent. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        PgComponent.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        PgComponent.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 component: Optional[str] = None,
                 host: Optional[str] = None,
                 kafka_authentication_method: Optional[str] = None,
                 port: Optional[int] = None,
                 route: Optional[str] = None,
                 ssl: Optional[bool] = None,
                 usage: Optional[str] = None):
        """
        :param str host: hostname or IP address of the server where to migrate data from.
        :param int port: port number of the server where to migrate data from.
        :param bool ssl: the server where to migrate data from is secured with SSL.
        """
        if component is not None:
            pulumi.set(__self__, "component", component)
        if host is not None:
            pulumi.set(__self__, "host", host)
        if kafka_authentication_method is not None:
            pulumi.set(__self__, "kafka_authentication_method", kafka_authentication_method)
        if port is not None:
            pulumi.set(__self__, "port", port)
        if route is not None:
            pulumi.set(__self__, "route", route)
        if ssl is not None:
            pulumi.set(__self__, "ssl", ssl)
        if usage is not None:
            pulumi.set(__self__, "usage", usage)

    @property
    @pulumi.getter
    def component(self) -> Optional[str]:
        return pulumi.get(self, "component")

    @property
    @pulumi.getter
    def host(self) -> Optional[str]:
        """
        hostname or IP address of the server where to migrate data from.
        """
        return pulumi.get(self, "host")

    @property
    @pulumi.getter(name="kafkaAuthenticationMethod")
    def kafka_authentication_method(self) -> Optional[str]:
        return pulumi.get(self, "kafka_authentication_method")

    @property
    @pulumi.getter
    def port(self) -> Optional[int]:
        """
        port number of the server where to migrate data from.
        """
        return pulumi.get(self, "port")

    @property
    @pulumi.getter
    def route(self) -> Optional[str]:
        return pulumi.get(self, "route")

    @property
    @pulumi.getter
    def ssl(self) -> Optional[bool]:
        """
        the server where to migrate data from is secured with SSL.
        """
        return pulumi.get(self, "ssl")

    @property
    @pulumi.getter
    def usage(self) -> Optional[str]:
        return pulumi.get(self, "usage")


@pulumi.output_type
class PgPg(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "replicaUri":
            suggest = "replica_uri"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in PgPg. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        PgPg.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        PgPg.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 dbname: Optional[str] = None,
                 host: Optional[str] = None,
                 password: Optional[str] = None,
                 port: Optional[int] = None,
                 replica_uri: Optional[str] = None,
                 sslmode: Optional[str] = None,
                 uri: Optional[str] = None,
                 user: Optional[str] = None):
        """
        :param str dbname: database name for bootstrapping the initial connection.
        :param str host: hostname or IP address of the server where to migrate data from.
        :param str password: password for authentication with the server where to migrate data from.
        :param int port: port number of the server where to migrate data from.
        :param str replica_uri: PostgreSQL replica URI for services with a replica
        :param str sslmode: PostgreSQL sslmode setting (currently always `require`)
        :param str uri: PostgreSQL master connection URI
        :param str user: PostgreSQL admin user name
        """
        if dbname is not None:
            pulumi.set(__self__, "dbname", dbname)
        if host is not None:
            pulumi.set(__self__, "host", host)
        if password is not None:
            pulumi.set(__self__, "password", password)
        if port is not None:
            pulumi.set(__self__, "port", port)
        if replica_uri is not None:
            pulumi.set(__self__, "replica_uri", replica_uri)
        if sslmode is not None:
            pulumi.set(__self__, "sslmode", sslmode)
        if uri is not None:
            pulumi.set(__self__, "uri", uri)
        if user is not None:
            pulumi.set(__self__, "user", user)

    @property
    @pulumi.getter
    def dbname(self) -> Optional[str]:
        """
        database name for bootstrapping the initial connection.
        """
        return pulumi.get(self, "dbname")

    @property
    @pulumi.getter
    def host(self) -> Optional[str]:
        """
        hostname or IP address of the server where to migrate data from.
        """
        return pulumi.get(self, "host")

    @property
    @pulumi.getter
    def password(self) -> Optional[str]:
        """
        password for authentication with the server where to migrate data from.
        """
        return pulumi.get(self, "password")

    @property
    @pulumi.getter
    def port(self) -> Optional[int]:
        """
        port number of the server where to migrate data from.
        """
        return pulumi.get(self, "port")

    @property
    @pulumi.getter(name="replicaUri")
    def replica_uri(self) -> Optional[str]:
        """
        PostgreSQL replica URI for services with a replica
        """
        return pulumi.get(self, "replica_uri")

    @property
    @pulumi.getter
    def sslmode(self) -> Optional[str]:
        """
        PostgreSQL sslmode setting (currently always `require`)
        """
        return pulumi.get(self, "sslmode")

    @property
    @pulumi.getter
    def uri(self) -> Optional[str]:
        """
        PostgreSQL master connection URI
        """
        return pulumi.get(self, "uri")

    @property
    @pulumi.getter
    def user(self) -> Optional[str]:
        """
        PostgreSQL admin user name
        """
        return pulumi.get(self, "user")


@pulumi.output_type
class PgPgUserConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "adminPassword":
            suggest = "admin_password"
        elif key == "adminUsername":
            suggest = "admin_username"
        elif key == "backupHour":
            suggest = "backup_hour"
        elif key == "backupMinute":
            suggest = "backup_minute"
        elif key == "ipFilters":
            suggest = "ip_filters"
        elif key == "pgReadReplica":
            suggest = "pg_read_replica"
        elif key == "pgServiceToForkFrom":
            suggest = "pg_service_to_fork_from"
        elif key == "pgVersion":
            suggest = "pg_version"
        elif key == "privateAccess":
            suggest = "private_access"
        elif key == "privatelinkAccess":
            suggest = "privatelink_access"
        elif key == "projectToForkFrom":
            suggest = "project_to_fork_from"
        elif key == "publicAccess":
            suggest = "public_access"
        elif key == "recoveryTargetTime":
            suggest = "recovery_target_time"
        elif key == "serviceToForkFrom":
            suggest = "service_to_fork_from"
        elif key == "sharedBuffersPercentage":
            suggest = "shared_buffers_percentage"
        elif key == "synchronousReplication":
            suggest = "synchronous_replication"
        elif key == "workMem":
            suggest = "work_mem"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in PgPgUserConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        PgPgUserConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        PgPgUserConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 admin_password: Optional[str] = None,
                 admin_username: Optional[str] = None,
                 backup_hour: Optional[str] = None,
                 backup_minute: Optional[str] = None,
                 ip_filters: Optional[Sequence[str]] = None,
                 migration: Optional['outputs.PgPgUserConfigMigration'] = None,
                 pg: Optional['outputs.PgPgUserConfigPg'] = None,
                 pg_read_replica: Optional[str] = None,
                 pg_service_to_fork_from: Optional[str] = None,
                 pg_version: Optional[str] = None,
                 pgbouncer: Optional['outputs.PgPgUserConfigPgbouncer'] = None,
                 pglookout: Optional['outputs.PgPgUserConfigPglookout'] = None,
                 private_access: Optional['outputs.PgPgUserConfigPrivateAccess'] = None,
                 privatelink_access: Optional['outputs.PgPgUserConfigPrivatelinkAccess'] = None,
                 project_to_fork_from: Optional[str] = None,
                 public_access: Optional['outputs.PgPgUserConfigPublicAccess'] = None,
                 recovery_target_time: Optional[str] = None,
                 service_to_fork_from: Optional[str] = None,
                 shared_buffers_percentage: Optional[str] = None,
                 synchronous_replication: Optional[str] = None,
                 timescaledb: Optional['outputs.PgPgUserConfigTimescaledb'] = None,
                 variant: Optional[str] = None,
                 work_mem: Optional[str] = None):
        """
        :param str admin_password: custom password for admin user. Defaults to random string. *This must
               be set only when a new service is being created.*
        :param str admin_username: custom username for admin user. *This must be set only when a new service
               is being created.*
        :param str backup_hour: the hour of day (in UTC) when backup for the service is started. New backup 
               is only started if previous backup has already completed.
        :param str backup_minute: the minute of an hour when backup for the service is started. New backup 
               is only started if previous backup has already completed.
        :param Sequence[str] ip_filters: allow incoming connections from CIDR address block, e.g. `10.20.0.0/16`
        :param 'PgPgUserConfigMigrationArgs' migration: migrate data from existing server, has the following options:
        :param 'PgPgUserConfigPgArgs' pg: Enable pg.
        :param str pg_read_replica: This setting is deprecated. Use read-replica service integration instead.
        :param str pg_service_to_fork_from: Name of the PG Service from which to fork (deprecated, use service_to_fork_from). 
               This has effect only when a new service is being created.
        :param str pg_version: PostgreSQL major version.
        :param 'PgPgUserConfigPgbouncerArgs' pgbouncer: Enable pgbouncer.
        :param 'PgPgUserConfigPglookoutArgs' pglookout: PGLookout settings.
        :param 'PgPgUserConfigPrivateAccessArgs' private_access: Allow access to selected service ports from private networks.
        :param 'PgPgUserConfigPrivatelinkAccessArgs' privatelink_access: Allow access to selected service components through Privatelink.
        :param str project_to_fork_from: Name of another project to fork a service from. This has
               effect only when a new service is being created.
        :param 'PgPgUserConfigPublicAccessArgs' public_access: Allow access to selected service ports from the public Internet
        :param str recovery_target_time: Recovery target time when forking a service. This has effect 
               only when a new service is being created.
        :param str service_to_fork_from: Name of another service to fork from. This has effect only 
               when a new service is being created.
        :param str shared_buffers_percentage: Percentage of total RAM that the database server uses for 
               memory buffers. Valid range is 20-60 (float), which corresponds to 20% - 60%. This setting adjusts
               the shared_buffers configuration value. The absolute maximum is 12 GB.
        :param str synchronous_replication: Synchronous replication type. Note that the service plan 
               also needs to support synchronous replication.
        :param 'PgPgUserConfigTimescaledbArgs' timescaledb: TimescaleDB extension configuration values.
        :param str variant: Variant of the PostgreSQL service, may affect the features that are 
               exposed by default. Options: `aiven` or `timescale`.
        :param str work_mem: Sets the maximum amount of memory to be used by a query operation (such 
               as a sort or hash table) before writing to temporary disk files, in MB. Default is 1MB + 0.075% of
               total RAM (up to 32MB).
        """
        if admin_password is not None:
            pulumi.set(__self__, "admin_password", admin_password)
        if admin_username is not None:
            pulumi.set(__self__, "admin_username", admin_username)
        if backup_hour is not None:
            pulumi.set(__self__, "backup_hour", backup_hour)
        if backup_minute is not None:
            pulumi.set(__self__, "backup_minute", backup_minute)
        if ip_filters is not None:
            pulumi.set(__self__, "ip_filters", ip_filters)
        if migration is not None:
            pulumi.set(__self__, "migration", migration)
        if pg is not None:
            pulumi.set(__self__, "pg", pg)
        if pg_read_replica is not None:
            pulumi.set(__self__, "pg_read_replica", pg_read_replica)
        if pg_service_to_fork_from is not None:
            pulumi.set(__self__, "pg_service_to_fork_from", pg_service_to_fork_from)
        if pg_version is not None:
            pulumi.set(__self__, "pg_version", pg_version)
        if pgbouncer is not None:
            pulumi.set(__self__, "pgbouncer", pgbouncer)
        if pglookout is not None:
            pulumi.set(__self__, "pglookout", pglookout)
        if private_access is not None:
            pulumi.set(__self__, "private_access", private_access)
        if privatelink_access is not None:
            pulumi.set(__self__, "privatelink_access", privatelink_access)
        if project_to_fork_from is not None:
            pulumi.set(__self__, "project_to_fork_from", project_to_fork_from)
        if public_access is not None:
            pulumi.set(__self__, "public_access", public_access)
        if recovery_target_time is not None:
            pulumi.set(__self__, "recovery_target_time", recovery_target_time)
        if service_to_fork_from is not None:
            pulumi.set(__self__, "service_to_fork_from", service_to_fork_from)
        if shared_buffers_percentage is not None:
            pulumi.set(__self__, "shared_buffers_percentage", shared_buffers_percentage)
        if synchronous_replication is not None:
            pulumi.set(__self__, "synchronous_replication", synchronous_replication)
        if timescaledb is not None:
            pulumi.set(__self__, "timescaledb", timescaledb)
        if variant is not None:
            pulumi.set(__self__, "variant", variant)
        if work_mem is not None:
            pulumi.set(__self__, "work_mem", work_mem)

    @property
    @pulumi.getter(name="adminPassword")
    def admin_password(self) -> Optional[str]:
        """
        custom password for admin user. Defaults to random string. *This must
        be set only when a new service is being created.*
        """
        return pulumi.get(self, "admin_password")

    @property
    @pulumi.getter(name="adminUsername")
    def admin_username(self) -> Optional[str]:
        """
        custom username for admin user. *This must be set only when a new service
        is being created.*
        """
        return pulumi.get(self, "admin_username")

    @property
    @pulumi.getter(name="backupHour")
    def backup_hour(self) -> Optional[str]:
        """
        the hour of day (in UTC) when backup for the service is started. New backup 
        is only started if previous backup has already completed.
        """
        return pulumi.get(self, "backup_hour")

    @property
    @pulumi.getter(name="backupMinute")
    def backup_minute(self) -> Optional[str]:
        """
        the minute of an hour when backup for the service is started. New backup 
        is only started if previous backup has already completed.
        """
        return pulumi.get(self, "backup_minute")

    @property
    @pulumi.getter(name="ipFilters")
    def ip_filters(self) -> Optional[Sequence[str]]:
        """
        allow incoming connections from CIDR address block, e.g. `10.20.0.0/16`
        """
        return pulumi.get(self, "ip_filters")

    @property
    @pulumi.getter
    def migration(self) -> Optional['outputs.PgPgUserConfigMigration']:
        """
        migrate data from existing server, has the following options:
        """
        return pulumi.get(self, "migration")

    @property
    @pulumi.getter
    def pg(self) -> Optional['outputs.PgPgUserConfigPg']:
        """
        Enable pg.
        """
        return pulumi.get(self, "pg")

    @property
    @pulumi.getter(name="pgReadReplica")
    def pg_read_replica(self) -> Optional[str]:
        """
        This setting is deprecated. Use read-replica service integration instead.
        """
        return pulumi.get(self, "pg_read_replica")

    @property
    @pulumi.getter(name="pgServiceToForkFrom")
    def pg_service_to_fork_from(self) -> Optional[str]:
        """
        Name of the PG Service from which to fork (deprecated, use service_to_fork_from). 
        This has effect only when a new service is being created.
        """
        return pulumi.get(self, "pg_service_to_fork_from")

    @property
    @pulumi.getter(name="pgVersion")
    def pg_version(self) -> Optional[str]:
        """
        PostgreSQL major version.
        """
        return pulumi.get(self, "pg_version")

    @property
    @pulumi.getter
    def pgbouncer(self) -> Optional['outputs.PgPgUserConfigPgbouncer']:
        """
        Enable pgbouncer.
        """
        return pulumi.get(self, "pgbouncer")

    @property
    @pulumi.getter
    def pglookout(self) -> Optional['outputs.PgPgUserConfigPglookout']:
        """
        PGLookout settings.
        """
        return pulumi.get(self, "pglookout")

    @property
    @pulumi.getter(name="privateAccess")
    def private_access(self) -> Optional['outputs.PgPgUserConfigPrivateAccess']:
        """
        Allow access to selected service ports from private networks.
        """
        return pulumi.get(self, "private_access")

    @property
    @pulumi.getter(name="privatelinkAccess")
    def privatelink_access(self) -> Optional['outputs.PgPgUserConfigPrivatelinkAccess']:
        """
        Allow access to selected service components through Privatelink.
        """
        return pulumi.get(self, "privatelink_access")

    @property
    @pulumi.getter(name="projectToForkFrom")
    def project_to_fork_from(self) -> Optional[str]:
        """
        Name of another project to fork a service from. This has
        effect only when a new service is being created.
        """
        return pulumi.get(self, "project_to_fork_from")

    @property
    @pulumi.getter(name="publicAccess")
    def public_access(self) -> Optional['outputs.PgPgUserConfigPublicAccess']:
        """
        Allow access to selected service ports from the public Internet
        """
        return pulumi.get(self, "public_access")

    @property
    @pulumi.getter(name="recoveryTargetTime")
    def recovery_target_time(self) -> Optional[str]:
        """
        Recovery target time when forking a service. This has effect 
        only when a new service is being created.
        """
        return pulumi.get(self, "recovery_target_time")

    @property
    @pulumi.getter(name="serviceToForkFrom")
    def service_to_fork_from(self) -> Optional[str]:
        """
        Name of another service to fork from. This has effect only 
        when a new service is being created.
        """
        return pulumi.get(self, "service_to_fork_from")

    @property
    @pulumi.getter(name="sharedBuffersPercentage")
    def shared_buffers_percentage(self) -> Optional[str]:
        """
        Percentage of total RAM that the database server uses for 
        memory buffers. Valid range is 20-60 (float), which corresponds to 20% - 60%. This setting adjusts
        the shared_buffers configuration value. The absolute maximum is 12 GB.
        """
        return pulumi.get(self, "shared_buffers_percentage")

    @property
    @pulumi.getter(name="synchronousReplication")
    def synchronous_replication(self) -> Optional[str]:
        """
        Synchronous replication type. Note that the service plan 
        also needs to support synchronous replication.
        """
        return pulumi.get(self, "synchronous_replication")

    @property
    @pulumi.getter
    def timescaledb(self) -> Optional['outputs.PgPgUserConfigTimescaledb']:
        """
        TimescaleDB extension configuration values.
        """
        return pulumi.get(self, "timescaledb")

    @property
    @pulumi.getter
    def variant(self) -> Optional[str]:
        """
        Variant of the PostgreSQL service, may affect the features that are 
        exposed by default. Options: `aiven` or `timescale`.
        """
        return pulumi.get(self, "variant")

    @property
    @pulumi.getter(name="workMem")
    def work_mem(self) -> Optional[str]:
        """
        Sets the maximum amount of memory to be used by a query operation (such 
        as a sort or hash table) before writing to temporary disk files, in MB. Default is 1MB + 0.075% of
        total RAM (up to 32MB).
        """
        return pulumi.get(self, "work_mem")


@pulumi.output_type
class PgPgUserConfigMigration(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "ignoreDbs":
            suggest = "ignore_dbs"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in PgPgUserConfigMigration. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        PgPgUserConfigMigration.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        PgPgUserConfigMigration.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 dbname: Optional[str] = None,
                 host: Optional[str] = None,
                 ignore_dbs: Optional[str] = None,
                 password: Optional[str] = None,
                 port: Optional[str] = None,
                 ssl: Optional[str] = None,
                 username: Optional[str] = None):
        """
        :param str dbname: database name for bootstrapping the initial connection.
        :param str host: hostname or IP address of the server where to migrate data from.
        :param str ignore_dbs: Comma-separated list of databases, which should be ignored during 
               migration (supported by MySQL only at the moment)
        :param str password: password for authentication with the server where to migrate data from.
        :param str port: port number of the server where to migrate data from.
        :param str ssl: the server where to migrate data from is secured with SSL.
        :param str username: user name for authentication with the server where to migrate data from.
        """
        if dbname is not None:
            pulumi.set(__self__, "dbname", dbname)
        if host is not None:
            pulumi.set(__self__, "host", host)
        if ignore_dbs is not None:
            pulumi.set(__self__, "ignore_dbs", ignore_dbs)
        if password is not None:
            pulumi.set(__self__, "password", password)
        if port is not None:
            pulumi.set(__self__, "port", port)
        if ssl is not None:
            pulumi.set(__self__, "ssl", ssl)
        if username is not None:
            pulumi.set(__self__, "username", username)

    @property
    @pulumi.getter
    def dbname(self) -> Optional[str]:
        """
        database name for bootstrapping the initial connection.
        """
        return pulumi.get(self, "dbname")

    @property
    @pulumi.getter
    def host(self) -> Optional[str]:
        """
        hostname or IP address of the server where to migrate data from.
        """
        return pulumi.get(self, "host")

    @property
    @pulumi.getter(name="ignoreDbs")
    def ignore_dbs(self) -> Optional[str]:
        """
        Comma-separated list of databases, which should be ignored during 
        migration (supported by MySQL only at the moment)
        """
        return pulumi.get(self, "ignore_dbs")

    @property
    @pulumi.getter
    def password(self) -> Optional[str]:
        """
        password for authentication with the server where to migrate data from.
        """
        return pulumi.get(self, "password")

    @property
    @pulumi.getter
    def port(self) -> Optional[str]:
        """
        port number of the server where to migrate data from.
        """
        return pulumi.get(self, "port")

    @property
    @pulumi.getter
    def ssl(self) -> Optional[str]:
        """
        the server where to migrate data from is secured with SSL.
        """
        return pulumi.get(self, "ssl")

    @property
    @pulumi.getter
    def username(self) -> Optional[str]:
        """
        user name for authentication with the server where to migrate data from.
        """
        return pulumi.get(self, "username")


@pulumi.output_type
class PgPgUserConfigPg(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "autovacuumAnalyzeScaleFactor":
            suggest = "autovacuum_analyze_scale_factor"
        elif key == "autovacuumAnalyzeThreshold":
            suggest = "autovacuum_analyze_threshold"
        elif key == "autovacuumFreezeMaxAge":
            suggest = "autovacuum_freeze_max_age"
        elif key == "autovacuumMaxWorkers":
            suggest = "autovacuum_max_workers"
        elif key == "autovacuumNaptime":
            suggest = "autovacuum_naptime"
        elif key == "autovacuumVacuumCostDelay":
            suggest = "autovacuum_vacuum_cost_delay"
        elif key == "autovacuumVacuumCostLimit":
            suggest = "autovacuum_vacuum_cost_limit"
        elif key == "autovacuumVacuumScaleFactor":
            suggest = "autovacuum_vacuum_scale_factor"
        elif key == "autovacuumVacuumThreshold":
            suggest = "autovacuum_vacuum_threshold"
        elif key == "deadlockTimeout":
            suggest = "deadlock_timeout"
        elif key == "idleInTransactionSessionTimeout":
            suggest = "idle_in_transaction_session_timeout"
        elif key == "logAutovacuumMinDuration":
            suggest = "log_autovacuum_min_duration"
        elif key == "logErrorVerbosity":
            suggest = "log_error_verbosity"
        elif key == "logLinePrefix":
            suggest = "log_line_prefix"
        elif key == "logMinDurationStatement":
            suggest = "log_min_duration_statement"
        elif key == "maxFilesPerProcess":
            suggest = "max_files_per_process"
        elif key == "maxLocksPerTransaction":
            suggest = "max_locks_per_transaction"
        elif key == "maxLogicalReplicationWorkers":
            suggest = "max_logical_replication_workers"
        elif key == "maxParallelWorkers":
            suggest = "max_parallel_workers"
        elif key == "maxParallelWorkersPerGather":
            suggest = "max_parallel_workers_per_gather"
        elif key == "maxPredLocksPerTransaction":
            suggest = "max_pred_locks_per_transaction"
        elif key == "maxPreparedTransactions":
            suggest = "max_prepared_transactions"
        elif key == "maxReplicationSlots":
            suggest = "max_replication_slots"
        elif key == "maxStackDepth":
            suggest = "max_stack_depth"
        elif key == "maxStandbyArchiveDelay":
            suggest = "max_standby_archive_delay"
        elif key == "maxStandbyStreamingDelay":
            suggest = "max_standby_streaming_delay"
        elif key == "maxWalSenders":
            suggest = "max_wal_senders"
        elif key == "maxWorkerProcesses":
            suggest = "max_worker_processes"
        elif key == "pgPartmanBgwDotInterval":
            suggest = "pg_partman_bgw_dot_interval"
        elif key == "pgPartmanBgwDotRole":
            suggest = "pg_partman_bgw_dot_role"
        elif key == "pgStatStatementsDotTrack":
            suggest = "pg_stat_statements_dot_track"
        elif key == "tempFileLimit":
            suggest = "temp_file_limit"
        elif key == "trackActivityQuerySize":
            suggest = "track_activity_query_size"
        elif key == "trackCommitTimestamp":
            suggest = "track_commit_timestamp"
        elif key == "trackFunctions":
            suggest = "track_functions"
        elif key == "trackIoTiming":
            suggest = "track_io_timing"
        elif key == "walSenderTimeout":
            suggest = "wal_sender_timeout"
        elif key == "walWriterDelay":
            suggest = "wal_writer_delay"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in PgPgUserConfigPg. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        PgPgUserConfigPg.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        PgPgUserConfigPg.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 autovacuum_analyze_scale_factor: Optional[str] = None,
                 autovacuum_analyze_threshold: Optional[str] = None,
                 autovacuum_freeze_max_age: Optional[str] = None,
                 autovacuum_max_workers: Optional[str] = None,
                 autovacuum_naptime: Optional[str] = None,
                 autovacuum_vacuum_cost_delay: Optional[str] = None,
                 autovacuum_vacuum_cost_limit: Optional[str] = None,
                 autovacuum_vacuum_scale_factor: Optional[str] = None,
                 autovacuum_vacuum_threshold: Optional[str] = None,
                 deadlock_timeout: Optional[str] = None,
                 idle_in_transaction_session_timeout: Optional[str] = None,
                 jit: Optional[str] = None,
                 log_autovacuum_min_duration: Optional[str] = None,
                 log_error_verbosity: Optional[str] = None,
                 log_line_prefix: Optional[str] = None,
                 log_min_duration_statement: Optional[str] = None,
                 max_files_per_process: Optional[str] = None,
                 max_locks_per_transaction: Optional[str] = None,
                 max_logical_replication_workers: Optional[str] = None,
                 max_parallel_workers: Optional[str] = None,
                 max_parallel_workers_per_gather: Optional[str] = None,
                 max_pred_locks_per_transaction: Optional[str] = None,
                 max_prepared_transactions: Optional[str] = None,
                 max_replication_slots: Optional[str] = None,
                 max_stack_depth: Optional[str] = None,
                 max_standby_archive_delay: Optional[str] = None,
                 max_standby_streaming_delay: Optional[str] = None,
                 max_wal_senders: Optional[str] = None,
                 max_worker_processes: Optional[str] = None,
                 pg_partman_bgw_dot_interval: Optional[str] = None,
                 pg_partman_bgw_dot_role: Optional[str] = None,
                 pg_stat_statements_dot_track: Optional[str] = None,
                 temp_file_limit: Optional[str] = None,
                 timezone: Optional[str] = None,
                 track_activity_query_size: Optional[str] = None,
                 track_commit_timestamp: Optional[str] = None,
                 track_functions: Optional[str] = None,
                 track_io_timing: Optional[str] = None,
                 wal_sender_timeout: Optional[str] = None,
                 wal_writer_delay: Optional[str] = None):
        """
        :param str autovacuum_analyze_scale_factor: Specifies a fraction of the table size to add to 
               autovacuum_analyze_threshold when deciding whether to trigger an ANALYZE. The default is 0.2
               (20% of table size).
        :param str autovacuum_analyze_threshold: specifies the minimum number of inserted, updated 
               or deleted tuples needed to trigger an ANALYZE in any one table. The default is 50 tuples.
        :param str autovacuum_freeze_max_age: specifies the maximum age (in transactions) that a table's 
               pg_class.relfrozenxid field can attain before a VACUUM operation is forced to prevent transaction ID
               wraparound within the table. Note that the system will launch autovacuum processes to prevent wraparound
               even when autovacuum is otherwise disabled. This parameter will cause the server to be restarted.
        :param str autovacuum_max_workers: specifies the maximum number of autovacuum processes (other 
               than the autovacuum launcher) that may be running at any one time. The default is three. This parameter
               can only be set at server start.
        :param str autovacuum_naptime: specifies the minimum delay between autovacuum runs on any 
               given database. The delay is measured in seconds, and the default is one minute.
        :param str autovacuum_vacuum_cost_delay: specifies the cost delay value that will be used 
               in automatic VACUUM operations. If -1 is specified, the regular vacuum_cost_delay value will be
               used. The default value is 20 milliseconds.
        :param str autovacuum_vacuum_cost_limit: specifies the cost limit value that will be used in 
               automatic VACUUM operations. If -1 is specified (which is the default), the regular vacuum_cost_limit
               value will be used.
        :param str autovacuum_vacuum_scale_factor: specifies a fraction of the table size to add to 
               autovacuum_vacuum_threshold when deciding whether to trigger a VACUUM. The default is 0.2 (20% of table size).
        :param str autovacuum_vacuum_threshold: specifies the minimum number of updated or deleted tuples 
               needed to trigger a VACUUM in any one table. The default is 50 tuples
        :param str deadlock_timeout: this is the amount of time, in milliseconds, to wait on a lock before 
               checking to see if there is a deadlock condition.
        :param str idle_in_transaction_session_timeout: Time out sessions with open transactions after 
               this number of milliseconds.
        :param str jit: Controls system-wide use of Just-in-Time Compilation (JIT).
        :param str log_autovacuum_min_duration: Causes each action executed by autovacuum to be logged 
               if it ran for at least the specified number of milliseconds. Setting this to zero logs all autovacuum
               actions. Minus-one (the default) disables logging autovacuum actions.
        :param str log_error_verbosity: Controls the amount of detail written in the server log for 
               each message that is logged. Possible values: `TERSE`, `DEFAULT` and `VERBOSE`.
        :param str log_line_prefix: Choose from one of the available log-formats. These can support 
               popular log analyzers like pgbadger, pganalyze etc.
               milliseconds to run, -1 disables
        :param str log_min_duration_statement: Log statements that take more than this number of
        :param str max_files_per_process: PostgreSQL maximum number of files that can be open per process
        :param str max_locks_per_transaction: PostgreSQL maximum locks per transaction
        :param str max_logical_replication_workers: PostgreSQL maximum logical replication workers 
               (taken from the pool of max_parallel_workers)
        :param str max_parallel_workers: Sets the maximum number of workers that the system can 
               support for parallel queries.
        :param str max_parallel_workers_per_gather: Sets the maximum number of workers that can be 
               started by a single Gather or Gather Merge node.
        :param str max_pred_locks_per_transaction: PostgreSQL maximum predicate locks per transaction
        :param str max_prepared_transactions: PostgreSQL maximum prepared transactions
        :param str max_replication_slots: PostgreSQL maximum replication slots
        :param str max_stack_depth: Maximum depth of the stack in bytes
        :param str max_standby_archive_delay: Max standby archive delay in milliseconds
        :param str max_standby_streaming_delay: Max standby streaming delay in milliseconds
        :param str max_wal_senders: PostgreSQL maximum WAL senders
        :param str max_worker_processes: Sets the maximum number of background processes that the system
               can support
               * `pg_partman_bgw.interval` - (Optional) Sets the time interval to run pg_partman's scheduled tasks
               * `pg_partman_bgw.role` - (Optional) Controls which role to use for pg_partman's scheduled
               background tasks.
               * `pg_stat_statements.track` - (Optional) Controls which statements are counted. Specify top
               to track top-level statements (those issued directly by clients), all to also track nested
               statements (such as statements invoked within functions), or none to disable statement statistics
               collection. The default value is top.
        :param str temp_file_limit: PostgreSQL temporary file limit in KiB, -1 for unlimited
        :param str timezone: PostgreSQL service timezone
        :param str track_activity_query_size: Specifies the number of bytes reserved to track the currently 
               executing command for each active session.
        :param str track_commit_timestamp: Record commit time of transactions
        :param str track_functions: Enables tracking of function call counts and time used.
        :param str track_io_timing: Enables timing of database I/O calls. This parameter is off by default, 
               because it will repeatedly query the operating system for the current time, which may cause significant
               overhead on some platforms.
        :param str wal_sender_timeout: Terminate replication connections that are inactive for longer than 
               this amount of time, in milliseconds.
        :param str wal_writer_delay: WAL flush interval in milliseconds. Note that setting this value 
               to lower than the default 200ms may negatively impact performance
        """
        if autovacuum_analyze_scale_factor is not None:
            pulumi.set(__self__, "autovacuum_analyze_scale_factor", autovacuum_analyze_scale_factor)
        if autovacuum_analyze_threshold is not None:
            pulumi.set(__self__, "autovacuum_analyze_threshold", autovacuum_analyze_threshold)
        if autovacuum_freeze_max_age is not None:
            pulumi.set(__self__, "autovacuum_freeze_max_age", autovacuum_freeze_max_age)
        if autovacuum_max_workers is not None:
            pulumi.set(__self__, "autovacuum_max_workers", autovacuum_max_workers)
        if autovacuum_naptime is not None:
            pulumi.set(__self__, "autovacuum_naptime", autovacuum_naptime)
        if autovacuum_vacuum_cost_delay is not None:
            pulumi.set(__self__, "autovacuum_vacuum_cost_delay", autovacuum_vacuum_cost_delay)
        if autovacuum_vacuum_cost_limit is not None:
            pulumi.set(__self__, "autovacuum_vacuum_cost_limit", autovacuum_vacuum_cost_limit)
        if autovacuum_vacuum_scale_factor is not None:
            pulumi.set(__self__, "autovacuum_vacuum_scale_factor", autovacuum_vacuum_scale_factor)
        if autovacuum_vacuum_threshold is not None:
            pulumi.set(__self__, "autovacuum_vacuum_threshold", autovacuum_vacuum_threshold)
        if deadlock_timeout is not None:
            pulumi.set(__self__, "deadlock_timeout", deadlock_timeout)
        if idle_in_transaction_session_timeout is not None:
            pulumi.set(__self__, "idle_in_transaction_session_timeout", idle_in_transaction_session_timeout)
        if jit is not None:
            pulumi.set(__self__, "jit", jit)
        if log_autovacuum_min_duration is not None:
            pulumi.set(__self__, "log_autovacuum_min_duration", log_autovacuum_min_duration)
        if log_error_verbosity is not None:
            pulumi.set(__self__, "log_error_verbosity", log_error_verbosity)
        if log_line_prefix is not None:
            pulumi.set(__self__, "log_line_prefix", log_line_prefix)
        if log_min_duration_statement is not None:
            pulumi.set(__self__, "log_min_duration_statement", log_min_duration_statement)
        if max_files_per_process is not None:
            pulumi.set(__self__, "max_files_per_process", max_files_per_process)
        if max_locks_per_transaction is not None:
            pulumi.set(__self__, "max_locks_per_transaction", max_locks_per_transaction)
        if max_logical_replication_workers is not None:
            pulumi.set(__self__, "max_logical_replication_workers", max_logical_replication_workers)
        if max_parallel_workers is not None:
            pulumi.set(__self__, "max_parallel_workers", max_parallel_workers)
        if max_parallel_workers_per_gather is not None:
            pulumi.set(__self__, "max_parallel_workers_per_gather", max_parallel_workers_per_gather)
        if max_pred_locks_per_transaction is not None:
            pulumi.set(__self__, "max_pred_locks_per_transaction", max_pred_locks_per_transaction)
        if max_prepared_transactions is not None:
            pulumi.set(__self__, "max_prepared_transactions", max_prepared_transactions)
        if max_replication_slots is not None:
            pulumi.set(__self__, "max_replication_slots", max_replication_slots)
        if max_stack_depth is not None:
            pulumi.set(__self__, "max_stack_depth", max_stack_depth)
        if max_standby_archive_delay is not None:
            pulumi.set(__self__, "max_standby_archive_delay", max_standby_archive_delay)
        if max_standby_streaming_delay is not None:
            pulumi.set(__self__, "max_standby_streaming_delay", max_standby_streaming_delay)
        if max_wal_senders is not None:
            pulumi.set(__self__, "max_wal_senders", max_wal_senders)
        if max_worker_processes is not None:
            pulumi.set(__self__, "max_worker_processes", max_worker_processes)
        if pg_partman_bgw_dot_interval is not None:
            pulumi.set(__self__, "pg_partman_bgw_dot_interval", pg_partman_bgw_dot_interval)
        if pg_partman_bgw_dot_role is not None:
            pulumi.set(__self__, "pg_partman_bgw_dot_role", pg_partman_bgw_dot_role)
        if pg_stat_statements_dot_track is not None:
            pulumi.set(__self__, "pg_stat_statements_dot_track", pg_stat_statements_dot_track)
        if temp_file_limit is not None:
            pulumi.set(__self__, "temp_file_limit", temp_file_limit)
        if timezone is not None:
            pulumi.set(__self__, "timezone", timezone)
        if track_activity_query_size is not None:
            pulumi.set(__self__, "track_activity_query_size", track_activity_query_size)
        if track_commit_timestamp is not None:
            pulumi.set(__self__, "track_commit_timestamp", track_commit_timestamp)
        if track_functions is not None:
            pulumi.set(__self__, "track_functions", track_functions)
        if track_io_timing is not None:
            pulumi.set(__self__, "track_io_timing", track_io_timing)
        if wal_sender_timeout is not None:
            pulumi.set(__self__, "wal_sender_timeout", wal_sender_timeout)
        if wal_writer_delay is not None:
            pulumi.set(__self__, "wal_writer_delay", wal_writer_delay)

    @property
    @pulumi.getter(name="autovacuumAnalyzeScaleFactor")
    def autovacuum_analyze_scale_factor(self) -> Optional[str]:
        """
        Specifies a fraction of the table size to add to 
        autovacuum_analyze_threshold when deciding whether to trigger an ANALYZE. The default is 0.2
        (20% of table size).
        """
        return pulumi.get(self, "autovacuum_analyze_scale_factor")

    @property
    @pulumi.getter(name="autovacuumAnalyzeThreshold")
    def autovacuum_analyze_threshold(self) -> Optional[str]:
        """
        specifies the minimum number of inserted, updated 
        or deleted tuples needed to trigger an ANALYZE in any one table. The default is 50 tuples.
        """
        return pulumi.get(self, "autovacuum_analyze_threshold")

    @property
    @pulumi.getter(name="autovacuumFreezeMaxAge")
    def autovacuum_freeze_max_age(self) -> Optional[str]:
        """
        specifies the maximum age (in transactions) that a table's 
        pg_class.relfrozenxid field can attain before a VACUUM operation is forced to prevent transaction ID
        wraparound within the table. Note that the system will launch autovacuum processes to prevent wraparound
        even when autovacuum is otherwise disabled. This parameter will cause the server to be restarted.
        """
        return pulumi.get(self, "autovacuum_freeze_max_age")

    @property
    @pulumi.getter(name="autovacuumMaxWorkers")
    def autovacuum_max_workers(self) -> Optional[str]:
        """
        specifies the maximum number of autovacuum processes (other 
        than the autovacuum launcher) that may be running at any one time. The default is three. This parameter
        can only be set at server start.
        """
        return pulumi.get(self, "autovacuum_max_workers")

    @property
    @pulumi.getter(name="autovacuumNaptime")
    def autovacuum_naptime(self) -> Optional[str]:
        """
        specifies the minimum delay between autovacuum runs on any 
        given database. The delay is measured in seconds, and the default is one minute.
        """
        return pulumi.get(self, "autovacuum_naptime")

    @property
    @pulumi.getter(name="autovacuumVacuumCostDelay")
    def autovacuum_vacuum_cost_delay(self) -> Optional[str]:
        """
        specifies the cost delay value that will be used 
        in automatic VACUUM operations. If -1 is specified, the regular vacuum_cost_delay value will be
        used. The default value is 20 milliseconds.
        """
        return pulumi.get(self, "autovacuum_vacuum_cost_delay")

    @property
    @pulumi.getter(name="autovacuumVacuumCostLimit")
    def autovacuum_vacuum_cost_limit(self) -> Optional[str]:
        """
        specifies the cost limit value that will be used in 
        automatic VACUUM operations. If -1 is specified (which is the default), the regular vacuum_cost_limit
        value will be used.
        """
        return pulumi.get(self, "autovacuum_vacuum_cost_limit")

    @property
    @pulumi.getter(name="autovacuumVacuumScaleFactor")
    def autovacuum_vacuum_scale_factor(self) -> Optional[str]:
        """
        specifies a fraction of the table size to add to 
        autovacuum_vacuum_threshold when deciding whether to trigger a VACUUM. The default is 0.2 (20% of table size).
        """
        return pulumi.get(self, "autovacuum_vacuum_scale_factor")

    @property
    @pulumi.getter(name="autovacuumVacuumThreshold")
    def autovacuum_vacuum_threshold(self) -> Optional[str]:
        """
        specifies the minimum number of updated or deleted tuples 
        needed to trigger a VACUUM in any one table. The default is 50 tuples
        """
        return pulumi.get(self, "autovacuum_vacuum_threshold")

    @property
    @pulumi.getter(name="deadlockTimeout")
    def deadlock_timeout(self) -> Optional[str]:
        """
        this is the amount of time, in milliseconds, to wait on a lock before 
        checking to see if there is a deadlock condition.
        """
        return pulumi.get(self, "deadlock_timeout")

    @property
    @pulumi.getter(name="idleInTransactionSessionTimeout")
    def idle_in_transaction_session_timeout(self) -> Optional[str]:
        """
        Time out sessions with open transactions after 
        this number of milliseconds.
        """
        return pulumi.get(self, "idle_in_transaction_session_timeout")

    @property
    @pulumi.getter
    def jit(self) -> Optional[str]:
        """
        Controls system-wide use of Just-in-Time Compilation (JIT).
        """
        return pulumi.get(self, "jit")

    @property
    @pulumi.getter(name="logAutovacuumMinDuration")
    def log_autovacuum_min_duration(self) -> Optional[str]:
        """
        Causes each action executed by autovacuum to be logged 
        if it ran for at least the specified number of milliseconds. Setting this to zero logs all autovacuum
        actions. Minus-one (the default) disables logging autovacuum actions.
        """
        return pulumi.get(self, "log_autovacuum_min_duration")

    @property
    @pulumi.getter(name="logErrorVerbosity")
    def log_error_verbosity(self) -> Optional[str]:
        """
        Controls the amount of detail written in the server log for 
        each message that is logged. Possible values: `TERSE`, `DEFAULT` and `VERBOSE`.
        """
        return pulumi.get(self, "log_error_verbosity")

    @property
    @pulumi.getter(name="logLinePrefix")
    def log_line_prefix(self) -> Optional[str]:
        """
        Choose from one of the available log-formats. These can support 
        popular log analyzers like pgbadger, pganalyze etc.
        milliseconds to run, -1 disables
        """
        return pulumi.get(self, "log_line_prefix")

    @property
    @pulumi.getter(name="logMinDurationStatement")
    def log_min_duration_statement(self) -> Optional[str]:
        """
        Log statements that take more than this number of
        """
        return pulumi.get(self, "log_min_duration_statement")

    @property
    @pulumi.getter(name="maxFilesPerProcess")
    def max_files_per_process(self) -> Optional[str]:
        """
        PostgreSQL maximum number of files that can be open per process
        """
        return pulumi.get(self, "max_files_per_process")

    @property
    @pulumi.getter(name="maxLocksPerTransaction")
    def max_locks_per_transaction(self) -> Optional[str]:
        """
        PostgreSQL maximum locks per transaction
        """
        return pulumi.get(self, "max_locks_per_transaction")

    @property
    @pulumi.getter(name="maxLogicalReplicationWorkers")
    def max_logical_replication_workers(self) -> Optional[str]:
        """
        PostgreSQL maximum logical replication workers 
        (taken from the pool of max_parallel_workers)
        """
        return pulumi.get(self, "max_logical_replication_workers")

    @property
    @pulumi.getter(name="maxParallelWorkers")
    def max_parallel_workers(self) -> Optional[str]:
        """
        Sets the maximum number of workers that the system can 
        support for parallel queries.
        """
        return pulumi.get(self, "max_parallel_workers")

    @property
    @pulumi.getter(name="maxParallelWorkersPerGather")
    def max_parallel_workers_per_gather(self) -> Optional[str]:
        """
        Sets the maximum number of workers that can be 
        started by a single Gather or Gather Merge node.
        """
        return pulumi.get(self, "max_parallel_workers_per_gather")

    @property
    @pulumi.getter(name="maxPredLocksPerTransaction")
    def max_pred_locks_per_transaction(self) -> Optional[str]:
        """
        PostgreSQL maximum predicate locks per transaction
        """
        return pulumi.get(self, "max_pred_locks_per_transaction")

    @property
    @pulumi.getter(name="maxPreparedTransactions")
    def max_prepared_transactions(self) -> Optional[str]:
        """
        PostgreSQL maximum prepared transactions
        """
        return pulumi.get(self, "max_prepared_transactions")

    @property
    @pulumi.getter(name="maxReplicationSlots")
    def max_replication_slots(self) -> Optional[str]:
        """
        PostgreSQL maximum replication slots
        """
        return pulumi.get(self, "max_replication_slots")

    @property
    @pulumi.getter(name="maxStackDepth")
    def max_stack_depth(self) -> Optional[str]:
        """
        Maximum depth of the stack in bytes
        """
        return pulumi.get(self, "max_stack_depth")

    @property
    @pulumi.getter(name="maxStandbyArchiveDelay")
    def max_standby_archive_delay(self) -> Optional[str]:
        """
        Max standby archive delay in milliseconds
        """
        return pulumi.get(self, "max_standby_archive_delay")

    @property
    @pulumi.getter(name="maxStandbyStreamingDelay")
    def max_standby_streaming_delay(self) -> Optional[str]:
        """
        Max standby streaming delay in milliseconds
        """
        return pulumi.get(self, "max_standby_streaming_delay")

    @property
    @pulumi.getter(name="maxWalSenders")
    def max_wal_senders(self) -> Optional[str]:
        """
        PostgreSQL maximum WAL senders
        """
        return pulumi.get(self, "max_wal_senders")

    @property
    @pulumi.getter(name="maxWorkerProcesses")
    def max_worker_processes(self) -> Optional[str]:
        """
        Sets the maximum number of background processes that the system
        can support
        * `pg_partman_bgw.interval` - (Optional) Sets the time interval to run pg_partman's scheduled tasks
        * `pg_partman_bgw.role` - (Optional) Controls which role to use for pg_partman's scheduled
        background tasks.
        * `pg_stat_statements.track` - (Optional) Controls which statements are counted. Specify top
        to track top-level statements (those issued directly by clients), all to also track nested
        statements (such as statements invoked within functions), or none to disable statement statistics
        collection. The default value is top.
        """
        return pulumi.get(self, "max_worker_processes")

    @property
    @pulumi.getter(name="pgPartmanBgwDotInterval")
    def pg_partman_bgw_dot_interval(self) -> Optional[str]:
        return pulumi.get(self, "pg_partman_bgw_dot_interval")

    @property
    @pulumi.getter(name="pgPartmanBgwDotRole")
    def pg_partman_bgw_dot_role(self) -> Optional[str]:
        return pulumi.get(self, "pg_partman_bgw_dot_role")

    @property
    @pulumi.getter(name="pgStatStatementsDotTrack")
    def pg_stat_statements_dot_track(self) -> Optional[str]:
        return pulumi.get(self, "pg_stat_statements_dot_track")

    @property
    @pulumi.getter(name="tempFileLimit")
    def temp_file_limit(self) -> Optional[str]:
        """
        PostgreSQL temporary file limit in KiB, -1 for unlimited
        """
        return pulumi.get(self, "temp_file_limit")

    @property
    @pulumi.getter
    def timezone(self) -> Optional[str]:
        """
        PostgreSQL service timezone
        """
        return pulumi.get(self, "timezone")

    @property
    @pulumi.getter(name="trackActivityQuerySize")
    def track_activity_query_size(self) -> Optional[str]:
        """
        Specifies the number of bytes reserved to track the currently 
        executing command for each active session.
        """
        return pulumi.get(self, "track_activity_query_size")

    @property
    @pulumi.getter(name="trackCommitTimestamp")
    def track_commit_timestamp(self) -> Optional[str]:
        """
        Record commit time of transactions
        """
        return pulumi.get(self, "track_commit_timestamp")

    @property
    @pulumi.getter(name="trackFunctions")
    def track_functions(self) -> Optional[str]:
        """
        Enables tracking of function call counts and time used.
        """
        return pulumi.get(self, "track_functions")

    @property
    @pulumi.getter(name="trackIoTiming")
    def track_io_timing(self) -> Optional[str]:
        """
        Enables timing of database I/O calls. This parameter is off by default, 
        because it will repeatedly query the operating system for the current time, which may cause significant
        overhead on some platforms.
        """
        return pulumi.get(self, "track_io_timing")

    @property
    @pulumi.getter(name="walSenderTimeout")
    def wal_sender_timeout(self) -> Optional[str]:
        """
        Terminate replication connections that are inactive for longer than 
        this amount of time, in milliseconds.
        """
        return pulumi.get(self, "wal_sender_timeout")

    @property
    @pulumi.getter(name="walWriterDelay")
    def wal_writer_delay(self) -> Optional[str]:
        """
        WAL flush interval in milliseconds. Note that setting this value 
        to lower than the default 200ms may negatively impact performance
        """
        return pulumi.get(self, "wal_writer_delay")


@pulumi.output_type
class PgPgUserConfigPgbouncer(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "autodbIdleTimeout":
            suggest = "autodb_idle_timeout"
        elif key == "autodbMaxDbConnections":
            suggest = "autodb_max_db_connections"
        elif key == "autodbPoolMode":
            suggest = "autodb_pool_mode"
        elif key == "autodbPoolSize":
            suggest = "autodb_pool_size"
        elif key == "ignoreStartupParameters":
            suggest = "ignore_startup_parameters"
        elif key == "minPoolSize":
            suggest = "min_pool_size"
        elif key == "serverIdleTimeout":
            suggest = "server_idle_timeout"
        elif key == "serverLifetime":
            suggest = "server_lifetime"
        elif key == "serverResetQueryAlways":
            suggest = "server_reset_query_always"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in PgPgUserConfigPgbouncer. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        PgPgUserConfigPgbouncer.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        PgPgUserConfigPgbouncer.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 autodb_idle_timeout: Optional[str] = None,
                 autodb_max_db_connections: Optional[str] = None,
                 autodb_pool_mode: Optional[str] = None,
                 autodb_pool_size: Optional[str] = None,
                 ignore_startup_parameters: Optional[Sequence[str]] = None,
                 min_pool_size: Optional[str] = None,
                 server_idle_timeout: Optional[str] = None,
                 server_lifetime: Optional[str] = None,
                 server_reset_query_always: Optional[str] = None):
        """
        :param str autodb_idle_timeout: If the automatically created database pools have been unused this 
               many seconds, they are freed. If 0 then timeout is disabled.
        :param str autodb_max_db_connections: Do not allow more than this many server connections per database 
               (regardless of user). Setting it to 0 means unlimited.
        :param str autodb_pool_mode: PGBouncer pool mode
        :param str autodb_pool_size: If non-zero then create automatically a pool of that size per user 
               when a pool doesn't exist.
        :param Sequence[str] ignore_startup_parameters: Enum of parameters to ignore when given in startup packet.
        :param str min_pool_size: Add more server connections to pool if below this number. Improves 
               behavior when usual load comes suddenly back after period of total inactivity. The value is
               effectively capped at the pool size.
        :param str server_idle_timeout: If a server connection has been idle more than this many seconds 
               it will be dropped. If 0 then timeout is disabled.
        :param str server_lifetime: The pooler will close an unused server connection that has been connected 
               longer than this.
        :param str server_reset_query_always: Run server_reset_query (DISCARD ALL) in all pooling modes.
        """
        if autodb_idle_timeout is not None:
            pulumi.set(__self__, "autodb_idle_timeout", autodb_idle_timeout)
        if autodb_max_db_connections is not None:
            pulumi.set(__self__, "autodb_max_db_connections", autodb_max_db_connections)
        if autodb_pool_mode is not None:
            pulumi.set(__self__, "autodb_pool_mode", autodb_pool_mode)
        if autodb_pool_size is not None:
            pulumi.set(__self__, "autodb_pool_size", autodb_pool_size)
        if ignore_startup_parameters is not None:
            pulumi.set(__self__, "ignore_startup_parameters", ignore_startup_parameters)
        if min_pool_size is not None:
            pulumi.set(__self__, "min_pool_size", min_pool_size)
        if server_idle_timeout is not None:
            pulumi.set(__self__, "server_idle_timeout", server_idle_timeout)
        if server_lifetime is not None:
            pulumi.set(__self__, "server_lifetime", server_lifetime)
        if server_reset_query_always is not None:
            pulumi.set(__self__, "server_reset_query_always", server_reset_query_always)

    @property
    @pulumi.getter(name="autodbIdleTimeout")
    def autodb_idle_timeout(self) -> Optional[str]:
        """
        If the automatically created database pools have been unused this 
        many seconds, they are freed. If 0 then timeout is disabled.
        """
        return pulumi.get(self, "autodb_idle_timeout")

    @property
    @pulumi.getter(name="autodbMaxDbConnections")
    def autodb_max_db_connections(self) -> Optional[str]:
        """
        Do not allow more than this many server connections per database 
        (regardless of user). Setting it to 0 means unlimited.
        """
        return pulumi.get(self, "autodb_max_db_connections")

    @property
    @pulumi.getter(name="autodbPoolMode")
    def autodb_pool_mode(self) -> Optional[str]:
        """
        PGBouncer pool mode
        """
        return pulumi.get(self, "autodb_pool_mode")

    @property
    @pulumi.getter(name="autodbPoolSize")
    def autodb_pool_size(self) -> Optional[str]:
        """
        If non-zero then create automatically a pool of that size per user 
        when a pool doesn't exist.
        """
        return pulumi.get(self, "autodb_pool_size")

    @property
    @pulumi.getter(name="ignoreStartupParameters")
    def ignore_startup_parameters(self) -> Optional[Sequence[str]]:
        """
        Enum of parameters to ignore when given in startup packet.
        """
        return pulumi.get(self, "ignore_startup_parameters")

    @property
    @pulumi.getter(name="minPoolSize")
    def min_pool_size(self) -> Optional[str]:
        """
        Add more server connections to pool if below this number. Improves 
        behavior when usual load comes suddenly back after period of total inactivity. The value is
        effectively capped at the pool size.
        """
        return pulumi.get(self, "min_pool_size")

    @property
    @pulumi.getter(name="serverIdleTimeout")
    def server_idle_timeout(self) -> Optional[str]:
        """
        If a server connection has been idle more than this many seconds 
        it will be dropped. If 0 then timeout is disabled.
        """
        return pulumi.get(self, "server_idle_timeout")

    @property
    @pulumi.getter(name="serverLifetime")
    def server_lifetime(self) -> Optional[str]:
        """
        The pooler will close an unused server connection that has been connected 
        longer than this.
        """
        return pulumi.get(self, "server_lifetime")

    @property
    @pulumi.getter(name="serverResetQueryAlways")
    def server_reset_query_always(self) -> Optional[str]:
        """
        Run server_reset_query (DISCARD ALL) in all pooling modes.
        """
        return pulumi.get(self, "server_reset_query_always")


@pulumi.output_type
class PgPgUserConfigPglookout(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "maxFailoverReplicationTimeLag":
            suggest = "max_failover_replication_time_lag"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in PgPgUserConfigPglookout. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        PgPgUserConfigPglookout.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        PgPgUserConfigPglookout.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 max_failover_replication_time_lag: Optional[str] = None):
        """
        :param str max_failover_replication_time_lag: Number of seconds of master unavailability before 
               triggering database failover to standby
        """
        if max_failover_replication_time_lag is not None:
            pulumi.set(__self__, "max_failover_replication_time_lag", max_failover_replication_time_lag)

    @property
    @pulumi.getter(name="maxFailoverReplicationTimeLag")
    def max_failover_replication_time_lag(self) -> Optional[str]:
        """
        Number of seconds of master unavailability before 
        triggering database failover to standby
        """
        return pulumi.get(self, "max_failover_replication_time_lag")


@pulumi.output_type
class PgPgUserConfigPrivateAccess(dict):
    def __init__(__self__, *,
                 pg: Optional[str] = None,
                 pgbouncer: Optional[str] = None,
                 prometheus: Optional[str] = None):
        """
        :param str pg: Enable pg.
        :param str pgbouncer: Enable pgbouncer.
        :param str prometheus: Allow clients to connect to prometheus from the public internet for 
               service nodes that are in a project VPC or another type of private network
        """
        if pg is not None:
            pulumi.set(__self__, "pg", pg)
        if pgbouncer is not None:
            pulumi.set(__self__, "pgbouncer", pgbouncer)
        if prometheus is not None:
            pulumi.set(__self__, "prometheus", prometheus)

    @property
    @pulumi.getter
    def pg(self) -> Optional[str]:
        """
        Enable pg.
        """
        return pulumi.get(self, "pg")

    @property
    @pulumi.getter
    def pgbouncer(self) -> Optional[str]:
        """
        Enable pgbouncer.
        """
        return pulumi.get(self, "pgbouncer")

    @property
    @pulumi.getter
    def prometheus(self) -> Optional[str]:
        """
        Allow clients to connect to prometheus from the public internet for 
        service nodes that are in a project VPC or another type of private network
        """
        return pulumi.get(self, "prometheus")


@pulumi.output_type
class PgPgUserConfigPrivatelinkAccess(dict):
    def __init__(__self__, *,
                 pg: Optional[str] = None,
                 pgbouncer: Optional[str] = None):
        """
        :param str pg: Enable pg.
        :param str pgbouncer: Enable pgbouncer.
        """
        if pg is not None:
            pulumi.set(__self__, "pg", pg)
        if pgbouncer is not None:
            pulumi.set(__self__, "pgbouncer", pgbouncer)

    @property
    @pulumi.getter
    def pg(self) -> Optional[str]:
        """
        Enable pg.
        """
        return pulumi.get(self, "pg")

    @property
    @pulumi.getter
    def pgbouncer(self) -> Optional[str]:
        """
        Enable pgbouncer.
        """
        return pulumi.get(self, "pgbouncer")


@pulumi.output_type
class PgPgUserConfigPublicAccess(dict):
    def __init__(__self__, *,
                 pg: Optional[str] = None,
                 pgbouncer: Optional[str] = None,
                 prometheus: Optional[str] = None):
        """
        :param str pg: Enable pg.
        :param str pgbouncer: Enable pgbouncer.
        :param str prometheus: Allow clients to connect to prometheus from the public internet for 
               service nodes that are in a project VPC or another type of private network
        """
        if pg is not None:
            pulumi.set(__self__, "pg", pg)
        if pgbouncer is not None:
            pulumi.set(__self__, "pgbouncer", pgbouncer)
        if prometheus is not None:
            pulumi.set(__self__, "prometheus", prometheus)

    @property
    @pulumi.getter
    def pg(self) -> Optional[str]:
        """
        Enable pg.
        """
        return pulumi.get(self, "pg")

    @property
    @pulumi.getter
    def pgbouncer(self) -> Optional[str]:
        """
        Enable pgbouncer.
        """
        return pulumi.get(self, "pgbouncer")

    @property
    @pulumi.getter
    def prometheus(self) -> Optional[str]:
        """
        Allow clients to connect to prometheus from the public internet for 
        service nodes that are in a project VPC or another type of private network
        """
        return pulumi.get(self, "prometheus")


@pulumi.output_type
class PgPgUserConfigTimescaledb(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "maxBackgroundWorkers":
            suggest = "max_background_workers"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in PgPgUserConfigTimescaledb. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        PgPgUserConfigTimescaledb.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        PgPgUserConfigTimescaledb.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 max_background_workers: Optional[str] = None):
        """
        :param str max_background_workers: The number of background workers for timescaledb 
               operations. You should configure this setting to the sum of your number of databases and the
               total number of concurrent background workers you want running at any given point in time.
        """
        if max_background_workers is not None:
            pulumi.set(__self__, "max_background_workers", max_background_workers)

    @property
    @pulumi.getter(name="maxBackgroundWorkers")
    def max_background_workers(self) -> Optional[str]:
        """
        The number of background workers for timescaledb 
        operations. You should configure this setting to the sum of your number of databases and the
        total number of concurrent background workers you want running at any given point in time.
        """
        return pulumi.get(self, "max_background_workers")


@pulumi.output_type
class PgServiceIntegration(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "integrationType":
            suggest = "integration_type"
        elif key == "sourceServiceName":
            suggest = "source_service_name"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in PgServiceIntegration. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        PgServiceIntegration.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        PgServiceIntegration.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 integration_type: str,
                 source_service_name: str):
        pulumi.set(__self__, "integration_type", integration_type)
        pulumi.set(__self__, "source_service_name", source_service_name)

    @property
    @pulumi.getter(name="integrationType")
    def integration_type(self) -> str:
        return pulumi.get(self, "integration_type")

    @property
    @pulumi.getter(name="sourceServiceName")
    def source_service_name(self) -> str:
        return pulumi.get(self, "source_service_name")


@pulumi.output_type
class RedisComponent(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "kafkaAuthenticationMethod":
            suggest = "kafka_authentication_method"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in RedisComponent. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        RedisComponent.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        RedisComponent.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 component: Optional[str] = None,
                 host: Optional[str] = None,
                 kafka_authentication_method: Optional[str] = None,
                 port: Optional[int] = None,
                 route: Optional[str] = None,
                 ssl: Optional[bool] = None,
                 usage: Optional[str] = None):
        """
        :param str host: Hostname or IP address of the server where to migrate data from
        :param int port: Port number of the server where to migrate data from
        :param bool ssl: The server where to migrate data from is secured with SSL
        """
        if component is not None:
            pulumi.set(__self__, "component", component)
        if host is not None:
            pulumi.set(__self__, "host", host)
        if kafka_authentication_method is not None:
            pulumi.set(__self__, "kafka_authentication_method", kafka_authentication_method)
        if port is not None:
            pulumi.set(__self__, "port", port)
        if route is not None:
            pulumi.set(__self__, "route", route)
        if ssl is not None:
            pulumi.set(__self__, "ssl", ssl)
        if usage is not None:
            pulumi.set(__self__, "usage", usage)

    @property
    @pulumi.getter
    def component(self) -> Optional[str]:
        return pulumi.get(self, "component")

    @property
    @pulumi.getter
    def host(self) -> Optional[str]:
        """
        Hostname or IP address of the server where to migrate data from
        """
        return pulumi.get(self, "host")

    @property
    @pulumi.getter(name="kafkaAuthenticationMethod")
    def kafka_authentication_method(self) -> Optional[str]:
        return pulumi.get(self, "kafka_authentication_method")

    @property
    @pulumi.getter
    def port(self) -> Optional[int]:
        """
        Port number of the server where to migrate data from
        """
        return pulumi.get(self, "port")

    @property
    @pulumi.getter
    def route(self) -> Optional[str]:
        return pulumi.get(self, "route")

    @property
    @pulumi.getter
    def ssl(self) -> Optional[bool]:
        """
        The server where to migrate data from is secured with SSL
        """
        return pulumi.get(self, "ssl")

    @property
    @pulumi.getter
    def usage(self) -> Optional[str]:
        return pulumi.get(self, "usage")


@pulumi.output_type
class RedisRedis(dict):
    def __init__(__self__):
        pass


@pulumi.output_type
class RedisRedisUserConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "ipFilters":
            suggest = "ip_filters"
        elif key == "privateAccess":
            suggest = "private_access"
        elif key == "privatelinkAccess":
            suggest = "privatelink_access"
        elif key == "projectToForkFrom":
            suggest = "project_to_fork_from"
        elif key == "publicAccess":
            suggest = "public_access"
        elif key == "recoveryBasebackupName":
            suggest = "recovery_basebackup_name"
        elif key == "redisIoThreads":
            suggest = "redis_io_threads"
        elif key == "redisLfuDecayTime":
            suggest = "redis_lfu_decay_time"
        elif key == "redisLfuLogFactor":
            suggest = "redis_lfu_log_factor"
        elif key == "redisMaxmemoryPolicy":
            suggest = "redis_maxmemory_policy"
        elif key == "redisNotifyKeyspaceEvents":
            suggest = "redis_notify_keyspace_events"
        elif key == "redisSsl":
            suggest = "redis_ssl"
        elif key == "redisTimeout":
            suggest = "redis_timeout"
        elif key == "serviceToForkFrom":
            suggest = "service_to_fork_from"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in RedisRedisUserConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        RedisRedisUserConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        RedisRedisUserConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 ip_filters: Optional[Sequence[str]] = None,
                 migration: Optional['outputs.RedisRedisUserConfigMigration'] = None,
                 private_access: Optional['outputs.RedisRedisUserConfigPrivateAccess'] = None,
                 privatelink_access: Optional['outputs.RedisRedisUserConfigPrivatelinkAccess'] = None,
                 project_to_fork_from: Optional[str] = None,
                 public_access: Optional['outputs.RedisRedisUserConfigPublicAccess'] = None,
                 recovery_basebackup_name: Optional[str] = None,
                 redis_io_threads: Optional[str] = None,
                 redis_lfu_decay_time: Optional[str] = None,
                 redis_lfu_log_factor: Optional[str] = None,
                 redis_maxmemory_policy: Optional[str] = None,
                 redis_notify_keyspace_events: Optional[str] = None,
                 redis_ssl: Optional[str] = None,
                 redis_timeout: Optional[str] = None,
                 service_to_fork_from: Optional[str] = None):
        """
        :param Sequence[str] ip_filters: Allow incoming connections from CIDR address block, e.g. `10.20.0.0/16`
        :param 'RedisRedisUserConfigMigrationArgs' migration: Migrate data from existing server
        :param 'RedisRedisUserConfigPrivateAccessArgs' private_access: Allow access to selected service ports from private networks
        :param 'RedisRedisUserConfigPrivatelinkAccessArgs' privatelink_access: Allow access to selected service components through Privatelink
        :param str project_to_fork_from: Name of another project to fork a service from. This has
               effect only when a new service is being created.
        :param 'RedisRedisUserConfigPublicAccessArgs' public_access: Allow access to selected service ports from the public Internet
        :param str recovery_basebackup_name: Name of the basebackup to restore in forked service
        :param str redis_io_threads: Redis IO thread count
               * `redis_lfu_decay_time"` - (Optional) LFU maxmemory-policy counter decay time in minutes
        :param str redis_lfu_log_factor: Counter logarithm factor for volatile-lfu and allkeys-lfu 
               maxmemory-policies
        :param str redis_maxmemory_policy: Redis maxmemory-policy
        :param str redis_notify_keyspace_events: Set notify-keyspace-events option
        :param str redis_ssl: Require SSL to access Redis
        :param str redis_timeout: Redis idle connection timeout
               * `service_to_fork_from"` - (Optional) Name of another service to fork from. This has effect only
               when a new service is being created.
        """
        if ip_filters is not None:
            pulumi.set(__self__, "ip_filters", ip_filters)
        if migration is not None:
            pulumi.set(__self__, "migration", migration)
        if private_access is not None:
            pulumi.set(__self__, "private_access", private_access)
        if privatelink_access is not None:
            pulumi.set(__self__, "privatelink_access", privatelink_access)
        if project_to_fork_from is not None:
            pulumi.set(__self__, "project_to_fork_from", project_to_fork_from)
        if public_access is not None:
            pulumi.set(__self__, "public_access", public_access)
        if recovery_basebackup_name is not None:
            pulumi.set(__self__, "recovery_basebackup_name", recovery_basebackup_name)
        if redis_io_threads is not None:
            pulumi.set(__self__, "redis_io_threads", redis_io_threads)
        if redis_lfu_decay_time is not None:
            pulumi.set(__self__, "redis_lfu_decay_time", redis_lfu_decay_time)
        if redis_lfu_log_factor is not None:
            pulumi.set(__self__, "redis_lfu_log_factor", redis_lfu_log_factor)
        if redis_maxmemory_policy is not None:
            pulumi.set(__self__, "redis_maxmemory_policy", redis_maxmemory_policy)
        if redis_notify_keyspace_events is not None:
            pulumi.set(__self__, "redis_notify_keyspace_events", redis_notify_keyspace_events)
        if redis_ssl is not None:
            pulumi.set(__self__, "redis_ssl", redis_ssl)
        if redis_timeout is not None:
            pulumi.set(__self__, "redis_timeout", redis_timeout)
        if service_to_fork_from is not None:
            pulumi.set(__self__, "service_to_fork_from", service_to_fork_from)

    @property
    @pulumi.getter(name="ipFilters")
    def ip_filters(self) -> Optional[Sequence[str]]:
        """
        Allow incoming connections from CIDR address block, e.g. `10.20.0.0/16`
        """
        return pulumi.get(self, "ip_filters")

    @property
    @pulumi.getter
    def migration(self) -> Optional['outputs.RedisRedisUserConfigMigration']:
        """
        Migrate data from existing server
        """
        return pulumi.get(self, "migration")

    @property
    @pulumi.getter(name="privateAccess")
    def private_access(self) -> Optional['outputs.RedisRedisUserConfigPrivateAccess']:
        """
        Allow access to selected service ports from private networks
        """
        return pulumi.get(self, "private_access")

    @property
    @pulumi.getter(name="privatelinkAccess")
    def privatelink_access(self) -> Optional['outputs.RedisRedisUserConfigPrivatelinkAccess']:
        """
        Allow access to selected service components through Privatelink
        """
        return pulumi.get(self, "privatelink_access")

    @property
    @pulumi.getter(name="projectToForkFrom")
    def project_to_fork_from(self) -> Optional[str]:
        """
        Name of another project to fork a service from. This has
        effect only when a new service is being created.
        """
        return pulumi.get(self, "project_to_fork_from")

    @property
    @pulumi.getter(name="publicAccess")
    def public_access(self) -> Optional['outputs.RedisRedisUserConfigPublicAccess']:
        """
        Allow access to selected service ports from the public Internet
        """
        return pulumi.get(self, "public_access")

    @property
    @pulumi.getter(name="recoveryBasebackupName")
    def recovery_basebackup_name(self) -> Optional[str]:
        """
        Name of the basebackup to restore in forked service
        """
        return pulumi.get(self, "recovery_basebackup_name")

    @property
    @pulumi.getter(name="redisIoThreads")
    def redis_io_threads(self) -> Optional[str]:
        """
        Redis IO thread count
        * `redis_lfu_decay_time"` - (Optional) LFU maxmemory-policy counter decay time in minutes
        """
        return pulumi.get(self, "redis_io_threads")

    @property
    @pulumi.getter(name="redisLfuDecayTime")
    def redis_lfu_decay_time(self) -> Optional[str]:
        return pulumi.get(self, "redis_lfu_decay_time")

    @property
    @pulumi.getter(name="redisLfuLogFactor")
    def redis_lfu_log_factor(self) -> Optional[str]:
        """
        Counter logarithm factor for volatile-lfu and allkeys-lfu 
        maxmemory-policies
        """
        return pulumi.get(self, "redis_lfu_log_factor")

    @property
    @pulumi.getter(name="redisMaxmemoryPolicy")
    def redis_maxmemory_policy(self) -> Optional[str]:
        """
        Redis maxmemory-policy
        """
        return pulumi.get(self, "redis_maxmemory_policy")

    @property
    @pulumi.getter(name="redisNotifyKeyspaceEvents")
    def redis_notify_keyspace_events(self) -> Optional[str]:
        """
        Set notify-keyspace-events option
        """
        return pulumi.get(self, "redis_notify_keyspace_events")

    @property
    @pulumi.getter(name="redisSsl")
    def redis_ssl(self) -> Optional[str]:
        """
        Require SSL to access Redis
        """
        return pulumi.get(self, "redis_ssl")

    @property
    @pulumi.getter(name="redisTimeout")
    def redis_timeout(self) -> Optional[str]:
        """
        Redis idle connection timeout
        * `service_to_fork_from"` - (Optional) Name of another service to fork from. This has effect only
        when a new service is being created.
        """
        return pulumi.get(self, "redis_timeout")

    @property
    @pulumi.getter(name="serviceToForkFrom")
    def service_to_fork_from(self) -> Optional[str]:
        return pulumi.get(self, "service_to_fork_from")


@pulumi.output_type
class RedisRedisUserConfigMigration(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "ignoreDbs":
            suggest = "ignore_dbs"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in RedisRedisUserConfigMigration. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        RedisRedisUserConfigMigration.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        RedisRedisUserConfigMigration.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 dbname: Optional[str] = None,
                 host: Optional[str] = None,
                 ignore_dbs: Optional[str] = None,
                 password: Optional[str] = None,
                 port: Optional[str] = None,
                 ssl: Optional[str] = None,
                 username: Optional[str] = None):
        """
        :param str dbname: Database name for bootstrapping the initial connection
        :param str host: Hostname or IP address of the server where to migrate data from
        :param str ignore_dbs: Comma-separated list of databases, which should be ignored during 
               migration (supported by MySQL only at the moment)
        :param str password: Password for authentication with the server where to migrate data from
        :param str port: Port number of the server where to migrate data from
        :param str ssl: The server where to migrate data from is secured with SSL
        :param str username: User name for authentication with the server where to migrate data from
        """
        if dbname is not None:
            pulumi.set(__self__, "dbname", dbname)
        if host is not None:
            pulumi.set(__self__, "host", host)
        if ignore_dbs is not None:
            pulumi.set(__self__, "ignore_dbs", ignore_dbs)
        if password is not None:
            pulumi.set(__self__, "password", password)
        if port is not None:
            pulumi.set(__self__, "port", port)
        if ssl is not None:
            pulumi.set(__self__, "ssl", ssl)
        if username is not None:
            pulumi.set(__self__, "username", username)

    @property
    @pulumi.getter
    def dbname(self) -> Optional[str]:
        """
        Database name for bootstrapping the initial connection
        """
        return pulumi.get(self, "dbname")

    @property
    @pulumi.getter
    def host(self) -> Optional[str]:
        """
        Hostname or IP address of the server where to migrate data from
        """
        return pulumi.get(self, "host")

    @property
    @pulumi.getter(name="ignoreDbs")
    def ignore_dbs(self) -> Optional[str]:
        """
        Comma-separated list of databases, which should be ignored during 
        migration (supported by MySQL only at the moment)
        """
        return pulumi.get(self, "ignore_dbs")

    @property
    @pulumi.getter
    def password(self) -> Optional[str]:
        """
        Password for authentication with the server where to migrate data from
        """
        return pulumi.get(self, "password")

    @property
    @pulumi.getter
    def port(self) -> Optional[str]:
        """
        Port number of the server where to migrate data from
        """
        return pulumi.get(self, "port")

    @property
    @pulumi.getter
    def ssl(self) -> Optional[str]:
        """
        The server where to migrate data from is secured with SSL
        """
        return pulumi.get(self, "ssl")

    @property
    @pulumi.getter
    def username(self) -> Optional[str]:
        """
        User name for authentication with the server where to migrate data from
        """
        return pulumi.get(self, "username")


@pulumi.output_type
class RedisRedisUserConfigPrivateAccess(dict):
    def __init__(__self__, *,
                 prometheus: Optional[str] = None,
                 redis: Optional[str] = None):
        """
        :param str prometheus: Allow clients to connect to prometheus from the public internet 
               for service nodes that are in a project VPC or another type of private network
        :param str redis: Allow clients to connect to redis from the public internet for service 
               nodes that are in a project VPC or another type of private network
        """
        if prometheus is not None:
            pulumi.set(__self__, "prometheus", prometheus)
        if redis is not None:
            pulumi.set(__self__, "redis", redis)

    @property
    @pulumi.getter
    def prometheus(self) -> Optional[str]:
        """
        Allow clients to connect to prometheus from the public internet 
        for service nodes that are in a project VPC or another type of private network
        """
        return pulumi.get(self, "prometheus")

    @property
    @pulumi.getter
    def redis(self) -> Optional[str]:
        """
        Allow clients to connect to redis from the public internet for service 
        nodes that are in a project VPC or another type of private network
        """
        return pulumi.get(self, "redis")


@pulumi.output_type
class RedisRedisUserConfigPrivatelinkAccess(dict):
    def __init__(__self__, *,
                 redis: Optional[str] = None):
        """
        :param str redis: Allow clients to connect to redis from the public internet for service 
               nodes that are in a project VPC or another type of private network
        """
        if redis is not None:
            pulumi.set(__self__, "redis", redis)

    @property
    @pulumi.getter
    def redis(self) -> Optional[str]:
        """
        Allow clients to connect to redis from the public internet for service 
        nodes that are in a project VPC or another type of private network
        """
        return pulumi.get(self, "redis")


@pulumi.output_type
class RedisRedisUserConfigPublicAccess(dict):
    def __init__(__self__, *,
                 prometheus: Optional[str] = None,
                 redis: Optional[str] = None):
        """
        :param str prometheus: Allow clients to connect to prometheus from the public internet 
               for service nodes that are in a project VPC or another type of private network
        :param str redis: Allow clients to connect to redis from the public internet for service 
               nodes that are in a project VPC or another type of private network
        """
        if prometheus is not None:
            pulumi.set(__self__, "prometheus", prometheus)
        if redis is not None:
            pulumi.set(__self__, "redis", redis)

    @property
    @pulumi.getter
    def prometheus(self) -> Optional[str]:
        """
        Allow clients to connect to prometheus from the public internet 
        for service nodes that are in a project VPC or another type of private network
        """
        return pulumi.get(self, "prometheus")

    @property
    @pulumi.getter
    def redis(self) -> Optional[str]:
        """
        Allow clients to connect to redis from the public internet for service 
        nodes that are in a project VPC or another type of private network
        """
        return pulumi.get(self, "redis")


@pulumi.output_type
class RedisServiceIntegration(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "integrationType":
            suggest = "integration_type"
        elif key == "sourceServiceName":
            suggest = "source_service_name"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in RedisServiceIntegration. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        RedisServiceIntegration.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        RedisServiceIntegration.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 integration_type: str,
                 source_service_name: str):
        pulumi.set(__self__, "integration_type", integration_type)
        pulumi.set(__self__, "source_service_name", source_service_name)

    @property
    @pulumi.getter(name="integrationType")
    def integration_type(self) -> str:
        return pulumi.get(self, "integration_type")

    @property
    @pulumi.getter(name="sourceServiceName")
    def source_service_name(self) -> str:
        return pulumi.get(self, "source_service_name")


@pulumi.output_type
class ServiceCassandra(dict):
    def __init__(__self__):
        pass


@pulumi.output_type
class ServiceCassandraUserConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "ipFilters":
            suggest = "ip_filters"
        elif key == "migrateSstableloader":
            suggest = "migrate_sstableloader"
        elif key == "privateAccess":
            suggest = "private_access"
        elif key == "projectToForkFrom":
            suggest = "project_to_fork_from"
        elif key == "publicAccess":
            suggest = "public_access"
        elif key == "serviceToForkFrom":
            suggest = "service_to_fork_from"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ServiceCassandraUserConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ServiceCassandraUserConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ServiceCassandraUserConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 cassandra: Optional['outputs.ServiceCassandraUserConfigCassandra'] = None,
                 ip_filters: Optional[Sequence[str]] = None,
                 migrate_sstableloader: Optional[str] = None,
                 private_access: Optional['outputs.ServiceCassandraUserConfigPrivateAccess'] = None,
                 project_to_fork_from: Optional[str] = None,
                 public_access: Optional['outputs.ServiceCassandraUserConfigPublicAccess'] = None,
                 service_to_fork_from: Optional[str] = None):
        if cassandra is not None:
            pulumi.set(__self__, "cassandra", cassandra)
        if ip_filters is not None:
            pulumi.set(__self__, "ip_filters", ip_filters)
        if migrate_sstableloader is not None:
            pulumi.set(__self__, "migrate_sstableloader", migrate_sstableloader)
        if private_access is not None:
            pulumi.set(__self__, "private_access", private_access)
        if project_to_fork_from is not None:
            pulumi.set(__self__, "project_to_fork_from", project_to_fork_from)
        if public_access is not None:
            pulumi.set(__self__, "public_access", public_access)
        if service_to_fork_from is not None:
            pulumi.set(__self__, "service_to_fork_from", service_to_fork_from)

    @property
    @pulumi.getter
    def cassandra(self) -> Optional['outputs.ServiceCassandraUserConfigCassandra']:
        return pulumi.get(self, "cassandra")

    @property
    @pulumi.getter(name="ipFilters")
    def ip_filters(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "ip_filters")

    @property
    @pulumi.getter(name="migrateSstableloader")
    def migrate_sstableloader(self) -> Optional[str]:
        return pulumi.get(self, "migrate_sstableloader")

    @property
    @pulumi.getter(name="privateAccess")
    def private_access(self) -> Optional['outputs.ServiceCassandraUserConfigPrivateAccess']:
        return pulumi.get(self, "private_access")

    @property
    @pulumi.getter(name="projectToForkFrom")
    def project_to_fork_from(self) -> Optional[str]:
        return pulumi.get(self, "project_to_fork_from")

    @property
    @pulumi.getter(name="publicAccess")
    def public_access(self) -> Optional['outputs.ServiceCassandraUserConfigPublicAccess']:
        return pulumi.get(self, "public_access")

    @property
    @pulumi.getter(name="serviceToForkFrom")
    def service_to_fork_from(self) -> Optional[str]:
        return pulumi.get(self, "service_to_fork_from")


@pulumi.output_type
class ServiceCassandraUserConfigCassandra(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "batchSizeFailThresholdInKb":
            suggest = "batch_size_fail_threshold_in_kb"
        elif key == "batchSizeWarnThresholdInKb":
            suggest = "batch_size_warn_threshold_in_kb"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ServiceCassandraUserConfigCassandra. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ServiceCassandraUserConfigCassandra.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ServiceCassandraUserConfigCassandra.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 batch_size_fail_threshold_in_kb: Optional[str] = None,
                 batch_size_warn_threshold_in_kb: Optional[str] = None):
        if batch_size_fail_threshold_in_kb is not None:
            pulumi.set(__self__, "batch_size_fail_threshold_in_kb", batch_size_fail_threshold_in_kb)
        if batch_size_warn_threshold_in_kb is not None:
            pulumi.set(__self__, "batch_size_warn_threshold_in_kb", batch_size_warn_threshold_in_kb)

    @property
    @pulumi.getter(name="batchSizeFailThresholdInKb")
    def batch_size_fail_threshold_in_kb(self) -> Optional[str]:
        return pulumi.get(self, "batch_size_fail_threshold_in_kb")

    @property
    @pulumi.getter(name="batchSizeWarnThresholdInKb")
    def batch_size_warn_threshold_in_kb(self) -> Optional[str]:
        return pulumi.get(self, "batch_size_warn_threshold_in_kb")


@pulumi.output_type
class ServiceCassandraUserConfigPrivateAccess(dict):
    def __init__(__self__, *,
                 prometheus: Optional[str] = None):
        if prometheus is not None:
            pulumi.set(__self__, "prometheus", prometheus)

    @property
    @pulumi.getter
    def prometheus(self) -> Optional[str]:
        return pulumi.get(self, "prometheus")


@pulumi.output_type
class ServiceCassandraUserConfigPublicAccess(dict):
    def __init__(__self__, *,
                 prometheus: Optional[str] = None):
        if prometheus is not None:
            pulumi.set(__self__, "prometheus", prometheus)

    @property
    @pulumi.getter
    def prometheus(self) -> Optional[str]:
        return pulumi.get(self, "prometheus")


@pulumi.output_type
class ServiceComponent(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "kafkaAuthenticationMethod":
            suggest = "kafka_authentication_method"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ServiceComponent. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ServiceComponent.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ServiceComponent.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 component: Optional[str] = None,
                 host: Optional[str] = None,
                 kafka_authentication_method: Optional[str] = None,
                 port: Optional[int] = None,
                 route: Optional[str] = None,
                 ssl: Optional[bool] = None,
                 usage: Optional[str] = None):
        if component is not None:
            pulumi.set(__self__, "component", component)
        if host is not None:
            pulumi.set(__self__, "host", host)
        if kafka_authentication_method is not None:
            pulumi.set(__self__, "kafka_authentication_method", kafka_authentication_method)
        if port is not None:
            pulumi.set(__self__, "port", port)
        if route is not None:
            pulumi.set(__self__, "route", route)
        if ssl is not None:
            pulumi.set(__self__, "ssl", ssl)
        if usage is not None:
            pulumi.set(__self__, "usage", usage)

    @property
    @pulumi.getter
    def component(self) -> Optional[str]:
        return pulumi.get(self, "component")

    @property
    @pulumi.getter
    def host(self) -> Optional[str]:
        return pulumi.get(self, "host")

    @property
    @pulumi.getter(name="kafkaAuthenticationMethod")
    def kafka_authentication_method(self) -> Optional[str]:
        return pulumi.get(self, "kafka_authentication_method")

    @property
    @pulumi.getter
    def port(self) -> Optional[int]:
        return pulumi.get(self, "port")

    @property
    @pulumi.getter
    def route(self) -> Optional[str]:
        return pulumi.get(self, "route")

    @property
    @pulumi.getter
    def ssl(self) -> Optional[bool]:
        return pulumi.get(self, "ssl")

    @property
    @pulumi.getter
    def usage(self) -> Optional[str]:
        return pulumi.get(self, "usage")


@pulumi.output_type
class ServiceElasticsearch(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "kibanaUri":
            suggest = "kibana_uri"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ServiceElasticsearch. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ServiceElasticsearch.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ServiceElasticsearch.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 kibana_uri: Optional[str] = None):
        if kibana_uri is not None:
            pulumi.set(__self__, "kibana_uri", kibana_uri)

    @property
    @pulumi.getter(name="kibanaUri")
    def kibana_uri(self) -> Optional[str]:
        return pulumi.get(self, "kibana_uri")


@pulumi.output_type
class ServiceElasticsearchUserConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "customDomain":
            suggest = "custom_domain"
        elif key == "disableReplicationFactorAdjustment":
            suggest = "disable_replication_factor_adjustment"
        elif key == "elasticsearchVersion":
            suggest = "elasticsearch_version"
        elif key == "indexPatterns":
            suggest = "index_patterns"
        elif key == "indexTemplate":
            suggest = "index_template"
        elif key == "ipFilters":
            suggest = "ip_filters"
        elif key == "maxIndexCount":
            suggest = "max_index_count"
        elif key == "privateAccess":
            suggest = "private_access"
        elif key == "privatelinkAccess":
            suggest = "privatelink_access"
        elif key == "projectToForkFrom":
            suggest = "project_to_fork_from"
        elif key == "publicAccess":
            suggest = "public_access"
        elif key == "recoveryBasebackupName":
            suggest = "recovery_basebackup_name"
        elif key == "serviceToForkFrom":
            suggest = "service_to_fork_from"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ServiceElasticsearchUserConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ServiceElasticsearchUserConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ServiceElasticsearchUserConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 custom_domain: Optional[str] = None,
                 disable_replication_factor_adjustment: Optional[str] = None,
                 elasticsearch: Optional['outputs.ServiceElasticsearchUserConfigElasticsearch'] = None,
                 elasticsearch_version: Optional[str] = None,
                 index_patterns: Optional[Sequence['outputs.ServiceElasticsearchUserConfigIndexPattern']] = None,
                 index_template: Optional['outputs.ServiceElasticsearchUserConfigIndexTemplate'] = None,
                 ip_filters: Optional[Sequence[str]] = None,
                 kibana: Optional['outputs.ServiceElasticsearchUserConfigKibana'] = None,
                 max_index_count: Optional[str] = None,
                 private_access: Optional['outputs.ServiceElasticsearchUserConfigPrivateAccess'] = None,
                 privatelink_access: Optional['outputs.ServiceElasticsearchUserConfigPrivatelinkAccess'] = None,
                 project_to_fork_from: Optional[str] = None,
                 public_access: Optional['outputs.ServiceElasticsearchUserConfigPublicAccess'] = None,
                 recovery_basebackup_name: Optional[str] = None,
                 service_to_fork_from: Optional[str] = None):
        if custom_domain is not None:
            pulumi.set(__self__, "custom_domain", custom_domain)
        if disable_replication_factor_adjustment is not None:
            pulumi.set(__self__, "disable_replication_factor_adjustment", disable_replication_factor_adjustment)
        if elasticsearch is not None:
            pulumi.set(__self__, "elasticsearch", elasticsearch)
        if elasticsearch_version is not None:
            pulumi.set(__self__, "elasticsearch_version", elasticsearch_version)
        if index_patterns is not None:
            pulumi.set(__self__, "index_patterns", index_patterns)
        if index_template is not None:
            pulumi.set(__self__, "index_template", index_template)
        if ip_filters is not None:
            pulumi.set(__self__, "ip_filters", ip_filters)
        if kibana is not None:
            pulumi.set(__self__, "kibana", kibana)
        if max_index_count is not None:
            pulumi.set(__self__, "max_index_count", max_index_count)
        if private_access is not None:
            pulumi.set(__self__, "private_access", private_access)
        if privatelink_access is not None:
            pulumi.set(__self__, "privatelink_access", privatelink_access)
        if project_to_fork_from is not None:
            pulumi.set(__self__, "project_to_fork_from", project_to_fork_from)
        if public_access is not None:
            pulumi.set(__self__, "public_access", public_access)
        if recovery_basebackup_name is not None:
            pulumi.set(__self__, "recovery_basebackup_name", recovery_basebackup_name)
        if service_to_fork_from is not None:
            pulumi.set(__self__, "service_to_fork_from", service_to_fork_from)

    @property
    @pulumi.getter(name="customDomain")
    def custom_domain(self) -> Optional[str]:
        return pulumi.get(self, "custom_domain")

    @property
    @pulumi.getter(name="disableReplicationFactorAdjustment")
    def disable_replication_factor_adjustment(self) -> Optional[str]:
        return pulumi.get(self, "disable_replication_factor_adjustment")

    @property
    @pulumi.getter
    def elasticsearch(self) -> Optional['outputs.ServiceElasticsearchUserConfigElasticsearch']:
        return pulumi.get(self, "elasticsearch")

    @property
    @pulumi.getter(name="elasticsearchVersion")
    def elasticsearch_version(self) -> Optional[str]:
        return pulumi.get(self, "elasticsearch_version")

    @property
    @pulumi.getter(name="indexPatterns")
    def index_patterns(self) -> Optional[Sequence['outputs.ServiceElasticsearchUserConfigIndexPattern']]:
        return pulumi.get(self, "index_patterns")

    @property
    @pulumi.getter(name="indexTemplate")
    def index_template(self) -> Optional['outputs.ServiceElasticsearchUserConfigIndexTemplate']:
        return pulumi.get(self, "index_template")

    @property
    @pulumi.getter(name="ipFilters")
    def ip_filters(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "ip_filters")

    @property
    @pulumi.getter
    def kibana(self) -> Optional['outputs.ServiceElasticsearchUserConfigKibana']:
        return pulumi.get(self, "kibana")

    @property
    @pulumi.getter(name="maxIndexCount")
    def max_index_count(self) -> Optional[str]:
        return pulumi.get(self, "max_index_count")

    @property
    @pulumi.getter(name="privateAccess")
    def private_access(self) -> Optional['outputs.ServiceElasticsearchUserConfigPrivateAccess']:
        return pulumi.get(self, "private_access")

    @property
    @pulumi.getter(name="privatelinkAccess")
    def privatelink_access(self) -> Optional['outputs.ServiceElasticsearchUserConfigPrivatelinkAccess']:
        return pulumi.get(self, "privatelink_access")

    @property
    @pulumi.getter(name="projectToForkFrom")
    def project_to_fork_from(self) -> Optional[str]:
        return pulumi.get(self, "project_to_fork_from")

    @property
    @pulumi.getter(name="publicAccess")
    def public_access(self) -> Optional['outputs.ServiceElasticsearchUserConfigPublicAccess']:
        return pulumi.get(self, "public_access")

    @property
    @pulumi.getter(name="recoveryBasebackupName")
    def recovery_basebackup_name(self) -> Optional[str]:
        return pulumi.get(self, "recovery_basebackup_name")

    @property
    @pulumi.getter(name="serviceToForkFrom")
    def service_to_fork_from(self) -> Optional[str]:
        return pulumi.get(self, "service_to_fork_from")


@pulumi.output_type
class ServiceElasticsearchUserConfigElasticsearch(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "actionAutoCreateIndexEnabled":
            suggest = "action_auto_create_index_enabled"
        elif key == "actionDestructiveRequiresName":
            suggest = "action_destructive_requires_name"
        elif key == "clusterMaxShardsPerNode":
            suggest = "cluster_max_shards_per_node"
        elif key == "httpMaxContentLength":
            suggest = "http_max_content_length"
        elif key == "httpMaxHeaderSize":
            suggest = "http_max_header_size"
        elif key == "httpMaxInitialLineLength":
            suggest = "http_max_initial_line_length"
        elif key == "indicesFielddataCacheSize":
            suggest = "indices_fielddata_cache_size"
        elif key == "indicesMemoryIndexBufferSize":
            suggest = "indices_memory_index_buffer_size"
        elif key == "indicesQueriesCacheSize":
            suggest = "indices_queries_cache_size"
        elif key == "indicesQueryBoolMaxClauseCount":
            suggest = "indices_query_bool_max_clause_count"
        elif key == "reindexRemoteWhitelists":
            suggest = "reindex_remote_whitelists"
        elif key == "searchMaxBuckets":
            suggest = "search_max_buckets"
        elif key == "threadPoolAnalyzeQueueSize":
            suggest = "thread_pool_analyze_queue_size"
        elif key == "threadPoolAnalyzeSize":
            suggest = "thread_pool_analyze_size"
        elif key == "threadPoolForceMergeSize":
            suggest = "thread_pool_force_merge_size"
        elif key == "threadPoolGetQueueSize":
            suggest = "thread_pool_get_queue_size"
        elif key == "threadPoolGetSize":
            suggest = "thread_pool_get_size"
        elif key == "threadPoolIndexQueueSize":
            suggest = "thread_pool_index_queue_size"
        elif key == "threadPoolIndexSize":
            suggest = "thread_pool_index_size"
        elif key == "threadPoolSearchQueueSize":
            suggest = "thread_pool_search_queue_size"
        elif key == "threadPoolSearchSize":
            suggest = "thread_pool_search_size"
        elif key == "threadPoolSearchThrottledQueueSize":
            suggest = "thread_pool_search_throttled_queue_size"
        elif key == "threadPoolSearchThrottledSize":
            suggest = "thread_pool_search_throttled_size"
        elif key == "threadPoolWriteQueueSize":
            suggest = "thread_pool_write_queue_size"
        elif key == "threadPoolWriteSize":
            suggest = "thread_pool_write_size"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ServiceElasticsearchUserConfigElasticsearch. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ServiceElasticsearchUserConfigElasticsearch.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ServiceElasticsearchUserConfigElasticsearch.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 action_auto_create_index_enabled: Optional[str] = None,
                 action_destructive_requires_name: Optional[str] = None,
                 cluster_max_shards_per_node: Optional[str] = None,
                 http_max_content_length: Optional[str] = None,
                 http_max_header_size: Optional[str] = None,
                 http_max_initial_line_length: Optional[str] = None,
                 indices_fielddata_cache_size: Optional[str] = None,
                 indices_memory_index_buffer_size: Optional[str] = None,
                 indices_queries_cache_size: Optional[str] = None,
                 indices_query_bool_max_clause_count: Optional[str] = None,
                 reindex_remote_whitelists: Optional[Sequence[str]] = None,
                 search_max_buckets: Optional[str] = None,
                 thread_pool_analyze_queue_size: Optional[str] = None,
                 thread_pool_analyze_size: Optional[str] = None,
                 thread_pool_force_merge_size: Optional[str] = None,
                 thread_pool_get_queue_size: Optional[str] = None,
                 thread_pool_get_size: Optional[str] = None,
                 thread_pool_index_queue_size: Optional[str] = None,
                 thread_pool_index_size: Optional[str] = None,
                 thread_pool_search_queue_size: Optional[str] = None,
                 thread_pool_search_size: Optional[str] = None,
                 thread_pool_search_throttled_queue_size: Optional[str] = None,
                 thread_pool_search_throttled_size: Optional[str] = None,
                 thread_pool_write_queue_size: Optional[str] = None,
                 thread_pool_write_size: Optional[str] = None):
        if action_auto_create_index_enabled is not None:
            pulumi.set(__self__, "action_auto_create_index_enabled", action_auto_create_index_enabled)
        if action_destructive_requires_name is not None:
            pulumi.set(__self__, "action_destructive_requires_name", action_destructive_requires_name)
        if cluster_max_shards_per_node is not None:
            pulumi.set(__self__, "cluster_max_shards_per_node", cluster_max_shards_per_node)
        if http_max_content_length is not None:
            pulumi.set(__self__, "http_max_content_length", http_max_content_length)
        if http_max_header_size is not None:
            pulumi.set(__self__, "http_max_header_size", http_max_header_size)
        if http_max_initial_line_length is not None:
            pulumi.set(__self__, "http_max_initial_line_length", http_max_initial_line_length)
        if indices_fielddata_cache_size is not None:
            pulumi.set(__self__, "indices_fielddata_cache_size", indices_fielddata_cache_size)
        if indices_memory_index_buffer_size is not None:
            pulumi.set(__self__, "indices_memory_index_buffer_size", indices_memory_index_buffer_size)
        if indices_queries_cache_size is not None:
            pulumi.set(__self__, "indices_queries_cache_size", indices_queries_cache_size)
        if indices_query_bool_max_clause_count is not None:
            pulumi.set(__self__, "indices_query_bool_max_clause_count", indices_query_bool_max_clause_count)
        if reindex_remote_whitelists is not None:
            pulumi.set(__self__, "reindex_remote_whitelists", reindex_remote_whitelists)
        if search_max_buckets is not None:
            pulumi.set(__self__, "search_max_buckets", search_max_buckets)
        if thread_pool_analyze_queue_size is not None:
            pulumi.set(__self__, "thread_pool_analyze_queue_size", thread_pool_analyze_queue_size)
        if thread_pool_analyze_size is not None:
            pulumi.set(__self__, "thread_pool_analyze_size", thread_pool_analyze_size)
        if thread_pool_force_merge_size is not None:
            pulumi.set(__self__, "thread_pool_force_merge_size", thread_pool_force_merge_size)
        if thread_pool_get_queue_size is not None:
            pulumi.set(__self__, "thread_pool_get_queue_size", thread_pool_get_queue_size)
        if thread_pool_get_size is not None:
            pulumi.set(__self__, "thread_pool_get_size", thread_pool_get_size)
        if thread_pool_index_queue_size is not None:
            pulumi.set(__self__, "thread_pool_index_queue_size", thread_pool_index_queue_size)
        if thread_pool_index_size is not None:
            pulumi.set(__self__, "thread_pool_index_size", thread_pool_index_size)
        if thread_pool_search_queue_size is not None:
            pulumi.set(__self__, "thread_pool_search_queue_size", thread_pool_search_queue_size)
        if thread_pool_search_size is not None:
            pulumi.set(__self__, "thread_pool_search_size", thread_pool_search_size)
        if thread_pool_search_throttled_queue_size is not None:
            pulumi.set(__self__, "thread_pool_search_throttled_queue_size", thread_pool_search_throttled_queue_size)
        if thread_pool_search_throttled_size is not None:
            pulumi.set(__self__, "thread_pool_search_throttled_size", thread_pool_search_throttled_size)
        if thread_pool_write_queue_size is not None:
            pulumi.set(__self__, "thread_pool_write_queue_size", thread_pool_write_queue_size)
        if thread_pool_write_size is not None:
            pulumi.set(__self__, "thread_pool_write_size", thread_pool_write_size)

    @property
    @pulumi.getter(name="actionAutoCreateIndexEnabled")
    def action_auto_create_index_enabled(self) -> Optional[str]:
        return pulumi.get(self, "action_auto_create_index_enabled")

    @property
    @pulumi.getter(name="actionDestructiveRequiresName")
    def action_destructive_requires_name(self) -> Optional[str]:
        return pulumi.get(self, "action_destructive_requires_name")

    @property
    @pulumi.getter(name="clusterMaxShardsPerNode")
    def cluster_max_shards_per_node(self) -> Optional[str]:
        return pulumi.get(self, "cluster_max_shards_per_node")

    @property
    @pulumi.getter(name="httpMaxContentLength")
    def http_max_content_length(self) -> Optional[str]:
        return pulumi.get(self, "http_max_content_length")

    @property
    @pulumi.getter(name="httpMaxHeaderSize")
    def http_max_header_size(self) -> Optional[str]:
        return pulumi.get(self, "http_max_header_size")

    @property
    @pulumi.getter(name="httpMaxInitialLineLength")
    def http_max_initial_line_length(self) -> Optional[str]:
        return pulumi.get(self, "http_max_initial_line_length")

    @property
    @pulumi.getter(name="indicesFielddataCacheSize")
    def indices_fielddata_cache_size(self) -> Optional[str]:
        return pulumi.get(self, "indices_fielddata_cache_size")

    @property
    @pulumi.getter(name="indicesMemoryIndexBufferSize")
    def indices_memory_index_buffer_size(self) -> Optional[str]:
        return pulumi.get(self, "indices_memory_index_buffer_size")

    @property
    @pulumi.getter(name="indicesQueriesCacheSize")
    def indices_queries_cache_size(self) -> Optional[str]:
        return pulumi.get(self, "indices_queries_cache_size")

    @property
    @pulumi.getter(name="indicesQueryBoolMaxClauseCount")
    def indices_query_bool_max_clause_count(self) -> Optional[str]:
        return pulumi.get(self, "indices_query_bool_max_clause_count")

    @property
    @pulumi.getter(name="reindexRemoteWhitelists")
    def reindex_remote_whitelists(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "reindex_remote_whitelists")

    @property
    @pulumi.getter(name="searchMaxBuckets")
    def search_max_buckets(self) -> Optional[str]:
        return pulumi.get(self, "search_max_buckets")

    @property
    @pulumi.getter(name="threadPoolAnalyzeQueueSize")
    def thread_pool_analyze_queue_size(self) -> Optional[str]:
        return pulumi.get(self, "thread_pool_analyze_queue_size")

    @property
    @pulumi.getter(name="threadPoolAnalyzeSize")
    def thread_pool_analyze_size(self) -> Optional[str]:
        return pulumi.get(self, "thread_pool_analyze_size")

    @property
    @pulumi.getter(name="threadPoolForceMergeSize")
    def thread_pool_force_merge_size(self) -> Optional[str]:
        return pulumi.get(self, "thread_pool_force_merge_size")

    @property
    @pulumi.getter(name="threadPoolGetQueueSize")
    def thread_pool_get_queue_size(self) -> Optional[str]:
        return pulumi.get(self, "thread_pool_get_queue_size")

    @property
    @pulumi.getter(name="threadPoolGetSize")
    def thread_pool_get_size(self) -> Optional[str]:
        return pulumi.get(self, "thread_pool_get_size")

    @property
    @pulumi.getter(name="threadPoolIndexQueueSize")
    def thread_pool_index_queue_size(self) -> Optional[str]:
        return pulumi.get(self, "thread_pool_index_queue_size")

    @property
    @pulumi.getter(name="threadPoolIndexSize")
    def thread_pool_index_size(self) -> Optional[str]:
        return pulumi.get(self, "thread_pool_index_size")

    @property
    @pulumi.getter(name="threadPoolSearchQueueSize")
    def thread_pool_search_queue_size(self) -> Optional[str]:
        return pulumi.get(self, "thread_pool_search_queue_size")

    @property
    @pulumi.getter(name="threadPoolSearchSize")
    def thread_pool_search_size(self) -> Optional[str]:
        return pulumi.get(self, "thread_pool_search_size")

    @property
    @pulumi.getter(name="threadPoolSearchThrottledQueueSize")
    def thread_pool_search_throttled_queue_size(self) -> Optional[str]:
        return pulumi.get(self, "thread_pool_search_throttled_queue_size")

    @property
    @pulumi.getter(name="threadPoolSearchThrottledSize")
    def thread_pool_search_throttled_size(self) -> Optional[str]:
        return pulumi.get(self, "thread_pool_search_throttled_size")

    @property
    @pulumi.getter(name="threadPoolWriteQueueSize")
    def thread_pool_write_queue_size(self) -> Optional[str]:
        return pulumi.get(self, "thread_pool_write_queue_size")

    @property
    @pulumi.getter(name="threadPoolWriteSize")
    def thread_pool_write_size(self) -> Optional[str]:
        return pulumi.get(self, "thread_pool_write_size")


@pulumi.output_type
class ServiceElasticsearchUserConfigIndexPattern(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "maxIndexCount":
            suggest = "max_index_count"
        elif key == "sortingAlgorithm":
            suggest = "sorting_algorithm"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ServiceElasticsearchUserConfigIndexPattern. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ServiceElasticsearchUserConfigIndexPattern.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ServiceElasticsearchUserConfigIndexPattern.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 max_index_count: Optional[str] = None,
                 pattern: Optional[str] = None,
                 sorting_algorithm: Optional[str] = None):
        if max_index_count is not None:
            pulumi.set(__self__, "max_index_count", max_index_count)
        if pattern is not None:
            pulumi.set(__self__, "pattern", pattern)
        if sorting_algorithm is not None:
            pulumi.set(__self__, "sorting_algorithm", sorting_algorithm)

    @property
    @pulumi.getter(name="maxIndexCount")
    def max_index_count(self) -> Optional[str]:
        return pulumi.get(self, "max_index_count")

    @property
    @pulumi.getter
    def pattern(self) -> Optional[str]:
        return pulumi.get(self, "pattern")

    @property
    @pulumi.getter(name="sortingAlgorithm")
    def sorting_algorithm(self) -> Optional[str]:
        return pulumi.get(self, "sorting_algorithm")


@pulumi.output_type
class ServiceElasticsearchUserConfigIndexTemplate(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "mappingNestedObjectsLimit":
            suggest = "mapping_nested_objects_limit"
        elif key == "numberOfReplicas":
            suggest = "number_of_replicas"
        elif key == "numberOfShards":
            suggest = "number_of_shards"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ServiceElasticsearchUserConfigIndexTemplate. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ServiceElasticsearchUserConfigIndexTemplate.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ServiceElasticsearchUserConfigIndexTemplate.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 mapping_nested_objects_limit: Optional[str] = None,
                 number_of_replicas: Optional[str] = None,
                 number_of_shards: Optional[str] = None):
        if mapping_nested_objects_limit is not None:
            pulumi.set(__self__, "mapping_nested_objects_limit", mapping_nested_objects_limit)
        if number_of_replicas is not None:
            pulumi.set(__self__, "number_of_replicas", number_of_replicas)
        if number_of_shards is not None:
            pulumi.set(__self__, "number_of_shards", number_of_shards)

    @property
    @pulumi.getter(name="mappingNestedObjectsLimit")
    def mapping_nested_objects_limit(self) -> Optional[str]:
        return pulumi.get(self, "mapping_nested_objects_limit")

    @property
    @pulumi.getter(name="numberOfReplicas")
    def number_of_replicas(self) -> Optional[str]:
        return pulumi.get(self, "number_of_replicas")

    @property
    @pulumi.getter(name="numberOfShards")
    def number_of_shards(self) -> Optional[str]:
        return pulumi.get(self, "number_of_shards")


@pulumi.output_type
class ServiceElasticsearchUserConfigKibana(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "elasticsearchRequestTimeout":
            suggest = "elasticsearch_request_timeout"
        elif key == "maxOldSpaceSize":
            suggest = "max_old_space_size"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ServiceElasticsearchUserConfigKibana. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ServiceElasticsearchUserConfigKibana.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ServiceElasticsearchUserConfigKibana.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 elasticsearch_request_timeout: Optional[str] = None,
                 enabled: Optional[str] = None,
                 max_old_space_size: Optional[str] = None):
        if elasticsearch_request_timeout is not None:
            pulumi.set(__self__, "elasticsearch_request_timeout", elasticsearch_request_timeout)
        if enabled is not None:
            pulumi.set(__self__, "enabled", enabled)
        if max_old_space_size is not None:
            pulumi.set(__self__, "max_old_space_size", max_old_space_size)

    @property
    @pulumi.getter(name="elasticsearchRequestTimeout")
    def elasticsearch_request_timeout(self) -> Optional[str]:
        return pulumi.get(self, "elasticsearch_request_timeout")

    @property
    @pulumi.getter
    def enabled(self) -> Optional[str]:
        return pulumi.get(self, "enabled")

    @property
    @pulumi.getter(name="maxOldSpaceSize")
    def max_old_space_size(self) -> Optional[str]:
        return pulumi.get(self, "max_old_space_size")


@pulumi.output_type
class ServiceElasticsearchUserConfigPrivateAccess(dict):
    def __init__(__self__, *,
                 elasticsearch: Optional[str] = None,
                 kibana: Optional[str] = None,
                 prometheus: Optional[str] = None):
        if elasticsearch is not None:
            pulumi.set(__self__, "elasticsearch", elasticsearch)
        if kibana is not None:
            pulumi.set(__self__, "kibana", kibana)
        if prometheus is not None:
            pulumi.set(__self__, "prometheus", prometheus)

    @property
    @pulumi.getter
    def elasticsearch(self) -> Optional[str]:
        return pulumi.get(self, "elasticsearch")

    @property
    @pulumi.getter
    def kibana(self) -> Optional[str]:
        return pulumi.get(self, "kibana")

    @property
    @pulumi.getter
    def prometheus(self) -> Optional[str]:
        return pulumi.get(self, "prometheus")


@pulumi.output_type
class ServiceElasticsearchUserConfigPrivatelinkAccess(dict):
    def __init__(__self__, *,
                 elasticsearch: Optional[str] = None,
                 kibana: Optional[str] = None):
        if elasticsearch is not None:
            pulumi.set(__self__, "elasticsearch", elasticsearch)
        if kibana is not None:
            pulumi.set(__self__, "kibana", kibana)

    @property
    @pulumi.getter
    def elasticsearch(self) -> Optional[str]:
        return pulumi.get(self, "elasticsearch")

    @property
    @pulumi.getter
    def kibana(self) -> Optional[str]:
        return pulumi.get(self, "kibana")


@pulumi.output_type
class ServiceElasticsearchUserConfigPublicAccess(dict):
    def __init__(__self__, *,
                 elasticsearch: Optional[str] = None,
                 kibana: Optional[str] = None,
                 prometheus: Optional[str] = None):
        if elasticsearch is not None:
            pulumi.set(__self__, "elasticsearch", elasticsearch)
        if kibana is not None:
            pulumi.set(__self__, "kibana", kibana)
        if prometheus is not None:
            pulumi.set(__self__, "prometheus", prometheus)

    @property
    @pulumi.getter
    def elasticsearch(self) -> Optional[str]:
        return pulumi.get(self, "elasticsearch")

    @property
    @pulumi.getter
    def kibana(self) -> Optional[str]:
        return pulumi.get(self, "kibana")

    @property
    @pulumi.getter
    def prometheus(self) -> Optional[str]:
        return pulumi.get(self, "prometheus")


@pulumi.output_type
class ServiceGrafana(dict):
    def __init__(__self__):
        pass


@pulumi.output_type
class ServiceGrafanaUserConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "alertingEnabled":
            suggest = "alerting_enabled"
        elif key == "alertingErrorOrTimeout":
            suggest = "alerting_error_or_timeout"
        elif key == "alertingNodataOrNullvalues":
            suggest = "alerting_nodata_or_nullvalues"
        elif key == "allowEmbedding":
            suggest = "allow_embedding"
        elif key == "authBasicEnabled":
            suggest = "auth_basic_enabled"
        elif key == "authGenericOauth":
            suggest = "auth_generic_oauth"
        elif key == "authGithub":
            suggest = "auth_github"
        elif key == "authGitlab":
            suggest = "auth_gitlab"
        elif key == "authGoogle":
            suggest = "auth_google"
        elif key == "cookieSamesite":
            suggest = "cookie_samesite"
        elif key == "customDomain":
            suggest = "custom_domain"
        elif key == "dashboardsMinRefreshInterval":
            suggest = "dashboards_min_refresh_interval"
        elif key == "dashboardsVersionsToKeep":
            suggest = "dashboards_versions_to_keep"
        elif key == "dataproxySendUserHeader":
            suggest = "dataproxy_send_user_header"
        elif key == "dataproxyTimeout":
            suggest = "dataproxy_timeout"
        elif key == "disableGravatar":
            suggest = "disable_gravatar"
        elif key == "editorsCanAdmin":
            suggest = "editors_can_admin"
        elif key == "externalImageStorage":
            suggest = "external_image_storage"
        elif key == "googleAnalyticsUaId":
            suggest = "google_analytics_ua_id"
        elif key == "ipFilters":
            suggest = "ip_filters"
        elif key == "metricsEnabled":
            suggest = "metrics_enabled"
        elif key == "privateAccess":
            suggest = "private_access"
        elif key == "privatelinkAccess":
            suggest = "privatelink_access"
        elif key == "projectToForkFrom":
            suggest = "project_to_fork_from"
        elif key == "publicAccess":
            suggest = "public_access"
        elif key == "recoveryBasebackupName":
            suggest = "recovery_basebackup_name"
        elif key == "serviceToForkFrom":
            suggest = "service_to_fork_from"
        elif key == "smtpServer":
            suggest = "smtp_server"
        elif key == "userAutoAssignOrg":
            suggest = "user_auto_assign_org"
        elif key == "userAutoAssignOrgRole":
            suggest = "user_auto_assign_org_role"
        elif key == "viewersCanEdit":
            suggest = "viewers_can_edit"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ServiceGrafanaUserConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ServiceGrafanaUserConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ServiceGrafanaUserConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 alerting_enabled: Optional[str] = None,
                 alerting_error_or_timeout: Optional[str] = None,
                 alerting_nodata_or_nullvalues: Optional[str] = None,
                 allow_embedding: Optional[str] = None,
                 auth_basic_enabled: Optional[str] = None,
                 auth_generic_oauth: Optional['outputs.ServiceGrafanaUserConfigAuthGenericOauth'] = None,
                 auth_github: Optional['outputs.ServiceGrafanaUserConfigAuthGithub'] = None,
                 auth_gitlab: Optional['outputs.ServiceGrafanaUserConfigAuthGitlab'] = None,
                 auth_google: Optional['outputs.ServiceGrafanaUserConfigAuthGoogle'] = None,
                 cookie_samesite: Optional[str] = None,
                 custom_domain: Optional[str] = None,
                 dashboards_min_refresh_interval: Optional[str] = None,
                 dashboards_versions_to_keep: Optional[str] = None,
                 dataproxy_send_user_header: Optional[str] = None,
                 dataproxy_timeout: Optional[str] = None,
                 disable_gravatar: Optional[str] = None,
                 editors_can_admin: Optional[str] = None,
                 external_image_storage: Optional['outputs.ServiceGrafanaUserConfigExternalImageStorage'] = None,
                 google_analytics_ua_id: Optional[str] = None,
                 ip_filters: Optional[Sequence[str]] = None,
                 metrics_enabled: Optional[str] = None,
                 private_access: Optional['outputs.ServiceGrafanaUserConfigPrivateAccess'] = None,
                 privatelink_access: Optional['outputs.ServiceGrafanaUserConfigPrivatelinkAccess'] = None,
                 project_to_fork_from: Optional[str] = None,
                 public_access: Optional['outputs.ServiceGrafanaUserConfigPublicAccess'] = None,
                 recovery_basebackup_name: Optional[str] = None,
                 service_to_fork_from: Optional[str] = None,
                 smtp_server: Optional['outputs.ServiceGrafanaUserConfigSmtpServer'] = None,
                 user_auto_assign_org: Optional[str] = None,
                 user_auto_assign_org_role: Optional[str] = None,
                 viewers_can_edit: Optional[str] = None):
        if alerting_enabled is not None:
            pulumi.set(__self__, "alerting_enabled", alerting_enabled)
        if alerting_error_or_timeout is not None:
            pulumi.set(__self__, "alerting_error_or_timeout", alerting_error_or_timeout)
        if alerting_nodata_or_nullvalues is not None:
            pulumi.set(__self__, "alerting_nodata_or_nullvalues", alerting_nodata_or_nullvalues)
        if allow_embedding is not None:
            pulumi.set(__self__, "allow_embedding", allow_embedding)
        if auth_basic_enabled is not None:
            pulumi.set(__self__, "auth_basic_enabled", auth_basic_enabled)
        if auth_generic_oauth is not None:
            pulumi.set(__self__, "auth_generic_oauth", auth_generic_oauth)
        if auth_github is not None:
            pulumi.set(__self__, "auth_github", auth_github)
        if auth_gitlab is not None:
            pulumi.set(__self__, "auth_gitlab", auth_gitlab)
        if auth_google is not None:
            pulumi.set(__self__, "auth_google", auth_google)
        if cookie_samesite is not None:
            pulumi.set(__self__, "cookie_samesite", cookie_samesite)
        if custom_domain is not None:
            pulumi.set(__self__, "custom_domain", custom_domain)
        if dashboards_min_refresh_interval is not None:
            pulumi.set(__self__, "dashboards_min_refresh_interval", dashboards_min_refresh_interval)
        if dashboards_versions_to_keep is not None:
            pulumi.set(__self__, "dashboards_versions_to_keep", dashboards_versions_to_keep)
        if dataproxy_send_user_header is not None:
            pulumi.set(__self__, "dataproxy_send_user_header", dataproxy_send_user_header)
        if dataproxy_timeout is not None:
            pulumi.set(__self__, "dataproxy_timeout", dataproxy_timeout)
        if disable_gravatar is not None:
            pulumi.set(__self__, "disable_gravatar", disable_gravatar)
        if editors_can_admin is not None:
            pulumi.set(__self__, "editors_can_admin", editors_can_admin)
        if external_image_storage is not None:
            pulumi.set(__self__, "external_image_storage", external_image_storage)
        if google_analytics_ua_id is not None:
            pulumi.set(__self__, "google_analytics_ua_id", google_analytics_ua_id)
        if ip_filters is not None:
            pulumi.set(__self__, "ip_filters", ip_filters)
        if metrics_enabled is not None:
            pulumi.set(__self__, "metrics_enabled", metrics_enabled)
        if private_access is not None:
            pulumi.set(__self__, "private_access", private_access)
        if privatelink_access is not None:
            pulumi.set(__self__, "privatelink_access", privatelink_access)
        if project_to_fork_from is not None:
            pulumi.set(__self__, "project_to_fork_from", project_to_fork_from)
        if public_access is not None:
            pulumi.set(__self__, "public_access", public_access)
        if recovery_basebackup_name is not None:
            pulumi.set(__self__, "recovery_basebackup_name", recovery_basebackup_name)
        if service_to_fork_from is not None:
            pulumi.set(__self__, "service_to_fork_from", service_to_fork_from)
        if smtp_server is not None:
            pulumi.set(__self__, "smtp_server", smtp_server)
        if user_auto_assign_org is not None:
            pulumi.set(__self__, "user_auto_assign_org", user_auto_assign_org)
        if user_auto_assign_org_role is not None:
            pulumi.set(__self__, "user_auto_assign_org_role", user_auto_assign_org_role)
        if viewers_can_edit is not None:
            pulumi.set(__self__, "viewers_can_edit", viewers_can_edit)

    @property
    @pulumi.getter(name="alertingEnabled")
    def alerting_enabled(self) -> Optional[str]:
        return pulumi.get(self, "alerting_enabled")

    @property
    @pulumi.getter(name="alertingErrorOrTimeout")
    def alerting_error_or_timeout(self) -> Optional[str]:
        return pulumi.get(self, "alerting_error_or_timeout")

    @property
    @pulumi.getter(name="alertingNodataOrNullvalues")
    def alerting_nodata_or_nullvalues(self) -> Optional[str]:
        return pulumi.get(self, "alerting_nodata_or_nullvalues")

    @property
    @pulumi.getter(name="allowEmbedding")
    def allow_embedding(self) -> Optional[str]:
        return pulumi.get(self, "allow_embedding")

    @property
    @pulumi.getter(name="authBasicEnabled")
    def auth_basic_enabled(self) -> Optional[str]:
        return pulumi.get(self, "auth_basic_enabled")

    @property
    @pulumi.getter(name="authGenericOauth")
    def auth_generic_oauth(self) -> Optional['outputs.ServiceGrafanaUserConfigAuthGenericOauth']:
        return pulumi.get(self, "auth_generic_oauth")

    @property
    @pulumi.getter(name="authGithub")
    def auth_github(self) -> Optional['outputs.ServiceGrafanaUserConfigAuthGithub']:
        return pulumi.get(self, "auth_github")

    @property
    @pulumi.getter(name="authGitlab")
    def auth_gitlab(self) -> Optional['outputs.ServiceGrafanaUserConfigAuthGitlab']:
        return pulumi.get(self, "auth_gitlab")

    @property
    @pulumi.getter(name="authGoogle")
    def auth_google(self) -> Optional['outputs.ServiceGrafanaUserConfigAuthGoogle']:
        return pulumi.get(self, "auth_google")

    @property
    @pulumi.getter(name="cookieSamesite")
    def cookie_samesite(self) -> Optional[str]:
        return pulumi.get(self, "cookie_samesite")

    @property
    @pulumi.getter(name="customDomain")
    def custom_domain(self) -> Optional[str]:
        return pulumi.get(self, "custom_domain")

    @property
    @pulumi.getter(name="dashboardsMinRefreshInterval")
    def dashboards_min_refresh_interval(self) -> Optional[str]:
        return pulumi.get(self, "dashboards_min_refresh_interval")

    @property
    @pulumi.getter(name="dashboardsVersionsToKeep")
    def dashboards_versions_to_keep(self) -> Optional[str]:
        return pulumi.get(self, "dashboards_versions_to_keep")

    @property
    @pulumi.getter(name="dataproxySendUserHeader")
    def dataproxy_send_user_header(self) -> Optional[str]:
        return pulumi.get(self, "dataproxy_send_user_header")

    @property
    @pulumi.getter(name="dataproxyTimeout")
    def dataproxy_timeout(self) -> Optional[str]:
        return pulumi.get(self, "dataproxy_timeout")

    @property
    @pulumi.getter(name="disableGravatar")
    def disable_gravatar(self) -> Optional[str]:
        return pulumi.get(self, "disable_gravatar")

    @property
    @pulumi.getter(name="editorsCanAdmin")
    def editors_can_admin(self) -> Optional[str]:
        return pulumi.get(self, "editors_can_admin")

    @property
    @pulumi.getter(name="externalImageStorage")
    def external_image_storage(self) -> Optional['outputs.ServiceGrafanaUserConfigExternalImageStorage']:
        return pulumi.get(self, "external_image_storage")

    @property
    @pulumi.getter(name="googleAnalyticsUaId")
    def google_analytics_ua_id(self) -> Optional[str]:
        return pulumi.get(self, "google_analytics_ua_id")

    @property
    @pulumi.getter(name="ipFilters")
    def ip_filters(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "ip_filters")

    @property
    @pulumi.getter(name="metricsEnabled")
    def metrics_enabled(self) -> Optional[str]:
        return pulumi.get(self, "metrics_enabled")

    @property
    @pulumi.getter(name="privateAccess")
    def private_access(self) -> Optional['outputs.ServiceGrafanaUserConfigPrivateAccess']:
        return pulumi.get(self, "private_access")

    @property
    @pulumi.getter(name="privatelinkAccess")
    def privatelink_access(self) -> Optional['outputs.ServiceGrafanaUserConfigPrivatelinkAccess']:
        return pulumi.get(self, "privatelink_access")

    @property
    @pulumi.getter(name="projectToForkFrom")
    def project_to_fork_from(self) -> Optional[str]:
        return pulumi.get(self, "project_to_fork_from")

    @property
    @pulumi.getter(name="publicAccess")
    def public_access(self) -> Optional['outputs.ServiceGrafanaUserConfigPublicAccess']:
        return pulumi.get(self, "public_access")

    @property
    @pulumi.getter(name="recoveryBasebackupName")
    def recovery_basebackup_name(self) -> Optional[str]:
        return pulumi.get(self, "recovery_basebackup_name")

    @property
    @pulumi.getter(name="serviceToForkFrom")
    def service_to_fork_from(self) -> Optional[str]:
        return pulumi.get(self, "service_to_fork_from")

    @property
    @pulumi.getter(name="smtpServer")
    def smtp_server(self) -> Optional['outputs.ServiceGrafanaUserConfigSmtpServer']:
        return pulumi.get(self, "smtp_server")

    @property
    @pulumi.getter(name="userAutoAssignOrg")
    def user_auto_assign_org(self) -> Optional[str]:
        return pulumi.get(self, "user_auto_assign_org")

    @property
    @pulumi.getter(name="userAutoAssignOrgRole")
    def user_auto_assign_org_role(self) -> Optional[str]:
        return pulumi.get(self, "user_auto_assign_org_role")

    @property
    @pulumi.getter(name="viewersCanEdit")
    def viewers_can_edit(self) -> Optional[str]:
        return pulumi.get(self, "viewers_can_edit")


@pulumi.output_type
class ServiceGrafanaUserConfigAuthGenericOauth(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "allowSignUp":
            suggest = "allow_sign_up"
        elif key == "allowedDomains":
            suggest = "allowed_domains"
        elif key == "allowedOrganizations":
            suggest = "allowed_organizations"
        elif key == "apiUrl":
            suggest = "api_url"
        elif key == "authUrl":
            suggest = "auth_url"
        elif key == "clientId":
            suggest = "client_id"
        elif key == "clientSecret":
            suggest = "client_secret"
        elif key == "tokenUrl":
            suggest = "token_url"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ServiceGrafanaUserConfigAuthGenericOauth. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ServiceGrafanaUserConfigAuthGenericOauth.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ServiceGrafanaUserConfigAuthGenericOauth.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 allow_sign_up: Optional[str] = None,
                 allowed_domains: Optional[Sequence[str]] = None,
                 allowed_organizations: Optional[Sequence[str]] = None,
                 api_url: Optional[str] = None,
                 auth_url: Optional[str] = None,
                 client_id: Optional[str] = None,
                 client_secret: Optional[str] = None,
                 name: Optional[str] = None,
                 scopes: Optional[Sequence[str]] = None,
                 token_url: Optional[str] = None):
        if allow_sign_up is not None:
            pulumi.set(__self__, "allow_sign_up", allow_sign_up)
        if allowed_domains is not None:
            pulumi.set(__self__, "allowed_domains", allowed_domains)
        if allowed_organizations is not None:
            pulumi.set(__self__, "allowed_organizations", allowed_organizations)
        if api_url is not None:
            pulumi.set(__self__, "api_url", api_url)
        if auth_url is not None:
            pulumi.set(__self__, "auth_url", auth_url)
        if client_id is not None:
            pulumi.set(__self__, "client_id", client_id)
        if client_secret is not None:
            pulumi.set(__self__, "client_secret", client_secret)
        if name is not None:
            pulumi.set(__self__, "name", name)
        if scopes is not None:
            pulumi.set(__self__, "scopes", scopes)
        if token_url is not None:
            pulumi.set(__self__, "token_url", token_url)

    @property
    @pulumi.getter(name="allowSignUp")
    def allow_sign_up(self) -> Optional[str]:
        return pulumi.get(self, "allow_sign_up")

    @property
    @pulumi.getter(name="allowedDomains")
    def allowed_domains(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "allowed_domains")

    @property
    @pulumi.getter(name="allowedOrganizations")
    def allowed_organizations(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "allowed_organizations")

    @property
    @pulumi.getter(name="apiUrl")
    def api_url(self) -> Optional[str]:
        return pulumi.get(self, "api_url")

    @property
    @pulumi.getter(name="authUrl")
    def auth_url(self) -> Optional[str]:
        return pulumi.get(self, "auth_url")

    @property
    @pulumi.getter(name="clientId")
    def client_id(self) -> Optional[str]:
        return pulumi.get(self, "client_id")

    @property
    @pulumi.getter(name="clientSecret")
    def client_secret(self) -> Optional[str]:
        return pulumi.get(self, "client_secret")

    @property
    @pulumi.getter
    def name(self) -> Optional[str]:
        return pulumi.get(self, "name")

    @property
    @pulumi.getter
    def scopes(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "scopes")

    @property
    @pulumi.getter(name="tokenUrl")
    def token_url(self) -> Optional[str]:
        return pulumi.get(self, "token_url")


@pulumi.output_type
class ServiceGrafanaUserConfigAuthGithub(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "allowSignUp":
            suggest = "allow_sign_up"
        elif key == "allowedOrganizations":
            suggest = "allowed_organizations"
        elif key == "clientId":
            suggest = "client_id"
        elif key == "clientSecret":
            suggest = "client_secret"
        elif key == "teamIds":
            suggest = "team_ids"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ServiceGrafanaUserConfigAuthGithub. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ServiceGrafanaUserConfigAuthGithub.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ServiceGrafanaUserConfigAuthGithub.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 allow_sign_up: Optional[str] = None,
                 allowed_organizations: Optional[Sequence[str]] = None,
                 client_id: Optional[str] = None,
                 client_secret: Optional[str] = None,
                 team_ids: Optional[Sequence[str]] = None):
        if allow_sign_up is not None:
            pulumi.set(__self__, "allow_sign_up", allow_sign_up)
        if allowed_organizations is not None:
            pulumi.set(__self__, "allowed_organizations", allowed_organizations)
        if client_id is not None:
            pulumi.set(__self__, "client_id", client_id)
        if client_secret is not None:
            pulumi.set(__self__, "client_secret", client_secret)
        if team_ids is not None:
            pulumi.set(__self__, "team_ids", team_ids)

    @property
    @pulumi.getter(name="allowSignUp")
    def allow_sign_up(self) -> Optional[str]:
        return pulumi.get(self, "allow_sign_up")

    @property
    @pulumi.getter(name="allowedOrganizations")
    def allowed_organizations(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "allowed_organizations")

    @property
    @pulumi.getter(name="clientId")
    def client_id(self) -> Optional[str]:
        return pulumi.get(self, "client_id")

    @property
    @pulumi.getter(name="clientSecret")
    def client_secret(self) -> Optional[str]:
        return pulumi.get(self, "client_secret")

    @property
    @pulumi.getter(name="teamIds")
    def team_ids(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "team_ids")


@pulumi.output_type
class ServiceGrafanaUserConfigAuthGitlab(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "allowSignUp":
            suggest = "allow_sign_up"
        elif key == "allowedGroups":
            suggest = "allowed_groups"
        elif key == "apiUrl":
            suggest = "api_url"
        elif key == "authUrl":
            suggest = "auth_url"
        elif key == "clientId":
            suggest = "client_id"
        elif key == "clientSecret":
            suggest = "client_secret"
        elif key == "tokenUrl":
            suggest = "token_url"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ServiceGrafanaUserConfigAuthGitlab. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ServiceGrafanaUserConfigAuthGitlab.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ServiceGrafanaUserConfigAuthGitlab.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 allow_sign_up: Optional[str] = None,
                 allowed_groups: Optional[Sequence[str]] = None,
                 api_url: Optional[str] = None,
                 auth_url: Optional[str] = None,
                 client_id: Optional[str] = None,
                 client_secret: Optional[str] = None,
                 token_url: Optional[str] = None):
        if allow_sign_up is not None:
            pulumi.set(__self__, "allow_sign_up", allow_sign_up)
        if allowed_groups is not None:
            pulumi.set(__self__, "allowed_groups", allowed_groups)
        if api_url is not None:
            pulumi.set(__self__, "api_url", api_url)
        if auth_url is not None:
            pulumi.set(__self__, "auth_url", auth_url)
        if client_id is not None:
            pulumi.set(__self__, "client_id", client_id)
        if client_secret is not None:
            pulumi.set(__self__, "client_secret", client_secret)
        if token_url is not None:
            pulumi.set(__self__, "token_url", token_url)

    @property
    @pulumi.getter(name="allowSignUp")
    def allow_sign_up(self) -> Optional[str]:
        return pulumi.get(self, "allow_sign_up")

    @property
    @pulumi.getter(name="allowedGroups")
    def allowed_groups(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "allowed_groups")

    @property
    @pulumi.getter(name="apiUrl")
    def api_url(self) -> Optional[str]:
        return pulumi.get(self, "api_url")

    @property
    @pulumi.getter(name="authUrl")
    def auth_url(self) -> Optional[str]:
        return pulumi.get(self, "auth_url")

    @property
    @pulumi.getter(name="clientId")
    def client_id(self) -> Optional[str]:
        return pulumi.get(self, "client_id")

    @property
    @pulumi.getter(name="clientSecret")
    def client_secret(self) -> Optional[str]:
        return pulumi.get(self, "client_secret")

    @property
    @pulumi.getter(name="tokenUrl")
    def token_url(self) -> Optional[str]:
        return pulumi.get(self, "token_url")


@pulumi.output_type
class ServiceGrafanaUserConfigAuthGoogle(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "allowSignUp":
            suggest = "allow_sign_up"
        elif key == "allowedDomains":
            suggest = "allowed_domains"
        elif key == "clientId":
            suggest = "client_id"
        elif key == "clientSecret":
            suggest = "client_secret"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ServiceGrafanaUserConfigAuthGoogle. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ServiceGrafanaUserConfigAuthGoogle.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ServiceGrafanaUserConfigAuthGoogle.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 allow_sign_up: Optional[str] = None,
                 allowed_domains: Optional[Sequence[str]] = None,
                 client_id: Optional[str] = None,
                 client_secret: Optional[str] = None):
        if allow_sign_up is not None:
            pulumi.set(__self__, "allow_sign_up", allow_sign_up)
        if allowed_domains is not None:
            pulumi.set(__self__, "allowed_domains", allowed_domains)
        if client_id is not None:
            pulumi.set(__self__, "client_id", client_id)
        if client_secret is not None:
            pulumi.set(__self__, "client_secret", client_secret)

    @property
    @pulumi.getter(name="allowSignUp")
    def allow_sign_up(self) -> Optional[str]:
        return pulumi.get(self, "allow_sign_up")

    @property
    @pulumi.getter(name="allowedDomains")
    def allowed_domains(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "allowed_domains")

    @property
    @pulumi.getter(name="clientId")
    def client_id(self) -> Optional[str]:
        return pulumi.get(self, "client_id")

    @property
    @pulumi.getter(name="clientSecret")
    def client_secret(self) -> Optional[str]:
        return pulumi.get(self, "client_secret")


@pulumi.output_type
class ServiceGrafanaUserConfigExternalImageStorage(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "accessKey":
            suggest = "access_key"
        elif key == "bucketUrl":
            suggest = "bucket_url"
        elif key == "secretKey":
            suggest = "secret_key"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ServiceGrafanaUserConfigExternalImageStorage. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ServiceGrafanaUserConfigExternalImageStorage.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ServiceGrafanaUserConfigExternalImageStorage.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 access_key: Optional[str] = None,
                 bucket_url: Optional[str] = None,
                 provider: Optional[str] = None,
                 secret_key: Optional[str] = None):
        if access_key is not None:
            pulumi.set(__self__, "access_key", access_key)
        if bucket_url is not None:
            pulumi.set(__self__, "bucket_url", bucket_url)
        if provider is not None:
            pulumi.set(__self__, "provider", provider)
        if secret_key is not None:
            pulumi.set(__self__, "secret_key", secret_key)

    @property
    @pulumi.getter(name="accessKey")
    def access_key(self) -> Optional[str]:
        return pulumi.get(self, "access_key")

    @property
    @pulumi.getter(name="bucketUrl")
    def bucket_url(self) -> Optional[str]:
        return pulumi.get(self, "bucket_url")

    @property
    @pulumi.getter
    def provider(self) -> Optional[str]:
        return pulumi.get(self, "provider")

    @property
    @pulumi.getter(name="secretKey")
    def secret_key(self) -> Optional[str]:
        return pulumi.get(self, "secret_key")


@pulumi.output_type
class ServiceGrafanaUserConfigPrivateAccess(dict):
    def __init__(__self__, *,
                 grafana: Optional[str] = None):
        if grafana is not None:
            pulumi.set(__self__, "grafana", grafana)

    @property
    @pulumi.getter
    def grafana(self) -> Optional[str]:
        return pulumi.get(self, "grafana")


@pulumi.output_type
class ServiceGrafanaUserConfigPrivatelinkAccess(dict):
    def __init__(__self__, *,
                 grafana: Optional[str] = None):
        if grafana is not None:
            pulumi.set(__self__, "grafana", grafana)

    @property
    @pulumi.getter
    def grafana(self) -> Optional[str]:
        return pulumi.get(self, "grafana")


@pulumi.output_type
class ServiceGrafanaUserConfigPublicAccess(dict):
    def __init__(__self__, *,
                 grafana: Optional[str] = None):
        if grafana is not None:
            pulumi.set(__self__, "grafana", grafana)

    @property
    @pulumi.getter
    def grafana(self) -> Optional[str]:
        return pulumi.get(self, "grafana")


@pulumi.output_type
class ServiceGrafanaUserConfigSmtpServer(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "fromAddress":
            suggest = "from_address"
        elif key == "fromName":
            suggest = "from_name"
        elif key == "skipVerify":
            suggest = "skip_verify"
        elif key == "starttlsPolicy":
            suggest = "starttls_policy"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ServiceGrafanaUserConfigSmtpServer. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ServiceGrafanaUserConfigSmtpServer.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ServiceGrafanaUserConfigSmtpServer.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 from_address: Optional[str] = None,
                 from_name: Optional[str] = None,
                 host: Optional[str] = None,
                 password: Optional[str] = None,
                 port: Optional[str] = None,
                 skip_verify: Optional[str] = None,
                 starttls_policy: Optional[str] = None,
                 username: Optional[str] = None):
        if from_address is not None:
            pulumi.set(__self__, "from_address", from_address)
        if from_name is not None:
            pulumi.set(__self__, "from_name", from_name)
        if host is not None:
            pulumi.set(__self__, "host", host)
        if password is not None:
            pulumi.set(__self__, "password", password)
        if port is not None:
            pulumi.set(__self__, "port", port)
        if skip_verify is not None:
            pulumi.set(__self__, "skip_verify", skip_verify)
        if starttls_policy is not None:
            pulumi.set(__self__, "starttls_policy", starttls_policy)
        if username is not None:
            pulumi.set(__self__, "username", username)

    @property
    @pulumi.getter(name="fromAddress")
    def from_address(self) -> Optional[str]:
        return pulumi.get(self, "from_address")

    @property
    @pulumi.getter(name="fromName")
    def from_name(self) -> Optional[str]:
        return pulumi.get(self, "from_name")

    @property
    @pulumi.getter
    def host(self) -> Optional[str]:
        return pulumi.get(self, "host")

    @property
    @pulumi.getter
    def password(self) -> Optional[str]:
        return pulumi.get(self, "password")

    @property
    @pulumi.getter
    def port(self) -> Optional[str]:
        return pulumi.get(self, "port")

    @property
    @pulumi.getter(name="skipVerify")
    def skip_verify(self) -> Optional[str]:
        return pulumi.get(self, "skip_verify")

    @property
    @pulumi.getter(name="starttlsPolicy")
    def starttls_policy(self) -> Optional[str]:
        return pulumi.get(self, "starttls_policy")

    @property
    @pulumi.getter
    def username(self) -> Optional[str]:
        return pulumi.get(self, "username")


@pulumi.output_type
class ServiceInfluxdb(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "databaseName":
            suggest = "database_name"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ServiceInfluxdb. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ServiceInfluxdb.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ServiceInfluxdb.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 database_name: Optional[str] = None):
        if database_name is not None:
            pulumi.set(__self__, "database_name", database_name)

    @property
    @pulumi.getter(name="databaseName")
    def database_name(self) -> Optional[str]:
        return pulumi.get(self, "database_name")


@pulumi.output_type
class ServiceInfluxdbUserConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "customDomain":
            suggest = "custom_domain"
        elif key == "ipFilters":
            suggest = "ip_filters"
        elif key == "privateAccess":
            suggest = "private_access"
        elif key == "privatelinkAccess":
            suggest = "privatelink_access"
        elif key == "projectToForkFrom":
            suggest = "project_to_fork_from"
        elif key == "publicAccess":
            suggest = "public_access"
        elif key == "recoveryBasebackupName":
            suggest = "recovery_basebackup_name"
        elif key == "serviceToForkFrom":
            suggest = "service_to_fork_from"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ServiceInfluxdbUserConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ServiceInfluxdbUserConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ServiceInfluxdbUserConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 custom_domain: Optional[str] = None,
                 influxdb: Optional['outputs.ServiceInfluxdbUserConfigInfluxdb'] = None,
                 ip_filters: Optional[Sequence[str]] = None,
                 private_access: Optional['outputs.ServiceInfluxdbUserConfigPrivateAccess'] = None,
                 privatelink_access: Optional['outputs.ServiceInfluxdbUserConfigPrivatelinkAccess'] = None,
                 project_to_fork_from: Optional[str] = None,
                 public_access: Optional['outputs.ServiceInfluxdbUserConfigPublicAccess'] = None,
                 recovery_basebackup_name: Optional[str] = None,
                 service_to_fork_from: Optional[str] = None):
        if custom_domain is not None:
            pulumi.set(__self__, "custom_domain", custom_domain)
        if influxdb is not None:
            pulumi.set(__self__, "influxdb", influxdb)
        if ip_filters is not None:
            pulumi.set(__self__, "ip_filters", ip_filters)
        if private_access is not None:
            pulumi.set(__self__, "private_access", private_access)
        if privatelink_access is not None:
            pulumi.set(__self__, "privatelink_access", privatelink_access)
        if project_to_fork_from is not None:
            pulumi.set(__self__, "project_to_fork_from", project_to_fork_from)
        if public_access is not None:
            pulumi.set(__self__, "public_access", public_access)
        if recovery_basebackup_name is not None:
            pulumi.set(__self__, "recovery_basebackup_name", recovery_basebackup_name)
        if service_to_fork_from is not None:
            pulumi.set(__self__, "service_to_fork_from", service_to_fork_from)

    @property
    @pulumi.getter(name="customDomain")
    def custom_domain(self) -> Optional[str]:
        return pulumi.get(self, "custom_domain")

    @property
    @pulumi.getter
    def influxdb(self) -> Optional['outputs.ServiceInfluxdbUserConfigInfluxdb']:
        return pulumi.get(self, "influxdb")

    @property
    @pulumi.getter(name="ipFilters")
    def ip_filters(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "ip_filters")

    @property
    @pulumi.getter(name="privateAccess")
    def private_access(self) -> Optional['outputs.ServiceInfluxdbUserConfigPrivateAccess']:
        return pulumi.get(self, "private_access")

    @property
    @pulumi.getter(name="privatelinkAccess")
    def privatelink_access(self) -> Optional['outputs.ServiceInfluxdbUserConfigPrivatelinkAccess']:
        return pulumi.get(self, "privatelink_access")

    @property
    @pulumi.getter(name="projectToForkFrom")
    def project_to_fork_from(self) -> Optional[str]:
        return pulumi.get(self, "project_to_fork_from")

    @property
    @pulumi.getter(name="publicAccess")
    def public_access(self) -> Optional['outputs.ServiceInfluxdbUserConfigPublicAccess']:
        return pulumi.get(self, "public_access")

    @property
    @pulumi.getter(name="recoveryBasebackupName")
    def recovery_basebackup_name(self) -> Optional[str]:
        return pulumi.get(self, "recovery_basebackup_name")

    @property
    @pulumi.getter(name="serviceToForkFrom")
    def service_to_fork_from(self) -> Optional[str]:
        return pulumi.get(self, "service_to_fork_from")


@pulumi.output_type
class ServiceInfluxdbUserConfigInfluxdb(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "logQueriesAfter":
            suggest = "log_queries_after"
        elif key == "maxRowLimit":
            suggest = "max_row_limit"
        elif key == "maxSelectBuckets":
            suggest = "max_select_buckets"
        elif key == "maxSelectPoint":
            suggest = "max_select_point"
        elif key == "queryTimeout":
            suggest = "query_timeout"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ServiceInfluxdbUserConfigInfluxdb. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ServiceInfluxdbUserConfigInfluxdb.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ServiceInfluxdbUserConfigInfluxdb.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 log_queries_after: Optional[str] = None,
                 max_row_limit: Optional[str] = None,
                 max_select_buckets: Optional[str] = None,
                 max_select_point: Optional[str] = None,
                 query_timeout: Optional[str] = None):
        if log_queries_after is not None:
            pulumi.set(__self__, "log_queries_after", log_queries_after)
        if max_row_limit is not None:
            pulumi.set(__self__, "max_row_limit", max_row_limit)
        if max_select_buckets is not None:
            pulumi.set(__self__, "max_select_buckets", max_select_buckets)
        if max_select_point is not None:
            pulumi.set(__self__, "max_select_point", max_select_point)
        if query_timeout is not None:
            pulumi.set(__self__, "query_timeout", query_timeout)

    @property
    @pulumi.getter(name="logQueriesAfter")
    def log_queries_after(self) -> Optional[str]:
        return pulumi.get(self, "log_queries_after")

    @property
    @pulumi.getter(name="maxRowLimit")
    def max_row_limit(self) -> Optional[str]:
        return pulumi.get(self, "max_row_limit")

    @property
    @pulumi.getter(name="maxSelectBuckets")
    def max_select_buckets(self) -> Optional[str]:
        return pulumi.get(self, "max_select_buckets")

    @property
    @pulumi.getter(name="maxSelectPoint")
    def max_select_point(self) -> Optional[str]:
        return pulumi.get(self, "max_select_point")

    @property
    @pulumi.getter(name="queryTimeout")
    def query_timeout(self) -> Optional[str]:
        return pulumi.get(self, "query_timeout")


@pulumi.output_type
class ServiceInfluxdbUserConfigPrivateAccess(dict):
    def __init__(__self__, *,
                 influxdb: Optional[str] = None):
        if influxdb is not None:
            pulumi.set(__self__, "influxdb", influxdb)

    @property
    @pulumi.getter
    def influxdb(self) -> Optional[str]:
        return pulumi.get(self, "influxdb")


@pulumi.output_type
class ServiceInfluxdbUserConfigPrivatelinkAccess(dict):
    def __init__(__self__, *,
                 influxdb: Optional[str] = None):
        if influxdb is not None:
            pulumi.set(__self__, "influxdb", influxdb)

    @property
    @pulumi.getter
    def influxdb(self) -> Optional[str]:
        return pulumi.get(self, "influxdb")


@pulumi.output_type
class ServiceInfluxdbUserConfigPublicAccess(dict):
    def __init__(__self__, *,
                 influxdb: Optional[str] = None):
        if influxdb is not None:
            pulumi.set(__self__, "influxdb", influxdb)

    @property
    @pulumi.getter
    def influxdb(self) -> Optional[str]:
        return pulumi.get(self, "influxdb")


@pulumi.output_type
class ServiceIntegrationDashboardUserConfig(dict):
    def __init__(__self__):
        pass


@pulumi.output_type
class ServiceIntegrationDatadogUserConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "datadogTags":
            suggest = "datadog_tags"
        elif key == "excludeConsumerGroups":
            suggest = "exclude_consumer_groups"
        elif key == "excludeTopics":
            suggest = "exclude_topics"
        elif key == "includeConsumerGroups":
            suggest = "include_consumer_groups"
        elif key == "includeTopics":
            suggest = "include_topics"
        elif key == "kafkaCustomMetrics":
            suggest = "kafka_custom_metrics"
        elif key == "maxJmxMetrics":
            suggest = "max_jmx_metrics"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ServiceIntegrationDatadogUserConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ServiceIntegrationDatadogUserConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ServiceIntegrationDatadogUserConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 datadog_tags: Optional[Sequence['outputs.ServiceIntegrationDatadogUserConfigDatadogTag']] = None,
                 exclude_consumer_groups: Optional[Sequence[str]] = None,
                 exclude_topics: Optional[Sequence[str]] = None,
                 include_consumer_groups: Optional[Sequence[str]] = None,
                 include_topics: Optional[Sequence[str]] = None,
                 kafka_custom_metrics: Optional[Sequence[str]] = None,
                 max_jmx_metrics: Optional[str] = None):
        if datadog_tags is not None:
            pulumi.set(__self__, "datadog_tags", datadog_tags)
        if exclude_consumer_groups is not None:
            pulumi.set(__self__, "exclude_consumer_groups", exclude_consumer_groups)
        if exclude_topics is not None:
            pulumi.set(__self__, "exclude_topics", exclude_topics)
        if include_consumer_groups is not None:
            pulumi.set(__self__, "include_consumer_groups", include_consumer_groups)
        if include_topics is not None:
            pulumi.set(__self__, "include_topics", include_topics)
        if kafka_custom_metrics is not None:
            pulumi.set(__self__, "kafka_custom_metrics", kafka_custom_metrics)
        if max_jmx_metrics is not None:
            pulumi.set(__self__, "max_jmx_metrics", max_jmx_metrics)

    @property
    @pulumi.getter(name="datadogTags")
    def datadog_tags(self) -> Optional[Sequence['outputs.ServiceIntegrationDatadogUserConfigDatadogTag']]:
        return pulumi.get(self, "datadog_tags")

    @property
    @pulumi.getter(name="excludeConsumerGroups")
    def exclude_consumer_groups(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "exclude_consumer_groups")

    @property
    @pulumi.getter(name="excludeTopics")
    def exclude_topics(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "exclude_topics")

    @property
    @pulumi.getter(name="includeConsumerGroups")
    def include_consumer_groups(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "include_consumer_groups")

    @property
    @pulumi.getter(name="includeTopics")
    def include_topics(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "include_topics")

    @property
    @pulumi.getter(name="kafkaCustomMetrics")
    def kafka_custom_metrics(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "kafka_custom_metrics")

    @property
    @pulumi.getter(name="maxJmxMetrics")
    def max_jmx_metrics(self) -> Optional[str]:
        return pulumi.get(self, "max_jmx_metrics")


@pulumi.output_type
class ServiceIntegrationDatadogUserConfigDatadogTag(dict):
    def __init__(__self__, *,
                 comment: Optional[str] = None,
                 tag: Optional[str] = None):
        if comment is not None:
            pulumi.set(__self__, "comment", comment)
        if tag is not None:
            pulumi.set(__self__, "tag", tag)

    @property
    @pulumi.getter
    def comment(self) -> Optional[str]:
        return pulumi.get(self, "comment")

    @property
    @pulumi.getter
    def tag(self) -> Optional[str]:
        return pulumi.get(self, "tag")


@pulumi.output_type
class ServiceIntegrationEndpointDatadogUserConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "datadogApiKey":
            suggest = "datadog_api_key"
        elif key == "datadogTags":
            suggest = "datadog_tags"
        elif key == "disableConsumerStats":
            suggest = "disable_consumer_stats"
        elif key == "maxPartitionContexts":
            suggest = "max_partition_contexts"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ServiceIntegrationEndpointDatadogUserConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ServiceIntegrationEndpointDatadogUserConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ServiceIntegrationEndpointDatadogUserConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 datadog_api_key: Optional[str] = None,
                 datadog_tags: Optional[Sequence['outputs.ServiceIntegrationEndpointDatadogUserConfigDatadogTag']] = None,
                 disable_consumer_stats: Optional[str] = None,
                 max_partition_contexts: Optional[str] = None,
                 site: Optional[str] = None):
        if datadog_api_key is not None:
            pulumi.set(__self__, "datadog_api_key", datadog_api_key)
        if datadog_tags is not None:
            pulumi.set(__self__, "datadog_tags", datadog_tags)
        if disable_consumer_stats is not None:
            pulumi.set(__self__, "disable_consumer_stats", disable_consumer_stats)
        if max_partition_contexts is not None:
            pulumi.set(__self__, "max_partition_contexts", max_partition_contexts)
        if site is not None:
            pulumi.set(__self__, "site", site)

    @property
    @pulumi.getter(name="datadogApiKey")
    def datadog_api_key(self) -> Optional[str]:
        return pulumi.get(self, "datadog_api_key")

    @property
    @pulumi.getter(name="datadogTags")
    def datadog_tags(self) -> Optional[Sequence['outputs.ServiceIntegrationEndpointDatadogUserConfigDatadogTag']]:
        return pulumi.get(self, "datadog_tags")

    @property
    @pulumi.getter(name="disableConsumerStats")
    def disable_consumer_stats(self) -> Optional[str]:
        return pulumi.get(self, "disable_consumer_stats")

    @property
    @pulumi.getter(name="maxPartitionContexts")
    def max_partition_contexts(self) -> Optional[str]:
        return pulumi.get(self, "max_partition_contexts")

    @property
    @pulumi.getter
    def site(self) -> Optional[str]:
        return pulumi.get(self, "site")


@pulumi.output_type
class ServiceIntegrationEndpointDatadogUserConfigDatadogTag(dict):
    def __init__(__self__, *,
                 comment: Optional[str] = None,
                 tag: Optional[str] = None):
        if comment is not None:
            pulumi.set(__self__, "comment", comment)
        if tag is not None:
            pulumi.set(__self__, "tag", tag)

    @property
    @pulumi.getter
    def comment(self) -> Optional[str]:
        return pulumi.get(self, "comment")

    @property
    @pulumi.getter
    def tag(self) -> Optional[str]:
        return pulumi.get(self, "tag")


@pulumi.output_type
class ServiceIntegrationEndpointExternalAwsCloudwatchLogsUserConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "accessKey":
            suggest = "access_key"
        elif key == "logGroupName":
            suggest = "log_group_name"
        elif key == "secretKey":
            suggest = "secret_key"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ServiceIntegrationEndpointExternalAwsCloudwatchLogsUserConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ServiceIntegrationEndpointExternalAwsCloudwatchLogsUserConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ServiceIntegrationEndpointExternalAwsCloudwatchLogsUserConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 access_key: Optional[str] = None,
                 log_group_name: Optional[str] = None,
                 region: Optional[str] = None,
                 secret_key: Optional[str] = None):
        if access_key is not None:
            pulumi.set(__self__, "access_key", access_key)
        if log_group_name is not None:
            pulumi.set(__self__, "log_group_name", log_group_name)
        if region is not None:
            pulumi.set(__self__, "region", region)
        if secret_key is not None:
            pulumi.set(__self__, "secret_key", secret_key)

    @property
    @pulumi.getter(name="accessKey")
    def access_key(self) -> Optional[str]:
        return pulumi.get(self, "access_key")

    @property
    @pulumi.getter(name="logGroupName")
    def log_group_name(self) -> Optional[str]:
        return pulumi.get(self, "log_group_name")

    @property
    @pulumi.getter
    def region(self) -> Optional[str]:
        return pulumi.get(self, "region")

    @property
    @pulumi.getter(name="secretKey")
    def secret_key(self) -> Optional[str]:
        return pulumi.get(self, "secret_key")


@pulumi.output_type
class ServiceIntegrationEndpointExternalAwsCloudwatchMetricsUserConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "accessKey":
            suggest = "access_key"
        elif key == "secretKey":
            suggest = "secret_key"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ServiceIntegrationEndpointExternalAwsCloudwatchMetricsUserConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ServiceIntegrationEndpointExternalAwsCloudwatchMetricsUserConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ServiceIntegrationEndpointExternalAwsCloudwatchMetricsUserConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 access_key: Optional[str] = None,
                 namespace: Optional[str] = None,
                 region: Optional[str] = None,
                 secret_key: Optional[str] = None):
        if access_key is not None:
            pulumi.set(__self__, "access_key", access_key)
        if namespace is not None:
            pulumi.set(__self__, "namespace", namespace)
        if region is not None:
            pulumi.set(__self__, "region", region)
        if secret_key is not None:
            pulumi.set(__self__, "secret_key", secret_key)

    @property
    @pulumi.getter(name="accessKey")
    def access_key(self) -> Optional[str]:
        return pulumi.get(self, "access_key")

    @property
    @pulumi.getter
    def namespace(self) -> Optional[str]:
        return pulumi.get(self, "namespace")

    @property
    @pulumi.getter
    def region(self) -> Optional[str]:
        return pulumi.get(self, "region")

    @property
    @pulumi.getter(name="secretKey")
    def secret_key(self) -> Optional[str]:
        return pulumi.get(self, "secret_key")


@pulumi.output_type
class ServiceIntegrationEndpointExternalElasticsearchLogsUserConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "indexDaysMax":
            suggest = "index_days_max"
        elif key == "indexPrefix":
            suggest = "index_prefix"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ServiceIntegrationEndpointExternalElasticsearchLogsUserConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ServiceIntegrationEndpointExternalElasticsearchLogsUserConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ServiceIntegrationEndpointExternalElasticsearchLogsUserConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 ca: Optional[str] = None,
                 index_days_max: Optional[str] = None,
                 index_prefix: Optional[str] = None,
                 timeout: Optional[str] = None,
                 url: Optional[str] = None):
        if ca is not None:
            pulumi.set(__self__, "ca", ca)
        if index_days_max is not None:
            pulumi.set(__self__, "index_days_max", index_days_max)
        if index_prefix is not None:
            pulumi.set(__self__, "index_prefix", index_prefix)
        if timeout is not None:
            pulumi.set(__self__, "timeout", timeout)
        if url is not None:
            pulumi.set(__self__, "url", url)

    @property
    @pulumi.getter
    def ca(self) -> Optional[str]:
        return pulumi.get(self, "ca")

    @property
    @pulumi.getter(name="indexDaysMax")
    def index_days_max(self) -> Optional[str]:
        return pulumi.get(self, "index_days_max")

    @property
    @pulumi.getter(name="indexPrefix")
    def index_prefix(self) -> Optional[str]:
        return pulumi.get(self, "index_prefix")

    @property
    @pulumi.getter
    def timeout(self) -> Optional[str]:
        return pulumi.get(self, "timeout")

    @property
    @pulumi.getter
    def url(self) -> Optional[str]:
        return pulumi.get(self, "url")


@pulumi.output_type
class ServiceIntegrationEndpointExternalGoogleCloudLoggingUserConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "logId":
            suggest = "log_id"
        elif key == "projectId":
            suggest = "project_id"
        elif key == "serviceAccountCredentials":
            suggest = "service_account_credentials"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ServiceIntegrationEndpointExternalGoogleCloudLoggingUserConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ServiceIntegrationEndpointExternalGoogleCloudLoggingUserConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ServiceIntegrationEndpointExternalGoogleCloudLoggingUserConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 log_id: Optional[str] = None,
                 project_id: Optional[str] = None,
                 service_account_credentials: Optional[str] = None):
        if log_id is not None:
            pulumi.set(__self__, "log_id", log_id)
        if project_id is not None:
            pulumi.set(__self__, "project_id", project_id)
        if service_account_credentials is not None:
            pulumi.set(__self__, "service_account_credentials", service_account_credentials)

    @property
    @pulumi.getter(name="logId")
    def log_id(self) -> Optional[str]:
        return pulumi.get(self, "log_id")

    @property
    @pulumi.getter(name="projectId")
    def project_id(self) -> Optional[str]:
        return pulumi.get(self, "project_id")

    @property
    @pulumi.getter(name="serviceAccountCredentials")
    def service_account_credentials(self) -> Optional[str]:
        return pulumi.get(self, "service_account_credentials")


@pulumi.output_type
class ServiceIntegrationEndpointExternalKafkaUserConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "bootstrapServers":
            suggest = "bootstrap_servers"
        elif key == "saslMechanism":
            suggest = "sasl_mechanism"
        elif key == "saslPlainPassword":
            suggest = "sasl_plain_password"
        elif key == "saslPlainUsername":
            suggest = "sasl_plain_username"
        elif key == "securityProtocol":
            suggest = "security_protocol"
        elif key == "sslCaCert":
            suggest = "ssl_ca_cert"
        elif key == "sslClientCert":
            suggest = "ssl_client_cert"
        elif key == "sslClientKey":
            suggest = "ssl_client_key"
        elif key == "sslEndpointIdentificationAlgorithm":
            suggest = "ssl_endpoint_identification_algorithm"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ServiceIntegrationEndpointExternalKafkaUserConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ServiceIntegrationEndpointExternalKafkaUserConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ServiceIntegrationEndpointExternalKafkaUserConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 bootstrap_servers: Optional[str] = None,
                 sasl_mechanism: Optional[str] = None,
                 sasl_plain_password: Optional[str] = None,
                 sasl_plain_username: Optional[str] = None,
                 security_protocol: Optional[str] = None,
                 ssl_ca_cert: Optional[str] = None,
                 ssl_client_cert: Optional[str] = None,
                 ssl_client_key: Optional[str] = None,
                 ssl_endpoint_identification_algorithm: Optional[str] = None):
        if bootstrap_servers is not None:
            pulumi.set(__self__, "bootstrap_servers", bootstrap_servers)
        if sasl_mechanism is not None:
            pulumi.set(__self__, "sasl_mechanism", sasl_mechanism)
        if sasl_plain_password is not None:
            pulumi.set(__self__, "sasl_plain_password", sasl_plain_password)
        if sasl_plain_username is not None:
            pulumi.set(__self__, "sasl_plain_username", sasl_plain_username)
        if security_protocol is not None:
            pulumi.set(__self__, "security_protocol", security_protocol)
        if ssl_ca_cert is not None:
            pulumi.set(__self__, "ssl_ca_cert", ssl_ca_cert)
        if ssl_client_cert is not None:
            pulumi.set(__self__, "ssl_client_cert", ssl_client_cert)
        if ssl_client_key is not None:
            pulumi.set(__self__, "ssl_client_key", ssl_client_key)
        if ssl_endpoint_identification_algorithm is not None:
            pulumi.set(__self__, "ssl_endpoint_identification_algorithm", ssl_endpoint_identification_algorithm)

    @property
    @pulumi.getter(name="bootstrapServers")
    def bootstrap_servers(self) -> Optional[str]:
        return pulumi.get(self, "bootstrap_servers")

    @property
    @pulumi.getter(name="saslMechanism")
    def sasl_mechanism(self) -> Optional[str]:
        return pulumi.get(self, "sasl_mechanism")

    @property
    @pulumi.getter(name="saslPlainPassword")
    def sasl_plain_password(self) -> Optional[str]:
        return pulumi.get(self, "sasl_plain_password")

    @property
    @pulumi.getter(name="saslPlainUsername")
    def sasl_plain_username(self) -> Optional[str]:
        return pulumi.get(self, "sasl_plain_username")

    @property
    @pulumi.getter(name="securityProtocol")
    def security_protocol(self) -> Optional[str]:
        return pulumi.get(self, "security_protocol")

    @property
    @pulumi.getter(name="sslCaCert")
    def ssl_ca_cert(self) -> Optional[str]:
        return pulumi.get(self, "ssl_ca_cert")

    @property
    @pulumi.getter(name="sslClientCert")
    def ssl_client_cert(self) -> Optional[str]:
        return pulumi.get(self, "ssl_client_cert")

    @property
    @pulumi.getter(name="sslClientKey")
    def ssl_client_key(self) -> Optional[str]:
        return pulumi.get(self, "ssl_client_key")

    @property
    @pulumi.getter(name="sslEndpointIdentificationAlgorithm")
    def ssl_endpoint_identification_algorithm(self) -> Optional[str]:
        return pulumi.get(self, "ssl_endpoint_identification_algorithm")


@pulumi.output_type
class ServiceIntegrationEndpointExternalSchemaRegistryUserConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "basicAuthPassword":
            suggest = "basic_auth_password"
        elif key == "basicAuthUsername":
            suggest = "basic_auth_username"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ServiceIntegrationEndpointExternalSchemaRegistryUserConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ServiceIntegrationEndpointExternalSchemaRegistryUserConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ServiceIntegrationEndpointExternalSchemaRegistryUserConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 authentication: Optional[str] = None,
                 basic_auth_password: Optional[str] = None,
                 basic_auth_username: Optional[str] = None,
                 url: Optional[str] = None):
        if authentication is not None:
            pulumi.set(__self__, "authentication", authentication)
        if basic_auth_password is not None:
            pulumi.set(__self__, "basic_auth_password", basic_auth_password)
        if basic_auth_username is not None:
            pulumi.set(__self__, "basic_auth_username", basic_auth_username)
        if url is not None:
            pulumi.set(__self__, "url", url)

    @property
    @pulumi.getter
    def authentication(self) -> Optional[str]:
        return pulumi.get(self, "authentication")

    @property
    @pulumi.getter(name="basicAuthPassword")
    def basic_auth_password(self) -> Optional[str]:
        return pulumi.get(self, "basic_auth_password")

    @property
    @pulumi.getter(name="basicAuthUsername")
    def basic_auth_username(self) -> Optional[str]:
        return pulumi.get(self, "basic_auth_username")

    @property
    @pulumi.getter
    def url(self) -> Optional[str]:
        return pulumi.get(self, "url")


@pulumi.output_type
class ServiceIntegrationEndpointJolokiaUserConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "basicAuthPassword":
            suggest = "basic_auth_password"
        elif key == "basicAuthUsername":
            suggest = "basic_auth_username"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ServiceIntegrationEndpointJolokiaUserConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ServiceIntegrationEndpointJolokiaUserConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ServiceIntegrationEndpointJolokiaUserConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 basic_auth_password: Optional[str] = None,
                 basic_auth_username: Optional[str] = None):
        if basic_auth_password is not None:
            pulumi.set(__self__, "basic_auth_password", basic_auth_password)
        if basic_auth_username is not None:
            pulumi.set(__self__, "basic_auth_username", basic_auth_username)

    @property
    @pulumi.getter(name="basicAuthPassword")
    def basic_auth_password(self) -> Optional[str]:
        return pulumi.get(self, "basic_auth_password")

    @property
    @pulumi.getter(name="basicAuthUsername")
    def basic_auth_username(self) -> Optional[str]:
        return pulumi.get(self, "basic_auth_username")


@pulumi.output_type
class ServiceIntegrationEndpointPrometheusUserConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "basicAuthPassword":
            suggest = "basic_auth_password"
        elif key == "basicAuthUsername":
            suggest = "basic_auth_username"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ServiceIntegrationEndpointPrometheusUserConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ServiceIntegrationEndpointPrometheusUserConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ServiceIntegrationEndpointPrometheusUserConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 basic_auth_password: Optional[str] = None,
                 basic_auth_username: Optional[str] = None):
        if basic_auth_password is not None:
            pulumi.set(__self__, "basic_auth_password", basic_auth_password)
        if basic_auth_username is not None:
            pulumi.set(__self__, "basic_auth_username", basic_auth_username)

    @property
    @pulumi.getter(name="basicAuthPassword")
    def basic_auth_password(self) -> Optional[str]:
        return pulumi.get(self, "basic_auth_password")

    @property
    @pulumi.getter(name="basicAuthUsername")
    def basic_auth_username(self) -> Optional[str]:
        return pulumi.get(self, "basic_auth_username")


@pulumi.output_type
class ServiceIntegrationEndpointRsyslogUserConfig(dict):
    def __init__(__self__, *,
                 ca: Optional[str] = None,
                 cert: Optional[str] = None,
                 format: Optional[str] = None,
                 key: Optional[str] = None,
                 logline: Optional[str] = None,
                 port: Optional[str] = None,
                 sd: Optional[str] = None,
                 server: Optional[str] = None,
                 tls: Optional[str] = None):
        if ca is not None:
            pulumi.set(__self__, "ca", ca)
        if cert is not None:
            pulumi.set(__self__, "cert", cert)
        if format is not None:
            pulumi.set(__self__, "format", format)
        if key is not None:
            pulumi.set(__self__, "key", key)
        if logline is not None:
            pulumi.set(__self__, "logline", logline)
        if port is not None:
            pulumi.set(__self__, "port", port)
        if sd is not None:
            pulumi.set(__self__, "sd", sd)
        if server is not None:
            pulumi.set(__self__, "server", server)
        if tls is not None:
            pulumi.set(__self__, "tls", tls)

    @property
    @pulumi.getter
    def ca(self) -> Optional[str]:
        return pulumi.get(self, "ca")

    @property
    @pulumi.getter
    def cert(self) -> Optional[str]:
        return pulumi.get(self, "cert")

    @property
    @pulumi.getter
    def format(self) -> Optional[str]:
        return pulumi.get(self, "format")

    @property
    @pulumi.getter
    def key(self) -> Optional[str]:
        return pulumi.get(self, "key")

    @property
    @pulumi.getter
    def logline(self) -> Optional[str]:
        return pulumi.get(self, "logline")

    @property
    @pulumi.getter
    def port(self) -> Optional[str]:
        return pulumi.get(self, "port")

    @property
    @pulumi.getter
    def sd(self) -> Optional[str]:
        return pulumi.get(self, "sd")

    @property
    @pulumi.getter
    def server(self) -> Optional[str]:
        return pulumi.get(self, "server")

    @property
    @pulumi.getter
    def tls(self) -> Optional[str]:
        return pulumi.get(self, "tls")


@pulumi.output_type
class ServiceIntegrationEndpointSignalfxUserConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "enabledMetrics":
            suggest = "enabled_metrics"
        elif key == "signalfxApiKey":
            suggest = "signalfx_api_key"
        elif key == "signalfxRealm":
            suggest = "signalfx_realm"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ServiceIntegrationEndpointSignalfxUserConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ServiceIntegrationEndpointSignalfxUserConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ServiceIntegrationEndpointSignalfxUserConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 enabled_metrics: Optional[Sequence[str]] = None,
                 signalfx_api_key: Optional[str] = None,
                 signalfx_realm: Optional[str] = None):
        if enabled_metrics is not None:
            pulumi.set(__self__, "enabled_metrics", enabled_metrics)
        if signalfx_api_key is not None:
            pulumi.set(__self__, "signalfx_api_key", signalfx_api_key)
        if signalfx_realm is not None:
            pulumi.set(__self__, "signalfx_realm", signalfx_realm)

    @property
    @pulumi.getter(name="enabledMetrics")
    def enabled_metrics(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "enabled_metrics")

    @property
    @pulumi.getter(name="signalfxApiKey")
    def signalfx_api_key(self) -> Optional[str]:
        return pulumi.get(self, "signalfx_api_key")

    @property
    @pulumi.getter(name="signalfxRealm")
    def signalfx_realm(self) -> Optional[str]:
        return pulumi.get(self, "signalfx_realm")


@pulumi.output_type
class ServiceIntegrationExternalAwsCloudwatchLogsUserConfig(dict):
    def __init__(__self__):
        pass


@pulumi.output_type
class ServiceIntegrationExternalAwsCloudwatchMetricsUserConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "droppedMetrics":
            suggest = "dropped_metrics"
        elif key == "extraMetrics":
            suggest = "extra_metrics"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ServiceIntegrationExternalAwsCloudwatchMetricsUserConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ServiceIntegrationExternalAwsCloudwatchMetricsUserConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ServiceIntegrationExternalAwsCloudwatchMetricsUserConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 dropped_metrics: Optional[Sequence['outputs.ServiceIntegrationExternalAwsCloudwatchMetricsUserConfigDroppedMetric']] = None,
                 extra_metrics: Optional[Sequence['outputs.ServiceIntegrationExternalAwsCloudwatchMetricsUserConfigExtraMetric']] = None):
        if dropped_metrics is not None:
            pulumi.set(__self__, "dropped_metrics", dropped_metrics)
        if extra_metrics is not None:
            pulumi.set(__self__, "extra_metrics", extra_metrics)

    @property
    @pulumi.getter(name="droppedMetrics")
    def dropped_metrics(self) -> Optional[Sequence['outputs.ServiceIntegrationExternalAwsCloudwatchMetricsUserConfigDroppedMetric']]:
        return pulumi.get(self, "dropped_metrics")

    @property
    @pulumi.getter(name="extraMetrics")
    def extra_metrics(self) -> Optional[Sequence['outputs.ServiceIntegrationExternalAwsCloudwatchMetricsUserConfigExtraMetric']]:
        return pulumi.get(self, "extra_metrics")


@pulumi.output_type
class ServiceIntegrationExternalAwsCloudwatchMetricsUserConfigDroppedMetric(dict):
    def __init__(__self__, *,
                 field: Optional[str] = None,
                 metric: Optional[str] = None):
        if field is not None:
            pulumi.set(__self__, "field", field)
        if metric is not None:
            pulumi.set(__self__, "metric", metric)

    @property
    @pulumi.getter
    def field(self) -> Optional[str]:
        return pulumi.get(self, "field")

    @property
    @pulumi.getter
    def metric(self) -> Optional[str]:
        return pulumi.get(self, "metric")


@pulumi.output_type
class ServiceIntegrationExternalAwsCloudwatchMetricsUserConfigExtraMetric(dict):
    def __init__(__self__, *,
                 field: Optional[str] = None,
                 metric: Optional[str] = None):
        if field is not None:
            pulumi.set(__self__, "field", field)
        if metric is not None:
            pulumi.set(__self__, "metric", metric)

    @property
    @pulumi.getter
    def field(self) -> Optional[str]:
        return pulumi.get(self, "field")

    @property
    @pulumi.getter
    def metric(self) -> Optional[str]:
        return pulumi.get(self, "metric")


@pulumi.output_type
class ServiceIntegrationExternalElasticsearchLogsUserConfig(dict):
    def __init__(__self__):
        pass


@pulumi.output_type
class ServiceIntegrationExternalGoogleCloudLoggingUserConfig(dict):
    def __init__(__self__):
        pass


@pulumi.output_type
class ServiceIntegrationKafkaConnectUserConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "kafkaConnect":
            suggest = "kafka_connect"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ServiceIntegrationKafkaConnectUserConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ServiceIntegrationKafkaConnectUserConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ServiceIntegrationKafkaConnectUserConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 kafka_connect: Optional['outputs.ServiceIntegrationKafkaConnectUserConfigKafkaConnect'] = None):
        if kafka_connect is not None:
            pulumi.set(__self__, "kafka_connect", kafka_connect)

    @property
    @pulumi.getter(name="kafkaConnect")
    def kafka_connect(self) -> Optional['outputs.ServiceIntegrationKafkaConnectUserConfigKafkaConnect']:
        return pulumi.get(self, "kafka_connect")


@pulumi.output_type
class ServiceIntegrationKafkaConnectUserConfigKafkaConnect(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "configStorageTopic":
            suggest = "config_storage_topic"
        elif key == "groupId":
            suggest = "group_id"
        elif key == "offsetStorageTopic":
            suggest = "offset_storage_topic"
        elif key == "statusStorageTopic":
            suggest = "status_storage_topic"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ServiceIntegrationKafkaConnectUserConfigKafkaConnect. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ServiceIntegrationKafkaConnectUserConfigKafkaConnect.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ServiceIntegrationKafkaConnectUserConfigKafkaConnect.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 config_storage_topic: Optional[str] = None,
                 group_id: Optional[str] = None,
                 offset_storage_topic: Optional[str] = None,
                 status_storage_topic: Optional[str] = None):
        if config_storage_topic is not None:
            pulumi.set(__self__, "config_storage_topic", config_storage_topic)
        if group_id is not None:
            pulumi.set(__self__, "group_id", group_id)
        if offset_storage_topic is not None:
            pulumi.set(__self__, "offset_storage_topic", offset_storage_topic)
        if status_storage_topic is not None:
            pulumi.set(__self__, "status_storage_topic", status_storage_topic)

    @property
    @pulumi.getter(name="configStorageTopic")
    def config_storage_topic(self) -> Optional[str]:
        return pulumi.get(self, "config_storage_topic")

    @property
    @pulumi.getter(name="groupId")
    def group_id(self) -> Optional[str]:
        return pulumi.get(self, "group_id")

    @property
    @pulumi.getter(name="offsetStorageTopic")
    def offset_storage_topic(self) -> Optional[str]:
        return pulumi.get(self, "offset_storage_topic")

    @property
    @pulumi.getter(name="statusStorageTopic")
    def status_storage_topic(self) -> Optional[str]:
        return pulumi.get(self, "status_storage_topic")


@pulumi.output_type
class ServiceIntegrationKafkaLogsUserConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "kafkaTopic":
            suggest = "kafka_topic"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ServiceIntegrationKafkaLogsUserConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ServiceIntegrationKafkaLogsUserConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ServiceIntegrationKafkaLogsUserConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 kafka_topic: Optional[str] = None):
        if kafka_topic is not None:
            pulumi.set(__self__, "kafka_topic", kafka_topic)

    @property
    @pulumi.getter(name="kafkaTopic")
    def kafka_topic(self) -> Optional[str]:
        return pulumi.get(self, "kafka_topic")


@pulumi.output_type
class ServiceIntegrationKafkaMirrormakerUserConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "clusterAlias":
            suggest = "cluster_alias"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ServiceIntegrationKafkaMirrormakerUserConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ServiceIntegrationKafkaMirrormakerUserConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ServiceIntegrationKafkaMirrormakerUserConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 cluster_alias: Optional[str] = None):
        if cluster_alias is not None:
            pulumi.set(__self__, "cluster_alias", cluster_alias)

    @property
    @pulumi.getter(name="clusterAlias")
    def cluster_alias(self) -> Optional[str]:
        return pulumi.get(self, "cluster_alias")


@pulumi.output_type
class ServiceIntegrationLogsUserConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "elasticsearchIndexDaysMax":
            suggest = "elasticsearch_index_days_max"
        elif key == "elasticsearchIndexPrefix":
            suggest = "elasticsearch_index_prefix"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ServiceIntegrationLogsUserConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ServiceIntegrationLogsUserConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ServiceIntegrationLogsUserConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 elasticsearch_index_days_max: Optional[str] = None,
                 elasticsearch_index_prefix: Optional[str] = None):
        if elasticsearch_index_days_max is not None:
            pulumi.set(__self__, "elasticsearch_index_days_max", elasticsearch_index_days_max)
        if elasticsearch_index_prefix is not None:
            pulumi.set(__self__, "elasticsearch_index_prefix", elasticsearch_index_prefix)

    @property
    @pulumi.getter(name="elasticsearchIndexDaysMax")
    def elasticsearch_index_days_max(self) -> Optional[str]:
        return pulumi.get(self, "elasticsearch_index_days_max")

    @property
    @pulumi.getter(name="elasticsearchIndexPrefix")
    def elasticsearch_index_prefix(self) -> Optional[str]:
        return pulumi.get(self, "elasticsearch_index_prefix")


@pulumi.output_type
class ServiceIntegrationM3aggregatorUserConfig(dict):
    def __init__(__self__):
        pass


@pulumi.output_type
class ServiceIntegrationM3coordinatorUserConfig(dict):
    def __init__(__self__):
        pass


@pulumi.output_type
class ServiceIntegrationMetricsUserConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "retentionDays":
            suggest = "retention_days"
        elif key == "roUsername":
            suggest = "ro_username"
        elif key == "sourceMysql":
            suggest = "source_mysql"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ServiceIntegrationMetricsUserConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ServiceIntegrationMetricsUserConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ServiceIntegrationMetricsUserConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 database: Optional[str] = None,
                 retention_days: Optional[str] = None,
                 ro_username: Optional[str] = None,
                 source_mysql: Optional['outputs.ServiceIntegrationMetricsUserConfigSourceMysql'] = None,
                 username: Optional[str] = None):
        if database is not None:
            pulumi.set(__self__, "database", database)
        if retention_days is not None:
            pulumi.set(__self__, "retention_days", retention_days)
        if ro_username is not None:
            pulumi.set(__self__, "ro_username", ro_username)
        if source_mysql is not None:
            pulumi.set(__self__, "source_mysql", source_mysql)
        if username is not None:
            pulumi.set(__self__, "username", username)

    @property
    @pulumi.getter
    def database(self) -> Optional[str]:
        return pulumi.get(self, "database")

    @property
    @pulumi.getter(name="retentionDays")
    def retention_days(self) -> Optional[str]:
        return pulumi.get(self, "retention_days")

    @property
    @pulumi.getter(name="roUsername")
    def ro_username(self) -> Optional[str]:
        return pulumi.get(self, "ro_username")

    @property
    @pulumi.getter(name="sourceMysql")
    def source_mysql(self) -> Optional['outputs.ServiceIntegrationMetricsUserConfigSourceMysql']:
        return pulumi.get(self, "source_mysql")

    @property
    @pulumi.getter
    def username(self) -> Optional[str]:
        return pulumi.get(self, "username")


@pulumi.output_type
class ServiceIntegrationMetricsUserConfigSourceMysql(dict):
    def __init__(__self__, *,
                 telegraf: Optional['outputs.ServiceIntegrationMetricsUserConfigSourceMysqlTelegraf'] = None):
        if telegraf is not None:
            pulumi.set(__self__, "telegraf", telegraf)

    @property
    @pulumi.getter
    def telegraf(self) -> Optional['outputs.ServiceIntegrationMetricsUserConfigSourceMysqlTelegraf']:
        return pulumi.get(self, "telegraf")


@pulumi.output_type
class ServiceIntegrationMetricsUserConfigSourceMysqlTelegraf(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "gatherEventWaits":
            suggest = "gather_event_waits"
        elif key == "gatherFileEventsStats":
            suggest = "gather_file_events_stats"
        elif key == "gatherIndexIoWaits":
            suggest = "gather_index_io_waits"
        elif key == "gatherInfoSchemaAutoInc":
            suggest = "gather_info_schema_auto_inc"
        elif key == "gatherInnodbMetrics":
            suggest = "gather_innodb_metrics"
        elif key == "gatherPerfEventsStatements":
            suggest = "gather_perf_events_statements"
        elif key == "gatherProcessList":
            suggest = "gather_process_list"
        elif key == "gatherSlaveStatus":
            suggest = "gather_slave_status"
        elif key == "gatherTableIoWaits":
            suggest = "gather_table_io_waits"
        elif key == "gatherTableLockWaits":
            suggest = "gather_table_lock_waits"
        elif key == "gatherTableSchema":
            suggest = "gather_table_schema"
        elif key == "perfEventsStatementsDigestTextLimit":
            suggest = "perf_events_statements_digest_text_limit"
        elif key == "perfEventsStatementsLimit":
            suggest = "perf_events_statements_limit"
        elif key == "perfEventsStatementsTimeLimit":
            suggest = "perf_events_statements_time_limit"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ServiceIntegrationMetricsUserConfigSourceMysqlTelegraf. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ServiceIntegrationMetricsUserConfigSourceMysqlTelegraf.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ServiceIntegrationMetricsUserConfigSourceMysqlTelegraf.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 gather_event_waits: Optional[str] = None,
                 gather_file_events_stats: Optional[str] = None,
                 gather_index_io_waits: Optional[str] = None,
                 gather_info_schema_auto_inc: Optional[str] = None,
                 gather_innodb_metrics: Optional[str] = None,
                 gather_perf_events_statements: Optional[str] = None,
                 gather_process_list: Optional[str] = None,
                 gather_slave_status: Optional[str] = None,
                 gather_table_io_waits: Optional[str] = None,
                 gather_table_lock_waits: Optional[str] = None,
                 gather_table_schema: Optional[str] = None,
                 perf_events_statements_digest_text_limit: Optional[str] = None,
                 perf_events_statements_limit: Optional[str] = None,
                 perf_events_statements_time_limit: Optional[str] = None):
        if gather_event_waits is not None:
            pulumi.set(__self__, "gather_event_waits", gather_event_waits)
        if gather_file_events_stats is not None:
            pulumi.set(__self__, "gather_file_events_stats", gather_file_events_stats)
        if gather_index_io_waits is not None:
            pulumi.set(__self__, "gather_index_io_waits", gather_index_io_waits)
        if gather_info_schema_auto_inc is not None:
            pulumi.set(__self__, "gather_info_schema_auto_inc", gather_info_schema_auto_inc)
        if gather_innodb_metrics is not None:
            pulumi.set(__self__, "gather_innodb_metrics", gather_innodb_metrics)
        if gather_perf_events_statements is not None:
            pulumi.set(__self__, "gather_perf_events_statements", gather_perf_events_statements)
        if gather_process_list is not None:
            pulumi.set(__self__, "gather_process_list", gather_process_list)
        if gather_slave_status is not None:
            pulumi.set(__self__, "gather_slave_status", gather_slave_status)
        if gather_table_io_waits is not None:
            pulumi.set(__self__, "gather_table_io_waits", gather_table_io_waits)
        if gather_table_lock_waits is not None:
            pulumi.set(__self__, "gather_table_lock_waits", gather_table_lock_waits)
        if gather_table_schema is not None:
            pulumi.set(__self__, "gather_table_schema", gather_table_schema)
        if perf_events_statements_digest_text_limit is not None:
            pulumi.set(__self__, "perf_events_statements_digest_text_limit", perf_events_statements_digest_text_limit)
        if perf_events_statements_limit is not None:
            pulumi.set(__self__, "perf_events_statements_limit", perf_events_statements_limit)
        if perf_events_statements_time_limit is not None:
            pulumi.set(__self__, "perf_events_statements_time_limit", perf_events_statements_time_limit)

    @property
    @pulumi.getter(name="gatherEventWaits")
    def gather_event_waits(self) -> Optional[str]:
        return pulumi.get(self, "gather_event_waits")

    @property
    @pulumi.getter(name="gatherFileEventsStats")
    def gather_file_events_stats(self) -> Optional[str]:
        return pulumi.get(self, "gather_file_events_stats")

    @property
    @pulumi.getter(name="gatherIndexIoWaits")
    def gather_index_io_waits(self) -> Optional[str]:
        return pulumi.get(self, "gather_index_io_waits")

    @property
    @pulumi.getter(name="gatherInfoSchemaAutoInc")
    def gather_info_schema_auto_inc(self) -> Optional[str]:
        return pulumi.get(self, "gather_info_schema_auto_inc")

    @property
    @pulumi.getter(name="gatherInnodbMetrics")
    def gather_innodb_metrics(self) -> Optional[str]:
        return pulumi.get(self, "gather_innodb_metrics")

    @property
    @pulumi.getter(name="gatherPerfEventsStatements")
    def gather_perf_events_statements(self) -> Optional[str]:
        return pulumi.get(self, "gather_perf_events_statements")

    @property
    @pulumi.getter(name="gatherProcessList")
    def gather_process_list(self) -> Optional[str]:
        return pulumi.get(self, "gather_process_list")

    @property
    @pulumi.getter(name="gatherSlaveStatus")
    def gather_slave_status(self) -> Optional[str]:
        return pulumi.get(self, "gather_slave_status")

    @property
    @pulumi.getter(name="gatherTableIoWaits")
    def gather_table_io_waits(self) -> Optional[str]:
        return pulumi.get(self, "gather_table_io_waits")

    @property
    @pulumi.getter(name="gatherTableLockWaits")
    def gather_table_lock_waits(self) -> Optional[str]:
        return pulumi.get(self, "gather_table_lock_waits")

    @property
    @pulumi.getter(name="gatherTableSchema")
    def gather_table_schema(self) -> Optional[str]:
        return pulumi.get(self, "gather_table_schema")

    @property
    @pulumi.getter(name="perfEventsStatementsDigestTextLimit")
    def perf_events_statements_digest_text_limit(self) -> Optional[str]:
        return pulumi.get(self, "perf_events_statements_digest_text_limit")

    @property
    @pulumi.getter(name="perfEventsStatementsLimit")
    def perf_events_statements_limit(self) -> Optional[str]:
        return pulumi.get(self, "perf_events_statements_limit")

    @property
    @pulumi.getter(name="perfEventsStatementsTimeLimit")
    def perf_events_statements_time_limit(self) -> Optional[str]:
        return pulumi.get(self, "perf_events_statements_time_limit")


@pulumi.output_type
class ServiceIntegrationMirrormakerUserConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "mirrormakerWhitelist":
            suggest = "mirrormaker_whitelist"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ServiceIntegrationMirrormakerUserConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ServiceIntegrationMirrormakerUserConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ServiceIntegrationMirrormakerUserConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 mirrormaker_whitelist: Optional[str] = None):
        if mirrormaker_whitelist is not None:
            pulumi.set(__self__, "mirrormaker_whitelist", mirrormaker_whitelist)

    @property
    @pulumi.getter(name="mirrormakerWhitelist")
    def mirrormaker_whitelist(self) -> Optional[str]:
        return pulumi.get(self, "mirrormaker_whitelist")


@pulumi.output_type
class ServiceIntegrationPrometheusUserConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "sourceMysql":
            suggest = "source_mysql"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ServiceIntegrationPrometheusUserConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ServiceIntegrationPrometheusUserConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ServiceIntegrationPrometheusUserConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 source_mysql: Optional['outputs.ServiceIntegrationPrometheusUserConfigSourceMysql'] = None):
        if source_mysql is not None:
            pulumi.set(__self__, "source_mysql", source_mysql)

    @property
    @pulumi.getter(name="sourceMysql")
    def source_mysql(self) -> Optional['outputs.ServiceIntegrationPrometheusUserConfigSourceMysql']:
        return pulumi.get(self, "source_mysql")


@pulumi.output_type
class ServiceIntegrationPrometheusUserConfigSourceMysql(dict):
    def __init__(__self__, *,
                 telegraf: Optional['outputs.ServiceIntegrationPrometheusUserConfigSourceMysqlTelegraf'] = None):
        if telegraf is not None:
            pulumi.set(__self__, "telegraf", telegraf)

    @property
    @pulumi.getter
    def telegraf(self) -> Optional['outputs.ServiceIntegrationPrometheusUserConfigSourceMysqlTelegraf']:
        return pulumi.get(self, "telegraf")


@pulumi.output_type
class ServiceIntegrationPrometheusUserConfigSourceMysqlTelegraf(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "gatherEventWaits":
            suggest = "gather_event_waits"
        elif key == "gatherFileEventsStats":
            suggest = "gather_file_events_stats"
        elif key == "gatherIndexIoWaits":
            suggest = "gather_index_io_waits"
        elif key == "gatherInfoSchemaAutoInc":
            suggest = "gather_info_schema_auto_inc"
        elif key == "gatherInnodbMetrics":
            suggest = "gather_innodb_metrics"
        elif key == "gatherPerfEventsStatements":
            suggest = "gather_perf_events_statements"
        elif key == "gatherProcessList":
            suggest = "gather_process_list"
        elif key == "gatherSlaveStatus":
            suggest = "gather_slave_status"
        elif key == "gatherTableIoWaits":
            suggest = "gather_table_io_waits"
        elif key == "gatherTableLockWaits":
            suggest = "gather_table_lock_waits"
        elif key == "gatherTableSchema":
            suggest = "gather_table_schema"
        elif key == "perfEventsStatementsDigestTextLimit":
            suggest = "perf_events_statements_digest_text_limit"
        elif key == "perfEventsStatementsLimit":
            suggest = "perf_events_statements_limit"
        elif key == "perfEventsStatementsTimeLimit":
            suggest = "perf_events_statements_time_limit"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ServiceIntegrationPrometheusUserConfigSourceMysqlTelegraf. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ServiceIntegrationPrometheusUserConfigSourceMysqlTelegraf.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ServiceIntegrationPrometheusUserConfigSourceMysqlTelegraf.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 gather_event_waits: Optional[str] = None,
                 gather_file_events_stats: Optional[str] = None,
                 gather_index_io_waits: Optional[str] = None,
                 gather_info_schema_auto_inc: Optional[str] = None,
                 gather_innodb_metrics: Optional[str] = None,
                 gather_perf_events_statements: Optional[str] = None,
                 gather_process_list: Optional[str] = None,
                 gather_slave_status: Optional[str] = None,
                 gather_table_io_waits: Optional[str] = None,
                 gather_table_lock_waits: Optional[str] = None,
                 gather_table_schema: Optional[str] = None,
                 perf_events_statements_digest_text_limit: Optional[str] = None,
                 perf_events_statements_limit: Optional[str] = None,
                 perf_events_statements_time_limit: Optional[str] = None):
        if gather_event_waits is not None:
            pulumi.set(__self__, "gather_event_waits", gather_event_waits)
        if gather_file_events_stats is not None:
            pulumi.set(__self__, "gather_file_events_stats", gather_file_events_stats)
        if gather_index_io_waits is not None:
            pulumi.set(__self__, "gather_index_io_waits", gather_index_io_waits)
        if gather_info_schema_auto_inc is not None:
            pulumi.set(__self__, "gather_info_schema_auto_inc", gather_info_schema_auto_inc)
        if gather_innodb_metrics is not None:
            pulumi.set(__self__, "gather_innodb_metrics", gather_innodb_metrics)
        if gather_perf_events_statements is not None:
            pulumi.set(__self__, "gather_perf_events_statements", gather_perf_events_statements)
        if gather_process_list is not None:
            pulumi.set(__self__, "gather_process_list", gather_process_list)
        if gather_slave_status is not None:
            pulumi.set(__self__, "gather_slave_status", gather_slave_status)
        if gather_table_io_waits is not None:
            pulumi.set(__self__, "gather_table_io_waits", gather_table_io_waits)
        if gather_table_lock_waits is not None:
            pulumi.set(__self__, "gather_table_lock_waits", gather_table_lock_waits)
        if gather_table_schema is not None:
            pulumi.set(__self__, "gather_table_schema", gather_table_schema)
        if perf_events_statements_digest_text_limit is not None:
            pulumi.set(__self__, "perf_events_statements_digest_text_limit", perf_events_statements_digest_text_limit)
        if perf_events_statements_limit is not None:
            pulumi.set(__self__, "perf_events_statements_limit", perf_events_statements_limit)
        if perf_events_statements_time_limit is not None:
            pulumi.set(__self__, "perf_events_statements_time_limit", perf_events_statements_time_limit)

    @property
    @pulumi.getter(name="gatherEventWaits")
    def gather_event_waits(self) -> Optional[str]:
        return pulumi.get(self, "gather_event_waits")

    @property
    @pulumi.getter(name="gatherFileEventsStats")
    def gather_file_events_stats(self) -> Optional[str]:
        return pulumi.get(self, "gather_file_events_stats")

    @property
    @pulumi.getter(name="gatherIndexIoWaits")
    def gather_index_io_waits(self) -> Optional[str]:
        return pulumi.get(self, "gather_index_io_waits")

    @property
    @pulumi.getter(name="gatherInfoSchemaAutoInc")
    def gather_info_schema_auto_inc(self) -> Optional[str]:
        return pulumi.get(self, "gather_info_schema_auto_inc")

    @property
    @pulumi.getter(name="gatherInnodbMetrics")
    def gather_innodb_metrics(self) -> Optional[str]:
        return pulumi.get(self, "gather_innodb_metrics")

    @property
    @pulumi.getter(name="gatherPerfEventsStatements")
    def gather_perf_events_statements(self) -> Optional[str]:
        return pulumi.get(self, "gather_perf_events_statements")

    @property
    @pulumi.getter(name="gatherProcessList")
    def gather_process_list(self) -> Optional[str]:
        return pulumi.get(self, "gather_process_list")

    @property
    @pulumi.getter(name="gatherSlaveStatus")
    def gather_slave_status(self) -> Optional[str]:
        return pulumi.get(self, "gather_slave_status")

    @property
    @pulumi.getter(name="gatherTableIoWaits")
    def gather_table_io_waits(self) -> Optional[str]:
        return pulumi.get(self, "gather_table_io_waits")

    @property
    @pulumi.getter(name="gatherTableLockWaits")
    def gather_table_lock_waits(self) -> Optional[str]:
        return pulumi.get(self, "gather_table_lock_waits")

    @property
    @pulumi.getter(name="gatherTableSchema")
    def gather_table_schema(self) -> Optional[str]:
        return pulumi.get(self, "gather_table_schema")

    @property
    @pulumi.getter(name="perfEventsStatementsDigestTextLimit")
    def perf_events_statements_digest_text_limit(self) -> Optional[str]:
        return pulumi.get(self, "perf_events_statements_digest_text_limit")

    @property
    @pulumi.getter(name="perfEventsStatementsLimit")
    def perf_events_statements_limit(self) -> Optional[str]:
        return pulumi.get(self, "perf_events_statements_limit")

    @property
    @pulumi.getter(name="perfEventsStatementsTimeLimit")
    def perf_events_statements_time_limit(self) -> Optional[str]:
        return pulumi.get(self, "perf_events_statements_time_limit")


@pulumi.output_type
class ServiceIntegrationReadReplicaUserConfig(dict):
    def __init__(__self__):
        pass


@pulumi.output_type
class ServiceIntegrationRsyslogUserConfig(dict):
    def __init__(__self__):
        pass


@pulumi.output_type
class ServiceIntegrationSchemaRegistryProxyUserConfig(dict):
    def __init__(__self__):
        pass


@pulumi.output_type
class ServiceIntegrationSignalfxUserConfig(dict):
    def __init__(__self__):
        pass


@pulumi.output_type
class ServiceKafka(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "accessCert":
            suggest = "access_cert"
        elif key == "accessKey":
            suggest = "access_key"
        elif key == "connectUri":
            suggest = "connect_uri"
        elif key == "restUri":
            suggest = "rest_uri"
        elif key == "schemaRegistryUri":
            suggest = "schema_registry_uri"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ServiceKafka. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ServiceKafka.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ServiceKafka.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 access_cert: Optional[str] = None,
                 access_key: Optional[str] = None,
                 connect_uri: Optional[str] = None,
                 rest_uri: Optional[str] = None,
                 schema_registry_uri: Optional[str] = None):
        if access_cert is not None:
            pulumi.set(__self__, "access_cert", access_cert)
        if access_key is not None:
            pulumi.set(__self__, "access_key", access_key)
        if connect_uri is not None:
            pulumi.set(__self__, "connect_uri", connect_uri)
        if rest_uri is not None:
            pulumi.set(__self__, "rest_uri", rest_uri)
        if schema_registry_uri is not None:
            pulumi.set(__self__, "schema_registry_uri", schema_registry_uri)

    @property
    @pulumi.getter(name="accessCert")
    def access_cert(self) -> Optional[str]:
        return pulumi.get(self, "access_cert")

    @property
    @pulumi.getter(name="accessKey")
    def access_key(self) -> Optional[str]:
        return pulumi.get(self, "access_key")

    @property
    @pulumi.getter(name="connectUri")
    def connect_uri(self) -> Optional[str]:
        return pulumi.get(self, "connect_uri")

    @property
    @pulumi.getter(name="restUri")
    def rest_uri(self) -> Optional[str]:
        return pulumi.get(self, "rest_uri")

    @property
    @pulumi.getter(name="schemaRegistryUri")
    def schema_registry_uri(self) -> Optional[str]:
        return pulumi.get(self, "schema_registry_uri")


@pulumi.output_type
class ServiceKafkaConnect(dict):
    def __init__(__self__):
        pass


@pulumi.output_type
class ServiceKafkaConnectUserConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "ipFilters":
            suggest = "ip_filters"
        elif key == "kafkaConnect":
            suggest = "kafka_connect"
        elif key == "privateAccess":
            suggest = "private_access"
        elif key == "privatelinkAccess":
            suggest = "privatelink_access"
        elif key == "publicAccess":
            suggest = "public_access"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ServiceKafkaConnectUserConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ServiceKafkaConnectUserConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ServiceKafkaConnectUserConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 ip_filters: Optional[Sequence[str]] = None,
                 kafka_connect: Optional['outputs.ServiceKafkaConnectUserConfigKafkaConnect'] = None,
                 private_access: Optional['outputs.ServiceKafkaConnectUserConfigPrivateAccess'] = None,
                 privatelink_access: Optional['outputs.ServiceKafkaConnectUserConfigPrivatelinkAccess'] = None,
                 public_access: Optional['outputs.ServiceKafkaConnectUserConfigPublicAccess'] = None):
        if ip_filters is not None:
            pulumi.set(__self__, "ip_filters", ip_filters)
        if kafka_connect is not None:
            pulumi.set(__self__, "kafka_connect", kafka_connect)
        if private_access is not None:
            pulumi.set(__self__, "private_access", private_access)
        if privatelink_access is not None:
            pulumi.set(__self__, "privatelink_access", privatelink_access)
        if public_access is not None:
            pulumi.set(__self__, "public_access", public_access)

    @property
    @pulumi.getter(name="ipFilters")
    def ip_filters(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "ip_filters")

    @property
    @pulumi.getter(name="kafkaConnect")
    def kafka_connect(self) -> Optional['outputs.ServiceKafkaConnectUserConfigKafkaConnect']:
        return pulumi.get(self, "kafka_connect")

    @property
    @pulumi.getter(name="privateAccess")
    def private_access(self) -> Optional['outputs.ServiceKafkaConnectUserConfigPrivateAccess']:
        return pulumi.get(self, "private_access")

    @property
    @pulumi.getter(name="privatelinkAccess")
    def privatelink_access(self) -> Optional['outputs.ServiceKafkaConnectUserConfigPrivatelinkAccess']:
        return pulumi.get(self, "privatelink_access")

    @property
    @pulumi.getter(name="publicAccess")
    def public_access(self) -> Optional['outputs.ServiceKafkaConnectUserConfigPublicAccess']:
        return pulumi.get(self, "public_access")


@pulumi.output_type
class ServiceKafkaConnectUserConfigKafkaConnect(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "connectorClientConfigOverridePolicy":
            suggest = "connector_client_config_override_policy"
        elif key == "consumerAutoOffsetReset":
            suggest = "consumer_auto_offset_reset"
        elif key == "consumerFetchMaxBytes":
            suggest = "consumer_fetch_max_bytes"
        elif key == "consumerIsolationLevel":
            suggest = "consumer_isolation_level"
        elif key == "consumerMaxPartitionFetchBytes":
            suggest = "consumer_max_partition_fetch_bytes"
        elif key == "consumerMaxPollIntervalMs":
            suggest = "consumer_max_poll_interval_ms"
        elif key == "consumerMaxPollRecords":
            suggest = "consumer_max_poll_records"
        elif key == "offsetFlushIntervalMs":
            suggest = "offset_flush_interval_ms"
        elif key == "offsetFlushTimeoutMs":
            suggest = "offset_flush_timeout_ms"
        elif key == "producerMaxRequestSize":
            suggest = "producer_max_request_size"
        elif key == "sessionTimeoutMs":
            suggest = "session_timeout_ms"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ServiceKafkaConnectUserConfigKafkaConnect. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ServiceKafkaConnectUserConfigKafkaConnect.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ServiceKafkaConnectUserConfigKafkaConnect.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 connector_client_config_override_policy: Optional[str] = None,
                 consumer_auto_offset_reset: Optional[str] = None,
                 consumer_fetch_max_bytes: Optional[str] = None,
                 consumer_isolation_level: Optional[str] = None,
                 consumer_max_partition_fetch_bytes: Optional[str] = None,
                 consumer_max_poll_interval_ms: Optional[str] = None,
                 consumer_max_poll_records: Optional[str] = None,
                 offset_flush_interval_ms: Optional[str] = None,
                 offset_flush_timeout_ms: Optional[str] = None,
                 producer_max_request_size: Optional[str] = None,
                 session_timeout_ms: Optional[str] = None):
        if connector_client_config_override_policy is not None:
            pulumi.set(__self__, "connector_client_config_override_policy", connector_client_config_override_policy)
        if consumer_auto_offset_reset is not None:
            pulumi.set(__self__, "consumer_auto_offset_reset", consumer_auto_offset_reset)
        if consumer_fetch_max_bytes is not None:
            pulumi.set(__self__, "consumer_fetch_max_bytes", consumer_fetch_max_bytes)
        if consumer_isolation_level is not None:
            pulumi.set(__self__, "consumer_isolation_level", consumer_isolation_level)
        if consumer_max_partition_fetch_bytes is not None:
            pulumi.set(__self__, "consumer_max_partition_fetch_bytes", consumer_max_partition_fetch_bytes)
        if consumer_max_poll_interval_ms is not None:
            pulumi.set(__self__, "consumer_max_poll_interval_ms", consumer_max_poll_interval_ms)
        if consumer_max_poll_records is not None:
            pulumi.set(__self__, "consumer_max_poll_records", consumer_max_poll_records)
        if offset_flush_interval_ms is not None:
            pulumi.set(__self__, "offset_flush_interval_ms", offset_flush_interval_ms)
        if offset_flush_timeout_ms is not None:
            pulumi.set(__self__, "offset_flush_timeout_ms", offset_flush_timeout_ms)
        if producer_max_request_size is not None:
            pulumi.set(__self__, "producer_max_request_size", producer_max_request_size)
        if session_timeout_ms is not None:
            pulumi.set(__self__, "session_timeout_ms", session_timeout_ms)

    @property
    @pulumi.getter(name="connectorClientConfigOverridePolicy")
    def connector_client_config_override_policy(self) -> Optional[str]:
        return pulumi.get(self, "connector_client_config_override_policy")

    @property
    @pulumi.getter(name="consumerAutoOffsetReset")
    def consumer_auto_offset_reset(self) -> Optional[str]:
        return pulumi.get(self, "consumer_auto_offset_reset")

    @property
    @pulumi.getter(name="consumerFetchMaxBytes")
    def consumer_fetch_max_bytes(self) -> Optional[str]:
        return pulumi.get(self, "consumer_fetch_max_bytes")

    @property
    @pulumi.getter(name="consumerIsolationLevel")
    def consumer_isolation_level(self) -> Optional[str]:
        return pulumi.get(self, "consumer_isolation_level")

    @property
    @pulumi.getter(name="consumerMaxPartitionFetchBytes")
    def consumer_max_partition_fetch_bytes(self) -> Optional[str]:
        return pulumi.get(self, "consumer_max_partition_fetch_bytes")

    @property
    @pulumi.getter(name="consumerMaxPollIntervalMs")
    def consumer_max_poll_interval_ms(self) -> Optional[str]:
        return pulumi.get(self, "consumer_max_poll_interval_ms")

    @property
    @pulumi.getter(name="consumerMaxPollRecords")
    def consumer_max_poll_records(self) -> Optional[str]:
        return pulumi.get(self, "consumer_max_poll_records")

    @property
    @pulumi.getter(name="offsetFlushIntervalMs")
    def offset_flush_interval_ms(self) -> Optional[str]:
        return pulumi.get(self, "offset_flush_interval_ms")

    @property
    @pulumi.getter(name="offsetFlushTimeoutMs")
    def offset_flush_timeout_ms(self) -> Optional[str]:
        return pulumi.get(self, "offset_flush_timeout_ms")

    @property
    @pulumi.getter(name="producerMaxRequestSize")
    def producer_max_request_size(self) -> Optional[str]:
        return pulumi.get(self, "producer_max_request_size")

    @property
    @pulumi.getter(name="sessionTimeoutMs")
    def session_timeout_ms(self) -> Optional[str]:
        return pulumi.get(self, "session_timeout_ms")


@pulumi.output_type
class ServiceKafkaConnectUserConfigPrivateAccess(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "kafkaConnect":
            suggest = "kafka_connect"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ServiceKafkaConnectUserConfigPrivateAccess. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ServiceKafkaConnectUserConfigPrivateAccess.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ServiceKafkaConnectUserConfigPrivateAccess.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 kafka_connect: Optional[str] = None,
                 prometheus: Optional[str] = None):
        if kafka_connect is not None:
            pulumi.set(__self__, "kafka_connect", kafka_connect)
        if prometheus is not None:
            pulumi.set(__self__, "prometheus", prometheus)

    @property
    @pulumi.getter(name="kafkaConnect")
    def kafka_connect(self) -> Optional[str]:
        return pulumi.get(self, "kafka_connect")

    @property
    @pulumi.getter
    def prometheus(self) -> Optional[str]:
        return pulumi.get(self, "prometheus")


@pulumi.output_type
class ServiceKafkaConnectUserConfigPrivatelinkAccess(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "kafkaConnect":
            suggest = "kafka_connect"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ServiceKafkaConnectUserConfigPrivatelinkAccess. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ServiceKafkaConnectUserConfigPrivatelinkAccess.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ServiceKafkaConnectUserConfigPrivatelinkAccess.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 kafka_connect: Optional[str] = None):
        if kafka_connect is not None:
            pulumi.set(__self__, "kafka_connect", kafka_connect)

    @property
    @pulumi.getter(name="kafkaConnect")
    def kafka_connect(self) -> Optional[str]:
        return pulumi.get(self, "kafka_connect")


@pulumi.output_type
class ServiceKafkaConnectUserConfigPublicAccess(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "kafkaConnect":
            suggest = "kafka_connect"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ServiceKafkaConnectUserConfigPublicAccess. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ServiceKafkaConnectUserConfigPublicAccess.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ServiceKafkaConnectUserConfigPublicAccess.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 kafka_connect: Optional[str] = None,
                 prometheus: Optional[str] = None):
        if kafka_connect is not None:
            pulumi.set(__self__, "kafka_connect", kafka_connect)
        if prometheus is not None:
            pulumi.set(__self__, "prometheus", prometheus)

    @property
    @pulumi.getter(name="kafkaConnect")
    def kafka_connect(self) -> Optional[str]:
        return pulumi.get(self, "kafka_connect")

    @property
    @pulumi.getter
    def prometheus(self) -> Optional[str]:
        return pulumi.get(self, "prometheus")


@pulumi.output_type
class ServiceKafkaMirrormaker(dict):
    def __init__(__self__):
        pass


@pulumi.output_type
class ServiceKafkaMirrormakerUserConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "ipFilters":
            suggest = "ip_filters"
        elif key == "kafkaMirrormaker":
            suggest = "kafka_mirrormaker"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ServiceKafkaMirrormakerUserConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ServiceKafkaMirrormakerUserConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ServiceKafkaMirrormakerUserConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 ip_filters: Optional[Sequence[str]] = None,
                 kafka_mirrormaker: Optional['outputs.ServiceKafkaMirrormakerUserConfigKafkaMirrormaker'] = None):
        if ip_filters is not None:
            pulumi.set(__self__, "ip_filters", ip_filters)
        if kafka_mirrormaker is not None:
            pulumi.set(__self__, "kafka_mirrormaker", kafka_mirrormaker)

    @property
    @pulumi.getter(name="ipFilters")
    def ip_filters(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "ip_filters")

    @property
    @pulumi.getter(name="kafkaMirrormaker")
    def kafka_mirrormaker(self) -> Optional['outputs.ServiceKafkaMirrormakerUserConfigKafkaMirrormaker']:
        return pulumi.get(self, "kafka_mirrormaker")


@pulumi.output_type
class ServiceKafkaMirrormakerUserConfigKafkaMirrormaker(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "emitCheckpointsEnabled":
            suggest = "emit_checkpoints_enabled"
        elif key == "emitCheckpointsIntervalSeconds":
            suggest = "emit_checkpoints_interval_seconds"
        elif key == "refreshGroupsEnabled":
            suggest = "refresh_groups_enabled"
        elif key == "refreshGroupsIntervalSeconds":
            suggest = "refresh_groups_interval_seconds"
        elif key == "refreshTopicsEnabled":
            suggest = "refresh_topics_enabled"
        elif key == "refreshTopicsIntervalSeconds":
            suggest = "refresh_topics_interval_seconds"
        elif key == "syncGroupOffsetsEnabled":
            suggest = "sync_group_offsets_enabled"
        elif key == "syncGroupOffsetsIntervalSeconds":
            suggest = "sync_group_offsets_interval_seconds"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ServiceKafkaMirrormakerUserConfigKafkaMirrormaker. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ServiceKafkaMirrormakerUserConfigKafkaMirrormaker.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ServiceKafkaMirrormakerUserConfigKafkaMirrormaker.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 emit_checkpoints_enabled: Optional[str] = None,
                 emit_checkpoints_interval_seconds: Optional[str] = None,
                 refresh_groups_enabled: Optional[str] = None,
                 refresh_groups_interval_seconds: Optional[str] = None,
                 refresh_topics_enabled: Optional[str] = None,
                 refresh_topics_interval_seconds: Optional[str] = None,
                 sync_group_offsets_enabled: Optional[str] = None,
                 sync_group_offsets_interval_seconds: Optional[str] = None):
        if emit_checkpoints_enabled is not None:
            pulumi.set(__self__, "emit_checkpoints_enabled", emit_checkpoints_enabled)
        if emit_checkpoints_interval_seconds is not None:
            pulumi.set(__self__, "emit_checkpoints_interval_seconds", emit_checkpoints_interval_seconds)
        if refresh_groups_enabled is not None:
            pulumi.set(__self__, "refresh_groups_enabled", refresh_groups_enabled)
        if refresh_groups_interval_seconds is not None:
            pulumi.set(__self__, "refresh_groups_interval_seconds", refresh_groups_interval_seconds)
        if refresh_topics_enabled is not None:
            pulumi.set(__self__, "refresh_topics_enabled", refresh_topics_enabled)
        if refresh_topics_interval_seconds is not None:
            pulumi.set(__self__, "refresh_topics_interval_seconds", refresh_topics_interval_seconds)
        if sync_group_offsets_enabled is not None:
            pulumi.set(__self__, "sync_group_offsets_enabled", sync_group_offsets_enabled)
        if sync_group_offsets_interval_seconds is not None:
            pulumi.set(__self__, "sync_group_offsets_interval_seconds", sync_group_offsets_interval_seconds)

    @property
    @pulumi.getter(name="emitCheckpointsEnabled")
    def emit_checkpoints_enabled(self) -> Optional[str]:
        return pulumi.get(self, "emit_checkpoints_enabled")

    @property
    @pulumi.getter(name="emitCheckpointsIntervalSeconds")
    def emit_checkpoints_interval_seconds(self) -> Optional[str]:
        return pulumi.get(self, "emit_checkpoints_interval_seconds")

    @property
    @pulumi.getter(name="refreshGroupsEnabled")
    def refresh_groups_enabled(self) -> Optional[str]:
        return pulumi.get(self, "refresh_groups_enabled")

    @property
    @pulumi.getter(name="refreshGroupsIntervalSeconds")
    def refresh_groups_interval_seconds(self) -> Optional[str]:
        return pulumi.get(self, "refresh_groups_interval_seconds")

    @property
    @pulumi.getter(name="refreshTopicsEnabled")
    def refresh_topics_enabled(self) -> Optional[str]:
        return pulumi.get(self, "refresh_topics_enabled")

    @property
    @pulumi.getter(name="refreshTopicsIntervalSeconds")
    def refresh_topics_interval_seconds(self) -> Optional[str]:
        return pulumi.get(self, "refresh_topics_interval_seconds")

    @property
    @pulumi.getter(name="syncGroupOffsetsEnabled")
    def sync_group_offsets_enabled(self) -> Optional[str]:
        return pulumi.get(self, "sync_group_offsets_enabled")

    @property
    @pulumi.getter(name="syncGroupOffsetsIntervalSeconds")
    def sync_group_offsets_interval_seconds(self) -> Optional[str]:
        return pulumi.get(self, "sync_group_offsets_interval_seconds")


@pulumi.output_type
class ServiceKafkaUserConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "customDomain":
            suggest = "custom_domain"
        elif key == "ipFilters":
            suggest = "ip_filters"
        elif key == "kafkaAuthenticationMethods":
            suggest = "kafka_authentication_methods"
        elif key == "kafkaConnect":
            suggest = "kafka_connect"
        elif key == "kafkaConnectConfig":
            suggest = "kafka_connect_config"
        elif key == "kafkaRest":
            suggest = "kafka_rest"
        elif key == "kafkaRestConfig":
            suggest = "kafka_rest_config"
        elif key == "kafkaVersion":
            suggest = "kafka_version"
        elif key == "privateAccess":
            suggest = "private_access"
        elif key == "privatelinkAccess":
            suggest = "privatelink_access"
        elif key == "publicAccess":
            suggest = "public_access"
        elif key == "schemaRegistry":
            suggest = "schema_registry"
        elif key == "schemaRegistryConfig":
            suggest = "schema_registry_config"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ServiceKafkaUserConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ServiceKafkaUserConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ServiceKafkaUserConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 custom_domain: Optional[str] = None,
                 ip_filters: Optional[Sequence[str]] = None,
                 kafka: Optional['outputs.ServiceKafkaUserConfigKafka'] = None,
                 kafka_authentication_methods: Optional['outputs.ServiceKafkaUserConfigKafkaAuthenticationMethods'] = None,
                 kafka_connect: Optional[str] = None,
                 kafka_connect_config: Optional['outputs.ServiceKafkaUserConfigKafkaConnectConfig'] = None,
                 kafka_rest: Optional[str] = None,
                 kafka_rest_config: Optional['outputs.ServiceKafkaUserConfigKafkaRestConfig'] = None,
                 kafka_version: Optional[str] = None,
                 private_access: Optional['outputs.ServiceKafkaUserConfigPrivateAccess'] = None,
                 privatelink_access: Optional['outputs.ServiceKafkaUserConfigPrivatelinkAccess'] = None,
                 public_access: Optional['outputs.ServiceKafkaUserConfigPublicAccess'] = None,
                 schema_registry: Optional[str] = None,
                 schema_registry_config: Optional['outputs.ServiceKafkaUserConfigSchemaRegistryConfig'] = None):
        if custom_domain is not None:
            pulumi.set(__self__, "custom_domain", custom_domain)
        if ip_filters is not None:
            pulumi.set(__self__, "ip_filters", ip_filters)
        if kafka is not None:
            pulumi.set(__self__, "kafka", kafka)
        if kafka_authentication_methods is not None:
            pulumi.set(__self__, "kafka_authentication_methods", kafka_authentication_methods)
        if kafka_connect is not None:
            pulumi.set(__self__, "kafka_connect", kafka_connect)
        if kafka_connect_config is not None:
            pulumi.set(__self__, "kafka_connect_config", kafka_connect_config)
        if kafka_rest is not None:
            pulumi.set(__self__, "kafka_rest", kafka_rest)
        if kafka_rest_config is not None:
            pulumi.set(__self__, "kafka_rest_config", kafka_rest_config)
        if kafka_version is not None:
            pulumi.set(__self__, "kafka_version", kafka_version)
        if private_access is not None:
            pulumi.set(__self__, "private_access", private_access)
        if privatelink_access is not None:
            pulumi.set(__self__, "privatelink_access", privatelink_access)
        if public_access is not None:
            pulumi.set(__self__, "public_access", public_access)
        if schema_registry is not None:
            pulumi.set(__self__, "schema_registry", schema_registry)
        if schema_registry_config is not None:
            pulumi.set(__self__, "schema_registry_config", schema_registry_config)

    @property
    @pulumi.getter(name="customDomain")
    def custom_domain(self) -> Optional[str]:
        return pulumi.get(self, "custom_domain")

    @property
    @pulumi.getter(name="ipFilters")
    def ip_filters(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "ip_filters")

    @property
    @pulumi.getter
    def kafka(self) -> Optional['outputs.ServiceKafkaUserConfigKafka']:
        return pulumi.get(self, "kafka")

    @property
    @pulumi.getter(name="kafkaAuthenticationMethods")
    def kafka_authentication_methods(self) -> Optional['outputs.ServiceKafkaUserConfigKafkaAuthenticationMethods']:
        return pulumi.get(self, "kafka_authentication_methods")

    @property
    @pulumi.getter(name="kafkaConnect")
    def kafka_connect(self) -> Optional[str]:
        return pulumi.get(self, "kafka_connect")

    @property
    @pulumi.getter(name="kafkaConnectConfig")
    def kafka_connect_config(self) -> Optional['outputs.ServiceKafkaUserConfigKafkaConnectConfig']:
        return pulumi.get(self, "kafka_connect_config")

    @property
    @pulumi.getter(name="kafkaRest")
    def kafka_rest(self) -> Optional[str]:
        return pulumi.get(self, "kafka_rest")

    @property
    @pulumi.getter(name="kafkaRestConfig")
    def kafka_rest_config(self) -> Optional['outputs.ServiceKafkaUserConfigKafkaRestConfig']:
        return pulumi.get(self, "kafka_rest_config")

    @property
    @pulumi.getter(name="kafkaVersion")
    def kafka_version(self) -> Optional[str]:
        return pulumi.get(self, "kafka_version")

    @property
    @pulumi.getter(name="privateAccess")
    def private_access(self) -> Optional['outputs.ServiceKafkaUserConfigPrivateAccess']:
        return pulumi.get(self, "private_access")

    @property
    @pulumi.getter(name="privatelinkAccess")
    def privatelink_access(self) -> Optional['outputs.ServiceKafkaUserConfigPrivatelinkAccess']:
        return pulumi.get(self, "privatelink_access")

    @property
    @pulumi.getter(name="publicAccess")
    def public_access(self) -> Optional['outputs.ServiceKafkaUserConfigPublicAccess']:
        return pulumi.get(self, "public_access")

    @property
    @pulumi.getter(name="schemaRegistry")
    def schema_registry(self) -> Optional[str]:
        return pulumi.get(self, "schema_registry")

    @property
    @pulumi.getter(name="schemaRegistryConfig")
    def schema_registry_config(self) -> Optional['outputs.ServiceKafkaUserConfigSchemaRegistryConfig']:
        return pulumi.get(self, "schema_registry_config")


@pulumi.output_type
class ServiceKafkaUserConfigKafka(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "autoCreateTopicsEnable":
            suggest = "auto_create_topics_enable"
        elif key == "compressionType":
            suggest = "compression_type"
        elif key == "connectionsMaxIdleMs":
            suggest = "connections_max_idle_ms"
        elif key == "defaultReplicationFactor":
            suggest = "default_replication_factor"
        elif key == "groupInitialRebalanceDelayMs":
            suggest = "group_initial_rebalance_delay_ms"
        elif key == "groupMaxSessionTimeoutMs":
            suggest = "group_max_session_timeout_ms"
        elif key == "groupMinSessionTimeoutMs":
            suggest = "group_min_session_timeout_ms"
        elif key == "logCleanerDeleteRetentionMs":
            suggest = "log_cleaner_delete_retention_ms"
        elif key == "logCleanerMaxCompactionLagMs":
            suggest = "log_cleaner_max_compaction_lag_ms"
        elif key == "logCleanerMinCleanableRatio":
            suggest = "log_cleaner_min_cleanable_ratio"
        elif key == "logCleanerMinCompactionLagMs":
            suggest = "log_cleaner_min_compaction_lag_ms"
        elif key == "logCleanupPolicy":
            suggest = "log_cleanup_policy"
        elif key == "logFlushIntervalMessages":
            suggest = "log_flush_interval_messages"
        elif key == "logFlushIntervalMs":
            suggest = "log_flush_interval_ms"
        elif key == "logIndexIntervalBytes":
            suggest = "log_index_interval_bytes"
        elif key == "logIndexSizeMaxBytes":
            suggest = "log_index_size_max_bytes"
        elif key == "logMessageDownconversionEnable":
            suggest = "log_message_downconversion_enable"
        elif key == "logMessageTimestampDifferenceMaxMs":
            suggest = "log_message_timestamp_difference_max_ms"
        elif key == "logMessageTimestampType":
            suggest = "log_message_timestamp_type"
        elif key == "logPreallocate":
            suggest = "log_preallocate"
        elif key == "logRetentionBytes":
            suggest = "log_retention_bytes"
        elif key == "logRetentionHours":
            suggest = "log_retention_hours"
        elif key == "logRetentionMs":
            suggest = "log_retention_ms"
        elif key == "logRollJitterMs":
            suggest = "log_roll_jitter_ms"
        elif key == "logRollMs":
            suggest = "log_roll_ms"
        elif key == "logSegmentBytes":
            suggest = "log_segment_bytes"
        elif key == "logSegmentDeleteDelayMs":
            suggest = "log_segment_delete_delay_ms"
        elif key == "maxConnectionsPerIp":
            suggest = "max_connections_per_ip"
        elif key == "maxIncrementalFetchSessionCacheSlots":
            suggest = "max_incremental_fetch_session_cache_slots"
        elif key == "messageMaxBytes":
            suggest = "message_max_bytes"
        elif key == "minInsyncReplicas":
            suggest = "min_insync_replicas"
        elif key == "numPartitions":
            suggest = "num_partitions"
        elif key == "offsetsRetentionMinutes":
            suggest = "offsets_retention_minutes"
        elif key == "producerPurgatoryPurgeIntervalRequests":
            suggest = "producer_purgatory_purge_interval_requests"
        elif key == "replicaFetchMaxBytes":
            suggest = "replica_fetch_max_bytes"
        elif key == "replicaFetchResponseMaxBytes":
            suggest = "replica_fetch_response_max_bytes"
        elif key == "socketRequestMaxBytes":
            suggest = "socket_request_max_bytes"
        elif key == "transactionRemoveExpiredTransactionCleanupIntervalMs":
            suggest = "transaction_remove_expired_transaction_cleanup_interval_ms"
        elif key == "transactionStateLogSegmentBytes":
            suggest = "transaction_state_log_segment_bytes"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ServiceKafkaUserConfigKafka. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ServiceKafkaUserConfigKafka.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ServiceKafkaUserConfigKafka.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 auto_create_topics_enable: Optional[str] = None,
                 compression_type: Optional[str] = None,
                 connections_max_idle_ms: Optional[str] = None,
                 default_replication_factor: Optional[str] = None,
                 group_initial_rebalance_delay_ms: Optional[str] = None,
                 group_max_session_timeout_ms: Optional[str] = None,
                 group_min_session_timeout_ms: Optional[str] = None,
                 log_cleaner_delete_retention_ms: Optional[str] = None,
                 log_cleaner_max_compaction_lag_ms: Optional[str] = None,
                 log_cleaner_min_cleanable_ratio: Optional[str] = None,
                 log_cleaner_min_compaction_lag_ms: Optional[str] = None,
                 log_cleanup_policy: Optional[str] = None,
                 log_flush_interval_messages: Optional[str] = None,
                 log_flush_interval_ms: Optional[str] = None,
                 log_index_interval_bytes: Optional[str] = None,
                 log_index_size_max_bytes: Optional[str] = None,
                 log_message_downconversion_enable: Optional[str] = None,
                 log_message_timestamp_difference_max_ms: Optional[str] = None,
                 log_message_timestamp_type: Optional[str] = None,
                 log_preallocate: Optional[str] = None,
                 log_retention_bytes: Optional[str] = None,
                 log_retention_hours: Optional[str] = None,
                 log_retention_ms: Optional[str] = None,
                 log_roll_jitter_ms: Optional[str] = None,
                 log_roll_ms: Optional[str] = None,
                 log_segment_bytes: Optional[str] = None,
                 log_segment_delete_delay_ms: Optional[str] = None,
                 max_connections_per_ip: Optional[str] = None,
                 max_incremental_fetch_session_cache_slots: Optional[str] = None,
                 message_max_bytes: Optional[str] = None,
                 min_insync_replicas: Optional[str] = None,
                 num_partitions: Optional[str] = None,
                 offsets_retention_minutes: Optional[str] = None,
                 producer_purgatory_purge_interval_requests: Optional[str] = None,
                 replica_fetch_max_bytes: Optional[str] = None,
                 replica_fetch_response_max_bytes: Optional[str] = None,
                 socket_request_max_bytes: Optional[str] = None,
                 transaction_remove_expired_transaction_cleanup_interval_ms: Optional[str] = None,
                 transaction_state_log_segment_bytes: Optional[str] = None):
        if auto_create_topics_enable is not None:
            pulumi.set(__self__, "auto_create_topics_enable", auto_create_topics_enable)
        if compression_type is not None:
            pulumi.set(__self__, "compression_type", compression_type)
        if connections_max_idle_ms is not None:
            pulumi.set(__self__, "connections_max_idle_ms", connections_max_idle_ms)
        if default_replication_factor is not None:
            pulumi.set(__self__, "default_replication_factor", default_replication_factor)
        if group_initial_rebalance_delay_ms is not None:
            pulumi.set(__self__, "group_initial_rebalance_delay_ms", group_initial_rebalance_delay_ms)
        if group_max_session_timeout_ms is not None:
            pulumi.set(__self__, "group_max_session_timeout_ms", group_max_session_timeout_ms)
        if group_min_session_timeout_ms is not None:
            pulumi.set(__self__, "group_min_session_timeout_ms", group_min_session_timeout_ms)
        if log_cleaner_delete_retention_ms is not None:
            pulumi.set(__self__, "log_cleaner_delete_retention_ms", log_cleaner_delete_retention_ms)
        if log_cleaner_max_compaction_lag_ms is not None:
            pulumi.set(__self__, "log_cleaner_max_compaction_lag_ms", log_cleaner_max_compaction_lag_ms)
        if log_cleaner_min_cleanable_ratio is not None:
            pulumi.set(__self__, "log_cleaner_min_cleanable_ratio", log_cleaner_min_cleanable_ratio)
        if log_cleaner_min_compaction_lag_ms is not None:
            pulumi.set(__self__, "log_cleaner_min_compaction_lag_ms", log_cleaner_min_compaction_lag_ms)
        if log_cleanup_policy is not None:
            pulumi.set(__self__, "log_cleanup_policy", log_cleanup_policy)
        if log_flush_interval_messages is not None:
            pulumi.set(__self__, "log_flush_interval_messages", log_flush_interval_messages)
        if log_flush_interval_ms is not None:
            pulumi.set(__self__, "log_flush_interval_ms", log_flush_interval_ms)
        if log_index_interval_bytes is not None:
            pulumi.set(__self__, "log_index_interval_bytes", log_index_interval_bytes)
        if log_index_size_max_bytes is not None:
            pulumi.set(__self__, "log_index_size_max_bytes", log_index_size_max_bytes)
        if log_message_downconversion_enable is not None:
            pulumi.set(__self__, "log_message_downconversion_enable", log_message_downconversion_enable)
        if log_message_timestamp_difference_max_ms is not None:
            pulumi.set(__self__, "log_message_timestamp_difference_max_ms", log_message_timestamp_difference_max_ms)
        if log_message_timestamp_type is not None:
            pulumi.set(__self__, "log_message_timestamp_type", log_message_timestamp_type)
        if log_preallocate is not None:
            pulumi.set(__self__, "log_preallocate", log_preallocate)
        if log_retention_bytes is not None:
            pulumi.set(__self__, "log_retention_bytes", log_retention_bytes)
        if log_retention_hours is not None:
            pulumi.set(__self__, "log_retention_hours", log_retention_hours)
        if log_retention_ms is not None:
            pulumi.set(__self__, "log_retention_ms", log_retention_ms)
        if log_roll_jitter_ms is not None:
            pulumi.set(__self__, "log_roll_jitter_ms", log_roll_jitter_ms)
        if log_roll_ms is not None:
            pulumi.set(__self__, "log_roll_ms", log_roll_ms)
        if log_segment_bytes is not None:
            pulumi.set(__self__, "log_segment_bytes", log_segment_bytes)
        if log_segment_delete_delay_ms is not None:
            pulumi.set(__self__, "log_segment_delete_delay_ms", log_segment_delete_delay_ms)
        if max_connections_per_ip is not None:
            pulumi.set(__self__, "max_connections_per_ip", max_connections_per_ip)
        if max_incremental_fetch_session_cache_slots is not None:
            pulumi.set(__self__, "max_incremental_fetch_session_cache_slots", max_incremental_fetch_session_cache_slots)
        if message_max_bytes is not None:
            pulumi.set(__self__, "message_max_bytes", message_max_bytes)
        if min_insync_replicas is not None:
            pulumi.set(__self__, "min_insync_replicas", min_insync_replicas)
        if num_partitions is not None:
            pulumi.set(__self__, "num_partitions", num_partitions)
        if offsets_retention_minutes is not None:
            pulumi.set(__self__, "offsets_retention_minutes", offsets_retention_minutes)
        if producer_purgatory_purge_interval_requests is not None:
            pulumi.set(__self__, "producer_purgatory_purge_interval_requests", producer_purgatory_purge_interval_requests)
        if replica_fetch_max_bytes is not None:
            pulumi.set(__self__, "replica_fetch_max_bytes", replica_fetch_max_bytes)
        if replica_fetch_response_max_bytes is not None:
            pulumi.set(__self__, "replica_fetch_response_max_bytes", replica_fetch_response_max_bytes)
        if socket_request_max_bytes is not None:
            pulumi.set(__self__, "socket_request_max_bytes", socket_request_max_bytes)
        if transaction_remove_expired_transaction_cleanup_interval_ms is not None:
            pulumi.set(__self__, "transaction_remove_expired_transaction_cleanup_interval_ms", transaction_remove_expired_transaction_cleanup_interval_ms)
        if transaction_state_log_segment_bytes is not None:
            pulumi.set(__self__, "transaction_state_log_segment_bytes", transaction_state_log_segment_bytes)

    @property
    @pulumi.getter(name="autoCreateTopicsEnable")
    def auto_create_topics_enable(self) -> Optional[str]:
        return pulumi.get(self, "auto_create_topics_enable")

    @property
    @pulumi.getter(name="compressionType")
    def compression_type(self) -> Optional[str]:
        return pulumi.get(self, "compression_type")

    @property
    @pulumi.getter(name="connectionsMaxIdleMs")
    def connections_max_idle_ms(self) -> Optional[str]:
        return pulumi.get(self, "connections_max_idle_ms")

    @property
    @pulumi.getter(name="defaultReplicationFactor")
    def default_replication_factor(self) -> Optional[str]:
        return pulumi.get(self, "default_replication_factor")

    @property
    @pulumi.getter(name="groupInitialRebalanceDelayMs")
    def group_initial_rebalance_delay_ms(self) -> Optional[str]:
        return pulumi.get(self, "group_initial_rebalance_delay_ms")

    @property
    @pulumi.getter(name="groupMaxSessionTimeoutMs")
    def group_max_session_timeout_ms(self) -> Optional[str]:
        return pulumi.get(self, "group_max_session_timeout_ms")

    @property
    @pulumi.getter(name="groupMinSessionTimeoutMs")
    def group_min_session_timeout_ms(self) -> Optional[str]:
        return pulumi.get(self, "group_min_session_timeout_ms")

    @property
    @pulumi.getter(name="logCleanerDeleteRetentionMs")
    def log_cleaner_delete_retention_ms(self) -> Optional[str]:
        return pulumi.get(self, "log_cleaner_delete_retention_ms")

    @property
    @pulumi.getter(name="logCleanerMaxCompactionLagMs")
    def log_cleaner_max_compaction_lag_ms(self) -> Optional[str]:
        return pulumi.get(self, "log_cleaner_max_compaction_lag_ms")

    @property
    @pulumi.getter(name="logCleanerMinCleanableRatio")
    def log_cleaner_min_cleanable_ratio(self) -> Optional[str]:
        return pulumi.get(self, "log_cleaner_min_cleanable_ratio")

    @property
    @pulumi.getter(name="logCleanerMinCompactionLagMs")
    def log_cleaner_min_compaction_lag_ms(self) -> Optional[str]:
        return pulumi.get(self, "log_cleaner_min_compaction_lag_ms")

    @property
    @pulumi.getter(name="logCleanupPolicy")
    def log_cleanup_policy(self) -> Optional[str]:
        return pulumi.get(self, "log_cleanup_policy")

    @property
    @pulumi.getter(name="logFlushIntervalMessages")
    def log_flush_interval_messages(self) -> Optional[str]:
        return pulumi.get(self, "log_flush_interval_messages")

    @property
    @pulumi.getter(name="logFlushIntervalMs")
    def log_flush_interval_ms(self) -> Optional[str]:
        return pulumi.get(self, "log_flush_interval_ms")

    @property
    @pulumi.getter(name="logIndexIntervalBytes")
    def log_index_interval_bytes(self) -> Optional[str]:
        return pulumi.get(self, "log_index_interval_bytes")

    @property
    @pulumi.getter(name="logIndexSizeMaxBytes")
    def log_index_size_max_bytes(self) -> Optional[str]:
        return pulumi.get(self, "log_index_size_max_bytes")

    @property
    @pulumi.getter(name="logMessageDownconversionEnable")
    def log_message_downconversion_enable(self) -> Optional[str]:
        return pulumi.get(self, "log_message_downconversion_enable")

    @property
    @pulumi.getter(name="logMessageTimestampDifferenceMaxMs")
    def log_message_timestamp_difference_max_ms(self) -> Optional[str]:
        return pulumi.get(self, "log_message_timestamp_difference_max_ms")

    @property
    @pulumi.getter(name="logMessageTimestampType")
    def log_message_timestamp_type(self) -> Optional[str]:
        return pulumi.get(self, "log_message_timestamp_type")

    @property
    @pulumi.getter(name="logPreallocate")
    def log_preallocate(self) -> Optional[str]:
        return pulumi.get(self, "log_preallocate")

    @property
    @pulumi.getter(name="logRetentionBytes")
    def log_retention_bytes(self) -> Optional[str]:
        return pulumi.get(self, "log_retention_bytes")

    @property
    @pulumi.getter(name="logRetentionHours")
    def log_retention_hours(self) -> Optional[str]:
        return pulumi.get(self, "log_retention_hours")

    @property
    @pulumi.getter(name="logRetentionMs")
    def log_retention_ms(self) -> Optional[str]:
        return pulumi.get(self, "log_retention_ms")

    @property
    @pulumi.getter(name="logRollJitterMs")
    def log_roll_jitter_ms(self) -> Optional[str]:
        return pulumi.get(self, "log_roll_jitter_ms")

    @property
    @pulumi.getter(name="logRollMs")
    def log_roll_ms(self) -> Optional[str]:
        return pulumi.get(self, "log_roll_ms")

    @property
    @pulumi.getter(name="logSegmentBytes")
    def log_segment_bytes(self) -> Optional[str]:
        return pulumi.get(self, "log_segment_bytes")

    @property
    @pulumi.getter(name="logSegmentDeleteDelayMs")
    def log_segment_delete_delay_ms(self) -> Optional[str]:
        return pulumi.get(self, "log_segment_delete_delay_ms")

    @property
    @pulumi.getter(name="maxConnectionsPerIp")
    def max_connections_per_ip(self) -> Optional[str]:
        return pulumi.get(self, "max_connections_per_ip")

    @property
    @pulumi.getter(name="maxIncrementalFetchSessionCacheSlots")
    def max_incremental_fetch_session_cache_slots(self) -> Optional[str]:
        return pulumi.get(self, "max_incremental_fetch_session_cache_slots")

    @property
    @pulumi.getter(name="messageMaxBytes")
    def message_max_bytes(self) -> Optional[str]:
        return pulumi.get(self, "message_max_bytes")

    @property
    @pulumi.getter(name="minInsyncReplicas")
    def min_insync_replicas(self) -> Optional[str]:
        return pulumi.get(self, "min_insync_replicas")

    @property
    @pulumi.getter(name="numPartitions")
    def num_partitions(self) -> Optional[str]:
        return pulumi.get(self, "num_partitions")

    @property
    @pulumi.getter(name="offsetsRetentionMinutes")
    def offsets_retention_minutes(self) -> Optional[str]:
        return pulumi.get(self, "offsets_retention_minutes")

    @property
    @pulumi.getter(name="producerPurgatoryPurgeIntervalRequests")
    def producer_purgatory_purge_interval_requests(self) -> Optional[str]:
        return pulumi.get(self, "producer_purgatory_purge_interval_requests")

    @property
    @pulumi.getter(name="replicaFetchMaxBytes")
    def replica_fetch_max_bytes(self) -> Optional[str]:
        return pulumi.get(self, "replica_fetch_max_bytes")

    @property
    @pulumi.getter(name="replicaFetchResponseMaxBytes")
    def replica_fetch_response_max_bytes(self) -> Optional[str]:
        return pulumi.get(self, "replica_fetch_response_max_bytes")

    @property
    @pulumi.getter(name="socketRequestMaxBytes")
    def socket_request_max_bytes(self) -> Optional[str]:
        return pulumi.get(self, "socket_request_max_bytes")

    @property
    @pulumi.getter(name="transactionRemoveExpiredTransactionCleanupIntervalMs")
    def transaction_remove_expired_transaction_cleanup_interval_ms(self) -> Optional[str]:
        return pulumi.get(self, "transaction_remove_expired_transaction_cleanup_interval_ms")

    @property
    @pulumi.getter(name="transactionStateLogSegmentBytes")
    def transaction_state_log_segment_bytes(self) -> Optional[str]:
        return pulumi.get(self, "transaction_state_log_segment_bytes")


@pulumi.output_type
class ServiceKafkaUserConfigKafkaAuthenticationMethods(dict):
    def __init__(__self__, *,
                 certificate: Optional[str] = None,
                 sasl: Optional[str] = None):
        if certificate is not None:
            pulumi.set(__self__, "certificate", certificate)
        if sasl is not None:
            pulumi.set(__self__, "sasl", sasl)

    @property
    @pulumi.getter
    def certificate(self) -> Optional[str]:
        return pulumi.get(self, "certificate")

    @property
    @pulumi.getter
    def sasl(self) -> Optional[str]:
        return pulumi.get(self, "sasl")


@pulumi.output_type
class ServiceKafkaUserConfigKafkaConnectConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "connectorClientConfigOverridePolicy":
            suggest = "connector_client_config_override_policy"
        elif key == "consumerAutoOffsetReset":
            suggest = "consumer_auto_offset_reset"
        elif key == "consumerFetchMaxBytes":
            suggest = "consumer_fetch_max_bytes"
        elif key == "consumerIsolationLevel":
            suggest = "consumer_isolation_level"
        elif key == "consumerMaxPartitionFetchBytes":
            suggest = "consumer_max_partition_fetch_bytes"
        elif key == "consumerMaxPollIntervalMs":
            suggest = "consumer_max_poll_interval_ms"
        elif key == "consumerMaxPollRecords":
            suggest = "consumer_max_poll_records"
        elif key == "offsetFlushIntervalMs":
            suggest = "offset_flush_interval_ms"
        elif key == "offsetFlushTimeoutMs":
            suggest = "offset_flush_timeout_ms"
        elif key == "producerMaxRequestSize":
            suggest = "producer_max_request_size"
        elif key == "sessionTimeoutMs":
            suggest = "session_timeout_ms"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ServiceKafkaUserConfigKafkaConnectConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ServiceKafkaUserConfigKafkaConnectConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ServiceKafkaUserConfigKafkaConnectConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 connector_client_config_override_policy: Optional[str] = None,
                 consumer_auto_offset_reset: Optional[str] = None,
                 consumer_fetch_max_bytes: Optional[str] = None,
                 consumer_isolation_level: Optional[str] = None,
                 consumer_max_partition_fetch_bytes: Optional[str] = None,
                 consumer_max_poll_interval_ms: Optional[str] = None,
                 consumer_max_poll_records: Optional[str] = None,
                 offset_flush_interval_ms: Optional[str] = None,
                 offset_flush_timeout_ms: Optional[str] = None,
                 producer_max_request_size: Optional[str] = None,
                 session_timeout_ms: Optional[str] = None):
        if connector_client_config_override_policy is not None:
            pulumi.set(__self__, "connector_client_config_override_policy", connector_client_config_override_policy)
        if consumer_auto_offset_reset is not None:
            pulumi.set(__self__, "consumer_auto_offset_reset", consumer_auto_offset_reset)
        if consumer_fetch_max_bytes is not None:
            pulumi.set(__self__, "consumer_fetch_max_bytes", consumer_fetch_max_bytes)
        if consumer_isolation_level is not None:
            pulumi.set(__self__, "consumer_isolation_level", consumer_isolation_level)
        if consumer_max_partition_fetch_bytes is not None:
            pulumi.set(__self__, "consumer_max_partition_fetch_bytes", consumer_max_partition_fetch_bytes)
        if consumer_max_poll_interval_ms is not None:
            pulumi.set(__self__, "consumer_max_poll_interval_ms", consumer_max_poll_interval_ms)
        if consumer_max_poll_records is not None:
            pulumi.set(__self__, "consumer_max_poll_records", consumer_max_poll_records)
        if offset_flush_interval_ms is not None:
            pulumi.set(__self__, "offset_flush_interval_ms", offset_flush_interval_ms)
        if offset_flush_timeout_ms is not None:
            pulumi.set(__self__, "offset_flush_timeout_ms", offset_flush_timeout_ms)
        if producer_max_request_size is not None:
            pulumi.set(__self__, "producer_max_request_size", producer_max_request_size)
        if session_timeout_ms is not None:
            pulumi.set(__self__, "session_timeout_ms", session_timeout_ms)

    @property
    @pulumi.getter(name="connectorClientConfigOverridePolicy")
    def connector_client_config_override_policy(self) -> Optional[str]:
        return pulumi.get(self, "connector_client_config_override_policy")

    @property
    @pulumi.getter(name="consumerAutoOffsetReset")
    def consumer_auto_offset_reset(self) -> Optional[str]:
        return pulumi.get(self, "consumer_auto_offset_reset")

    @property
    @pulumi.getter(name="consumerFetchMaxBytes")
    def consumer_fetch_max_bytes(self) -> Optional[str]:
        return pulumi.get(self, "consumer_fetch_max_bytes")

    @property
    @pulumi.getter(name="consumerIsolationLevel")
    def consumer_isolation_level(self) -> Optional[str]:
        return pulumi.get(self, "consumer_isolation_level")

    @property
    @pulumi.getter(name="consumerMaxPartitionFetchBytes")
    def consumer_max_partition_fetch_bytes(self) -> Optional[str]:
        return pulumi.get(self, "consumer_max_partition_fetch_bytes")

    @property
    @pulumi.getter(name="consumerMaxPollIntervalMs")
    def consumer_max_poll_interval_ms(self) -> Optional[str]:
        return pulumi.get(self, "consumer_max_poll_interval_ms")

    @property
    @pulumi.getter(name="consumerMaxPollRecords")
    def consumer_max_poll_records(self) -> Optional[str]:
        return pulumi.get(self, "consumer_max_poll_records")

    @property
    @pulumi.getter(name="offsetFlushIntervalMs")
    def offset_flush_interval_ms(self) -> Optional[str]:
        return pulumi.get(self, "offset_flush_interval_ms")

    @property
    @pulumi.getter(name="offsetFlushTimeoutMs")
    def offset_flush_timeout_ms(self) -> Optional[str]:
        return pulumi.get(self, "offset_flush_timeout_ms")

    @property
    @pulumi.getter(name="producerMaxRequestSize")
    def producer_max_request_size(self) -> Optional[str]:
        return pulumi.get(self, "producer_max_request_size")

    @property
    @pulumi.getter(name="sessionTimeoutMs")
    def session_timeout_ms(self) -> Optional[str]:
        return pulumi.get(self, "session_timeout_ms")


@pulumi.output_type
class ServiceKafkaUserConfigKafkaRestConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "consumerEnableAutoCommit":
            suggest = "consumer_enable_auto_commit"
        elif key == "consumerRequestMaxBytes":
            suggest = "consumer_request_max_bytes"
        elif key == "consumerRequestTimeoutMs":
            suggest = "consumer_request_timeout_ms"
        elif key == "producerAcks":
            suggest = "producer_acks"
        elif key == "producerLingerMs":
            suggest = "producer_linger_ms"
        elif key == "simpleconsumerPoolSizeMax":
            suggest = "simpleconsumer_pool_size_max"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ServiceKafkaUserConfigKafkaRestConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ServiceKafkaUserConfigKafkaRestConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ServiceKafkaUserConfigKafkaRestConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 consumer_enable_auto_commit: Optional[str] = None,
                 consumer_request_max_bytes: Optional[str] = None,
                 consumer_request_timeout_ms: Optional[str] = None,
                 producer_acks: Optional[str] = None,
                 producer_linger_ms: Optional[str] = None,
                 simpleconsumer_pool_size_max: Optional[str] = None):
        if consumer_enable_auto_commit is not None:
            pulumi.set(__self__, "consumer_enable_auto_commit", consumer_enable_auto_commit)
        if consumer_request_max_bytes is not None:
            pulumi.set(__self__, "consumer_request_max_bytes", consumer_request_max_bytes)
        if consumer_request_timeout_ms is not None:
            pulumi.set(__self__, "consumer_request_timeout_ms", consumer_request_timeout_ms)
        if producer_acks is not None:
            pulumi.set(__self__, "producer_acks", producer_acks)
        if producer_linger_ms is not None:
            pulumi.set(__self__, "producer_linger_ms", producer_linger_ms)
        if simpleconsumer_pool_size_max is not None:
            pulumi.set(__self__, "simpleconsumer_pool_size_max", simpleconsumer_pool_size_max)

    @property
    @pulumi.getter(name="consumerEnableAutoCommit")
    def consumer_enable_auto_commit(self) -> Optional[str]:
        return pulumi.get(self, "consumer_enable_auto_commit")

    @property
    @pulumi.getter(name="consumerRequestMaxBytes")
    def consumer_request_max_bytes(self) -> Optional[str]:
        return pulumi.get(self, "consumer_request_max_bytes")

    @property
    @pulumi.getter(name="consumerRequestTimeoutMs")
    def consumer_request_timeout_ms(self) -> Optional[str]:
        return pulumi.get(self, "consumer_request_timeout_ms")

    @property
    @pulumi.getter(name="producerAcks")
    def producer_acks(self) -> Optional[str]:
        return pulumi.get(self, "producer_acks")

    @property
    @pulumi.getter(name="producerLingerMs")
    def producer_linger_ms(self) -> Optional[str]:
        return pulumi.get(self, "producer_linger_ms")

    @property
    @pulumi.getter(name="simpleconsumerPoolSizeMax")
    def simpleconsumer_pool_size_max(self) -> Optional[str]:
        return pulumi.get(self, "simpleconsumer_pool_size_max")


@pulumi.output_type
class ServiceKafkaUserConfigPrivateAccess(dict):
    def __init__(__self__, *,
                 prometheus: Optional[str] = None):
        if prometheus is not None:
            pulumi.set(__self__, "prometheus", prometheus)

    @property
    @pulumi.getter
    def prometheus(self) -> Optional[str]:
        return pulumi.get(self, "prometheus")


@pulumi.output_type
class ServiceKafkaUserConfigPrivatelinkAccess(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "kafkaConnect":
            suggest = "kafka_connect"
        elif key == "kafkaRest":
            suggest = "kafka_rest"
        elif key == "schemaRegistry":
            suggest = "schema_registry"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ServiceKafkaUserConfigPrivatelinkAccess. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ServiceKafkaUserConfigPrivatelinkAccess.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ServiceKafkaUserConfigPrivatelinkAccess.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 kafka: Optional[str] = None,
                 kafka_connect: Optional[str] = None,
                 kafka_rest: Optional[str] = None,
                 schema_registry: Optional[str] = None):
        if kafka is not None:
            pulumi.set(__self__, "kafka", kafka)
        if kafka_connect is not None:
            pulumi.set(__self__, "kafka_connect", kafka_connect)
        if kafka_rest is not None:
            pulumi.set(__self__, "kafka_rest", kafka_rest)
        if schema_registry is not None:
            pulumi.set(__self__, "schema_registry", schema_registry)

    @property
    @pulumi.getter
    def kafka(self) -> Optional[str]:
        return pulumi.get(self, "kafka")

    @property
    @pulumi.getter(name="kafkaConnect")
    def kafka_connect(self) -> Optional[str]:
        return pulumi.get(self, "kafka_connect")

    @property
    @pulumi.getter(name="kafkaRest")
    def kafka_rest(self) -> Optional[str]:
        return pulumi.get(self, "kafka_rest")

    @property
    @pulumi.getter(name="schemaRegistry")
    def schema_registry(self) -> Optional[str]:
        return pulumi.get(self, "schema_registry")


@pulumi.output_type
class ServiceKafkaUserConfigPublicAccess(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "kafkaConnect":
            suggest = "kafka_connect"
        elif key == "kafkaRest":
            suggest = "kafka_rest"
        elif key == "schemaRegistry":
            suggest = "schema_registry"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ServiceKafkaUserConfigPublicAccess. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ServiceKafkaUserConfigPublicAccess.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ServiceKafkaUserConfigPublicAccess.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 kafka: Optional[str] = None,
                 kafka_connect: Optional[str] = None,
                 kafka_rest: Optional[str] = None,
                 prometheus: Optional[str] = None,
                 schema_registry: Optional[str] = None):
        if kafka is not None:
            pulumi.set(__self__, "kafka", kafka)
        if kafka_connect is not None:
            pulumi.set(__self__, "kafka_connect", kafka_connect)
        if kafka_rest is not None:
            pulumi.set(__self__, "kafka_rest", kafka_rest)
        if prometheus is not None:
            pulumi.set(__self__, "prometheus", prometheus)
        if schema_registry is not None:
            pulumi.set(__self__, "schema_registry", schema_registry)

    @property
    @pulumi.getter
    def kafka(self) -> Optional[str]:
        return pulumi.get(self, "kafka")

    @property
    @pulumi.getter(name="kafkaConnect")
    def kafka_connect(self) -> Optional[str]:
        return pulumi.get(self, "kafka_connect")

    @property
    @pulumi.getter(name="kafkaRest")
    def kafka_rest(self) -> Optional[str]:
        return pulumi.get(self, "kafka_rest")

    @property
    @pulumi.getter
    def prometheus(self) -> Optional[str]:
        return pulumi.get(self, "prometheus")

    @property
    @pulumi.getter(name="schemaRegistry")
    def schema_registry(self) -> Optional[str]:
        return pulumi.get(self, "schema_registry")


@pulumi.output_type
class ServiceKafkaUserConfigSchemaRegistryConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "leaderEligibility":
            suggest = "leader_eligibility"
        elif key == "topicName":
            suggest = "topic_name"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ServiceKafkaUserConfigSchemaRegistryConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ServiceKafkaUserConfigSchemaRegistryConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ServiceKafkaUserConfigSchemaRegistryConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 leader_eligibility: Optional[str] = None,
                 topic_name: Optional[str] = None):
        if leader_eligibility is not None:
            pulumi.set(__self__, "leader_eligibility", leader_eligibility)
        if topic_name is not None:
            pulumi.set(__self__, "topic_name", topic_name)

    @property
    @pulumi.getter(name="leaderEligibility")
    def leader_eligibility(self) -> Optional[str]:
        return pulumi.get(self, "leader_eligibility")

    @property
    @pulumi.getter(name="topicName")
    def topic_name(self) -> Optional[str]:
        return pulumi.get(self, "topic_name")


@pulumi.output_type
class ServiceMysql(dict):
    def __init__(__self__):
        pass


@pulumi.output_type
class ServiceMysqlUserConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "adminPassword":
            suggest = "admin_password"
        elif key == "adminUsername":
            suggest = "admin_username"
        elif key == "backupHour":
            suggest = "backup_hour"
        elif key == "backupMinute":
            suggest = "backup_minute"
        elif key == "binlogRetentionPeriod":
            suggest = "binlog_retention_period"
        elif key == "ipFilters":
            suggest = "ip_filters"
        elif key == "mysqlVersion":
            suggest = "mysql_version"
        elif key == "privateAccess":
            suggest = "private_access"
        elif key == "privatelinkAccess":
            suggest = "privatelink_access"
        elif key == "projectToForkFrom":
            suggest = "project_to_fork_from"
        elif key == "publicAccess":
            suggest = "public_access"
        elif key == "recoveryTargetTime":
            suggest = "recovery_target_time"
        elif key == "serviceToForkFrom":
            suggest = "service_to_fork_from"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ServiceMysqlUserConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ServiceMysqlUserConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ServiceMysqlUserConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 admin_password: Optional[str] = None,
                 admin_username: Optional[str] = None,
                 backup_hour: Optional[str] = None,
                 backup_minute: Optional[str] = None,
                 binlog_retention_period: Optional[str] = None,
                 ip_filters: Optional[Sequence[str]] = None,
                 migration: Optional['outputs.ServiceMysqlUserConfigMigration'] = None,
                 mysql: Optional['outputs.ServiceMysqlUserConfigMysql'] = None,
                 mysql_version: Optional[str] = None,
                 private_access: Optional['outputs.ServiceMysqlUserConfigPrivateAccess'] = None,
                 privatelink_access: Optional['outputs.ServiceMysqlUserConfigPrivatelinkAccess'] = None,
                 project_to_fork_from: Optional[str] = None,
                 public_access: Optional['outputs.ServiceMysqlUserConfigPublicAccess'] = None,
                 recovery_target_time: Optional[str] = None,
                 service_to_fork_from: Optional[str] = None):
        if admin_password is not None:
            pulumi.set(__self__, "admin_password", admin_password)
        if admin_username is not None:
            pulumi.set(__self__, "admin_username", admin_username)
        if backup_hour is not None:
            pulumi.set(__self__, "backup_hour", backup_hour)
        if backup_minute is not None:
            pulumi.set(__self__, "backup_minute", backup_minute)
        if binlog_retention_period is not None:
            pulumi.set(__self__, "binlog_retention_period", binlog_retention_period)
        if ip_filters is not None:
            pulumi.set(__self__, "ip_filters", ip_filters)
        if migration is not None:
            pulumi.set(__self__, "migration", migration)
        if mysql is not None:
            pulumi.set(__self__, "mysql", mysql)
        if mysql_version is not None:
            pulumi.set(__self__, "mysql_version", mysql_version)
        if private_access is not None:
            pulumi.set(__self__, "private_access", private_access)
        if privatelink_access is not None:
            pulumi.set(__self__, "privatelink_access", privatelink_access)
        if project_to_fork_from is not None:
            pulumi.set(__self__, "project_to_fork_from", project_to_fork_from)
        if public_access is not None:
            pulumi.set(__self__, "public_access", public_access)
        if recovery_target_time is not None:
            pulumi.set(__self__, "recovery_target_time", recovery_target_time)
        if service_to_fork_from is not None:
            pulumi.set(__self__, "service_to_fork_from", service_to_fork_from)

    @property
    @pulumi.getter(name="adminPassword")
    def admin_password(self) -> Optional[str]:
        return pulumi.get(self, "admin_password")

    @property
    @pulumi.getter(name="adminUsername")
    def admin_username(self) -> Optional[str]:
        return pulumi.get(self, "admin_username")

    @property
    @pulumi.getter(name="backupHour")
    def backup_hour(self) -> Optional[str]:
        return pulumi.get(self, "backup_hour")

    @property
    @pulumi.getter(name="backupMinute")
    def backup_minute(self) -> Optional[str]:
        return pulumi.get(self, "backup_minute")

    @property
    @pulumi.getter(name="binlogRetentionPeriod")
    def binlog_retention_period(self) -> Optional[str]:
        return pulumi.get(self, "binlog_retention_period")

    @property
    @pulumi.getter(name="ipFilters")
    def ip_filters(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "ip_filters")

    @property
    @pulumi.getter
    def migration(self) -> Optional['outputs.ServiceMysqlUserConfigMigration']:
        return pulumi.get(self, "migration")

    @property
    @pulumi.getter
    def mysql(self) -> Optional['outputs.ServiceMysqlUserConfigMysql']:
        return pulumi.get(self, "mysql")

    @property
    @pulumi.getter(name="mysqlVersion")
    def mysql_version(self) -> Optional[str]:
        return pulumi.get(self, "mysql_version")

    @property
    @pulumi.getter(name="privateAccess")
    def private_access(self) -> Optional['outputs.ServiceMysqlUserConfigPrivateAccess']:
        return pulumi.get(self, "private_access")

    @property
    @pulumi.getter(name="privatelinkAccess")
    def privatelink_access(self) -> Optional['outputs.ServiceMysqlUserConfigPrivatelinkAccess']:
        return pulumi.get(self, "privatelink_access")

    @property
    @pulumi.getter(name="projectToForkFrom")
    def project_to_fork_from(self) -> Optional[str]:
        return pulumi.get(self, "project_to_fork_from")

    @property
    @pulumi.getter(name="publicAccess")
    def public_access(self) -> Optional['outputs.ServiceMysqlUserConfigPublicAccess']:
        return pulumi.get(self, "public_access")

    @property
    @pulumi.getter(name="recoveryTargetTime")
    def recovery_target_time(self) -> Optional[str]:
        return pulumi.get(self, "recovery_target_time")

    @property
    @pulumi.getter(name="serviceToForkFrom")
    def service_to_fork_from(self) -> Optional[str]:
        return pulumi.get(self, "service_to_fork_from")


@pulumi.output_type
class ServiceMysqlUserConfigMigration(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "ignoreDbs":
            suggest = "ignore_dbs"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ServiceMysqlUserConfigMigration. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ServiceMysqlUserConfigMigration.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ServiceMysqlUserConfigMigration.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 dbname: Optional[str] = None,
                 host: Optional[str] = None,
                 ignore_dbs: Optional[str] = None,
                 password: Optional[str] = None,
                 port: Optional[str] = None,
                 ssl: Optional[str] = None,
                 username: Optional[str] = None):
        if dbname is not None:
            pulumi.set(__self__, "dbname", dbname)
        if host is not None:
            pulumi.set(__self__, "host", host)
        if ignore_dbs is not None:
            pulumi.set(__self__, "ignore_dbs", ignore_dbs)
        if password is not None:
            pulumi.set(__self__, "password", password)
        if port is not None:
            pulumi.set(__self__, "port", port)
        if ssl is not None:
            pulumi.set(__self__, "ssl", ssl)
        if username is not None:
            pulumi.set(__self__, "username", username)

    @property
    @pulumi.getter
    def dbname(self) -> Optional[str]:
        return pulumi.get(self, "dbname")

    @property
    @pulumi.getter
    def host(self) -> Optional[str]:
        return pulumi.get(self, "host")

    @property
    @pulumi.getter(name="ignoreDbs")
    def ignore_dbs(self) -> Optional[str]:
        return pulumi.get(self, "ignore_dbs")

    @property
    @pulumi.getter
    def password(self) -> Optional[str]:
        return pulumi.get(self, "password")

    @property
    @pulumi.getter
    def port(self) -> Optional[str]:
        return pulumi.get(self, "port")

    @property
    @pulumi.getter
    def ssl(self) -> Optional[str]:
        return pulumi.get(self, "ssl")

    @property
    @pulumi.getter
    def username(self) -> Optional[str]:
        return pulumi.get(self, "username")


@pulumi.output_type
class ServiceMysqlUserConfigMysql(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "connectTimeout":
            suggest = "connect_timeout"
        elif key == "defaultTimeZone":
            suggest = "default_time_zone"
        elif key == "groupConcatMaxLen":
            suggest = "group_concat_max_len"
        elif key == "informationSchemaStatsExpiry":
            suggest = "information_schema_stats_expiry"
        elif key == "innodbFtMinTokenSize":
            suggest = "innodb_ft_min_token_size"
        elif key == "innodbFtServerStopwordTable":
            suggest = "innodb_ft_server_stopword_table"
        elif key == "innodbLockWaitTimeout":
            suggest = "innodb_lock_wait_timeout"
        elif key == "innodbLogBufferSize":
            suggest = "innodb_log_buffer_size"
        elif key == "innodbOnlineAlterLogMaxSize":
            suggest = "innodb_online_alter_log_max_size"
        elif key == "innodbPrintAllDeadlocks":
            suggest = "innodb_print_all_deadlocks"
        elif key == "innodbRollbackOnTimeout":
            suggest = "innodb_rollback_on_timeout"
        elif key == "interactiveTimeout":
            suggest = "interactive_timeout"
        elif key == "longQueryTime":
            suggest = "long_query_time"
        elif key == "maxAllowedPacket":
            suggest = "max_allowed_packet"
        elif key == "maxHeapTableSize":
            suggest = "max_heap_table_size"
        elif key == "netReadTimeout":
            suggest = "net_read_timeout"
        elif key == "netWriteTimeout":
            suggest = "net_write_timeout"
        elif key == "slowQueryLog":
            suggest = "slow_query_log"
        elif key == "sortBufferSize":
            suggest = "sort_buffer_size"
        elif key == "sqlMode":
            suggest = "sql_mode"
        elif key == "sqlRequirePrimaryKey":
            suggest = "sql_require_primary_key"
        elif key == "tmpTableSize":
            suggest = "tmp_table_size"
        elif key == "waitTimeout":
            suggest = "wait_timeout"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ServiceMysqlUserConfigMysql. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ServiceMysqlUserConfigMysql.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ServiceMysqlUserConfigMysql.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 connect_timeout: Optional[str] = None,
                 default_time_zone: Optional[str] = None,
                 group_concat_max_len: Optional[str] = None,
                 information_schema_stats_expiry: Optional[str] = None,
                 innodb_ft_min_token_size: Optional[str] = None,
                 innodb_ft_server_stopword_table: Optional[str] = None,
                 innodb_lock_wait_timeout: Optional[str] = None,
                 innodb_log_buffer_size: Optional[str] = None,
                 innodb_online_alter_log_max_size: Optional[str] = None,
                 innodb_print_all_deadlocks: Optional[str] = None,
                 innodb_rollback_on_timeout: Optional[str] = None,
                 interactive_timeout: Optional[str] = None,
                 long_query_time: Optional[str] = None,
                 max_allowed_packet: Optional[str] = None,
                 max_heap_table_size: Optional[str] = None,
                 net_read_timeout: Optional[str] = None,
                 net_write_timeout: Optional[str] = None,
                 slow_query_log: Optional[str] = None,
                 sort_buffer_size: Optional[str] = None,
                 sql_mode: Optional[str] = None,
                 sql_require_primary_key: Optional[str] = None,
                 tmp_table_size: Optional[str] = None,
                 wait_timeout: Optional[str] = None):
        if connect_timeout is not None:
            pulumi.set(__self__, "connect_timeout", connect_timeout)
        if default_time_zone is not None:
            pulumi.set(__self__, "default_time_zone", default_time_zone)
        if group_concat_max_len is not None:
            pulumi.set(__self__, "group_concat_max_len", group_concat_max_len)
        if information_schema_stats_expiry is not None:
            pulumi.set(__self__, "information_schema_stats_expiry", information_schema_stats_expiry)
        if innodb_ft_min_token_size is not None:
            pulumi.set(__self__, "innodb_ft_min_token_size", innodb_ft_min_token_size)
        if innodb_ft_server_stopword_table is not None:
            pulumi.set(__self__, "innodb_ft_server_stopword_table", innodb_ft_server_stopword_table)
        if innodb_lock_wait_timeout is not None:
            pulumi.set(__self__, "innodb_lock_wait_timeout", innodb_lock_wait_timeout)
        if innodb_log_buffer_size is not None:
            pulumi.set(__self__, "innodb_log_buffer_size", innodb_log_buffer_size)
        if innodb_online_alter_log_max_size is not None:
            pulumi.set(__self__, "innodb_online_alter_log_max_size", innodb_online_alter_log_max_size)
        if innodb_print_all_deadlocks is not None:
            pulumi.set(__self__, "innodb_print_all_deadlocks", innodb_print_all_deadlocks)
        if innodb_rollback_on_timeout is not None:
            pulumi.set(__self__, "innodb_rollback_on_timeout", innodb_rollback_on_timeout)
        if interactive_timeout is not None:
            pulumi.set(__self__, "interactive_timeout", interactive_timeout)
        if long_query_time is not None:
            pulumi.set(__self__, "long_query_time", long_query_time)
        if max_allowed_packet is not None:
            pulumi.set(__self__, "max_allowed_packet", max_allowed_packet)
        if max_heap_table_size is not None:
            pulumi.set(__self__, "max_heap_table_size", max_heap_table_size)
        if net_read_timeout is not None:
            pulumi.set(__self__, "net_read_timeout", net_read_timeout)
        if net_write_timeout is not None:
            pulumi.set(__self__, "net_write_timeout", net_write_timeout)
        if slow_query_log is not None:
            pulumi.set(__self__, "slow_query_log", slow_query_log)
        if sort_buffer_size is not None:
            pulumi.set(__self__, "sort_buffer_size", sort_buffer_size)
        if sql_mode is not None:
            pulumi.set(__self__, "sql_mode", sql_mode)
        if sql_require_primary_key is not None:
            pulumi.set(__self__, "sql_require_primary_key", sql_require_primary_key)
        if tmp_table_size is not None:
            pulumi.set(__self__, "tmp_table_size", tmp_table_size)
        if wait_timeout is not None:
            pulumi.set(__self__, "wait_timeout", wait_timeout)

    @property
    @pulumi.getter(name="connectTimeout")
    def connect_timeout(self) -> Optional[str]:
        return pulumi.get(self, "connect_timeout")

    @property
    @pulumi.getter(name="defaultTimeZone")
    def default_time_zone(self) -> Optional[str]:
        return pulumi.get(self, "default_time_zone")

    @property
    @pulumi.getter(name="groupConcatMaxLen")
    def group_concat_max_len(self) -> Optional[str]:
        return pulumi.get(self, "group_concat_max_len")

    @property
    @pulumi.getter(name="informationSchemaStatsExpiry")
    def information_schema_stats_expiry(self) -> Optional[str]:
        return pulumi.get(self, "information_schema_stats_expiry")

    @property
    @pulumi.getter(name="innodbFtMinTokenSize")
    def innodb_ft_min_token_size(self) -> Optional[str]:
        return pulumi.get(self, "innodb_ft_min_token_size")

    @property
    @pulumi.getter(name="innodbFtServerStopwordTable")
    def innodb_ft_server_stopword_table(self) -> Optional[str]:
        return pulumi.get(self, "innodb_ft_server_stopword_table")

    @property
    @pulumi.getter(name="innodbLockWaitTimeout")
    def innodb_lock_wait_timeout(self) -> Optional[str]:
        return pulumi.get(self, "innodb_lock_wait_timeout")

    @property
    @pulumi.getter(name="innodbLogBufferSize")
    def innodb_log_buffer_size(self) -> Optional[str]:
        return pulumi.get(self, "innodb_log_buffer_size")

    @property
    @pulumi.getter(name="innodbOnlineAlterLogMaxSize")
    def innodb_online_alter_log_max_size(self) -> Optional[str]:
        return pulumi.get(self, "innodb_online_alter_log_max_size")

    @property
    @pulumi.getter(name="innodbPrintAllDeadlocks")
    def innodb_print_all_deadlocks(self) -> Optional[str]:
        return pulumi.get(self, "innodb_print_all_deadlocks")

    @property
    @pulumi.getter(name="innodbRollbackOnTimeout")
    def innodb_rollback_on_timeout(self) -> Optional[str]:
        return pulumi.get(self, "innodb_rollback_on_timeout")

    @property
    @pulumi.getter(name="interactiveTimeout")
    def interactive_timeout(self) -> Optional[str]:
        return pulumi.get(self, "interactive_timeout")

    @property
    @pulumi.getter(name="longQueryTime")
    def long_query_time(self) -> Optional[str]:
        return pulumi.get(self, "long_query_time")

    @property
    @pulumi.getter(name="maxAllowedPacket")
    def max_allowed_packet(self) -> Optional[str]:
        return pulumi.get(self, "max_allowed_packet")

    @property
    @pulumi.getter(name="maxHeapTableSize")
    def max_heap_table_size(self) -> Optional[str]:
        return pulumi.get(self, "max_heap_table_size")

    @property
    @pulumi.getter(name="netReadTimeout")
    def net_read_timeout(self) -> Optional[str]:
        return pulumi.get(self, "net_read_timeout")

    @property
    @pulumi.getter(name="netWriteTimeout")
    def net_write_timeout(self) -> Optional[str]:
        return pulumi.get(self, "net_write_timeout")

    @property
    @pulumi.getter(name="slowQueryLog")
    def slow_query_log(self) -> Optional[str]:
        return pulumi.get(self, "slow_query_log")

    @property
    @pulumi.getter(name="sortBufferSize")
    def sort_buffer_size(self) -> Optional[str]:
        return pulumi.get(self, "sort_buffer_size")

    @property
    @pulumi.getter(name="sqlMode")
    def sql_mode(self) -> Optional[str]:
        return pulumi.get(self, "sql_mode")

    @property
    @pulumi.getter(name="sqlRequirePrimaryKey")
    def sql_require_primary_key(self) -> Optional[str]:
        return pulumi.get(self, "sql_require_primary_key")

    @property
    @pulumi.getter(name="tmpTableSize")
    def tmp_table_size(self) -> Optional[str]:
        return pulumi.get(self, "tmp_table_size")

    @property
    @pulumi.getter(name="waitTimeout")
    def wait_timeout(self) -> Optional[str]:
        return pulumi.get(self, "wait_timeout")


@pulumi.output_type
class ServiceMysqlUserConfigPrivateAccess(dict):
    def __init__(__self__, *,
                 mysql: Optional[str] = None,
                 mysqlx: Optional[str] = None,
                 prometheus: Optional[str] = None):
        if mysql is not None:
            pulumi.set(__self__, "mysql", mysql)
        if mysqlx is not None:
            pulumi.set(__self__, "mysqlx", mysqlx)
        if prometheus is not None:
            pulumi.set(__self__, "prometheus", prometheus)

    @property
    @pulumi.getter
    def mysql(self) -> Optional[str]:
        return pulumi.get(self, "mysql")

    @property
    @pulumi.getter
    def mysqlx(self) -> Optional[str]:
        return pulumi.get(self, "mysqlx")

    @property
    @pulumi.getter
    def prometheus(self) -> Optional[str]:
        return pulumi.get(self, "prometheus")


@pulumi.output_type
class ServiceMysqlUserConfigPrivatelinkAccess(dict):
    def __init__(__self__, *,
                 mysql: Optional[str] = None,
                 mysqlx: Optional[str] = None):
        if mysql is not None:
            pulumi.set(__self__, "mysql", mysql)
        if mysqlx is not None:
            pulumi.set(__self__, "mysqlx", mysqlx)

    @property
    @pulumi.getter
    def mysql(self) -> Optional[str]:
        return pulumi.get(self, "mysql")

    @property
    @pulumi.getter
    def mysqlx(self) -> Optional[str]:
        return pulumi.get(self, "mysqlx")


@pulumi.output_type
class ServiceMysqlUserConfigPublicAccess(dict):
    def __init__(__self__, *,
                 mysql: Optional[str] = None,
                 mysqlx: Optional[str] = None,
                 prometheus: Optional[str] = None):
        if mysql is not None:
            pulumi.set(__self__, "mysql", mysql)
        if mysqlx is not None:
            pulumi.set(__self__, "mysqlx", mysqlx)
        if prometheus is not None:
            pulumi.set(__self__, "prometheus", prometheus)

    @property
    @pulumi.getter
    def mysql(self) -> Optional[str]:
        return pulumi.get(self, "mysql")

    @property
    @pulumi.getter
    def mysqlx(self) -> Optional[str]:
        return pulumi.get(self, "mysqlx")

    @property
    @pulumi.getter
    def prometheus(self) -> Optional[str]:
        return pulumi.get(self, "prometheus")


@pulumi.output_type
class ServicePg(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "replicaUri":
            suggest = "replica_uri"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ServicePg. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ServicePg.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ServicePg.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 dbname: Optional[str] = None,
                 host: Optional[str] = None,
                 password: Optional[str] = None,
                 port: Optional[int] = None,
                 replica_uri: Optional[str] = None,
                 sslmode: Optional[str] = None,
                 uri: Optional[str] = None,
                 user: Optional[str] = None):
        if dbname is not None:
            pulumi.set(__self__, "dbname", dbname)
        if host is not None:
            pulumi.set(__self__, "host", host)
        if password is not None:
            pulumi.set(__self__, "password", password)
        if port is not None:
            pulumi.set(__self__, "port", port)
        if replica_uri is not None:
            pulumi.set(__self__, "replica_uri", replica_uri)
        if sslmode is not None:
            pulumi.set(__self__, "sslmode", sslmode)
        if uri is not None:
            pulumi.set(__self__, "uri", uri)
        if user is not None:
            pulumi.set(__self__, "user", user)

    @property
    @pulumi.getter
    def dbname(self) -> Optional[str]:
        return pulumi.get(self, "dbname")

    @property
    @pulumi.getter
    def host(self) -> Optional[str]:
        return pulumi.get(self, "host")

    @property
    @pulumi.getter
    def password(self) -> Optional[str]:
        return pulumi.get(self, "password")

    @property
    @pulumi.getter
    def port(self) -> Optional[int]:
        return pulumi.get(self, "port")

    @property
    @pulumi.getter(name="replicaUri")
    def replica_uri(self) -> Optional[str]:
        return pulumi.get(self, "replica_uri")

    @property
    @pulumi.getter
    def sslmode(self) -> Optional[str]:
        return pulumi.get(self, "sslmode")

    @property
    @pulumi.getter
    def uri(self) -> Optional[str]:
        return pulumi.get(self, "uri")

    @property
    @pulumi.getter
    def user(self) -> Optional[str]:
        return pulumi.get(self, "user")


@pulumi.output_type
class ServicePgUserConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "adminPassword":
            suggest = "admin_password"
        elif key == "adminUsername":
            suggest = "admin_username"
        elif key == "backupHour":
            suggest = "backup_hour"
        elif key == "backupMinute":
            suggest = "backup_minute"
        elif key == "ipFilters":
            suggest = "ip_filters"
        elif key == "pgReadReplica":
            suggest = "pg_read_replica"
        elif key == "pgServiceToForkFrom":
            suggest = "pg_service_to_fork_from"
        elif key == "pgVersion":
            suggest = "pg_version"
        elif key == "privateAccess":
            suggest = "private_access"
        elif key == "privatelinkAccess":
            suggest = "privatelink_access"
        elif key == "projectToForkFrom":
            suggest = "project_to_fork_from"
        elif key == "publicAccess":
            suggest = "public_access"
        elif key == "recoveryTargetTime":
            suggest = "recovery_target_time"
        elif key == "serviceToForkFrom":
            suggest = "service_to_fork_from"
        elif key == "sharedBuffersPercentage":
            suggest = "shared_buffers_percentage"
        elif key == "synchronousReplication":
            suggest = "synchronous_replication"
        elif key == "workMem":
            suggest = "work_mem"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ServicePgUserConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ServicePgUserConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ServicePgUserConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 admin_password: Optional[str] = None,
                 admin_username: Optional[str] = None,
                 backup_hour: Optional[str] = None,
                 backup_minute: Optional[str] = None,
                 ip_filters: Optional[Sequence[str]] = None,
                 migration: Optional['outputs.ServicePgUserConfigMigration'] = None,
                 pg: Optional['outputs.ServicePgUserConfigPg'] = None,
                 pg_read_replica: Optional[str] = None,
                 pg_service_to_fork_from: Optional[str] = None,
                 pg_version: Optional[str] = None,
                 pgbouncer: Optional['outputs.ServicePgUserConfigPgbouncer'] = None,
                 pglookout: Optional['outputs.ServicePgUserConfigPglookout'] = None,
                 private_access: Optional['outputs.ServicePgUserConfigPrivateAccess'] = None,
                 privatelink_access: Optional['outputs.ServicePgUserConfigPrivatelinkAccess'] = None,
                 project_to_fork_from: Optional[str] = None,
                 public_access: Optional['outputs.ServicePgUserConfigPublicAccess'] = None,
                 recovery_target_time: Optional[str] = None,
                 service_to_fork_from: Optional[str] = None,
                 shared_buffers_percentage: Optional[str] = None,
                 synchronous_replication: Optional[str] = None,
                 timescaledb: Optional['outputs.ServicePgUserConfigTimescaledb'] = None,
                 variant: Optional[str] = None,
                 work_mem: Optional[str] = None):
        if admin_password is not None:
            pulumi.set(__self__, "admin_password", admin_password)
        if admin_username is not None:
            pulumi.set(__self__, "admin_username", admin_username)
        if backup_hour is not None:
            pulumi.set(__self__, "backup_hour", backup_hour)
        if backup_minute is not None:
            pulumi.set(__self__, "backup_minute", backup_minute)
        if ip_filters is not None:
            pulumi.set(__self__, "ip_filters", ip_filters)
        if migration is not None:
            pulumi.set(__self__, "migration", migration)
        if pg is not None:
            pulumi.set(__self__, "pg", pg)
        if pg_read_replica is not None:
            pulumi.set(__self__, "pg_read_replica", pg_read_replica)
        if pg_service_to_fork_from is not None:
            pulumi.set(__self__, "pg_service_to_fork_from", pg_service_to_fork_from)
        if pg_version is not None:
            pulumi.set(__self__, "pg_version", pg_version)
        if pgbouncer is not None:
            pulumi.set(__self__, "pgbouncer", pgbouncer)
        if pglookout is not None:
            pulumi.set(__self__, "pglookout", pglookout)
        if private_access is not None:
            pulumi.set(__self__, "private_access", private_access)
        if privatelink_access is not None:
            pulumi.set(__self__, "privatelink_access", privatelink_access)
        if project_to_fork_from is not None:
            pulumi.set(__self__, "project_to_fork_from", project_to_fork_from)
        if public_access is not None:
            pulumi.set(__self__, "public_access", public_access)
        if recovery_target_time is not None:
            pulumi.set(__self__, "recovery_target_time", recovery_target_time)
        if service_to_fork_from is not None:
            pulumi.set(__self__, "service_to_fork_from", service_to_fork_from)
        if shared_buffers_percentage is not None:
            pulumi.set(__self__, "shared_buffers_percentage", shared_buffers_percentage)
        if synchronous_replication is not None:
            pulumi.set(__self__, "synchronous_replication", synchronous_replication)
        if timescaledb is not None:
            pulumi.set(__self__, "timescaledb", timescaledb)
        if variant is not None:
            pulumi.set(__self__, "variant", variant)
        if work_mem is not None:
            pulumi.set(__self__, "work_mem", work_mem)

    @property
    @pulumi.getter(name="adminPassword")
    def admin_password(self) -> Optional[str]:
        return pulumi.get(self, "admin_password")

    @property
    @pulumi.getter(name="adminUsername")
    def admin_username(self) -> Optional[str]:
        return pulumi.get(self, "admin_username")

    @property
    @pulumi.getter(name="backupHour")
    def backup_hour(self) -> Optional[str]:
        return pulumi.get(self, "backup_hour")

    @property
    @pulumi.getter(name="backupMinute")
    def backup_minute(self) -> Optional[str]:
        return pulumi.get(self, "backup_minute")

    @property
    @pulumi.getter(name="ipFilters")
    def ip_filters(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "ip_filters")

    @property
    @pulumi.getter
    def migration(self) -> Optional['outputs.ServicePgUserConfigMigration']:
        return pulumi.get(self, "migration")

    @property
    @pulumi.getter
    def pg(self) -> Optional['outputs.ServicePgUserConfigPg']:
        return pulumi.get(self, "pg")

    @property
    @pulumi.getter(name="pgReadReplica")
    def pg_read_replica(self) -> Optional[str]:
        return pulumi.get(self, "pg_read_replica")

    @property
    @pulumi.getter(name="pgServiceToForkFrom")
    def pg_service_to_fork_from(self) -> Optional[str]:
        return pulumi.get(self, "pg_service_to_fork_from")

    @property
    @pulumi.getter(name="pgVersion")
    def pg_version(self) -> Optional[str]:
        return pulumi.get(self, "pg_version")

    @property
    @pulumi.getter
    def pgbouncer(self) -> Optional['outputs.ServicePgUserConfigPgbouncer']:
        return pulumi.get(self, "pgbouncer")

    @property
    @pulumi.getter
    def pglookout(self) -> Optional['outputs.ServicePgUserConfigPglookout']:
        return pulumi.get(self, "pglookout")

    @property
    @pulumi.getter(name="privateAccess")
    def private_access(self) -> Optional['outputs.ServicePgUserConfigPrivateAccess']:
        return pulumi.get(self, "private_access")

    @property
    @pulumi.getter(name="privatelinkAccess")
    def privatelink_access(self) -> Optional['outputs.ServicePgUserConfigPrivatelinkAccess']:
        return pulumi.get(self, "privatelink_access")

    @property
    @pulumi.getter(name="projectToForkFrom")
    def project_to_fork_from(self) -> Optional[str]:
        return pulumi.get(self, "project_to_fork_from")

    @property
    @pulumi.getter(name="publicAccess")
    def public_access(self) -> Optional['outputs.ServicePgUserConfigPublicAccess']:
        return pulumi.get(self, "public_access")

    @property
    @pulumi.getter(name="recoveryTargetTime")
    def recovery_target_time(self) -> Optional[str]:
        return pulumi.get(self, "recovery_target_time")

    @property
    @pulumi.getter(name="serviceToForkFrom")
    def service_to_fork_from(self) -> Optional[str]:
        return pulumi.get(self, "service_to_fork_from")

    @property
    @pulumi.getter(name="sharedBuffersPercentage")
    def shared_buffers_percentage(self) -> Optional[str]:
        return pulumi.get(self, "shared_buffers_percentage")

    @property
    @pulumi.getter(name="synchronousReplication")
    def synchronous_replication(self) -> Optional[str]:
        return pulumi.get(self, "synchronous_replication")

    @property
    @pulumi.getter
    def timescaledb(self) -> Optional['outputs.ServicePgUserConfigTimescaledb']:
        return pulumi.get(self, "timescaledb")

    @property
    @pulumi.getter
    def variant(self) -> Optional[str]:
        return pulumi.get(self, "variant")

    @property
    @pulumi.getter(name="workMem")
    def work_mem(self) -> Optional[str]:
        return pulumi.get(self, "work_mem")


@pulumi.output_type
class ServicePgUserConfigMigration(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "ignoreDbs":
            suggest = "ignore_dbs"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ServicePgUserConfigMigration. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ServicePgUserConfigMigration.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ServicePgUserConfigMigration.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 dbname: Optional[str] = None,
                 host: Optional[str] = None,
                 ignore_dbs: Optional[str] = None,
                 password: Optional[str] = None,
                 port: Optional[str] = None,
                 ssl: Optional[str] = None,
                 username: Optional[str] = None):
        if dbname is not None:
            pulumi.set(__self__, "dbname", dbname)
        if host is not None:
            pulumi.set(__self__, "host", host)
        if ignore_dbs is not None:
            pulumi.set(__self__, "ignore_dbs", ignore_dbs)
        if password is not None:
            pulumi.set(__self__, "password", password)
        if port is not None:
            pulumi.set(__self__, "port", port)
        if ssl is not None:
            pulumi.set(__self__, "ssl", ssl)
        if username is not None:
            pulumi.set(__self__, "username", username)

    @property
    @pulumi.getter
    def dbname(self) -> Optional[str]:
        return pulumi.get(self, "dbname")

    @property
    @pulumi.getter
    def host(self) -> Optional[str]:
        return pulumi.get(self, "host")

    @property
    @pulumi.getter(name="ignoreDbs")
    def ignore_dbs(self) -> Optional[str]:
        return pulumi.get(self, "ignore_dbs")

    @property
    @pulumi.getter
    def password(self) -> Optional[str]:
        return pulumi.get(self, "password")

    @property
    @pulumi.getter
    def port(self) -> Optional[str]:
        return pulumi.get(self, "port")

    @property
    @pulumi.getter
    def ssl(self) -> Optional[str]:
        return pulumi.get(self, "ssl")

    @property
    @pulumi.getter
    def username(self) -> Optional[str]:
        return pulumi.get(self, "username")


@pulumi.output_type
class ServicePgUserConfigPg(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "autovacuumAnalyzeScaleFactor":
            suggest = "autovacuum_analyze_scale_factor"
        elif key == "autovacuumAnalyzeThreshold":
            suggest = "autovacuum_analyze_threshold"
        elif key == "autovacuumFreezeMaxAge":
            suggest = "autovacuum_freeze_max_age"
        elif key == "autovacuumMaxWorkers":
            suggest = "autovacuum_max_workers"
        elif key == "autovacuumNaptime":
            suggest = "autovacuum_naptime"
        elif key == "autovacuumVacuumCostDelay":
            suggest = "autovacuum_vacuum_cost_delay"
        elif key == "autovacuumVacuumCostLimit":
            suggest = "autovacuum_vacuum_cost_limit"
        elif key == "autovacuumVacuumScaleFactor":
            suggest = "autovacuum_vacuum_scale_factor"
        elif key == "autovacuumVacuumThreshold":
            suggest = "autovacuum_vacuum_threshold"
        elif key == "deadlockTimeout":
            suggest = "deadlock_timeout"
        elif key == "idleInTransactionSessionTimeout":
            suggest = "idle_in_transaction_session_timeout"
        elif key == "logAutovacuumMinDuration":
            suggest = "log_autovacuum_min_duration"
        elif key == "logErrorVerbosity":
            suggest = "log_error_verbosity"
        elif key == "logLinePrefix":
            suggest = "log_line_prefix"
        elif key == "logMinDurationStatement":
            suggest = "log_min_duration_statement"
        elif key == "maxFilesPerProcess":
            suggest = "max_files_per_process"
        elif key == "maxLocksPerTransaction":
            suggest = "max_locks_per_transaction"
        elif key == "maxLogicalReplicationWorkers":
            suggest = "max_logical_replication_workers"
        elif key == "maxParallelWorkers":
            suggest = "max_parallel_workers"
        elif key == "maxParallelWorkersPerGather":
            suggest = "max_parallel_workers_per_gather"
        elif key == "maxPredLocksPerTransaction":
            suggest = "max_pred_locks_per_transaction"
        elif key == "maxPreparedTransactions":
            suggest = "max_prepared_transactions"
        elif key == "maxReplicationSlots":
            suggest = "max_replication_slots"
        elif key == "maxStackDepth":
            suggest = "max_stack_depth"
        elif key == "maxStandbyArchiveDelay":
            suggest = "max_standby_archive_delay"
        elif key == "maxStandbyStreamingDelay":
            suggest = "max_standby_streaming_delay"
        elif key == "maxWalSenders":
            suggest = "max_wal_senders"
        elif key == "maxWorkerProcesses":
            suggest = "max_worker_processes"
        elif key == "pgPartmanBgwInterval":
            suggest = "pg_partman_bgw_interval"
        elif key == "pgPartmanBgwRole":
            suggest = "pg_partman_bgw_role"
        elif key == "pgStatStatementsTrack":
            suggest = "pg_stat_statements_track"
        elif key == "tempFileLimit":
            suggest = "temp_file_limit"
        elif key == "trackActivityQuerySize":
            suggest = "track_activity_query_size"
        elif key == "trackCommitTimestamp":
            suggest = "track_commit_timestamp"
        elif key == "trackFunctions":
            suggest = "track_functions"
        elif key == "trackIoTiming":
            suggest = "track_io_timing"
        elif key == "walSenderTimeout":
            suggest = "wal_sender_timeout"
        elif key == "walWriterDelay":
            suggest = "wal_writer_delay"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ServicePgUserConfigPg. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ServicePgUserConfigPg.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ServicePgUserConfigPg.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 autovacuum_analyze_scale_factor: Optional[str] = None,
                 autovacuum_analyze_threshold: Optional[str] = None,
                 autovacuum_freeze_max_age: Optional[str] = None,
                 autovacuum_max_workers: Optional[str] = None,
                 autovacuum_naptime: Optional[str] = None,
                 autovacuum_vacuum_cost_delay: Optional[str] = None,
                 autovacuum_vacuum_cost_limit: Optional[str] = None,
                 autovacuum_vacuum_scale_factor: Optional[str] = None,
                 autovacuum_vacuum_threshold: Optional[str] = None,
                 deadlock_timeout: Optional[str] = None,
                 idle_in_transaction_session_timeout: Optional[str] = None,
                 jit: Optional[str] = None,
                 log_autovacuum_min_duration: Optional[str] = None,
                 log_error_verbosity: Optional[str] = None,
                 log_line_prefix: Optional[str] = None,
                 log_min_duration_statement: Optional[str] = None,
                 max_files_per_process: Optional[str] = None,
                 max_locks_per_transaction: Optional[str] = None,
                 max_logical_replication_workers: Optional[str] = None,
                 max_parallel_workers: Optional[str] = None,
                 max_parallel_workers_per_gather: Optional[str] = None,
                 max_pred_locks_per_transaction: Optional[str] = None,
                 max_prepared_transactions: Optional[str] = None,
                 max_replication_slots: Optional[str] = None,
                 max_stack_depth: Optional[str] = None,
                 max_standby_archive_delay: Optional[str] = None,
                 max_standby_streaming_delay: Optional[str] = None,
                 max_wal_senders: Optional[str] = None,
                 max_worker_processes: Optional[str] = None,
                 pg_partman_bgw_interval: Optional[str] = None,
                 pg_partman_bgw_role: Optional[str] = None,
                 pg_stat_statements_track: Optional[str] = None,
                 temp_file_limit: Optional[str] = None,
                 timezone: Optional[str] = None,
                 track_activity_query_size: Optional[str] = None,
                 track_commit_timestamp: Optional[str] = None,
                 track_functions: Optional[str] = None,
                 track_io_timing: Optional[str] = None,
                 wal_sender_timeout: Optional[str] = None,
                 wal_writer_delay: Optional[str] = None):
        if autovacuum_analyze_scale_factor is not None:
            pulumi.set(__self__, "autovacuum_analyze_scale_factor", autovacuum_analyze_scale_factor)
        if autovacuum_analyze_threshold is not None:
            pulumi.set(__self__, "autovacuum_analyze_threshold", autovacuum_analyze_threshold)
        if autovacuum_freeze_max_age is not None:
            pulumi.set(__self__, "autovacuum_freeze_max_age", autovacuum_freeze_max_age)
        if autovacuum_max_workers is not None:
            pulumi.set(__self__, "autovacuum_max_workers", autovacuum_max_workers)
        if autovacuum_naptime is not None:
            pulumi.set(__self__, "autovacuum_naptime", autovacuum_naptime)
        if autovacuum_vacuum_cost_delay is not None:
            pulumi.set(__self__, "autovacuum_vacuum_cost_delay", autovacuum_vacuum_cost_delay)
        if autovacuum_vacuum_cost_limit is not None:
            pulumi.set(__self__, "autovacuum_vacuum_cost_limit", autovacuum_vacuum_cost_limit)
        if autovacuum_vacuum_scale_factor is not None:
            pulumi.set(__self__, "autovacuum_vacuum_scale_factor", autovacuum_vacuum_scale_factor)
        if autovacuum_vacuum_threshold is not None:
            pulumi.set(__self__, "autovacuum_vacuum_threshold", autovacuum_vacuum_threshold)
        if deadlock_timeout is not None:
            pulumi.set(__self__, "deadlock_timeout", deadlock_timeout)
        if idle_in_transaction_session_timeout is not None:
            pulumi.set(__self__, "idle_in_transaction_session_timeout", idle_in_transaction_session_timeout)
        if jit is not None:
            pulumi.set(__self__, "jit", jit)
        if log_autovacuum_min_duration is not None:
            pulumi.set(__self__, "log_autovacuum_min_duration", log_autovacuum_min_duration)
        if log_error_verbosity is not None:
            pulumi.set(__self__, "log_error_verbosity", log_error_verbosity)
        if log_line_prefix is not None:
            pulumi.set(__self__, "log_line_prefix", log_line_prefix)
        if log_min_duration_statement is not None:
            pulumi.set(__self__, "log_min_duration_statement", log_min_duration_statement)
        if max_files_per_process is not None:
            pulumi.set(__self__, "max_files_per_process", max_files_per_process)
        if max_locks_per_transaction is not None:
            pulumi.set(__self__, "max_locks_per_transaction", max_locks_per_transaction)
        if max_logical_replication_workers is not None:
            pulumi.set(__self__, "max_logical_replication_workers", max_logical_replication_workers)
        if max_parallel_workers is not None:
            pulumi.set(__self__, "max_parallel_workers", max_parallel_workers)
        if max_parallel_workers_per_gather is not None:
            pulumi.set(__self__, "max_parallel_workers_per_gather", max_parallel_workers_per_gather)
        if max_pred_locks_per_transaction is not None:
            pulumi.set(__self__, "max_pred_locks_per_transaction", max_pred_locks_per_transaction)
        if max_prepared_transactions is not None:
            pulumi.set(__self__, "max_prepared_transactions", max_prepared_transactions)
        if max_replication_slots is not None:
            pulumi.set(__self__, "max_replication_slots", max_replication_slots)
        if max_stack_depth is not None:
            pulumi.set(__self__, "max_stack_depth", max_stack_depth)
        if max_standby_archive_delay is not None:
            pulumi.set(__self__, "max_standby_archive_delay", max_standby_archive_delay)
        if max_standby_streaming_delay is not None:
            pulumi.set(__self__, "max_standby_streaming_delay", max_standby_streaming_delay)
        if max_wal_senders is not None:
            pulumi.set(__self__, "max_wal_senders", max_wal_senders)
        if max_worker_processes is not None:
            pulumi.set(__self__, "max_worker_processes", max_worker_processes)
        if pg_partman_bgw_interval is not None:
            pulumi.set(__self__, "pg_partman_bgw_interval", pg_partman_bgw_interval)
        if pg_partman_bgw_role is not None:
            pulumi.set(__self__, "pg_partman_bgw_role", pg_partman_bgw_role)
        if pg_stat_statements_track is not None:
            pulumi.set(__self__, "pg_stat_statements_track", pg_stat_statements_track)
        if temp_file_limit is not None:
            pulumi.set(__self__, "temp_file_limit", temp_file_limit)
        if timezone is not None:
            pulumi.set(__self__, "timezone", timezone)
        if track_activity_query_size is not None:
            pulumi.set(__self__, "track_activity_query_size", track_activity_query_size)
        if track_commit_timestamp is not None:
            pulumi.set(__self__, "track_commit_timestamp", track_commit_timestamp)
        if track_functions is not None:
            pulumi.set(__self__, "track_functions", track_functions)
        if track_io_timing is not None:
            pulumi.set(__self__, "track_io_timing", track_io_timing)
        if wal_sender_timeout is not None:
            pulumi.set(__self__, "wal_sender_timeout", wal_sender_timeout)
        if wal_writer_delay is not None:
            pulumi.set(__self__, "wal_writer_delay", wal_writer_delay)

    @property
    @pulumi.getter(name="autovacuumAnalyzeScaleFactor")
    def autovacuum_analyze_scale_factor(self) -> Optional[str]:
        return pulumi.get(self, "autovacuum_analyze_scale_factor")

    @property
    @pulumi.getter(name="autovacuumAnalyzeThreshold")
    def autovacuum_analyze_threshold(self) -> Optional[str]:
        return pulumi.get(self, "autovacuum_analyze_threshold")

    @property
    @pulumi.getter(name="autovacuumFreezeMaxAge")
    def autovacuum_freeze_max_age(self) -> Optional[str]:
        return pulumi.get(self, "autovacuum_freeze_max_age")

    @property
    @pulumi.getter(name="autovacuumMaxWorkers")
    def autovacuum_max_workers(self) -> Optional[str]:
        return pulumi.get(self, "autovacuum_max_workers")

    @property
    @pulumi.getter(name="autovacuumNaptime")
    def autovacuum_naptime(self) -> Optional[str]:
        return pulumi.get(self, "autovacuum_naptime")

    @property
    @pulumi.getter(name="autovacuumVacuumCostDelay")
    def autovacuum_vacuum_cost_delay(self) -> Optional[str]:
        return pulumi.get(self, "autovacuum_vacuum_cost_delay")

    @property
    @pulumi.getter(name="autovacuumVacuumCostLimit")
    def autovacuum_vacuum_cost_limit(self) -> Optional[str]:
        return pulumi.get(self, "autovacuum_vacuum_cost_limit")

    @property
    @pulumi.getter(name="autovacuumVacuumScaleFactor")
    def autovacuum_vacuum_scale_factor(self) -> Optional[str]:
        return pulumi.get(self, "autovacuum_vacuum_scale_factor")

    @property
    @pulumi.getter(name="autovacuumVacuumThreshold")
    def autovacuum_vacuum_threshold(self) -> Optional[str]:
        return pulumi.get(self, "autovacuum_vacuum_threshold")

    @property
    @pulumi.getter(name="deadlockTimeout")
    def deadlock_timeout(self) -> Optional[str]:
        return pulumi.get(self, "deadlock_timeout")

    @property
    @pulumi.getter(name="idleInTransactionSessionTimeout")
    def idle_in_transaction_session_timeout(self) -> Optional[str]:
        return pulumi.get(self, "idle_in_transaction_session_timeout")

    @property
    @pulumi.getter
    def jit(self) -> Optional[str]:
        return pulumi.get(self, "jit")

    @property
    @pulumi.getter(name="logAutovacuumMinDuration")
    def log_autovacuum_min_duration(self) -> Optional[str]:
        return pulumi.get(self, "log_autovacuum_min_duration")

    @property
    @pulumi.getter(name="logErrorVerbosity")
    def log_error_verbosity(self) -> Optional[str]:
        return pulumi.get(self, "log_error_verbosity")

    @property
    @pulumi.getter(name="logLinePrefix")
    def log_line_prefix(self) -> Optional[str]:
        return pulumi.get(self, "log_line_prefix")

    @property
    @pulumi.getter(name="logMinDurationStatement")
    def log_min_duration_statement(self) -> Optional[str]:
        return pulumi.get(self, "log_min_duration_statement")

    @property
    @pulumi.getter(name="maxFilesPerProcess")
    def max_files_per_process(self) -> Optional[str]:
        return pulumi.get(self, "max_files_per_process")

    @property
    @pulumi.getter(name="maxLocksPerTransaction")
    def max_locks_per_transaction(self) -> Optional[str]:
        return pulumi.get(self, "max_locks_per_transaction")

    @property
    @pulumi.getter(name="maxLogicalReplicationWorkers")
    def max_logical_replication_workers(self) -> Optional[str]:
        return pulumi.get(self, "max_logical_replication_workers")

    @property
    @pulumi.getter(name="maxParallelWorkers")
    def max_parallel_workers(self) -> Optional[str]:
        return pulumi.get(self, "max_parallel_workers")

    @property
    @pulumi.getter(name="maxParallelWorkersPerGather")
    def max_parallel_workers_per_gather(self) -> Optional[str]:
        return pulumi.get(self, "max_parallel_workers_per_gather")

    @property
    @pulumi.getter(name="maxPredLocksPerTransaction")
    def max_pred_locks_per_transaction(self) -> Optional[str]:
        return pulumi.get(self, "max_pred_locks_per_transaction")

    @property
    @pulumi.getter(name="maxPreparedTransactions")
    def max_prepared_transactions(self) -> Optional[str]:
        return pulumi.get(self, "max_prepared_transactions")

    @property
    @pulumi.getter(name="maxReplicationSlots")
    def max_replication_slots(self) -> Optional[str]:
        return pulumi.get(self, "max_replication_slots")

    @property
    @pulumi.getter(name="maxStackDepth")
    def max_stack_depth(self) -> Optional[str]:
        return pulumi.get(self, "max_stack_depth")

    @property
    @pulumi.getter(name="maxStandbyArchiveDelay")
    def max_standby_archive_delay(self) -> Optional[str]:
        return pulumi.get(self, "max_standby_archive_delay")

    @property
    @pulumi.getter(name="maxStandbyStreamingDelay")
    def max_standby_streaming_delay(self) -> Optional[str]:
        return pulumi.get(self, "max_standby_streaming_delay")

    @property
    @pulumi.getter(name="maxWalSenders")
    def max_wal_senders(self) -> Optional[str]:
        return pulumi.get(self, "max_wal_senders")

    @property
    @pulumi.getter(name="maxWorkerProcesses")
    def max_worker_processes(self) -> Optional[str]:
        return pulumi.get(self, "max_worker_processes")

    @property
    @pulumi.getter(name="pgPartmanBgwInterval")
    def pg_partman_bgw_interval(self) -> Optional[str]:
        return pulumi.get(self, "pg_partman_bgw_interval")

    @property
    @pulumi.getter(name="pgPartmanBgwRole")
    def pg_partman_bgw_role(self) -> Optional[str]:
        return pulumi.get(self, "pg_partman_bgw_role")

    @property
    @pulumi.getter(name="pgStatStatementsTrack")
    def pg_stat_statements_track(self) -> Optional[str]:
        return pulumi.get(self, "pg_stat_statements_track")

    @property
    @pulumi.getter(name="tempFileLimit")
    def temp_file_limit(self) -> Optional[str]:
        return pulumi.get(self, "temp_file_limit")

    @property
    @pulumi.getter
    def timezone(self) -> Optional[str]:
        return pulumi.get(self, "timezone")

    @property
    @pulumi.getter(name="trackActivityQuerySize")
    def track_activity_query_size(self) -> Optional[str]:
        return pulumi.get(self, "track_activity_query_size")

    @property
    @pulumi.getter(name="trackCommitTimestamp")
    def track_commit_timestamp(self) -> Optional[str]:
        return pulumi.get(self, "track_commit_timestamp")

    @property
    @pulumi.getter(name="trackFunctions")
    def track_functions(self) -> Optional[str]:
        return pulumi.get(self, "track_functions")

    @property
    @pulumi.getter(name="trackIoTiming")
    def track_io_timing(self) -> Optional[str]:
        return pulumi.get(self, "track_io_timing")

    @property
    @pulumi.getter(name="walSenderTimeout")
    def wal_sender_timeout(self) -> Optional[str]:
        return pulumi.get(self, "wal_sender_timeout")

    @property
    @pulumi.getter(name="walWriterDelay")
    def wal_writer_delay(self) -> Optional[str]:
        return pulumi.get(self, "wal_writer_delay")


@pulumi.output_type
class ServicePgUserConfigPgbouncer(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "autodbIdleTimeout":
            suggest = "autodb_idle_timeout"
        elif key == "autodbMaxDbConnections":
            suggest = "autodb_max_db_connections"
        elif key == "autodbPoolMode":
            suggest = "autodb_pool_mode"
        elif key == "autodbPoolSize":
            suggest = "autodb_pool_size"
        elif key == "ignoreStartupParameters":
            suggest = "ignore_startup_parameters"
        elif key == "minPoolSize":
            suggest = "min_pool_size"
        elif key == "serverIdleTimeout":
            suggest = "server_idle_timeout"
        elif key == "serverLifetime":
            suggest = "server_lifetime"
        elif key == "serverResetQueryAlways":
            suggest = "server_reset_query_always"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ServicePgUserConfigPgbouncer. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ServicePgUserConfigPgbouncer.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ServicePgUserConfigPgbouncer.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 autodb_idle_timeout: Optional[str] = None,
                 autodb_max_db_connections: Optional[str] = None,
                 autodb_pool_mode: Optional[str] = None,
                 autodb_pool_size: Optional[str] = None,
                 ignore_startup_parameters: Optional[Sequence[str]] = None,
                 min_pool_size: Optional[str] = None,
                 server_idle_timeout: Optional[str] = None,
                 server_lifetime: Optional[str] = None,
                 server_reset_query_always: Optional[str] = None):
        if autodb_idle_timeout is not None:
            pulumi.set(__self__, "autodb_idle_timeout", autodb_idle_timeout)
        if autodb_max_db_connections is not None:
            pulumi.set(__self__, "autodb_max_db_connections", autodb_max_db_connections)
        if autodb_pool_mode is not None:
            pulumi.set(__self__, "autodb_pool_mode", autodb_pool_mode)
        if autodb_pool_size is not None:
            pulumi.set(__self__, "autodb_pool_size", autodb_pool_size)
        if ignore_startup_parameters is not None:
            pulumi.set(__self__, "ignore_startup_parameters", ignore_startup_parameters)
        if min_pool_size is not None:
            pulumi.set(__self__, "min_pool_size", min_pool_size)
        if server_idle_timeout is not None:
            pulumi.set(__self__, "server_idle_timeout", server_idle_timeout)
        if server_lifetime is not None:
            pulumi.set(__self__, "server_lifetime", server_lifetime)
        if server_reset_query_always is not None:
            pulumi.set(__self__, "server_reset_query_always", server_reset_query_always)

    @property
    @pulumi.getter(name="autodbIdleTimeout")
    def autodb_idle_timeout(self) -> Optional[str]:
        return pulumi.get(self, "autodb_idle_timeout")

    @property
    @pulumi.getter(name="autodbMaxDbConnections")
    def autodb_max_db_connections(self) -> Optional[str]:
        return pulumi.get(self, "autodb_max_db_connections")

    @property
    @pulumi.getter(name="autodbPoolMode")
    def autodb_pool_mode(self) -> Optional[str]:
        return pulumi.get(self, "autodb_pool_mode")

    @property
    @pulumi.getter(name="autodbPoolSize")
    def autodb_pool_size(self) -> Optional[str]:
        return pulumi.get(self, "autodb_pool_size")

    @property
    @pulumi.getter(name="ignoreStartupParameters")
    def ignore_startup_parameters(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "ignore_startup_parameters")

    @property
    @pulumi.getter(name="minPoolSize")
    def min_pool_size(self) -> Optional[str]:
        return pulumi.get(self, "min_pool_size")

    @property
    @pulumi.getter(name="serverIdleTimeout")
    def server_idle_timeout(self) -> Optional[str]:
        return pulumi.get(self, "server_idle_timeout")

    @property
    @pulumi.getter(name="serverLifetime")
    def server_lifetime(self) -> Optional[str]:
        return pulumi.get(self, "server_lifetime")

    @property
    @pulumi.getter(name="serverResetQueryAlways")
    def server_reset_query_always(self) -> Optional[str]:
        return pulumi.get(self, "server_reset_query_always")


@pulumi.output_type
class ServicePgUserConfigPglookout(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "maxFailoverReplicationTimeLag":
            suggest = "max_failover_replication_time_lag"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ServicePgUserConfigPglookout. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ServicePgUserConfigPglookout.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ServicePgUserConfigPglookout.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 max_failover_replication_time_lag: Optional[str] = None):
        if max_failover_replication_time_lag is not None:
            pulumi.set(__self__, "max_failover_replication_time_lag", max_failover_replication_time_lag)

    @property
    @pulumi.getter(name="maxFailoverReplicationTimeLag")
    def max_failover_replication_time_lag(self) -> Optional[str]:
        return pulumi.get(self, "max_failover_replication_time_lag")


@pulumi.output_type
class ServicePgUserConfigPrivateAccess(dict):
    def __init__(__self__, *,
                 pg: Optional[str] = None,
                 pgbouncer: Optional[str] = None,
                 prometheus: Optional[str] = None):
        if pg is not None:
            pulumi.set(__self__, "pg", pg)
        if pgbouncer is not None:
            pulumi.set(__self__, "pgbouncer", pgbouncer)
        if prometheus is not None:
            pulumi.set(__self__, "prometheus", prometheus)

    @property
    @pulumi.getter
    def pg(self) -> Optional[str]:
        return pulumi.get(self, "pg")

    @property
    @pulumi.getter
    def pgbouncer(self) -> Optional[str]:
        return pulumi.get(self, "pgbouncer")

    @property
    @pulumi.getter
    def prometheus(self) -> Optional[str]:
        return pulumi.get(self, "prometheus")


@pulumi.output_type
class ServicePgUserConfigPrivatelinkAccess(dict):
    def __init__(__self__, *,
                 pg: Optional[str] = None,
                 pgbouncer: Optional[str] = None):
        if pg is not None:
            pulumi.set(__self__, "pg", pg)
        if pgbouncer is not None:
            pulumi.set(__self__, "pgbouncer", pgbouncer)

    @property
    @pulumi.getter
    def pg(self) -> Optional[str]:
        return pulumi.get(self, "pg")

    @property
    @pulumi.getter
    def pgbouncer(self) -> Optional[str]:
        return pulumi.get(self, "pgbouncer")


@pulumi.output_type
class ServicePgUserConfigPublicAccess(dict):
    def __init__(__self__, *,
                 pg: Optional[str] = None,
                 pgbouncer: Optional[str] = None,
                 prometheus: Optional[str] = None):
        if pg is not None:
            pulumi.set(__self__, "pg", pg)
        if pgbouncer is not None:
            pulumi.set(__self__, "pgbouncer", pgbouncer)
        if prometheus is not None:
            pulumi.set(__self__, "prometheus", prometheus)

    @property
    @pulumi.getter
    def pg(self) -> Optional[str]:
        return pulumi.get(self, "pg")

    @property
    @pulumi.getter
    def pgbouncer(self) -> Optional[str]:
        return pulumi.get(self, "pgbouncer")

    @property
    @pulumi.getter
    def prometheus(self) -> Optional[str]:
        return pulumi.get(self, "prometheus")


@pulumi.output_type
class ServicePgUserConfigTimescaledb(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "maxBackgroundWorkers":
            suggest = "max_background_workers"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ServicePgUserConfigTimescaledb. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ServicePgUserConfigTimescaledb.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ServicePgUserConfigTimescaledb.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 max_background_workers: Optional[str] = None):
        if max_background_workers is not None:
            pulumi.set(__self__, "max_background_workers", max_background_workers)

    @property
    @pulumi.getter(name="maxBackgroundWorkers")
    def max_background_workers(self) -> Optional[str]:
        return pulumi.get(self, "max_background_workers")


@pulumi.output_type
class ServiceRedis(dict):
    def __init__(__self__):
        pass


@pulumi.output_type
class ServiceRedisUserConfig(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "ipFilters":
            suggest = "ip_filters"
        elif key == "privateAccess":
            suggest = "private_access"
        elif key == "privatelinkAccess":
            suggest = "privatelink_access"
        elif key == "projectToForkFrom":
            suggest = "project_to_fork_from"
        elif key == "publicAccess":
            suggest = "public_access"
        elif key == "recoveryBasebackupName":
            suggest = "recovery_basebackup_name"
        elif key == "redisIoThreads":
            suggest = "redis_io_threads"
        elif key == "redisLfuDecayTime":
            suggest = "redis_lfu_decay_time"
        elif key == "redisLfuLogFactor":
            suggest = "redis_lfu_log_factor"
        elif key == "redisMaxmemoryPolicy":
            suggest = "redis_maxmemory_policy"
        elif key == "redisNotifyKeyspaceEvents":
            suggest = "redis_notify_keyspace_events"
        elif key == "redisSsl":
            suggest = "redis_ssl"
        elif key == "redisTimeout":
            suggest = "redis_timeout"
        elif key == "serviceToForkFrom":
            suggest = "service_to_fork_from"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ServiceRedisUserConfig. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ServiceRedisUserConfig.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ServiceRedisUserConfig.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 ip_filters: Optional[Sequence[str]] = None,
                 migration: Optional['outputs.ServiceRedisUserConfigMigration'] = None,
                 private_access: Optional['outputs.ServiceRedisUserConfigPrivateAccess'] = None,
                 privatelink_access: Optional['outputs.ServiceRedisUserConfigPrivatelinkAccess'] = None,
                 project_to_fork_from: Optional[str] = None,
                 public_access: Optional['outputs.ServiceRedisUserConfigPublicAccess'] = None,
                 recovery_basebackup_name: Optional[str] = None,
                 redis_io_threads: Optional[str] = None,
                 redis_lfu_decay_time: Optional[str] = None,
                 redis_lfu_log_factor: Optional[str] = None,
                 redis_maxmemory_policy: Optional[str] = None,
                 redis_notify_keyspace_events: Optional[str] = None,
                 redis_ssl: Optional[str] = None,
                 redis_timeout: Optional[str] = None,
                 service_to_fork_from: Optional[str] = None):
        if ip_filters is not None:
            pulumi.set(__self__, "ip_filters", ip_filters)
        if migration is not None:
            pulumi.set(__self__, "migration", migration)
        if private_access is not None:
            pulumi.set(__self__, "private_access", private_access)
        if privatelink_access is not None:
            pulumi.set(__self__, "privatelink_access", privatelink_access)
        if project_to_fork_from is not None:
            pulumi.set(__self__, "project_to_fork_from", project_to_fork_from)
        if public_access is not None:
            pulumi.set(__self__, "public_access", public_access)
        if recovery_basebackup_name is not None:
            pulumi.set(__self__, "recovery_basebackup_name", recovery_basebackup_name)
        if redis_io_threads is not None:
            pulumi.set(__self__, "redis_io_threads", redis_io_threads)
        if redis_lfu_decay_time is not None:
            pulumi.set(__self__, "redis_lfu_decay_time", redis_lfu_decay_time)
        if redis_lfu_log_factor is not None:
            pulumi.set(__self__, "redis_lfu_log_factor", redis_lfu_log_factor)
        if redis_maxmemory_policy is not None:
            pulumi.set(__self__, "redis_maxmemory_policy", redis_maxmemory_policy)
        if redis_notify_keyspace_events is not None:
            pulumi.set(__self__, "redis_notify_keyspace_events", redis_notify_keyspace_events)
        if redis_ssl is not None:
            pulumi.set(__self__, "redis_ssl", redis_ssl)
        if redis_timeout is not None:
            pulumi.set(__self__, "redis_timeout", redis_timeout)
        if service_to_fork_from is not None:
            pulumi.set(__self__, "service_to_fork_from", service_to_fork_from)

    @property
    @pulumi.getter(name="ipFilters")
    def ip_filters(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "ip_filters")

    @property
    @pulumi.getter
    def migration(self) -> Optional['outputs.ServiceRedisUserConfigMigration']:
        return pulumi.get(self, "migration")

    @property
    @pulumi.getter(name="privateAccess")
    def private_access(self) -> Optional['outputs.ServiceRedisUserConfigPrivateAccess']:
        return pulumi.get(self, "private_access")

    @property
    @pulumi.getter(name="privatelinkAccess")
    def privatelink_access(self) -> Optional['outputs.ServiceRedisUserConfigPrivatelinkAccess']:
        return pulumi.get(self, "privatelink_access")

    @property
    @pulumi.getter(name="projectToForkFrom")
    def project_to_fork_from(self) -> Optional[str]:
        return pulumi.get(self, "project_to_fork_from")

    @property
    @pulumi.getter(name="publicAccess")
    def public_access(self) -> Optional['outputs.ServiceRedisUserConfigPublicAccess']:
        return pulumi.get(self, "public_access")

    @property
    @pulumi.getter(name="recoveryBasebackupName")
    def recovery_basebackup_name(self) -> Optional[str]:
        return pulumi.get(self, "recovery_basebackup_name")

    @property
    @pulumi.getter(name="redisIoThreads")
    def redis_io_threads(self) -> Optional[str]:
        return pulumi.get(self, "redis_io_threads")

    @property
    @pulumi.getter(name="redisLfuDecayTime")
    def redis_lfu_decay_time(self) -> Optional[str]:
        return pulumi.get(self, "redis_lfu_decay_time")

    @property
    @pulumi.getter(name="redisLfuLogFactor")
    def redis_lfu_log_factor(self) -> Optional[str]:
        return pulumi.get(self, "redis_lfu_log_factor")

    @property
    @pulumi.getter(name="redisMaxmemoryPolicy")
    def redis_maxmemory_policy(self) -> Optional[str]:
        return pulumi.get(self, "redis_maxmemory_policy")

    @property
    @pulumi.getter(name="redisNotifyKeyspaceEvents")
    def redis_notify_keyspace_events(self) -> Optional[str]:
        return pulumi.get(self, "redis_notify_keyspace_events")

    @property
    @pulumi.getter(name="redisSsl")
    def redis_ssl(self) -> Optional[str]:
        return pulumi.get(self, "redis_ssl")

    @property
    @pulumi.getter(name="redisTimeout")
    def redis_timeout(self) -> Optional[str]:
        return pulumi.get(self, "redis_timeout")

    @property
    @pulumi.getter(name="serviceToForkFrom")
    def service_to_fork_from(self) -> Optional[str]:
        return pulumi.get(self, "service_to_fork_from")


@pulumi.output_type
class ServiceRedisUserConfigMigration(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "ignoreDbs":
            suggest = "ignore_dbs"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ServiceRedisUserConfigMigration. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ServiceRedisUserConfigMigration.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ServiceRedisUserConfigMigration.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 dbname: Optional[str] = None,
                 host: Optional[str] = None,
                 ignore_dbs: Optional[str] = None,
                 password: Optional[str] = None,
                 port: Optional[str] = None,
                 ssl: Optional[str] = None,
                 username: Optional[str] = None):
        if dbname is not None:
            pulumi.set(__self__, "dbname", dbname)
        if host is not None:
            pulumi.set(__self__, "host", host)
        if ignore_dbs is not None:
            pulumi.set(__self__, "ignore_dbs", ignore_dbs)
        if password is not None:
            pulumi.set(__self__, "password", password)
        if port is not None:
            pulumi.set(__self__, "port", port)
        if ssl is not None:
            pulumi.set(__self__, "ssl", ssl)
        if username is not None:
            pulumi.set(__self__, "username", username)

    @property
    @pulumi.getter
    def dbname(self) -> Optional[str]:
        return pulumi.get(self, "dbname")

    @property
    @pulumi.getter
    def host(self) -> Optional[str]:
        return pulumi.get(self, "host")

    @property
    @pulumi.getter(name="ignoreDbs")
    def ignore_dbs(self) -> Optional[str]:
        return pulumi.get(self, "ignore_dbs")

    @property
    @pulumi.getter
    def password(self) -> Optional[str]:
        return pulumi.get(self, "password")

    @property
    @pulumi.getter
    def port(self) -> Optional[str]:
        return pulumi.get(self, "port")

    @property
    @pulumi.getter
    def ssl(self) -> Optional[str]:
        return pulumi.get(self, "ssl")

    @property
    @pulumi.getter
    def username(self) -> Optional[str]:
        return pulumi.get(self, "username")


@pulumi.output_type
class ServiceRedisUserConfigPrivateAccess(dict):
    def __init__(__self__, *,
                 prometheus: Optional[str] = None,
                 redis: Optional[str] = None):
        if prometheus is not None:
            pulumi.set(__self__, "prometheus", prometheus)
        if redis is not None:
            pulumi.set(__self__, "redis", redis)

    @property
    @pulumi.getter
    def prometheus(self) -> Optional[str]:
        return pulumi.get(self, "prometheus")

    @property
    @pulumi.getter
    def redis(self) -> Optional[str]:
        return pulumi.get(self, "redis")


@pulumi.output_type
class ServiceRedisUserConfigPrivatelinkAccess(dict):
    def __init__(__self__, *,
                 redis: Optional[str] = None):
        if redis is not None:
            pulumi.set(__self__, "redis", redis)

    @property
    @pulumi.getter
    def redis(self) -> Optional[str]:
        return pulumi.get(self, "redis")


@pulumi.output_type
class ServiceRedisUserConfigPublicAccess(dict):
    def __init__(__self__, *,
                 prometheus: Optional[str] = None,
                 redis: Optional[str] = None):
        if prometheus is not None:
            pulumi.set(__self__, "prometheus", prometheus)
        if redis is not None:
            pulumi.set(__self__, "redis", redis)

    @property
    @pulumi.getter
    def prometheus(self) -> Optional[str]:
        return pulumi.get(self, "prometheus")

    @property
    @pulumi.getter
    def redis(self) -> Optional[str]:
        return pulumi.get(self, "redis")


@pulumi.output_type
class ServiceServiceIntegration(dict):
    @staticmethod
    def __key_warning(key: str):
        suggest = None
        if key == "integrationType":
            suggest = "integration_type"
        elif key == "sourceServiceName":
            suggest = "source_service_name"

        if suggest:
            pulumi.log.warn(f"Key '{key}' not found in ServiceServiceIntegration. Access the value via the '{suggest}' property getter instead.")

    def __getitem__(self, key: str) -> Any:
        ServiceServiceIntegration.__key_warning(key)
        return super().__getitem__(key)

    def get(self, key: str, default = None) -> Any:
        ServiceServiceIntegration.__key_warning(key)
        return super().get(key, default)

    def __init__(__self__, *,
                 integration_type: str,
                 source_service_name: str):
        pulumi.set(__self__, "integration_type", integration_type)
        pulumi.set(__self__, "source_service_name", source_service_name)

    @property
    @pulumi.getter(name="integrationType")
    def integration_type(self) -> str:
        return pulumi.get(self, "integration_type")

    @property
    @pulumi.getter(name="sourceServiceName")
    def source_service_name(self) -> str:
        return pulumi.get(self, "source_service_name")


@pulumi.output_type
class GetCassandaCassandraResult(dict):
    def __init__(__self__):
        pass


@pulumi.output_type
class GetCassandaCassandraUserConfigResult(dict):
    def __init__(__self__, *,
                 cassandra: Optional['outputs.GetCassandaCassandraUserConfigCassandraResult'] = None,
                 ip_filters: Optional[Sequence[str]] = None,
                 migrate_sstableloader: Optional[str] = None,
                 private_access: Optional['outputs.GetCassandaCassandraUserConfigPrivateAccessResult'] = None,
                 project_to_fork_from: Optional[str] = None,
                 public_access: Optional['outputs.GetCassandaCassandraUserConfigPublicAccessResult'] = None,
                 service_to_fork_from: Optional[str] = None):
        """
        :param 'GetCassandaCassandraUserConfigCassandraArgs' cassandra: Cassandra specific server provided values.
        :param Sequence[str] ip_filters: allow incoming connections from CIDR address block, e.g. `10.20.0.0/16`
        :param str migrate_sstableloader: sets the service into migration mode enabling the sstableloader 
               utility to be used to upload Cassandra data files. Available only on service create.
        :param 'GetCassandaCassandraUserConfigPrivateAccessArgs' private_access: Allow access to selected service ports from private networks.
        :param 'GetCassandaCassandraUserConfigPublicAccessArgs' public_access: Allow access to selected service ports from the public Internet
        :param str service_to_fork_from: Name of another service to fork from. This has effect only 
               when a new service is being created.
        """
        if cassandra is not None:
            pulumi.set(__self__, "cassandra", cassandra)
        if ip_filters is not None:
            pulumi.set(__self__, "ip_filters", ip_filters)
        if migrate_sstableloader is not None:
            pulumi.set(__self__, "migrate_sstableloader", migrate_sstableloader)
        if private_access is not None:
            pulumi.set(__self__, "private_access", private_access)
        if project_to_fork_from is not None:
            pulumi.set(__self__, "project_to_fork_from", project_to_fork_from)
        if public_access is not None:
            pulumi.set(__self__, "public_access", public_access)
        if service_to_fork_from is not None:
            pulumi.set(__self__, "service_to_fork_from", service_to_fork_from)

    @property
    @pulumi.getter
    def cassandra(self) -> Optional['outputs.GetCassandaCassandraUserConfigCassandraResult']:
        """
        Cassandra specific server provided values.
        """
        return pulumi.get(self, "cassandra")

    @property
    @pulumi.getter(name="ipFilters")
    def ip_filters(self) -> Optional[Sequence[str]]:
        """
        allow incoming connections from CIDR address block, e.g. `10.20.0.0/16`
        """
        return pulumi.get(self, "ip_filters")

    @property
    @pulumi.getter(name="migrateSstableloader")
    def migrate_sstableloader(self) -> Optional[str]:
        """
        sets the service into migration mode enabling the sstableloader 
        utility to be used to upload Cassandra data files. Available only on service create.
        """
        return pulumi.get(self, "migrate_sstableloader")

    @property
    @pulumi.getter(name="privateAccess")
    def private_access(self) -> Optional['outputs.GetCassandaCassandraUserConfigPrivateAccessResult']:
        """
        Allow access to selected service ports from private networks.
        """
        return pulumi.get(self, "private_access")

    @property
    @pulumi.getter(name="projectToForkFrom")
    def project_to_fork_from(self) -> Optional[str]:
        return pulumi.get(self, "project_to_fork_from")

    @property
    @pulumi.getter(name="publicAccess")
    def public_access(self) -> Optional['outputs.GetCassandaCassandraUserConfigPublicAccessResult']:
        """
        Allow access to selected service ports from the public Internet
        """
        return pulumi.get(self, "public_access")

    @property
    @pulumi.getter(name="serviceToForkFrom")
    def service_to_fork_from(self) -> Optional[str]:
        """
        Name of another service to fork from. This has effect only 
        when a new service is being created.
        """
        return pulumi.get(self, "service_to_fork_from")


@pulumi.output_type
class GetCassandaCassandraUserConfigCassandraResult(dict):
    def __init__(__self__, *,
                 batch_size_fail_threshold_in_kb: Optional[str] = None,
                 batch_size_warn_threshold_in_kb: Optional[str] = None):
        """
        :param str batch_size_fail_threshold_in_kb: Fail any multiple-partition batch exceeding this value.
               50kb (10x warn threshold) by default.
        :param str batch_size_warn_threshold_in_kb: Log a warning message on any multiple-partition
               batch size exceeding this value.5kb per batch by default.Caution should be taken on increasing
               the size of this thresholdas it can lead to node instability.
        """
        if batch_size_fail_threshold_in_kb is not None:
            pulumi.set(__self__, "batch_size_fail_threshold_in_kb", batch_size_fail_threshold_in_kb)
        if batch_size_warn_threshold_in_kb is not None:
            pulumi.set(__self__, "batch_size_warn_threshold_in_kb", batch_size_warn_threshold_in_kb)

    @property
    @pulumi.getter(name="batchSizeFailThresholdInKb")
    def batch_size_fail_threshold_in_kb(self) -> Optional[str]:
        """
        Fail any multiple-partition batch exceeding this value.
        50kb (10x warn threshold) by default.
        """
        return pulumi.get(self, "batch_size_fail_threshold_in_kb")

    @property
    @pulumi.getter(name="batchSizeWarnThresholdInKb")
    def batch_size_warn_threshold_in_kb(self) -> Optional[str]:
        """
        Log a warning message on any multiple-partition
        batch size exceeding this value.5kb per batch by default.Caution should be taken on increasing
        the size of this thresholdas it can lead to node instability.
        """
        return pulumi.get(self, "batch_size_warn_threshold_in_kb")


@pulumi.output_type
class GetCassandaCassandraUserConfigPrivateAccessResult(dict):
    def __init__(__self__, *,
                 prometheus: Optional[str] = None):
        """
        :param str prometheus: Allow clients to connect to prometheus from the public internet 
               for service nodes that are in a project VPC or another type of private network.
        """
        if prometheus is not None:
            pulumi.set(__self__, "prometheus", prometheus)

    @property
    @pulumi.getter
    def prometheus(self) -> Optional[str]:
        """
        Allow clients to connect to prometheus from the public internet 
        for service nodes that are in a project VPC or another type of private network.
        """
        return pulumi.get(self, "prometheus")


@pulumi.output_type
class GetCassandaCassandraUserConfigPublicAccessResult(dict):
    def __init__(__self__, *,
                 prometheus: Optional[str] = None):
        """
        :param str prometheus: Allow clients to connect to prometheus from the public internet 
               for service nodes that are in a project VPC or another type of private network.
        """
        if prometheus is not None:
            pulumi.set(__self__, "prometheus", prometheus)

    @property
    @pulumi.getter
    def prometheus(self) -> Optional[str]:
        """
        Allow clients to connect to prometheus from the public internet 
        for service nodes that are in a project VPC or another type of private network.
        """
        return pulumi.get(self, "prometheus")


@pulumi.output_type
class GetCassandaComponentResult(dict):
    def __init__(__self__, *,
                 component: str,
                 host: str,
                 kafka_authentication_method: str,
                 port: int,
                 route: str,
                 ssl: bool,
                 usage: str):
        pulumi.set(__self__, "component", component)
        pulumi.set(__self__, "host", host)
        pulumi.set(__self__, "kafka_authentication_method", kafka_authentication_method)
        pulumi.set(__self__, "port", port)
        pulumi.set(__self__, "route", route)
        pulumi.set(__self__, "ssl", ssl)
        pulumi.set(__self__, "usage", usage)

    @property
    @pulumi.getter
    def component(self) -> str:
        return pulumi.get(self, "component")

    @property
    @pulumi.getter
    def host(self) -> str:
        return pulumi.get(self, "host")

    @property
    @pulumi.getter(name="kafkaAuthenticationMethod")
    def kafka_authentication_method(self) -> str:
        return pulumi.get(self, "kafka_authentication_method")

    @property
    @pulumi.getter
    def port(self) -> int:
        return pulumi.get(self, "port")

    @property
    @pulumi.getter
    def route(self) -> str:
        return pulumi.get(self, "route")

    @property
    @pulumi.getter
    def ssl(self) -> bool:
        return pulumi.get(self, "ssl")

    @property
    @pulumi.getter
    def usage(self) -> str:
        return pulumi.get(self, "usage")


@pulumi.output_type
class GetCassandaServiceIntegrationResult(dict):
    def __init__(__self__, *,
                 integration_type: str,
                 source_service_name: str):
        pulumi.set(__self__, "integration_type", integration_type)
        pulumi.set(__self__, "source_service_name", source_service_name)

    @property
    @pulumi.getter(name="integrationType")
    def integration_type(self) -> str:
        return pulumi.get(self, "integration_type")

    @property
    @pulumi.getter(name="sourceServiceName")
    def source_service_name(self) -> str:
        return pulumi.get(self, "source_service_name")


@pulumi.output_type
class GetElasticSearchAclAclResult(dict):
    def __init__(__self__, *,
                 rules: Sequence['outputs.GetElasticSearchAclAclRuleResult'],
                 username: str):
        pulumi.set(__self__, "rules", rules)
        pulumi.set(__self__, "username", username)

    @property
    @pulumi.getter
    def rules(self) -> Sequence['outputs.GetElasticSearchAclAclRuleResult']:
        return pulumi.get(self, "rules")

    @property
    @pulumi.getter
    def username(self) -> str:
        return pulumi.get(self, "username")


@pulumi.output_type
class GetElasticSearchAclAclRuleResult(dict):
    def __init__(__self__, *,
                 index: str,
                 permission: str):
        pulumi.set(__self__, "index", index)
        pulumi.set(__self__, "permission", permission)

    @property
    @pulumi.getter
    def index(self) -> str:
        return pulumi.get(self, "index")

    @property
    @pulumi.getter
    def permission(self) -> str:
        return pulumi.get(self, "permission")


@pulumi.output_type
class GetElasticSearchComponentResult(dict):
    def __init__(__self__, *,
                 component: str,
                 host: str,
                 kafka_authentication_method: str,
                 port: int,
                 route: str,
                 ssl: bool,
                 usage: str):
        pulumi.set(__self__, "component", component)
        pulumi.set(__self__, "host", host)
        pulumi.set(__self__, "kafka_authentication_method", kafka_authentication_method)
        pulumi.set(__self__, "port", port)
        pulumi.set(__self__, "route", route)
        pulumi.set(__self__, "ssl", ssl)
        pulumi.set(__self__, "usage", usage)

    @property
    @pulumi.getter
    def component(self) -> str:
        return pulumi.get(self, "component")

    @property
    @pulumi.getter
    def host(self) -> str:
        return pulumi.get(self, "host")

    @property
    @pulumi.getter(name="kafkaAuthenticationMethod")
    def kafka_authentication_method(self) -> str:
        return pulumi.get(self, "kafka_authentication_method")

    @property
    @pulumi.getter
    def port(self) -> int:
        return pulumi.get(self, "port")

    @property
    @pulumi.getter
    def route(self) -> str:
        return pulumi.get(self, "route")

    @property
    @pulumi.getter
    def ssl(self) -> bool:
        return pulumi.get(self, "ssl")

    @property
    @pulumi.getter
    def usage(self) -> str:
        return pulumi.get(self, "usage")


@pulumi.output_type
class GetElasticSearchElasticsearchResult(dict):
    def __init__(__self__, *,
                 kibana_uri: str):
        """
        :param str kibana_uri: URI for Kibana frontend.
        """
        pulumi.set(__self__, "kibana_uri", kibana_uri)

    @property
    @pulumi.getter(name="kibanaUri")
    def kibana_uri(self) -> str:
        """
        URI for Kibana frontend.
        """
        return pulumi.get(self, "kibana_uri")


@pulumi.output_type
class GetElasticSearchElasticsearchUserConfigResult(dict):
    def __init__(__self__, *,
                 custom_domain: Optional[str] = None,
                 disable_replication_factor_adjustment: Optional[str] = None,
                 elasticsearch: Optional['outputs.GetElasticSearchElasticsearchUserConfigElasticsearchResult'] = None,
                 elasticsearch_version: Optional[str] = None,
                 index_patterns: Optional[Sequence['outputs.GetElasticSearchElasticsearchUserConfigIndexPatternResult']] = None,
                 index_template: Optional['outputs.GetElasticSearchElasticsearchUserConfigIndexTemplateResult'] = None,
                 ip_filters: Optional[Sequence[str]] = None,
                 kibana: Optional['outputs.GetElasticSearchElasticsearchUserConfigKibanaResult'] = None,
                 max_index_count: Optional[str] = None,
                 private_access: Optional['outputs.GetElasticSearchElasticsearchUserConfigPrivateAccessResult'] = None,
                 privatelink_access: Optional['outputs.GetElasticSearchElasticsearchUserConfigPrivatelinkAccessResult'] = None,
                 project_to_fork_from: Optional[str] = None,
                 public_access: Optional['outputs.GetElasticSearchElasticsearchUserConfigPublicAccessResult'] = None,
                 recovery_basebackup_name: Optional[str] = None,
                 service_to_fork_from: Optional[str] = None):
        """
        :param str custom_domain: Serve the web frontend using a custom CNAME pointing to the 
               Aiven DNS name.
        :param str disable_replication_factor_adjustment: Disable automatic replication factor 
               adjustment for multi-node services. By default, Aiven ensures all indexes are replicated at
               least to two nodes. Note: setting this to true increases a risk of data loss in case of
               virtual machine failure.
        :param 'GetElasticSearchElasticsearchUserConfigElasticsearchArgs' elasticsearch: Elasticsearch specific server provided values.
        :param str elasticsearch_version: Elasticsearch major version.
        :param Sequence['GetElasticSearchElasticsearchUserConfigIndexPatternArgs'] index_patterns: Glob pattern and number of indexes matching that pattern to 
               be kept.
        :param 'GetElasticSearchElasticsearchUserConfigIndexTemplateArgs' index_template: Template settings for all new indexe.
        :param Sequence[str] ip_filters: allow incoming connections from CIDR address block, e.g. `10.20.0.0/16`
        :param 'GetElasticSearchElasticsearchUserConfigKibanaArgs' kibana: Allow clients to connect to kibana from the public internet for 
               service nodes that are in a project VPC or another type of private network.
        :param str max_index_count: Maximum number of indexes to keep before deleting the oldest one.
        :param 'GetElasticSearchElasticsearchUserConfigPrivateAccessArgs' private_access: Allow access to selected service ports from private networks.
        :param 'GetElasticSearchElasticsearchUserConfigPrivatelinkAccessArgs' privatelink_access: Allow access to selected service components through Privatelink
        :param str project_to_fork_from: Name of another project to fork a service from. This has
               effect only when a new service is being created.
        :param 'GetElasticSearchElasticsearchUserConfigPublicAccessArgs' public_access: Allow access to selected service ports from the public Internet.
        :param str recovery_basebackup_name: Name of the basebackup to restore in forked service.
        :param str service_to_fork_from: Name of another service to fork from. This has effect 
               only when a new service is being created.
        """
        if custom_domain is not None:
            pulumi.set(__self__, "custom_domain", custom_domain)
        if disable_replication_factor_adjustment is not None:
            pulumi.set(__self__, "disable_replication_factor_adjustment", disable_replication_factor_adjustment)
        if elasticsearch is not None:
            pulumi.set(__self__, "elasticsearch", elasticsearch)
        if elasticsearch_version is not None:
            pulumi.set(__self__, "elasticsearch_version", elasticsearch_version)
        if index_patterns is not None:
            pulumi.set(__self__, "index_patterns", index_patterns)
        if index_template is not None:
            pulumi.set(__self__, "index_template", index_template)
        if ip_filters is not None:
            pulumi.set(__self__, "ip_filters", ip_filters)
        if kibana is not None:
            pulumi.set(__self__, "kibana", kibana)
        if max_index_count is not None:
            pulumi.set(__self__, "max_index_count", max_index_count)
        if private_access is not None:
            pulumi.set(__self__, "private_access", private_access)
        if privatelink_access is not None:
            pulumi.set(__self__, "privatelink_access", privatelink_access)
        if project_to_fork_from is not None:
            pulumi.set(__self__, "project_to_fork_from", project_to_fork_from)
        if public_access is not None:
            pulumi.set(__self__, "public_access", public_access)
        if recovery_basebackup_name is not None:
            pulumi.set(__self__, "recovery_basebackup_name", recovery_basebackup_name)
        if service_to_fork_from is not None:
            pulumi.set(__self__, "service_to_fork_from", service_to_fork_from)

    @property
    @pulumi.getter(name="customDomain")
    def custom_domain(self) -> Optional[str]:
        """
        Serve the web frontend using a custom CNAME pointing to the 
        Aiven DNS name.
        """
        return pulumi.get(self, "custom_domain")

    @property
    @pulumi.getter(name="disableReplicationFactorAdjustment")
    def disable_replication_factor_adjustment(self) -> Optional[str]:
        """
        Disable automatic replication factor 
        adjustment for multi-node services. By default, Aiven ensures all indexes are replicated at
        least to two nodes. Note: setting this to true increases a risk of data loss in case of
        virtual machine failure.
        """
        return pulumi.get(self, "disable_replication_factor_adjustment")

    @property
    @pulumi.getter
    def elasticsearch(self) -> Optional['outputs.GetElasticSearchElasticsearchUserConfigElasticsearchResult']:
        """
        Elasticsearch specific server provided values.
        """
        return pulumi.get(self, "elasticsearch")

    @property
    @pulumi.getter(name="elasticsearchVersion")
    def elasticsearch_version(self) -> Optional[str]:
        """
        Elasticsearch major version.
        """
        return pulumi.get(self, "elasticsearch_version")

    @property
    @pulumi.getter(name="indexPatterns")
    def index_patterns(self) -> Optional[Sequence['outputs.GetElasticSearchElasticsearchUserConfigIndexPatternResult']]:
        """
        Glob pattern and number of indexes matching that pattern to 
        be kept.
        """
        return pulumi.get(self, "index_patterns")

    @property
    @pulumi.getter(name="indexTemplate")
    def index_template(self) -> Optional['outputs.GetElasticSearchElasticsearchUserConfigIndexTemplateResult']:
        """
        Template settings for all new indexe.
        """
        return pulumi.get(self, "index_template")

    @property
    @pulumi.getter(name="ipFilters")
    def ip_filters(self) -> Optional[Sequence[str]]:
        """
        allow incoming connections from CIDR address block, e.g. `10.20.0.0/16`
        """
        return pulumi.get(self, "ip_filters")

    @property
    @pulumi.getter
    def kibana(self) -> Optional['outputs.GetElasticSearchElasticsearchUserConfigKibanaResult']:
        """
        Allow clients to connect to kibana from the public internet for 
        service nodes that are in a project VPC or another type of private network.
        """
        return pulumi.get(self, "kibana")

    @property
    @pulumi.getter(name="maxIndexCount")
    def max_index_count(self) -> Optional[str]:
        """
        Maximum number of indexes to keep before deleting the oldest one.
        """
        return pulumi.get(self, "max_index_count")

    @property
    @pulumi.getter(name="privateAccess")
    def private_access(self) -> Optional['outputs.GetElasticSearchElasticsearchUserConfigPrivateAccessResult']:
        """
        Allow access to selected service ports from private networks.
        """
        return pulumi.get(self, "private_access")

    @property
    @pulumi.getter(name="privatelinkAccess")
    def privatelink_access(self) -> Optional['outputs.GetElasticSearchElasticsearchUserConfigPrivatelinkAccessResult']:
        """
        Allow access to selected service components through Privatelink
        """
        return pulumi.get(self, "privatelink_access")

    @property
    @pulumi.getter(name="projectToForkFrom")
    def project_to_fork_from(self) -> Optional[str]:
        """
        Name of another project to fork a service from. This has
        effect only when a new service is being created.
        """
        return pulumi.get(self, "project_to_fork_from")

    @property
    @pulumi.getter(name="publicAccess")
    def public_access(self) -> Optional['outputs.GetElasticSearchElasticsearchUserConfigPublicAccessResult']:
        """
        Allow access to selected service ports from the public Internet.
        """
        return pulumi.get(self, "public_access")

    @property
    @pulumi.getter(name="recoveryBasebackupName")
    def recovery_basebackup_name(self) -> Optional[str]:
        """
        Name of the basebackup to restore in forked service.
        """
        return pulumi.get(self, "recovery_basebackup_name")

    @property
    @pulumi.getter(name="serviceToForkFrom")
    def service_to_fork_from(self) -> Optional[str]:
        """
        Name of another service to fork from. This has effect 
        only when a new service is being created.
        """
        return pulumi.get(self, "service_to_fork_from")


@pulumi.output_type
class GetElasticSearchElasticsearchUserConfigElasticsearchResult(dict):
    def __init__(__self__, *,
                 action_auto_create_index_enabled: Optional[str] = None,
                 action_destructive_requires_name: Optional[str] = None,
                 cluster_max_shards_per_node: Optional[str] = None,
                 http_max_content_length: Optional[str] = None,
                 http_max_header_size: Optional[str] = None,
                 http_max_initial_line_length: Optional[str] = None,
                 indices_fielddata_cache_size: Optional[str] = None,
                 indices_memory_index_buffer_size: Optional[str] = None,
                 indices_queries_cache_size: Optional[str] = None,
                 indices_query_bool_max_clause_count: Optional[str] = None,
                 reindex_remote_whitelists: Optional[Sequence[str]] = None,
                 search_max_buckets: Optional[str] = None,
                 thread_pool_analyze_queue_size: Optional[str] = None,
                 thread_pool_analyze_size: Optional[str] = None,
                 thread_pool_force_merge_size: Optional[str] = None,
                 thread_pool_get_queue_size: Optional[str] = None,
                 thread_pool_get_size: Optional[str] = None,
                 thread_pool_index_queue_size: Optional[str] = None,
                 thread_pool_index_size: Optional[str] = None,
                 thread_pool_search_queue_size: Optional[str] = None,
                 thread_pool_search_size: Optional[str] = None,
                 thread_pool_search_throttled_queue_size: Optional[str] = None,
                 thread_pool_search_throttled_size: Optional[str] = None,
                 thread_pool_write_queue_size: Optional[str] = None,
                 thread_pool_write_size: Optional[str] = None):
        """
        :param str action_auto_create_index_enabled: Explicitly allow or block automatic 
               creation of indices. Defaults to true
        :param str action_destructive_requires_name: Require explicit index names when deleting
        :param str cluster_max_shards_per_node: Controls the number of shards allowed in the
               cluster per data node
        :param str http_max_content_length: Maximum content length for HTTP requests to 
               the Elasticsearch HTTP API, in bytes.
        :param str http_max_header_size: The max size of allowed headers, in bytes.
        :param str http_max_initial_line_length: The max length of an HTTP URL, in bytes.
        :param str indices_fielddata_cache_size: Relative amount. Maximum amount of 
               heap memory used for field data cache. This is an expert setting; decreasing the
               value too much will increase overhead of loading field data; too much memory used
               for field data cache will decrease amount of heap available for other operations.
        :param str indices_memory_index_buffer_size: Percentage value. Default is 10%. 
               Total amount of heap used for indexing buffer, before writing segments to disk.
               This is an expert setting. Too low value will slow down indexing; too high value
               will increase indexing performance but causes performance issues for query performance.
        :param str indices_queries_cache_size: Percentage value. Default is 10%. 
               Maximum amount of heap used for query cache. This is an expert setting.
               Too low value will decrease query performance and increase performance for other
               operations; too high value will cause issues with other Elasticsearch functionality.
        :param str indices_query_bool_max_clause_count: Maximum number of clauses Lucene 
               BooleanQuery can have. The default value (1024) is relatively high, and increasing it
               may cause performance issues. Investigate other approaches first before increasing this value.
        :param Sequence[str] reindex_remote_whitelists: Whitelisted addresses for reindexing. 
               Changing this value will cause all Elasticsearch instances to restart.
        :param str search_max_buckets: Maximum number of aggregation buckets allowed 
               in a single response. Elasticsearch default value is used when this is not defined.
        :param str thread_pool_analyze_queue_size: Size for the thread pool queue. 
               See documentation for exact details.
        :param str thread_pool_analyze_size: Size for the thread pool. See documentation 
               for exact details. Do note this may have maximum value depending on CPU count -
               value is automatically lowered if set to higher than maximum value.
        :param str thread_pool_force_merge_size: Size for the thread pool. See 
               documentation for exact details. Do note this may have maximum value depending on
               CPU count - value is automatically lowered if set to higher than maximum value.
        :param str thread_pool_get_queue_size: Size for the thread pool queue. See 
               documentation for exact details.
        :param str thread_pool_get_size: Size for the thread pool. See documentation 
               for exact details. Do note this may have maximum value depending on CPU count -
               value is automatically lowered if set to higher than maximum value.
        :param str thread_pool_index_queue_size: Size for the thread pool queue. 
               See documentation for exact details.
        :param str thread_pool_index_size: Size for the thread pool. See documentation 
               for exact details. Do note this may have maximum value depending on CPU count -
               value is automatically lowered if set to higher than maximum value.
        :param str thread_pool_search_queue_size: Size for the thread pool queue. See 
               documentation for exact details.
        :param str thread_pool_search_size: Size for the thread pool. See documentation 
               for exact details. Do note this may have maximum value depending on CPU count - value
               is automatically lowered if set to higher than maximum value.
        :param str thread_pool_search_throttled_queue_size: Size for the thread pool queue. 
               See documentation for exact details.
        :param str thread_pool_search_throttled_size: Size for the thread pool. See 
               documentation for exact details. Do note this may have maximum value depending on
               CPU count - value is automatically lowered if set to higher than maximum value.
        :param str thread_pool_write_queue_size: Size for the thread pool queue. See 
               documentation for exact details.
        :param str thread_pool_write_size: Size for the thread pool. See documentation 
               for exact details. Do note this may have maximum value depending on CPU count - value
               is automatically lowered if set to higher than maximum value.
        """
        if action_auto_create_index_enabled is not None:
            pulumi.set(__self__, "action_auto_create_index_enabled", action_auto_create_index_enabled)
        if action_destructive_requires_name is not None:
            pulumi.set(__self__, "action_destructive_requires_name", action_destructive_requires_name)
        if cluster_max_shards_per_node is not None:
            pulumi.set(__self__, "cluster_max_shards_per_node", cluster_max_shards_per_node)
        if http_max_content_length is not None:
            pulumi.set(__self__, "http_max_content_length", http_max_content_length)
        if http_max_header_size is not None:
            pulumi.set(__self__, "http_max_header_size", http_max_header_size)
        if http_max_initial_line_length is not None:
            pulumi.set(__self__, "http_max_initial_line_length", http_max_initial_line_length)
        if indices_fielddata_cache_size is not None:
            pulumi.set(__self__, "indices_fielddata_cache_size", indices_fielddata_cache_size)
        if indices_memory_index_buffer_size is not None:
            pulumi.set(__self__, "indices_memory_index_buffer_size", indices_memory_index_buffer_size)
        if indices_queries_cache_size is not None:
            pulumi.set(__self__, "indices_queries_cache_size", indices_queries_cache_size)
        if indices_query_bool_max_clause_count is not None:
            pulumi.set(__self__, "indices_query_bool_max_clause_count", indices_query_bool_max_clause_count)
        if reindex_remote_whitelists is not None:
            pulumi.set(__self__, "reindex_remote_whitelists", reindex_remote_whitelists)
        if search_max_buckets is not None:
            pulumi.set(__self__, "search_max_buckets", search_max_buckets)
        if thread_pool_analyze_queue_size is not None:
            pulumi.set(__self__, "thread_pool_analyze_queue_size", thread_pool_analyze_queue_size)
        if thread_pool_analyze_size is not None:
            pulumi.set(__self__, "thread_pool_analyze_size", thread_pool_analyze_size)
        if thread_pool_force_merge_size is not None:
            pulumi.set(__self__, "thread_pool_force_merge_size", thread_pool_force_merge_size)
        if thread_pool_get_queue_size is not None:
            pulumi.set(__self__, "thread_pool_get_queue_size", thread_pool_get_queue_size)
        if thread_pool_get_size is not None:
            pulumi.set(__self__, "thread_pool_get_size", thread_pool_get_size)
        if thread_pool_index_queue_size is not None:
            pulumi.set(__self__, "thread_pool_index_queue_size", thread_pool_index_queue_size)
        if thread_pool_index_size is not None:
            pulumi.set(__self__, "thread_pool_index_size", thread_pool_index_size)
        if thread_pool_search_queue_size is not None:
            pulumi.set(__self__, "thread_pool_search_queue_size", thread_pool_search_queue_size)
        if thread_pool_search_size is not None:
            pulumi.set(__self__, "thread_pool_search_size", thread_pool_search_size)
        if thread_pool_search_throttled_queue_size is not None:
            pulumi.set(__self__, "thread_pool_search_throttled_queue_size", thread_pool_search_throttled_queue_size)
        if thread_pool_search_throttled_size is not None:
            pulumi.set(__self__, "thread_pool_search_throttled_size", thread_pool_search_throttled_size)
        if thread_pool_write_queue_size is not None:
            pulumi.set(__self__, "thread_pool_write_queue_size", thread_pool_write_queue_size)
        if thread_pool_write_size is not None:
            pulumi.set(__self__, "thread_pool_write_size", thread_pool_write_size)

    @property
    @pulumi.getter(name="actionAutoCreateIndexEnabled")
    def action_auto_create_index_enabled(self) -> Optional[str]:
        """
        Explicitly allow or block automatic 
        creation of indices. Defaults to true
        """
        return pulumi.get(self, "action_auto_create_index_enabled")

    @property
    @pulumi.getter(name="actionDestructiveRequiresName")
    def action_destructive_requires_name(self) -> Optional[str]:
        """
        Require explicit index names when deleting
        """
        return pulumi.get(self, "action_destructive_requires_name")

    @property
    @pulumi.getter(name="clusterMaxShardsPerNode")
    def cluster_max_shards_per_node(self) -> Optional[str]:
        """
        Controls the number of shards allowed in the
        cluster per data node
        """
        return pulumi.get(self, "cluster_max_shards_per_node")

    @property
    @pulumi.getter(name="httpMaxContentLength")
    def http_max_content_length(self) -> Optional[str]:
        """
        Maximum content length for HTTP requests to 
        the Elasticsearch HTTP API, in bytes.
        """
        return pulumi.get(self, "http_max_content_length")

    @property
    @pulumi.getter(name="httpMaxHeaderSize")
    def http_max_header_size(self) -> Optional[str]:
        """
        The max size of allowed headers, in bytes.
        """
        return pulumi.get(self, "http_max_header_size")

    @property
    @pulumi.getter(name="httpMaxInitialLineLength")
    def http_max_initial_line_length(self) -> Optional[str]:
        """
        The max length of an HTTP URL, in bytes.
        """
        return pulumi.get(self, "http_max_initial_line_length")

    @property
    @pulumi.getter(name="indicesFielddataCacheSize")
    def indices_fielddata_cache_size(self) -> Optional[str]:
        """
        Relative amount. Maximum amount of 
        heap memory used for field data cache. This is an expert setting; decreasing the
        value too much will increase overhead of loading field data; too much memory used
        for field data cache will decrease amount of heap available for other operations.
        """
        return pulumi.get(self, "indices_fielddata_cache_size")

    @property
    @pulumi.getter(name="indicesMemoryIndexBufferSize")
    def indices_memory_index_buffer_size(self) -> Optional[str]:
        """
        Percentage value. Default is 10%. 
        Total amount of heap used for indexing buffer, before writing segments to disk.
        This is an expert setting. Too low value will slow down indexing; too high value
        will increase indexing performance but causes performance issues for query performance.
        """
        return pulumi.get(self, "indices_memory_index_buffer_size")

    @property
    @pulumi.getter(name="indicesQueriesCacheSize")
    def indices_queries_cache_size(self) -> Optional[str]:
        """
        Percentage value. Default is 10%. 
        Maximum amount of heap used for query cache. This is an expert setting.
        Too low value will decrease query performance and increase performance for other
        operations; too high value will cause issues with other Elasticsearch functionality.
        """
        return pulumi.get(self, "indices_queries_cache_size")

    @property
    @pulumi.getter(name="indicesQueryBoolMaxClauseCount")
    def indices_query_bool_max_clause_count(self) -> Optional[str]:
        """
        Maximum number of clauses Lucene 
        BooleanQuery can have. The default value (1024) is relatively high, and increasing it
        may cause performance issues. Investigate other approaches first before increasing this value.
        """
        return pulumi.get(self, "indices_query_bool_max_clause_count")

    @property
    @pulumi.getter(name="reindexRemoteWhitelists")
    def reindex_remote_whitelists(self) -> Optional[Sequence[str]]:
        """
        Whitelisted addresses for reindexing. 
        Changing this value will cause all Elasticsearch instances to restart.
        """
        return pulumi.get(self, "reindex_remote_whitelists")

    @property
    @pulumi.getter(name="searchMaxBuckets")
    def search_max_buckets(self) -> Optional[str]:
        """
        Maximum number of aggregation buckets allowed 
        in a single response. Elasticsearch default value is used when this is not defined.
        """
        return pulumi.get(self, "search_max_buckets")

    @property
    @pulumi.getter(name="threadPoolAnalyzeQueueSize")
    def thread_pool_analyze_queue_size(self) -> Optional[str]:
        """
        Size for the thread pool queue. 
        See documentation for exact details.
        """
        return pulumi.get(self, "thread_pool_analyze_queue_size")

    @property
    @pulumi.getter(name="threadPoolAnalyzeSize")
    def thread_pool_analyze_size(self) -> Optional[str]:
        """
        Size for the thread pool. See documentation 
        for exact details. Do note this may have maximum value depending on CPU count -
        value is automatically lowered if set to higher than maximum value.
        """
        return pulumi.get(self, "thread_pool_analyze_size")

    @property
    @pulumi.getter(name="threadPoolForceMergeSize")
    def thread_pool_force_merge_size(self) -> Optional[str]:
        """
        Size for the thread pool. See 
        documentation for exact details. Do note this may have maximum value depending on
        CPU count - value is automatically lowered if set to higher than maximum value.
        """
        return pulumi.get(self, "thread_pool_force_merge_size")

    @property
    @pulumi.getter(name="threadPoolGetQueueSize")
    def thread_pool_get_queue_size(self) -> Optional[str]:
        """
        Size for the thread pool queue. See 
        documentation for exact details.
        """
        return pulumi.get(self, "thread_pool_get_queue_size")

    @property
    @pulumi.getter(name="threadPoolGetSize")
    def thread_pool_get_size(self) -> Optional[str]:
        """
        Size for the thread pool. See documentation 
        for exact details. Do note this may have maximum value depending on CPU count -
        value is automatically lowered if set to higher than maximum value.
        """
        return pulumi.get(self, "thread_pool_get_size")

    @property
    @pulumi.getter(name="threadPoolIndexQueueSize")
    def thread_pool_index_queue_size(self) -> Optional[str]:
        """
        Size for the thread pool queue. 
        See documentation for exact details.
        """
        return pulumi.get(self, "thread_pool_index_queue_size")

    @property
    @pulumi.getter(name="threadPoolIndexSize")
    def thread_pool_index_size(self) -> Optional[str]:
        """
        Size for the thread pool. See documentation 
        for exact details. Do note this may have maximum value depending on CPU count -
        value is automatically lowered if set to higher than maximum value.
        """
        return pulumi.get(self, "thread_pool_index_size")

    @property
    @pulumi.getter(name="threadPoolSearchQueueSize")
    def thread_pool_search_queue_size(self) -> Optional[str]:
        """
        Size for the thread pool queue. See 
        documentation for exact details.
        """
        return pulumi.get(self, "thread_pool_search_queue_size")

    @property
    @pulumi.getter(name="threadPoolSearchSize")
    def thread_pool_search_size(self) -> Optional[str]:
        """
        Size for the thread pool. See documentation 
        for exact details. Do note this may have maximum value depending on CPU count - value
        is automatically lowered if set to higher than maximum value.
        """
        return pulumi.get(self, "thread_pool_search_size")

    @property
    @pulumi.getter(name="threadPoolSearchThrottledQueueSize")
    def thread_pool_search_throttled_queue_size(self) -> Optional[str]:
        """
        Size for the thread pool queue. 
        See documentation for exact details.
        """
        return pulumi.get(self, "thread_pool_search_throttled_queue_size")

    @property
    @pulumi.getter(name="threadPoolSearchThrottledSize")
    def thread_pool_search_throttled_size(self) -> Optional[str]:
        """
        Size for the thread pool. See 
        documentation for exact details. Do note this may have maximum value depending on
        CPU count - value is automatically lowered if set to higher than maximum value.
        """
        return pulumi.get(self, "thread_pool_search_throttled_size")

    @property
    @pulumi.getter(name="threadPoolWriteQueueSize")
    def thread_pool_write_queue_size(self) -> Optional[str]:
        """
        Size for the thread pool queue. See 
        documentation for exact details.
        """
        return pulumi.get(self, "thread_pool_write_queue_size")

    @property
    @pulumi.getter(name="threadPoolWriteSize")
    def thread_pool_write_size(self) -> Optional[str]:
        """
        Size for the thread pool. See documentation 
        for exact details. Do note this may have maximum value depending on CPU count - value
        is automatically lowered if set to higher than maximum value.
        """
        return pulumi.get(self, "thread_pool_write_size")


@pulumi.output_type
class GetElasticSearchElasticsearchUserConfigIndexPatternResult(dict):
    def __init__(__self__, *,
                 max_index_count: Optional[str] = None,
                 pattern: Optional[str] = None,
                 sorting_algorithm: Optional[str] = None):
        """
        :param str max_index_count: Maximum number of indexes to keep before deleting the oldest one.
        :param str pattern: Must consist of alpha-numeric characters, dashes, underscores, 
               dots and glob characters (* and ?)
        :param str sorting_algorithm: Deletion sorting algorithm
        """
        if max_index_count is not None:
            pulumi.set(__self__, "max_index_count", max_index_count)
        if pattern is not None:
            pulumi.set(__self__, "pattern", pattern)
        if sorting_algorithm is not None:
            pulumi.set(__self__, "sorting_algorithm", sorting_algorithm)

    @property
    @pulumi.getter(name="maxIndexCount")
    def max_index_count(self) -> Optional[str]:
        """
        Maximum number of indexes to keep before deleting the oldest one.
        """
        return pulumi.get(self, "max_index_count")

    @property
    @pulumi.getter
    def pattern(self) -> Optional[str]:
        """
        Must consist of alpha-numeric characters, dashes, underscores, 
        dots and glob characters (* and ?)
        """
        return pulumi.get(self, "pattern")

    @property
    @pulumi.getter(name="sortingAlgorithm")
    def sorting_algorithm(self) -> Optional[str]:
        """
        Deletion sorting algorithm
        """
        return pulumi.get(self, "sorting_algorithm")


@pulumi.output_type
class GetElasticSearchElasticsearchUserConfigIndexTemplateResult(dict):
    def __init__(__self__, *,
                 mapping_nested_objects_limit: Optional[str] = None,
                 number_of_replicas: Optional[str] = None,
                 number_of_shards: Optional[str] = None):
        """
        :param str mapping_nested_objects_limit: The maximum number of nested JSON objects that
               a single document can contain across all nested types. This limit helps to prevent out of
               memory errors when a document contains too many nested objects. Default is 10000.
        :param str number_of_replicas: The number of replicas each primary shard has.
        :param str number_of_shards: The number of primary shards that an index should have.
        """
        if mapping_nested_objects_limit is not None:
            pulumi.set(__self__, "mapping_nested_objects_limit", mapping_nested_objects_limit)
        if number_of_replicas is not None:
            pulumi.set(__self__, "number_of_replicas", number_of_replicas)
        if number_of_shards is not None:
            pulumi.set(__self__, "number_of_shards", number_of_shards)

    @property
    @pulumi.getter(name="mappingNestedObjectsLimit")
    def mapping_nested_objects_limit(self) -> Optional[str]:
        """
        The maximum number of nested JSON objects that
        a single document can contain across all nested types. This limit helps to prevent out of
        memory errors when a document contains too many nested objects. Default is 10000.
        """
        return pulumi.get(self, "mapping_nested_objects_limit")

    @property
    @pulumi.getter(name="numberOfReplicas")
    def number_of_replicas(self) -> Optional[str]:
        """
        The number of replicas each primary shard has.
        """
        return pulumi.get(self, "number_of_replicas")

    @property
    @pulumi.getter(name="numberOfShards")
    def number_of_shards(self) -> Optional[str]:
        """
        The number of primary shards that an index should have.
        """
        return pulumi.get(self, "number_of_shards")


@pulumi.output_type
class GetElasticSearchElasticsearchUserConfigKibanaResult(dict):
    def __init__(__self__, *,
                 elasticsearch_request_timeout: Optional[str] = None,
                 enabled: Optional[str] = None,
                 max_old_space_size: Optional[str] = None):
        """
        :param str elasticsearch_request_timeout: Timeout in milliseconds for requests 
               made by Kibana towards Elasticsearch.
        :param str enabled: Enable or disable Kibana.
        :param str max_old_space_size: Limits the maximum amount of memory (in MiB) the 
               Kibana process can use. This sets the max_old_space_size option of the nodejs running
               the Kibana. Note: the memory reserved by Kibana is not available for Elasticsearch.
        """
        if elasticsearch_request_timeout is not None:
            pulumi.set(__self__, "elasticsearch_request_timeout", elasticsearch_request_timeout)
        if enabled is not None:
            pulumi.set(__self__, "enabled", enabled)
        if max_old_space_size is not None:
            pulumi.set(__self__, "max_old_space_size", max_old_space_size)

    @property
    @pulumi.getter(name="elasticsearchRequestTimeout")
    def elasticsearch_request_timeout(self) -> Optional[str]:
        """
        Timeout in milliseconds for requests 
        made by Kibana towards Elasticsearch.
        """
        return pulumi.get(self, "elasticsearch_request_timeout")

    @property
    @pulumi.getter
    def enabled(self) -> Optional[str]:
        """
        Enable or disable Kibana.
        """
        return pulumi.get(self, "enabled")

    @property
    @pulumi.getter(name="maxOldSpaceSize")
    def max_old_space_size(self) -> Optional[str]:
        """
        Limits the maximum amount of memory (in MiB) the 
        Kibana process can use. This sets the max_old_space_size option of the nodejs running
        the Kibana. Note: the memory reserved by Kibana is not available for Elasticsearch.
        """
        return pulumi.get(self, "max_old_space_size")


@pulumi.output_type
class GetElasticSearchElasticsearchUserConfigPrivateAccessResult(dict):
    def __init__(__self__, *,
                 elasticsearch: Optional[str] = None,
                 kibana: Optional[str] = None,
                 prometheus: Optional[str] = None):
        """
        :param str elasticsearch: Elasticsearch specific server provided values.
        :param str kibana: Allow clients to connect to kibana from the public internet for 
               service nodes that are in a project VPC or another type of private network.
        :param str prometheus: Allow clients to connect to prometheus from the public 
               internet for service nodes that are in a project VPC or another type of private network.
        """
        if elasticsearch is not None:
            pulumi.set(__self__, "elasticsearch", elasticsearch)
        if kibana is not None:
            pulumi.set(__self__, "kibana", kibana)
        if prometheus is not None:
            pulumi.set(__self__, "prometheus", prometheus)

    @property
    @pulumi.getter
    def elasticsearch(self) -> Optional[str]:
        """
        Elasticsearch specific server provided values.
        """
        return pulumi.get(self, "elasticsearch")

    @property
    @pulumi.getter
    def kibana(self) -> Optional[str]:
        """
        Allow clients to connect to kibana from the public internet for 
        service nodes that are in a project VPC or another type of private network.
        """
        return pulumi.get(self, "kibana")

    @property
    @pulumi.getter
    def prometheus(self) -> Optional[str]:
        """
        Allow clients to connect to prometheus from the public 
        internet for service nodes that are in a project VPC or another type of private network.
        """
        return pulumi.get(self, "prometheus")


@pulumi.output_type
class GetElasticSearchElasticsearchUserConfigPrivatelinkAccessResult(dict):
    def __init__(__self__, *,
                 elasticsearch: Optional[str] = None,
                 kibana: Optional[str] = None):
        """
        :param str elasticsearch: Elasticsearch specific server provided values.
        :param str kibana: Allow clients to connect to kibana from the public internet for 
               service nodes that are in a project VPC or another type of private network.
        """
        if elasticsearch is not None:
            pulumi.set(__self__, "elasticsearch", elasticsearch)
        if kibana is not None:
            pulumi.set(__self__, "kibana", kibana)

    @property
    @pulumi.getter
    def elasticsearch(self) -> Optional[str]:
        """
        Elasticsearch specific server provided values.
        """
        return pulumi.get(self, "elasticsearch")

    @property
    @pulumi.getter
    def kibana(self) -> Optional[str]:
        """
        Allow clients to connect to kibana from the public internet for 
        service nodes that are in a project VPC or another type of private network.
        """
        return pulumi.get(self, "kibana")


@pulumi.output_type
class GetElasticSearchElasticsearchUserConfigPublicAccessResult(dict):
    def __init__(__self__, *,
                 elasticsearch: Optional[str] = None,
                 kibana: Optional[str] = None,
                 prometheus: Optional[str] = None):
        """
        :param str elasticsearch: Elasticsearch specific server provided values.
        :param str kibana: Allow clients to connect to kibana from the public internet for 
               service nodes that are in a project VPC or another type of private network.
        :param str prometheus: Allow clients to connect to prometheus from the public 
               internet for service nodes that are in a project VPC or another type of private network.
        """
        if elasticsearch is not None:
            pulumi.set(__self__, "elasticsearch", elasticsearch)
        if kibana is not None:
            pulumi.set(__self__, "kibana", kibana)
        if prometheus is not None:
            pulumi.set(__self__, "prometheus", prometheus)

    @property
    @pulumi.getter
    def elasticsearch(self) -> Optional[str]:
        """
        Elasticsearch specific server provided values.
        """
        return pulumi.get(self, "elasticsearch")

    @property
    @pulumi.getter
    def kibana(self) -> Optional[str]:
        """
        Allow clients to connect to kibana from the public internet for 
        service nodes that are in a project VPC or another type of private network.
        """
        return pulumi.get(self, "kibana")

    @property
    @pulumi.getter
    def prometheus(self) -> Optional[str]:
        """
        Allow clients to connect to prometheus from the public 
        internet for service nodes that are in a project VPC or another type of private network.
        """
        return pulumi.get(self, "prometheus")


@pulumi.output_type
class GetElasticSearchServiceIntegrationResult(dict):
    def __init__(__self__, *,
                 integration_type: str,
                 source_service_name: str):
        pulumi.set(__self__, "integration_type", integration_type)
        pulumi.set(__self__, "source_service_name", source_service_name)

    @property
    @pulumi.getter(name="integrationType")
    def integration_type(self) -> str:
        return pulumi.get(self, "integration_type")

    @property
    @pulumi.getter(name="sourceServiceName")
    def source_service_name(self) -> str:
        return pulumi.get(self, "source_service_name")


@pulumi.output_type
class GetGrafanaComponentResult(dict):
    def __init__(__self__, *,
                 component: str,
                 host: str,
                 kafka_authentication_method: str,
                 port: int,
                 route: str,
                 ssl: bool,
                 usage: str):
        """
        :param str host: Server hostname or IP
        :param int port: SMTP server port
        """
        pulumi.set(__self__, "component", component)
        pulumi.set(__self__, "host", host)
        pulumi.set(__self__, "kafka_authentication_method", kafka_authentication_method)
        pulumi.set(__self__, "port", port)
        pulumi.set(__self__, "route", route)
        pulumi.set(__self__, "ssl", ssl)
        pulumi.set(__self__, "usage", usage)

    @property
    @pulumi.getter
    def component(self) -> str:
        return pulumi.get(self, "component")

    @property
    @pulumi.getter
    def host(self) -> str:
        """
        Server hostname or IP
        """
        return pulumi.get(self, "host")

    @property
    @pulumi.getter(name="kafkaAuthenticationMethod")
    def kafka_authentication_method(self) -> str:
        return pulumi.get(self, "kafka_authentication_method")

    @property
    @pulumi.getter
    def port(self) -> int:
        """
        SMTP server port
        """
        return pulumi.get(self, "port")

    @property
    @pulumi.getter
    def route(self) -> str:
        return pulumi.get(self, "route")

    @property
    @pulumi.getter
    def ssl(self) -> bool:
        return pulumi.get(self, "ssl")

    @property
    @pulumi.getter
    def usage(self) -> str:
        return pulumi.get(self, "usage")


@pulumi.output_type
class GetGrafanaGrafanaResult(dict):
    def __init__(__self__):
        pass


@pulumi.output_type
class GetGrafanaGrafanaUserConfigResult(dict):
    def __init__(__self__, *,
                 alerting_enabled: Optional[str] = None,
                 alerting_error_or_timeout: Optional[str] = None,
                 alerting_nodata_or_nullvalues: Optional[str] = None,
                 allow_embedding: Optional[str] = None,
                 auth_basic_enabled: Optional[str] = None,
                 auth_generic_oauth: Optional['outputs.GetGrafanaGrafanaUserConfigAuthGenericOauthResult'] = None,
                 auth_github: Optional['outputs.GetGrafanaGrafanaUserConfigAuthGithubResult'] = None,
                 auth_gitlab: Optional['outputs.GetGrafanaGrafanaUserConfigAuthGitlabResult'] = None,
                 auth_google: Optional['outputs.GetGrafanaGrafanaUserConfigAuthGoogleResult'] = None,
                 cookie_samesite: Optional[str] = None,
                 custom_domain: Optional[str] = None,
                 dashboards_min_refresh_interval: Optional[str] = None,
                 dashboards_versions_to_keep: Optional[str] = None,
                 dataproxy_send_user_header: Optional[str] = None,
                 dataproxy_timeout: Optional[str] = None,
                 disable_gravatar: Optional[str] = None,
                 editors_can_admin: Optional[str] = None,
                 external_image_storage: Optional['outputs.GetGrafanaGrafanaUserConfigExternalImageStorageResult'] = None,
                 google_analytics_ua_id: Optional[str] = None,
                 ip_filters: Optional[Sequence[str]] = None,
                 metrics_enabled: Optional[str] = None,
                 private_access: Optional['outputs.GetGrafanaGrafanaUserConfigPrivateAccessResult'] = None,
                 privatelink_access: Optional['outputs.GetGrafanaGrafanaUserConfigPrivatelinkAccessResult'] = None,
                 project_to_fork_from: Optional[str] = None,
                 public_access: Optional['outputs.GetGrafanaGrafanaUserConfigPublicAccessResult'] = None,
                 recovery_basebackup_name: Optional[str] = None,
                 service_to_fork_from: Optional[str] = None,
                 smtp_server: Optional['outputs.GetGrafanaGrafanaUserConfigSmtpServerResult'] = None,
                 user_auto_assign_org: Optional[str] = None,
                 user_auto_assign_org_role: Optional[str] = None,
                 viewers_can_edit: Optional[str] = None):
        """
        :param str alerting_enabled: Enable or disable Grafana alerting functionality
        :param str alerting_error_or_timeout: Default error or timeout setting for new alerting rules
        :param str alerting_nodata_or_nullvalues: Default value for 'no data or null values' for
               new alerting rules
        :param str allow_embedding: Allow embedding Grafana dashboards with iframe/frame/object/embed 
               tags. Disabled by default to limit impact of clickjacking
        :param str auth_basic_enabled: Enable or disable basic authentication form, used by Grafana 
               built-in login.
        :param 'GetGrafanaGrafanaUserConfigAuthGenericOauthArgs' auth_generic_oauth: Generic OAuth integration.
        :param 'GetGrafanaGrafanaUserConfigAuthGithubArgs' auth_github: Automatically sign-up users on successful sign-in
        :param 'GetGrafanaGrafanaUserConfigAuthGitlabArgs' auth_gitlab: GitLab Auth integration.
        :param 'GetGrafanaGrafanaUserConfigAuthGoogleArgs' auth_google: Google Auth integration
        :param str cookie_samesite: Cookie SameSite attribute: 'strict' prevents sending cookie for 
               cross-site requests, effectively disabling direct linking from other sites to Grafana. 'lax' is the default value.
        :param str custom_domain: Serve the web frontend using a custom CNAME pointing to the Aiven DNS name.
        :param str dashboards_min_refresh_interval: Signed sequence of decimal numbers, followed
               by a unit suffix (ms, s, m, h, d), e.g. 30s, 1h.
        :param str dashboards_versions_to_keep: Dashboard versions to keep per dashboard.
        :param str dataproxy_send_user_header: Send 'X-Grafana-User' header to data source.
        :param str dataproxy_timeout: Timeout for data proxy requests in seconds.
        :param str disable_gravatar: Set to true to disable gravatar. Defaults to false 
               (gravatar is enabled).
        :param str editors_can_admin: Editors can manage folders, teams and dashboards created by them.
        :param 'GetGrafanaGrafanaUserConfigExternalImageStorageArgs' external_image_storage: External image store settings
        :param str google_analytics_ua_id: Google Analytics Universal Analytics ID for tracking Grafana usage
        :param Sequence[str] ip_filters: Allow incoming connections from CIDR address block, e.g. '10.20.0.0/16'
        :param str metrics_enabled: Enable Grafana /metrics endpoint
        :param 'GetGrafanaGrafanaUserConfigPrivatelinkAccessArgs' privatelink_access: Allow access to selected service components through Privatelink
        :param str project_to_fork_from: Name of another project to fork a service from. This has 
               effect only when a new service is being created.
        :param 'GetGrafanaGrafanaUserConfigPublicAccessArgs' public_access: Allow access to selected service ports from the public Internet.
        :param str recovery_basebackup_name: Name of the basebackup to restore in forked service.
        :param str service_to_fork_from: Name of another service to fork from. This has effect only 
               when a new service is being created.
        :param 'GetGrafanaGrafanaUserConfigSmtpServerArgs' smtp_server: SMTP server settings.
        :param str user_auto_assign_org: Auto-assign new users on signup to main organization. 
               Defaults to false.
        :param str user_auto_assign_org_role: Set role for new signups. Defaults to Viewer.
        :param str viewers_can_edit: Users with view-only permission can edit but not save dashboards.
        """
        if alerting_enabled is not None:
            pulumi.set(__self__, "alerting_enabled", alerting_enabled)
        if alerting_error_or_timeout is not None:
            pulumi.set(__self__, "alerting_error_or_timeout", alerting_error_or_timeout)
        if alerting_nodata_or_nullvalues is not None:
            pulumi.set(__self__, "alerting_nodata_or_nullvalues", alerting_nodata_or_nullvalues)
        if allow_embedding is not None:
            pulumi.set(__self__, "allow_embedding", allow_embedding)
        if auth_basic_enabled is not None:
            pulumi.set(__self__, "auth_basic_enabled", auth_basic_enabled)
        if auth_generic_oauth is not None:
            pulumi.set(__self__, "auth_generic_oauth", auth_generic_oauth)
        if auth_github is not None:
            pulumi.set(__self__, "auth_github", auth_github)
        if auth_gitlab is not None:
            pulumi.set(__self__, "auth_gitlab", auth_gitlab)
        if auth_google is not None:
            pulumi.set(__self__, "auth_google", auth_google)
        if cookie_samesite is not None:
            pulumi.set(__self__, "cookie_samesite", cookie_samesite)
        if custom_domain is not None:
            pulumi.set(__self__, "custom_domain", custom_domain)
        if dashboards_min_refresh_interval is not None:
            pulumi.set(__self__, "dashboards_min_refresh_interval", dashboards_min_refresh_interval)
        if dashboards_versions_to_keep is not None:
            pulumi.set(__self__, "dashboards_versions_to_keep", dashboards_versions_to_keep)
        if dataproxy_send_user_header is not None:
            pulumi.set(__self__, "dataproxy_send_user_header", dataproxy_send_user_header)
        if dataproxy_timeout is not None:
            pulumi.set(__self__, "dataproxy_timeout", dataproxy_timeout)
        if disable_gravatar is not None:
            pulumi.set(__self__, "disable_gravatar", disable_gravatar)
        if editors_can_admin is not None:
            pulumi.set(__self__, "editors_can_admin", editors_can_admin)
        if external_image_storage is not None:
            pulumi.set(__self__, "external_image_storage", external_image_storage)
        if google_analytics_ua_id is not None:
            pulumi.set(__self__, "google_analytics_ua_id", google_analytics_ua_id)
        if ip_filters is not None:
            pulumi.set(__self__, "ip_filters", ip_filters)
        if metrics_enabled is not None:
            pulumi.set(__self__, "metrics_enabled", metrics_enabled)
        if private_access is not None:
            pulumi.set(__self__, "private_access", private_access)
        if privatelink_access is not None:
            pulumi.set(__self__, "privatelink_access", privatelink_access)
        if project_to_fork_from is not None:
            pulumi.set(__self__, "project_to_fork_from", project_to_fork_from)
        if public_access is not None:
            pulumi.set(__self__, "public_access", public_access)
        if recovery_basebackup_name is not None:
            pulumi.set(__self__, "recovery_basebackup_name", recovery_basebackup_name)
        if service_to_fork_from is not None:
            pulumi.set(__self__, "service_to_fork_from", service_to_fork_from)
        if smtp_server is not None:
            pulumi.set(__self__, "smtp_server", smtp_server)
        if user_auto_assign_org is not None:
            pulumi.set(__self__, "user_auto_assign_org", user_auto_assign_org)
        if user_auto_assign_org_role is not None:
            pulumi.set(__self__, "user_auto_assign_org_role", user_auto_assign_org_role)
        if viewers_can_edit is not None:
            pulumi.set(__self__, "viewers_can_edit", viewers_can_edit)

    @property
    @pulumi.getter(name="alertingEnabled")
    def alerting_enabled(self) -> Optional[str]:
        """
        Enable or disable Grafana alerting functionality
        """
        return pulumi.get(self, "alerting_enabled")

    @property
    @pulumi.getter(name="alertingErrorOrTimeout")
    def alerting_error_or_timeout(self) -> Optional[str]:
        """
        Default error or timeout setting for new alerting rules
        """
        return pulumi.get(self, "alerting_error_or_timeout")

    @property
    @pulumi.getter(name="alertingNodataOrNullvalues")
    def alerting_nodata_or_nullvalues(self) -> Optional[str]:
        """
        Default value for 'no data or null values' for
        new alerting rules
        """
        return pulumi.get(self, "alerting_nodata_or_nullvalues")

    @property
    @pulumi.getter(name="allowEmbedding")
    def allow_embedding(self) -> Optional[str]:
        """
        Allow embedding Grafana dashboards with iframe/frame/object/embed 
        tags. Disabled by default to limit impact of clickjacking
        """
        return pulumi.get(self, "allow_embedding")

    @property
    @pulumi.getter(name="authBasicEnabled")
    def auth_basic_enabled(self) -> Optional[str]:
        """
        Enable or disable basic authentication form, used by Grafana 
        built-in login.
        """
        return pulumi.get(self, "auth_basic_enabled")

    @property
    @pulumi.getter(name="authGenericOauth")
    def auth_generic_oauth(self) -> Optional['outputs.GetGrafanaGrafanaUserConfigAuthGenericOauthResult']:
        """
        Generic OAuth integration.
        """
        return pulumi.get(self, "auth_generic_oauth")

    @property
    @pulumi.getter(name="authGithub")
    def auth_github(self) -> Optional['outputs.GetGrafanaGrafanaUserConfigAuthGithubResult']:
        """
        Automatically sign-up users on successful sign-in
        """
        return pulumi.get(self, "auth_github")

    @property
    @pulumi.getter(name="authGitlab")
    def auth_gitlab(self) -> Optional['outputs.GetGrafanaGrafanaUserConfigAuthGitlabResult']:
        """
        GitLab Auth integration.
        """
        return pulumi.get(self, "auth_gitlab")

    @property
    @pulumi.getter(name="authGoogle")
    def auth_google(self) -> Optional['outputs.GetGrafanaGrafanaUserConfigAuthGoogleResult']:
        """
        Google Auth integration
        """
        return pulumi.get(self, "auth_google")

    @property
    @pulumi.getter(name="cookieSamesite")
    def cookie_samesite(self) -> Optional[str]:
        """
        Cookie SameSite attribute: 'strict' prevents sending cookie for 
        cross-site requests, effectively disabling direct linking from other sites to Grafana. 'lax' is the default value.
        """
        return pulumi.get(self, "cookie_samesite")

    @property
    @pulumi.getter(name="customDomain")
    def custom_domain(self) -> Optional[str]:
        """
        Serve the web frontend using a custom CNAME pointing to the Aiven DNS name.
        """
        return pulumi.get(self, "custom_domain")

    @property
    @pulumi.getter(name="dashboardsMinRefreshInterval")
    def dashboards_min_refresh_interval(self) -> Optional[str]:
        """
        Signed sequence of decimal numbers, followed
        by a unit suffix (ms, s, m, h, d), e.g. 30s, 1h.
        """
        return pulumi.get(self, "dashboards_min_refresh_interval")

    @property
    @pulumi.getter(name="dashboardsVersionsToKeep")
    def dashboards_versions_to_keep(self) -> Optional[str]:
        """
        Dashboard versions to keep per dashboard.
        """
        return pulumi.get(self, "dashboards_versions_to_keep")

    @property
    @pulumi.getter(name="dataproxySendUserHeader")
    def dataproxy_send_user_header(self) -> Optional[str]:
        """
        Send 'X-Grafana-User' header to data source.
        """
        return pulumi.get(self, "dataproxy_send_user_header")

    @property
    @pulumi.getter(name="dataproxyTimeout")
    def dataproxy_timeout(self) -> Optional[str]:
        """
        Timeout for data proxy requests in seconds.
        """
        return pulumi.get(self, "dataproxy_timeout")

    @property
    @pulumi.getter(name="disableGravatar")
    def disable_gravatar(self) -> Optional[str]:
        """
        Set to true to disable gravatar. Defaults to false 
        (gravatar is enabled).
        """
        return pulumi.get(self, "disable_gravatar")

    @property
    @pulumi.getter(name="editorsCanAdmin")
    def editors_can_admin(self) -> Optional[str]:
        """
        Editors can manage folders, teams and dashboards created by them.
        """
        return pulumi.get(self, "editors_can_admin")

    @property
    @pulumi.getter(name="externalImageStorage")
    def external_image_storage(self) -> Optional['outputs.GetGrafanaGrafanaUserConfigExternalImageStorageResult']:
        """
        External image store settings
        """
        return pulumi.get(self, "external_image_storage")

    @property
    @pulumi.getter(name="googleAnalyticsUaId")
    def google_analytics_ua_id(self) -> Optional[str]:
        """
        Google Analytics Universal Analytics ID for tracking Grafana usage
        """
        return pulumi.get(self, "google_analytics_ua_id")

    @property
    @pulumi.getter(name="ipFilters")
    def ip_filters(self) -> Optional[Sequence[str]]:
        """
        Allow incoming connections from CIDR address block, e.g. '10.20.0.0/16'
        """
        return pulumi.get(self, "ip_filters")

    @property
    @pulumi.getter(name="metricsEnabled")
    def metrics_enabled(self) -> Optional[str]:
        """
        Enable Grafana /metrics endpoint
        """
        return pulumi.get(self, "metrics_enabled")

    @property
    @pulumi.getter(name="privateAccess")
    def private_access(self) -> Optional['outputs.GetGrafanaGrafanaUserConfigPrivateAccessResult']:
        return pulumi.get(self, "private_access")

    @property
    @pulumi.getter(name="privatelinkAccess")
    def privatelink_access(self) -> Optional['outputs.GetGrafanaGrafanaUserConfigPrivatelinkAccessResult']:
        """
        Allow access to selected service components through Privatelink
        """
        return pulumi.get(self, "privatelink_access")

    @property
    @pulumi.getter(name="projectToForkFrom")
    def project_to_fork_from(self) -> Optional[str]:
        """
        Name of another project to fork a service from. This has 
        effect only when a new service is being created.
        """
        return pulumi.get(self, "project_to_fork_from")

    @property
    @pulumi.getter(name="publicAccess")
    def public_access(self) -> Optional['outputs.GetGrafanaGrafanaUserConfigPublicAccessResult']:
        """
        Allow access to selected service ports from the public Internet.
        """
        return pulumi.get(self, "public_access")

    @property
    @pulumi.getter(name="recoveryBasebackupName")
    def recovery_basebackup_name(self) -> Optional[str]:
        """
        Name of the basebackup to restore in forked service.
        """
        return pulumi.get(self, "recovery_basebackup_name")

    @property
    @pulumi.getter(name="serviceToForkFrom")
    def service_to_fork_from(self) -> Optional[str]:
        """
        Name of another service to fork from. This has effect only 
        when a new service is being created.
        """
        return pulumi.get(self, "service_to_fork_from")

    @property
    @pulumi.getter(name="smtpServer")
    def smtp_server(self) -> Optional['outputs.GetGrafanaGrafanaUserConfigSmtpServerResult']:
        """
        SMTP server settings.
        """
        return pulumi.get(self, "smtp_server")

    @property
    @pulumi.getter(name="userAutoAssignOrg")
    def user_auto_assign_org(self) -> Optional[str]:
        """
        Auto-assign new users on signup to main organization. 
        Defaults to false.
        """
        return pulumi.get(self, "user_auto_assign_org")

    @property
    @pulumi.getter(name="userAutoAssignOrgRole")
    def user_auto_assign_org_role(self) -> Optional[str]:
        """
        Set role for new signups. Defaults to Viewer.
        """
        return pulumi.get(self, "user_auto_assign_org_role")

    @property
    @pulumi.getter(name="viewersCanEdit")
    def viewers_can_edit(self) -> Optional[str]:
        """
        Users with view-only permission can edit but not save dashboards.
        """
        return pulumi.get(self, "viewers_can_edit")


@pulumi.output_type
class GetGrafanaGrafanaUserConfigAuthGenericOauthResult(dict):
    def __init__(__self__, *,
                 allow_sign_up: Optional[str] = None,
                 allowed_domains: Optional[Sequence[str]] = None,
                 allowed_organizations: Optional[Sequence[str]] = None,
                 api_url: Optional[str] = None,
                 auth_url: Optional[str] = None,
                 client_id: Optional[str] = None,
                 client_secret: Optional[str] = None,
                 name: Optional[str] = None,
                 scopes: Optional[Sequence[str]] = None,
                 token_url: Optional[str] = None):
        """
        :param str allow_sign_up: Automatically sign-up users on successful sign-in
        :param Sequence[str] allowed_domains: Allowed domain
        :param Sequence[str] allowed_organizations: Must consist of alpha-numeric characters and dashes"
        :param str api_url: API URL. This only needs to be set when using self hosted GitLab
        :param str auth_url: Authorization URL. This only needs to be set when using self hosted GitLab
        :param str client_id: Client ID from provider
        :param str client_secret: Client secret from provider
        :param str name: Name of the OAuth integration
        :param Sequence[str] scopes: Scope must be non-empty string without whitespace
        :param str token_url: Token URL. This only needs to be set when using self hosted GitLab
        """
        if allow_sign_up is not None:
            pulumi.set(__self__, "allow_sign_up", allow_sign_up)
        if allowed_domains is not None:
            pulumi.set(__self__, "allowed_domains", allowed_domains)
        if allowed_organizations is not None:
            pulumi.set(__self__, "allowed_organizations", allowed_organizations)
        if api_url is not None:
            pulumi.set(__self__, "api_url", api_url)
        if auth_url is not None:
            pulumi.set(__self__, "auth_url", auth_url)
        if client_id is not None:
            pulumi.set(__self__, "client_id", client_id)
        if client_secret is not None:
            pulumi.set(__self__, "client_secret", client_secret)
        if name is not None:
            pulumi.set(__self__, "name", name)
        if scopes is not None:
            pulumi.set(__self__, "scopes", scopes)
        if token_url is not None:
            pulumi.set(__self__, "token_url", token_url)

    @property
    @pulumi.getter(name="allowSignUp")
    def allow_sign_up(self) -> Optional[str]:
        """
        Automatically sign-up users on successful sign-in
        """
        return pulumi.get(self, "allow_sign_up")

    @property
    @pulumi.getter(name="allowedDomains")
    def allowed_domains(self) -> Optional[Sequence[str]]:
        """
        Allowed domain
        """
        return pulumi.get(self, "allowed_domains")

    @property
    @pulumi.getter(name="allowedOrganizations")
    def allowed_organizations(self) -> Optional[Sequence[str]]:
        """
        Must consist of alpha-numeric characters and dashes"
        """
        return pulumi.get(self, "allowed_organizations")

    @property
    @pulumi.getter(name="apiUrl")
    def api_url(self) -> Optional[str]:
        """
        API URL. This only needs to be set when using self hosted GitLab
        """
        return pulumi.get(self, "api_url")

    @property
    @pulumi.getter(name="authUrl")
    def auth_url(self) -> Optional[str]:
        """
        Authorization URL. This only needs to be set when using self hosted GitLab
        """
        return pulumi.get(self, "auth_url")

    @property
    @pulumi.getter(name="clientId")
    def client_id(self) -> Optional[str]:
        """
        Client ID from provider
        """
        return pulumi.get(self, "client_id")

    @property
    @pulumi.getter(name="clientSecret")
    def client_secret(self) -> Optional[str]:
        """
        Client secret from provider
        """
        return pulumi.get(self, "client_secret")

    @property
    @pulumi.getter
    def name(self) -> Optional[str]:
        """
        Name of the OAuth integration
        """
        return pulumi.get(self, "name")

    @property
    @pulumi.getter
    def scopes(self) -> Optional[Sequence[str]]:
        """
        Scope must be non-empty string without whitespace
        """
        return pulumi.get(self, "scopes")

    @property
    @pulumi.getter(name="tokenUrl")
    def token_url(self) -> Optional[str]:
        """
        Token URL. This only needs to be set when using self hosted GitLab
        """
        return pulumi.get(self, "token_url")


@pulumi.output_type
class GetGrafanaGrafanaUserConfigAuthGithubResult(dict):
    def __init__(__self__, *,
                 allow_sign_up: Optional[str] = None,
                 allowed_organizations: Optional[Sequence[str]] = None,
                 client_id: Optional[str] = None,
                 client_secret: Optional[str] = None,
                 team_ids: Optional[Sequence[str]] = None):
        """
        :param str allow_sign_up: Automatically sign-up users on successful sign-in
        :param Sequence[str] allowed_organizations: Must consist of alpha-numeric characters and dashes"
        :param str client_id: Client ID from provider
        :param str client_secret: Client secret from provider
        :param Sequence[str] team_ids: Require users to belong to one of given team IDs
        """
        if allow_sign_up is not None:
            pulumi.set(__self__, "allow_sign_up", allow_sign_up)
        if allowed_organizations is not None:
            pulumi.set(__self__, "allowed_organizations", allowed_organizations)
        if client_id is not None:
            pulumi.set(__self__, "client_id", client_id)
        if client_secret is not None:
            pulumi.set(__self__, "client_secret", client_secret)
        if team_ids is not None:
            pulumi.set(__self__, "team_ids", team_ids)

    @property
    @pulumi.getter(name="allowSignUp")
    def allow_sign_up(self) -> Optional[str]:
        """
        Automatically sign-up users on successful sign-in
        """
        return pulumi.get(self, "allow_sign_up")

    @property
    @pulumi.getter(name="allowedOrganizations")
    def allowed_organizations(self) -> Optional[Sequence[str]]:
        """
        Must consist of alpha-numeric characters and dashes"
        """
        return pulumi.get(self, "allowed_organizations")

    @property
    @pulumi.getter(name="clientId")
    def client_id(self) -> Optional[str]:
        """
        Client ID from provider
        """
        return pulumi.get(self, "client_id")

    @property
    @pulumi.getter(name="clientSecret")
    def client_secret(self) -> Optional[str]:
        """
        Client secret from provider
        """
        return pulumi.get(self, "client_secret")

    @property
    @pulumi.getter(name="teamIds")
    def team_ids(self) -> Optional[Sequence[str]]:
        """
        Require users to belong to one of given team IDs
        """
        return pulumi.get(self, "team_ids")


@pulumi.output_type
class GetGrafanaGrafanaUserConfigAuthGitlabResult(dict):
    def __init__(__self__, *,
                 allow_sign_up: Optional[str] = None,
                 allowed_groups: Optional[Sequence[str]] = None,
                 api_url: Optional[str] = None,
                 auth_url: Optional[str] = None,
                 client_id: Optional[str] = None,
                 client_secret: Optional[str] = None,
                 token_url: Optional[str] = None):
        """
        :param str allow_sign_up: Automatically sign-up users on successful sign-in
        :param Sequence[str] allowed_groups: Require users to belong to one of given groups
        :param str api_url: API URL. This only needs to be set when using self hosted GitLab
        :param str auth_url: Authorization URL. This only needs to be set when using self hosted GitLab
        :param str client_id: Client ID from provider
        :param str client_secret: Client secret from provider
        :param str token_url: Token URL. This only needs to be set when using self hosted GitLab
        """
        if allow_sign_up is not None:
            pulumi.set(__self__, "allow_sign_up", allow_sign_up)
        if allowed_groups is not None:
            pulumi.set(__self__, "allowed_groups", allowed_groups)
        if api_url is not None:
            pulumi.set(__self__, "api_url", api_url)
        if auth_url is not None:
            pulumi.set(__self__, "auth_url", auth_url)
        if client_id is not None:
            pulumi.set(__self__, "client_id", client_id)
        if client_secret is not None:
            pulumi.set(__self__, "client_secret", client_secret)
        if token_url is not None:
            pulumi.set(__self__, "token_url", token_url)

    @property
    @pulumi.getter(name="allowSignUp")
    def allow_sign_up(self) -> Optional[str]:
        """
        Automatically sign-up users on successful sign-in
        """
        return pulumi.get(self, "allow_sign_up")

    @property
    @pulumi.getter(name="allowedGroups")
    def allowed_groups(self) -> Optional[Sequence[str]]:
        """
        Require users to belong to one of given groups
        """
        return pulumi.get(self, "allowed_groups")

    @property
    @pulumi.getter(name="apiUrl")
    def api_url(self) -> Optional[str]:
        """
        API URL. This only needs to be set when using self hosted GitLab
        """
        return pulumi.get(self, "api_url")

    @property
    @pulumi.getter(name="authUrl")
    def auth_url(self) -> Optional[str]:
        """
        Authorization URL. This only needs to be set when using self hosted GitLab
        """
        return pulumi.get(self, "auth_url")

    @property
    @pulumi.getter(name="clientId")
    def client_id(self) -> Optional[str]:
        """
        Client ID from provider
        """
        return pulumi.get(self, "client_id")

    @property
    @pulumi.getter(name="clientSecret")
    def client_secret(self) -> Optional[str]:
        """
        Client secret from provider
        """
        return pulumi.get(self, "client_secret")

    @property
    @pulumi.getter(name="tokenUrl")
    def token_url(self) -> Optional[str]:
        """
        Token URL. This only needs to be set when using self hosted GitLab
        """
        return pulumi.get(self, "token_url")


@pulumi.output_type
class GetGrafanaGrafanaUserConfigAuthGoogleResult(dict):
    def __init__(__self__, *,
                 allow_sign_up: Optional[str] = None,
                 allowed_domains: Optional[Sequence[str]] = None,
                 client_id: Optional[str] = None,
                 client_secret: Optional[str] = None):
        """
        :param str allow_sign_up: Automatically sign-up users on successful sign-in
        :param Sequence[str] allowed_domains: Allowed domain
        :param str client_id: Client ID from provider
        :param str client_secret: Client secret from provider
        """
        if allow_sign_up is not None:
            pulumi.set(__self__, "allow_sign_up", allow_sign_up)
        if allowed_domains is not None:
            pulumi.set(__self__, "allowed_domains", allowed_domains)
        if client_id is not None:
            pulumi.set(__self__, "client_id", client_id)
        if client_secret is not None:
            pulumi.set(__self__, "client_secret", client_secret)

    @property
    @pulumi.getter(name="allowSignUp")
    def allow_sign_up(self) -> Optional[str]:
        """
        Automatically sign-up users on successful sign-in
        """
        return pulumi.get(self, "allow_sign_up")

    @property
    @pulumi.getter(name="allowedDomains")
    def allowed_domains(self) -> Optional[Sequence[str]]:
        """
        Allowed domain
        """
        return pulumi.get(self, "allowed_domains")

    @property
    @pulumi.getter(name="clientId")
    def client_id(self) -> Optional[str]:
        """
        Client ID from provider
        """
        return pulumi.get(self, "client_id")

    @property
    @pulumi.getter(name="clientSecret")
    def client_secret(self) -> Optional[str]:
        """
        Client secret from provider
        """
        return pulumi.get(self, "client_secret")


@pulumi.output_type
class GetGrafanaGrafanaUserConfigExternalImageStorageResult(dict):
    def __init__(__self__, *,
                 access_key: Optional[str] = None,
                 bucket_url: Optional[str] = None,
                 provider: Optional[str] = None,
                 secret_key: Optional[str] = None):
        """
        :param str access_key: S3 access key. Requires permissions to the S3 bucket for the 
               s3:PutObject and s3:PutObjectAcl actions
        :param str bucket_url: Bucket URL for S3
        :param str provider: Provider type
        :param str secret_key: S3 secret key
        """
        if access_key is not None:
            pulumi.set(__self__, "access_key", access_key)
        if bucket_url is not None:
            pulumi.set(__self__, "bucket_url", bucket_url)
        if provider is not None:
            pulumi.set(__self__, "provider", provider)
        if secret_key is not None:
            pulumi.set(__self__, "secret_key", secret_key)

    @property
    @pulumi.getter(name="accessKey")
    def access_key(self) -> Optional[str]:
        """
        S3 access key. Requires permissions to the S3 bucket for the 
        s3:PutObject and s3:PutObjectAcl actions
        """
        return pulumi.get(self, "access_key")

    @property
    @pulumi.getter(name="bucketUrl")
    def bucket_url(self) -> Optional[str]:
        """
        Bucket URL for S3
        """
        return pulumi.get(self, "bucket_url")

    @property
    @pulumi.getter
    def provider(self) -> Optional[str]:
        """
        Provider type
        """
        return pulumi.get(self, "provider")

    @property
    @pulumi.getter(name="secretKey")
    def secret_key(self) -> Optional[str]:
        """
        S3 secret key
        """
        return pulumi.get(self, "secret_key")


@pulumi.output_type
class GetGrafanaGrafanaUserConfigPrivateAccessResult(dict):
    def __init__(__self__, *,
                 grafana: Optional[str] = None):
        """
        :param str grafana: Grafana specific server provided values.
        """
        if grafana is not None:
            pulumi.set(__self__, "grafana", grafana)

    @property
    @pulumi.getter
    def grafana(self) -> Optional[str]:
        """
        Grafana specific server provided values.
        """
        return pulumi.get(self, "grafana")


@pulumi.output_type
class GetGrafanaGrafanaUserConfigPrivatelinkAccessResult(dict):
    def __init__(__self__, *,
                 grafana: Optional[str] = None):
        """
        :param str grafana: Grafana specific server provided values.
        """
        if grafana is not None:
            pulumi.set(__self__, "grafana", grafana)

    @property
    @pulumi.getter
    def grafana(self) -> Optional[str]:
        """
        Grafana specific server provided values.
        """
        return pulumi.get(self, "grafana")


@pulumi.output_type
class GetGrafanaGrafanaUserConfigPublicAccessResult(dict):
    def __init__(__self__, *,
                 grafana: Optional[str] = None):
        """
        :param str grafana: Grafana specific server provided values.
        """
        if grafana is not None:
            pulumi.set(__self__, "grafana", grafana)

    @property
    @pulumi.getter
    def grafana(self) -> Optional[str]:
        """
        Grafana specific server provided values.
        """
        return pulumi.get(self, "grafana")


@pulumi.output_type
class GetGrafanaGrafanaUserConfigSmtpServerResult(dict):
    def __init__(__self__, *,
                 from_address: Optional[str] = None,
                 from_name: Optional[str] = None,
                 host: Optional[str] = None,
                 password: Optional[str] = None,
                 port: Optional[str] = None,
                 skip_verify: Optional[str] = None,
                 starttls_policy: Optional[str] = None,
                 username: Optional[str] = None):
        """
        :param str from_address: Address used for sending emails
        :param str from_name: Name used in outgoing emails, defaults to Grafana
        :param str host: Server hostname or IP
        :param str password: Password for SMTP authentication
        :param str port: SMTP server port
        :param str skip_verify: Skip verifying server certificate. Defaults to false
        :param str starttls_policy: Either OpportunisticStartTLS, MandatoryStartTLS or NoStartTLS. 
               Default is OpportunisticStartTLS.
        :param str username: Username for SMTP authentication
        """
        if from_address is not None:
            pulumi.set(__self__, "from_address", from_address)
        if from_name is not None:
            pulumi.set(__self__, "from_name", from_name)
        if host is not None:
            pulumi.set(__self__, "host", host)
        if password is not None:
            pulumi.set(__self__, "password", password)
        if port is not None:
            pulumi.set(__self__, "port", port)
        if skip_verify is not None:
            pulumi.set(__self__, "skip_verify", skip_verify)
        if starttls_policy is not None:
            pulumi.set(__self__, "starttls_policy", starttls_policy)
        if username is not None:
            pulumi.set(__self__, "username", username)

    @property
    @pulumi.getter(name="fromAddress")
    def from_address(self) -> Optional[str]:
        """
        Address used for sending emails
        """
        return pulumi.get(self, "from_address")

    @property
    @pulumi.getter(name="fromName")
    def from_name(self) -> Optional[str]:
        """
        Name used in outgoing emails, defaults to Grafana
        """
        return pulumi.get(self, "from_name")

    @property
    @pulumi.getter
    def host(self) -> Optional[str]:
        """
        Server hostname or IP
        """
        return pulumi.get(self, "host")

    @property
    @pulumi.getter
    def password(self) -> Optional[str]:
        """
        Password for SMTP authentication
        """
        return pulumi.get(self, "password")

    @property
    @pulumi.getter
    def port(self) -> Optional[str]:
        """
        SMTP server port
        """
        return pulumi.get(self, "port")

    @property
    @pulumi.getter(name="skipVerify")
    def skip_verify(self) -> Optional[str]:
        """
        Skip verifying server certificate. Defaults to false
        """
        return pulumi.get(self, "skip_verify")

    @property
    @pulumi.getter(name="starttlsPolicy")
    def starttls_policy(self) -> Optional[str]:
        """
        Either OpportunisticStartTLS, MandatoryStartTLS or NoStartTLS. 
        Default is OpportunisticStartTLS.
        """
        return pulumi.get(self, "starttls_policy")

    @property
    @pulumi.getter
    def username(self) -> Optional[str]:
        """
        Username for SMTP authentication
        """
        return pulumi.get(self, "username")


@pulumi.output_type
class GetGrafanaServiceIntegrationResult(dict):
    def __init__(__self__, *,
                 integration_type: str,
                 source_service_name: str):
        pulumi.set(__self__, "integration_type", integration_type)
        pulumi.set(__self__, "source_service_name", source_service_name)

    @property
    @pulumi.getter(name="integrationType")
    def integration_type(self) -> str:
        return pulumi.get(self, "integration_type")

    @property
    @pulumi.getter(name="sourceServiceName")
    def source_service_name(self) -> str:
        return pulumi.get(self, "source_service_name")


@pulumi.output_type
class GetInfluxDbComponentResult(dict):
    def __init__(__self__, *,
                 component: str,
                 host: str,
                 kafka_authentication_method: str,
                 port: int,
                 route: str,
                 ssl: bool,
                 usage: str):
        pulumi.set(__self__, "component", component)
        pulumi.set(__self__, "host", host)
        pulumi.set(__self__, "kafka_authentication_method", kafka_authentication_method)
        pulumi.set(__self__, "port", port)
        pulumi.set(__self__, "route", route)
        pulumi.set(__self__, "ssl", ssl)
        pulumi.set(__self__, "usage", usage)

    @property
    @pulumi.getter
    def component(self) -> str:
        return pulumi.get(self, "component")

    @property
    @pulumi.getter
    def host(self) -> str:
        return pulumi.get(self, "host")

    @property
    @pulumi.getter(name="kafkaAuthenticationMethod")
    def kafka_authentication_method(self) -> str:
        return pulumi.get(self, "kafka_authentication_method")

    @property
    @pulumi.getter
    def port(self) -> int:
        return pulumi.get(self, "port")

    @property
    @pulumi.getter
    def route(self) -> str:
        return pulumi.get(self, "route")

    @property
    @pulumi.getter
    def ssl(self) -> bool:
        return pulumi.get(self, "ssl")

    @property
    @pulumi.getter
    def usage(self) -> str:
        return pulumi.get(self, "usage")


@pulumi.output_type
class GetInfluxDbInfluxdbResult(dict):
    def __init__(__self__, *,
                 database_name: str):
        pulumi.set(__self__, "database_name", database_name)

    @property
    @pulumi.getter(name="databaseName")
    def database_name(self) -> str:
        return pulumi.get(self, "database_name")


@pulumi.output_type
class GetInfluxDbInfluxdbUserConfigResult(dict):
    def __init__(__self__, *,
                 custom_domain: Optional[str] = None,
                 influxdb: Optional['outputs.GetInfluxDbInfluxdbUserConfigInfluxdbResult'] = None,
                 ip_filters: Optional[Sequence[str]] = None,
                 private_access: Optional['outputs.GetInfluxDbInfluxdbUserConfigPrivateAccessResult'] = None,
                 privatelink_access: Optional['outputs.GetInfluxDbInfluxdbUserConfigPrivatelinkAccessResult'] = None,
                 project_to_fork_from: Optional[str] = None,
                 public_access: Optional['outputs.GetInfluxDbInfluxdbUserConfigPublicAccessResult'] = None,
                 recovery_basebackup_name: Optional[str] = None,
                 service_to_fork_from: Optional[str] = None):
        """
        :param str custom_domain: Serve the web frontend using a custom CNAME pointing to the Aiven DNS name
        :param 'GetInfluxDbInfluxdbUserConfigInfluxdbArgs' influxdb: InfluxDB specific server provided values.
        :param Sequence[str] ip_filters: allow incoming connections from CIDR address block, e.g. `10.20.0.0/16`
        :param 'GetInfluxDbInfluxdbUserConfigPrivateAccessArgs' private_access: Allow access to selected service ports from private networks
        :param 'GetInfluxDbInfluxdbUserConfigPrivatelinkAccessArgs' privatelink_access: Allow access to selected service components through Privatelink
        :param str project_to_fork_from: Name of another project to fork a service from. This has
               effect only when a new service is being created.
        :param 'GetInfluxDbInfluxdbUserConfigPublicAccessArgs' public_access: Allow access to selected service ports from the public Internet
        :param str recovery_basebackup_name: Name of the basebackup to restore in forked service
        :param str service_to_fork_from: Name of another service to fork from. This has effect 
               only when a new service is being created.
        """
        if custom_domain is not None:
            pulumi.set(__self__, "custom_domain", custom_domain)
        if influxdb is not None:
            pulumi.set(__self__, "influxdb", influxdb)
        if ip_filters is not None:
            pulumi.set(__self__, "ip_filters", ip_filters)
        if private_access is not None:
            pulumi.set(__self__, "private_access", private_access)
        if privatelink_access is not None:
            pulumi.set(__self__, "privatelink_access", privatelink_access)
        if project_to_fork_from is not None:
            pulumi.set(__self__, "project_to_fork_from", project_to_fork_from)
        if public_access is not None:
            pulumi.set(__self__, "public_access", public_access)
        if recovery_basebackup_name is not None:
            pulumi.set(__self__, "recovery_basebackup_name", recovery_basebackup_name)
        if service_to_fork_from is not None:
            pulumi.set(__self__, "service_to_fork_from", service_to_fork_from)

    @property
    @pulumi.getter(name="customDomain")
    def custom_domain(self) -> Optional[str]:
        """
        Serve the web frontend using a custom CNAME pointing to the Aiven DNS name
        """
        return pulumi.get(self, "custom_domain")

    @property
    @pulumi.getter
    def influxdb(self) -> Optional['outputs.GetInfluxDbInfluxdbUserConfigInfluxdbResult']:
        """
        InfluxDB specific server provided values.
        """
        return pulumi.get(self, "influxdb")

    @property
    @pulumi.getter(name="ipFilters")
    def ip_filters(self) -> Optional[Sequence[str]]:
        """
        allow incoming connections from CIDR address block, e.g. `10.20.0.0/16`
        """
        return pulumi.get(self, "ip_filters")

    @property
    @pulumi.getter(name="privateAccess")
    def private_access(self) -> Optional['outputs.GetInfluxDbInfluxdbUserConfigPrivateAccessResult']:
        """
        Allow access to selected service ports from private networks
        """
        return pulumi.get(self, "private_access")

    @property
    @pulumi.getter(name="privatelinkAccess")
    def privatelink_access(self) -> Optional['outputs.GetInfluxDbInfluxdbUserConfigPrivatelinkAccessResult']:
        """
        Allow access to selected service components through Privatelink
        """
        return pulumi.get(self, "privatelink_access")

    @property
    @pulumi.getter(name="projectToForkFrom")
    def project_to_fork_from(self) -> Optional[str]:
        """
        Name of another project to fork a service from. This has
        effect only when a new service is being created.
        """
        return pulumi.get(self, "project_to_fork_from")

    @property
    @pulumi.getter(name="publicAccess")
    def public_access(self) -> Optional['outputs.GetInfluxDbInfluxdbUserConfigPublicAccessResult']:
        """
        Allow access to selected service ports from the public Internet
        """
        return pulumi.get(self, "public_access")

    @property
    @pulumi.getter(name="recoveryBasebackupName")
    def recovery_basebackup_name(self) -> Optional[str]:
        """
        Name of the basebackup to restore in forked service
        """
        return pulumi.get(self, "recovery_basebackup_name")

    @property
    @pulumi.getter(name="serviceToForkFrom")
    def service_to_fork_from(self) -> Optional[str]:
        """
        Name of another service to fork from. This has effect 
        only when a new service is being created.
        """
        return pulumi.get(self, "service_to_fork_from")


@pulumi.output_type
class GetInfluxDbInfluxdbUserConfigInfluxdbResult(dict):
    def __init__(__self__, *,
                 log_queries_after: Optional[str] = None,
                 max_row_limit: Optional[str] = None,
                 max_select_buckets: Optional[str] = None,
                 max_select_point: Optional[str] = None,
                 query_timeout: Optional[str] = None):
        """
        :param str log_queries_after: The maximum duration in seconds before a query is 
               logged as a slow query. Setting this to 0 (the default) will never log slow queries.
        :param str max_row_limit: The maximum number of rows returned in a non-chunked query. 
               Setting this to 0 (the default) allows an unlimited number to be returned.
        :param str max_select_buckets: The maximum number of `GROUP BY time()` buckets that 
               can be processed in a query. Setting this to 0 (the default) allows an unlimited number to
               be processed.
        :param str max_select_point: The maximum number of points that can be processed in a 
               SELECT statement. Setting this to 0 (the default) allows an unlimited number to be processed.
        :param str query_timeout: The maximum duration in seconds before a query is killed. 
               Setting this to 0 (the default) will never kill slow queries.
        """
        if log_queries_after is not None:
            pulumi.set(__self__, "log_queries_after", log_queries_after)
        if max_row_limit is not None:
            pulumi.set(__self__, "max_row_limit", max_row_limit)
        if max_select_buckets is not None:
            pulumi.set(__self__, "max_select_buckets", max_select_buckets)
        if max_select_point is not None:
            pulumi.set(__self__, "max_select_point", max_select_point)
        if query_timeout is not None:
            pulumi.set(__self__, "query_timeout", query_timeout)

    @property
    @pulumi.getter(name="logQueriesAfter")
    def log_queries_after(self) -> Optional[str]:
        """
        The maximum duration in seconds before a query is 
        logged as a slow query. Setting this to 0 (the default) will never log slow queries.
        """
        return pulumi.get(self, "log_queries_after")

    @property
    @pulumi.getter(name="maxRowLimit")
    def max_row_limit(self) -> Optional[str]:
        """
        The maximum number of rows returned in a non-chunked query. 
        Setting this to 0 (the default) allows an unlimited number to be returned.
        """
        return pulumi.get(self, "max_row_limit")

    @property
    @pulumi.getter(name="maxSelectBuckets")
    def max_select_buckets(self) -> Optional[str]:
        """
        The maximum number of `GROUP BY time()` buckets that 
        can be processed in a query. Setting this to 0 (the default) allows an unlimited number to
        be processed.
        """
        return pulumi.get(self, "max_select_buckets")

    @property
    @pulumi.getter(name="maxSelectPoint")
    def max_select_point(self) -> Optional[str]:
        """
        The maximum number of points that can be processed in a 
        SELECT statement. Setting this to 0 (the default) allows an unlimited number to be processed.
        """
        return pulumi.get(self, "max_select_point")

    @property
    @pulumi.getter(name="queryTimeout")
    def query_timeout(self) -> Optional[str]:
        """
        The maximum duration in seconds before a query is killed. 
        Setting this to 0 (the default) will never kill slow queries.
        """
        return pulumi.get(self, "query_timeout")


@pulumi.output_type
class GetInfluxDbInfluxdbUserConfigPrivateAccessResult(dict):
    def __init__(__self__, *,
                 influxdb: Optional[str] = None):
        """
        :param str influxdb: InfluxDB specific server provided values.
        """
        if influxdb is not None:
            pulumi.set(__self__, "influxdb", influxdb)

    @property
    @pulumi.getter
    def influxdb(self) -> Optional[str]:
        """
        InfluxDB specific server provided values.
        """
        return pulumi.get(self, "influxdb")


@pulumi.output_type
class GetInfluxDbInfluxdbUserConfigPrivatelinkAccessResult(dict):
    def __init__(__self__, *,
                 influxdb: Optional[str] = None):
        """
        :param str influxdb: InfluxDB specific server provided values.
        """
        if influxdb is not None:
            pulumi.set(__self__, "influxdb", influxdb)

    @property
    @pulumi.getter
    def influxdb(self) -> Optional[str]:
        """
        InfluxDB specific server provided values.
        """
        return pulumi.get(self, "influxdb")


@pulumi.output_type
class GetInfluxDbInfluxdbUserConfigPublicAccessResult(dict):
    def __init__(__self__, *,
                 influxdb: Optional[str] = None):
        """
        :param str influxdb: InfluxDB specific server provided values.
        """
        if influxdb is not None:
            pulumi.set(__self__, "influxdb", influxdb)

    @property
    @pulumi.getter
    def influxdb(self) -> Optional[str]:
        """
        InfluxDB specific server provided values.
        """
        return pulumi.get(self, "influxdb")


@pulumi.output_type
class GetInfluxDbServiceIntegrationResult(dict):
    def __init__(__self__, *,
                 integration_type: str,
                 source_service_name: str):
        pulumi.set(__self__, "integration_type", integration_type)
        pulumi.set(__self__, "source_service_name", source_service_name)

    @property
    @pulumi.getter(name="integrationType")
    def integration_type(self) -> str:
        return pulumi.get(self, "integration_type")

    @property
    @pulumi.getter(name="sourceServiceName")
    def source_service_name(self) -> str:
        return pulumi.get(self, "source_service_name")


@pulumi.output_type
class GetKafkaComponentResult(dict):
    def __init__(__self__, *,
                 component: str,
                 host: str,
                 kafka_authentication_method: str,
                 port: int,
                 route: str,
                 ssl: bool,
                 usage: str):
        pulumi.set(__self__, "component", component)
        pulumi.set(__self__, "host", host)
        pulumi.set(__self__, "kafka_authentication_method", kafka_authentication_method)
        pulumi.set(__self__, "port", port)
        pulumi.set(__self__, "route", route)
        pulumi.set(__self__, "ssl", ssl)
        pulumi.set(__self__, "usage", usage)

    @property
    @pulumi.getter
    def component(self) -> str:
        return pulumi.get(self, "component")

    @property
    @pulumi.getter
    def host(self) -> str:
        return pulumi.get(self, "host")

    @property
    @pulumi.getter(name="kafkaAuthenticationMethod")
    def kafka_authentication_method(self) -> str:
        return pulumi.get(self, "kafka_authentication_method")

    @property
    @pulumi.getter
    def port(self) -> int:
        return pulumi.get(self, "port")

    @property
    @pulumi.getter
    def route(self) -> str:
        return pulumi.get(self, "route")

    @property
    @pulumi.getter
    def ssl(self) -> bool:
        return pulumi.get(self, "ssl")

    @property
    @pulumi.getter
    def usage(self) -> str:
        return pulumi.get(self, "usage")


@pulumi.output_type
class GetKafkaConnectComponentResult(dict):
    def __init__(__self__, *,
                 component: str,
                 host: str,
                 kafka_authentication_method: str,
                 port: int,
                 route: str,
                 ssl: bool,
                 usage: str):
        pulumi.set(__self__, "component", component)
        pulumi.set(__self__, "host", host)
        pulumi.set(__self__, "kafka_authentication_method", kafka_authentication_method)
        pulumi.set(__self__, "port", port)
        pulumi.set(__self__, "route", route)
        pulumi.set(__self__, "ssl", ssl)
        pulumi.set(__self__, "usage", usage)

    @property
    @pulumi.getter
    def component(self) -> str:
        return pulumi.get(self, "component")

    @property
    @pulumi.getter
    def host(self) -> str:
        return pulumi.get(self, "host")

    @property
    @pulumi.getter(name="kafkaAuthenticationMethod")
    def kafka_authentication_method(self) -> str:
        return pulumi.get(self, "kafka_authentication_method")

    @property
    @pulumi.getter
    def port(self) -> int:
        return pulumi.get(self, "port")

    @property
    @pulumi.getter
    def route(self) -> str:
        return pulumi.get(self, "route")

    @property
    @pulumi.getter
    def ssl(self) -> bool:
        return pulumi.get(self, "ssl")

    @property
    @pulumi.getter
    def usage(self) -> str:
        return pulumi.get(self, "usage")


@pulumi.output_type
class GetKafkaConnectKafkaConnectResult(dict):
    def __init__(__self__):
        pass


@pulumi.output_type
class GetKafkaConnectKafkaConnectUserConfigResult(dict):
    def __init__(__self__, *,
                 ip_filters: Optional[Sequence[str]] = None,
                 kafka_connect: Optional['outputs.GetKafkaConnectKafkaConnectUserConfigKafkaConnectResult'] = None,
                 private_access: Optional['outputs.GetKafkaConnectKafkaConnectUserConfigPrivateAccessResult'] = None,
                 privatelink_access: Optional['outputs.GetKafkaConnectKafkaConnectUserConfigPrivatelinkAccessResult'] = None,
                 public_access: Optional['outputs.GetKafkaConnectKafkaConnectUserConfigPublicAccessResult'] = None):
        """
        :param Sequence[str] ip_filters: allow incoming connections from CIDR address block, e.g. `10.20.0.0/16`
        :param 'GetKafkaConnectKafkaConnectUserConfigKafkaConnectArgs' kafka_connect: Kafka Connect specific server provided values.
        :param 'GetKafkaConnectKafkaConnectUserConfigPrivateAccessArgs' private_access: Allow access to selected service ports from private networks.
        :param 'GetKafkaConnectKafkaConnectUserConfigPrivatelinkAccessArgs' privatelink_access: Allow access to selected service components through Privatelink
        """
        if ip_filters is not None:
            pulumi.set(__self__, "ip_filters", ip_filters)
        if kafka_connect is not None:
            pulumi.set(__self__, "kafka_connect", kafka_connect)
        if private_access is not None:
            pulumi.set(__self__, "private_access", private_access)
        if privatelink_access is not None:
            pulumi.set(__self__, "privatelink_access", privatelink_access)
        if public_access is not None:
            pulumi.set(__self__, "public_access", public_access)

    @property
    @pulumi.getter(name="ipFilters")
    def ip_filters(self) -> Optional[Sequence[str]]:
        """
        allow incoming connections from CIDR address block, e.g. `10.20.0.0/16`
        """
        return pulumi.get(self, "ip_filters")

    @property
    @pulumi.getter(name="kafkaConnect")
    def kafka_connect(self) -> Optional['outputs.GetKafkaConnectKafkaConnectUserConfigKafkaConnectResult']:
        """
        Kafka Connect specific server provided values.
        """
        return pulumi.get(self, "kafka_connect")

    @property
    @pulumi.getter(name="privateAccess")
    def private_access(self) -> Optional['outputs.GetKafkaConnectKafkaConnectUserConfigPrivateAccessResult']:
        """
        Allow access to selected service ports from private networks.
        """
        return pulumi.get(self, "private_access")

    @property
    @pulumi.getter(name="privatelinkAccess")
    def privatelink_access(self) -> Optional['outputs.GetKafkaConnectKafkaConnectUserConfigPrivatelinkAccessResult']:
        """
        Allow access to selected service components through Privatelink
        """
        return pulumi.get(self, "privatelink_access")

    @property
    @pulumi.getter(name="publicAccess")
    def public_access(self) -> Optional['outputs.GetKafkaConnectKafkaConnectUserConfigPublicAccessResult']:
        return pulumi.get(self, "public_access")


@pulumi.output_type
class GetKafkaConnectKafkaConnectUserConfigKafkaConnectResult(dict):
    def __init__(__self__, *,
                 connector_client_config_override_policy: Optional[str] = None,
                 consumer_auto_offset_reset: Optional[str] = None,
                 consumer_fetch_max_bytes: Optional[str] = None,
                 consumer_isolation_level: Optional[str] = None,
                 consumer_max_partition_fetch_bytes: Optional[str] = None,
                 consumer_max_poll_interval_ms: Optional[str] = None,
                 consumer_max_poll_records: Optional[str] = None,
                 offset_flush_interval_ms: Optional[str] = None,
                 offset_flush_timeout_ms: Optional[str] = None,
                 producer_max_request_size: Optional[str] = None,
                 session_timeout_ms: Optional[str] = None):
        """
        :param str connector_client_config_override_policy: Defines what client configurations can be 
               overridden by the connector. Default is None.
        :param str consumer_auto_offset_reset: What to do when there is no initial offset in Kafka or 
               if the current offset does not exist any more on the server. Default is earliest.
        :param str consumer_fetch_max_bytes: Records are fetched in batches by the consumer, and if 
               the first record batch in the first non-empty partition of the fetch is larger than this value,
               the record batch will still be returned to ensure that the consumer can make progress. As such,
               this is not a absolute maximum.
        :param str consumer_isolation_level: Transaction read isolation level. read_uncommitted is 
               the default, but read_committed can be used if consume-exactly-once behavior is desired.
        :param str consumer_max_partition_fetch_bytes: Records are fetched in batches by the consumer.If 
               the first record batch in the first non-empty partition of the fetch is larger than this limit,
               the batch will still be returned to ensure that the consumer can make progress.
        :param str consumer_max_poll_interval_ms: The maximum delay in milliseconds between invocations 
               of poll() when using consumer group management (defaults to 300000).
               * `consumer_max_poll_records` The maximum number of records returned by a single poll.
        :param str offset_flush_interval_ms: The interval at which to try committing offsets for tasks 
               (defaults to 60000).
        :param str offset_flush_timeout_ms: Maximum number of milliseconds to wait for records to flush 
               and partition offset data to be committed to offset storage before cancelling the process and restoring
               the offset data to be committed in a future attempt (defaults to 5000).
        :param str producer_max_request_size: This setting will limit the number of record batches the 
               producer will send in a single request to avoid sending huge requests.
        :param str session_timeout_ms: The timeout in milliseconds used to detect failures when using Kafkas 
               group management facilities (defaults to 10000).
        """
        if connector_client_config_override_policy is not None:
            pulumi.set(__self__, "connector_client_config_override_policy", connector_client_config_override_policy)
        if consumer_auto_offset_reset is not None:
            pulumi.set(__self__, "consumer_auto_offset_reset", consumer_auto_offset_reset)
        if consumer_fetch_max_bytes is not None:
            pulumi.set(__self__, "consumer_fetch_max_bytes", consumer_fetch_max_bytes)
        if consumer_isolation_level is not None:
            pulumi.set(__self__, "consumer_isolation_level", consumer_isolation_level)
        if consumer_max_partition_fetch_bytes is not None:
            pulumi.set(__self__, "consumer_max_partition_fetch_bytes", consumer_max_partition_fetch_bytes)
        if consumer_max_poll_interval_ms is not None:
            pulumi.set(__self__, "consumer_max_poll_interval_ms", consumer_max_poll_interval_ms)
        if consumer_max_poll_records is not None:
            pulumi.set(__self__, "consumer_max_poll_records", consumer_max_poll_records)
        if offset_flush_interval_ms is not None:
            pulumi.set(__self__, "offset_flush_interval_ms", offset_flush_interval_ms)
        if offset_flush_timeout_ms is not None:
            pulumi.set(__self__, "offset_flush_timeout_ms", offset_flush_timeout_ms)
        if producer_max_request_size is not None:
            pulumi.set(__self__, "producer_max_request_size", producer_max_request_size)
        if session_timeout_ms is not None:
            pulumi.set(__self__, "session_timeout_ms", session_timeout_ms)

    @property
    @pulumi.getter(name="connectorClientConfigOverridePolicy")
    def connector_client_config_override_policy(self) -> Optional[str]:
        """
        Defines what client configurations can be 
        overridden by the connector. Default is None.
        """
        return pulumi.get(self, "connector_client_config_override_policy")

    @property
    @pulumi.getter(name="consumerAutoOffsetReset")
    def consumer_auto_offset_reset(self) -> Optional[str]:
        """
        What to do when there is no initial offset in Kafka or 
        if the current offset does not exist any more on the server. Default is earliest.
        """
        return pulumi.get(self, "consumer_auto_offset_reset")

    @property
    @pulumi.getter(name="consumerFetchMaxBytes")
    def consumer_fetch_max_bytes(self) -> Optional[str]:
        """
        Records are fetched in batches by the consumer, and if 
        the first record batch in the first non-empty partition of the fetch is larger than this value,
        the record batch will still be returned to ensure that the consumer can make progress. As such,
        this is not a absolute maximum.
        """
        return pulumi.get(self, "consumer_fetch_max_bytes")

    @property
    @pulumi.getter(name="consumerIsolationLevel")
    def consumer_isolation_level(self) -> Optional[str]:
        """
        Transaction read isolation level. read_uncommitted is 
        the default, but read_committed can be used if consume-exactly-once behavior is desired.
        """
        return pulumi.get(self, "consumer_isolation_level")

    @property
    @pulumi.getter(name="consumerMaxPartitionFetchBytes")
    def consumer_max_partition_fetch_bytes(self) -> Optional[str]:
        """
        Records are fetched in batches by the consumer.If 
        the first record batch in the first non-empty partition of the fetch is larger than this limit,
        the batch will still be returned to ensure that the consumer can make progress.
        """
        return pulumi.get(self, "consumer_max_partition_fetch_bytes")

    @property
    @pulumi.getter(name="consumerMaxPollIntervalMs")
    def consumer_max_poll_interval_ms(self) -> Optional[str]:
        """
        The maximum delay in milliseconds between invocations 
        of poll() when using consumer group management (defaults to 300000).
        * `consumer_max_poll_records` The maximum number of records returned by a single poll.
        """
        return pulumi.get(self, "consumer_max_poll_interval_ms")

    @property
    @pulumi.getter(name="consumerMaxPollRecords")
    def consumer_max_poll_records(self) -> Optional[str]:
        return pulumi.get(self, "consumer_max_poll_records")

    @property
    @pulumi.getter(name="offsetFlushIntervalMs")
    def offset_flush_interval_ms(self) -> Optional[str]:
        """
        The interval at which to try committing offsets for tasks 
        (defaults to 60000).
        """
        return pulumi.get(self, "offset_flush_interval_ms")

    @property
    @pulumi.getter(name="offsetFlushTimeoutMs")
    def offset_flush_timeout_ms(self) -> Optional[str]:
        """
        Maximum number of milliseconds to wait for records to flush 
        and partition offset data to be committed to offset storage before cancelling the process and restoring
        the offset data to be committed in a future attempt (defaults to 5000).
        """
        return pulumi.get(self, "offset_flush_timeout_ms")

    @property
    @pulumi.getter(name="producerMaxRequestSize")
    def producer_max_request_size(self) -> Optional[str]:
        """
        This setting will limit the number of record batches the 
        producer will send in a single request to avoid sending huge requests.
        """
        return pulumi.get(self, "producer_max_request_size")

    @property
    @pulumi.getter(name="sessionTimeoutMs")
    def session_timeout_ms(self) -> Optional[str]:
        """
        The timeout in milliseconds used to detect failures when using Kafkas 
        group management facilities (defaults to 10000).
        """
        return pulumi.get(self, "session_timeout_ms")


@pulumi.output_type
class GetKafkaConnectKafkaConnectUserConfigPrivateAccessResult(dict):
    def __init__(__self__, *,
                 kafka_connect: Optional[str] = None,
                 prometheus: Optional[str] = None):
        """
        :param str kafka_connect: Kafka Connect specific server provided values.
        :param str prometheus: Allow clients to connect to prometheus with a DNS name that always resolves to 
               the service's private IP addresses. Only available in certain network locations.
        """
        if kafka_connect is not None:
            pulumi.set(__self__, "kafka_connect", kafka_connect)
        if prometheus is not None:
            pulumi.set(__self__, "prometheus", prometheus)

    @property
    @pulumi.getter(name="kafkaConnect")
    def kafka_connect(self) -> Optional[str]:
        """
        Kafka Connect specific server provided values.
        """
        return pulumi.get(self, "kafka_connect")

    @property
    @pulumi.getter
    def prometheus(self) -> Optional[str]:
        """
        Allow clients to connect to prometheus with a DNS name that always resolves to 
        the service's private IP addresses. Only available in certain network locations.
        """
        return pulumi.get(self, "prometheus")


@pulumi.output_type
class GetKafkaConnectKafkaConnectUserConfigPrivatelinkAccessResult(dict):
    def __init__(__self__, *,
                 kafka_connect: Optional[str] = None):
        """
        :param str kafka_connect: Kafka Connect specific server provided values.
        """
        if kafka_connect is not None:
            pulumi.set(__self__, "kafka_connect", kafka_connect)

    @property
    @pulumi.getter(name="kafkaConnect")
    def kafka_connect(self) -> Optional[str]:
        """
        Kafka Connect specific server provided values.
        """
        return pulumi.get(self, "kafka_connect")


@pulumi.output_type
class GetKafkaConnectKafkaConnectUserConfigPublicAccessResult(dict):
    def __init__(__self__, *,
                 kafka_connect: Optional[str] = None,
                 prometheus: Optional[str] = None):
        """
        :param str kafka_connect: Kafka Connect specific server provided values.
        :param str prometheus: Allow clients to connect to prometheus with a DNS name that always resolves to 
               the service's private IP addresses. Only available in certain network locations.
        """
        if kafka_connect is not None:
            pulumi.set(__self__, "kafka_connect", kafka_connect)
        if prometheus is not None:
            pulumi.set(__self__, "prometheus", prometheus)

    @property
    @pulumi.getter(name="kafkaConnect")
    def kafka_connect(self) -> Optional[str]:
        """
        Kafka Connect specific server provided values.
        """
        return pulumi.get(self, "kafka_connect")

    @property
    @pulumi.getter
    def prometheus(self) -> Optional[str]:
        """
        Allow clients to connect to prometheus with a DNS name that always resolves to 
        the service's private IP addresses. Only available in certain network locations.
        """
        return pulumi.get(self, "prometheus")


@pulumi.output_type
class GetKafkaConnectServiceIntegrationResult(dict):
    def __init__(__self__, *,
                 integration_type: str,
                 source_service_name: str):
        pulumi.set(__self__, "integration_type", integration_type)
        pulumi.set(__self__, "source_service_name", source_service_name)

    @property
    @pulumi.getter(name="integrationType")
    def integration_type(self) -> str:
        return pulumi.get(self, "integration_type")

    @property
    @pulumi.getter(name="sourceServiceName")
    def source_service_name(self) -> str:
        return pulumi.get(self, "source_service_name")


@pulumi.output_type
class GetKafkaConnectorTaskResult(dict):
    def __init__(__self__, *,
                 connector: str,
                 task: int):
        """
        :param int task: List of tasks of a connector, each element contains `connector` 
               (Related connector name) and `task` (Task id / number).
        """
        pulumi.set(__self__, "connector", connector)
        pulumi.set(__self__, "task", task)

    @property
    @pulumi.getter
    def connector(self) -> str:
        return pulumi.get(self, "connector")

    @property
    @pulumi.getter
    def task(self) -> int:
        """
        List of tasks of a connector, each element contains `connector` 
        (Related connector name) and `task` (Task id / number).
        """
        return pulumi.get(self, "task")


@pulumi.output_type
class GetKafkaKafkaResult(dict):
    def __init__(__self__, *,
                 access_cert: str,
                 access_key: str,
                 connect_uri: str,
                 rest_uri: str,
                 schema_registry_uri: str):
        """
        :param str access_cert: The Kafka client certificate
        :param str access_key: The Kafka client certificate key
        :param str connect_uri: The Kafka Connect URI, if any
        :param str rest_uri: The Kafka REST URI, if any
        :param str schema_registry_uri: The Schema Registry URI, if any
        """
        pulumi.set(__self__, "access_cert", access_cert)
        pulumi.set(__self__, "access_key", access_key)
        pulumi.set(__self__, "connect_uri", connect_uri)
        pulumi.set(__self__, "rest_uri", rest_uri)
        pulumi.set(__self__, "schema_registry_uri", schema_registry_uri)

    @property
    @pulumi.getter(name="accessCert")
    def access_cert(self) -> str:
        """
        The Kafka client certificate
        """
        return pulumi.get(self, "access_cert")

    @property
    @pulumi.getter(name="accessKey")
    def access_key(self) -> str:
        """
        The Kafka client certificate key
        """
        return pulumi.get(self, "access_key")

    @property
    @pulumi.getter(name="connectUri")
    def connect_uri(self) -> str:
        """
        The Kafka Connect URI, if any
        """
        return pulumi.get(self, "connect_uri")

    @property
    @pulumi.getter(name="restUri")
    def rest_uri(self) -> str:
        """
        The Kafka REST URI, if any
        """
        return pulumi.get(self, "rest_uri")

    @property
    @pulumi.getter(name="schemaRegistryUri")
    def schema_registry_uri(self) -> str:
        """
        The Schema Registry URI, if any
        """
        return pulumi.get(self, "schema_registry_uri")


@pulumi.output_type
class GetKafkaKafkaUserConfigResult(dict):
    def __init__(__self__, *,
                 custom_domain: Optional[str] = None,
                 ip_filters: Optional[Sequence[str]] = None,
                 kafka: Optional['outputs.GetKafkaKafkaUserConfigKafkaResult'] = None,
                 kafka_authentication_methods: Optional['outputs.GetKafkaKafkaUserConfigKafkaAuthenticationMethodsResult'] = None,
                 kafka_connect: Optional[str] = None,
                 kafka_connect_config: Optional['outputs.GetKafkaKafkaUserConfigKafkaConnectConfigResult'] = None,
                 kafka_rest: Optional[str] = None,
                 kafka_rest_config: Optional['outputs.GetKafkaKafkaUserConfigKafkaRestConfigResult'] = None,
                 kafka_version: Optional[str] = None,
                 private_access: Optional['outputs.GetKafkaKafkaUserConfigPrivateAccessResult'] = None,
                 privatelink_access: Optional['outputs.GetKafkaKafkaUserConfigPrivatelinkAccessResult'] = None,
                 public_access: Optional['outputs.GetKafkaKafkaUserConfigPublicAccessResult'] = None,
                 schema_registry: Optional[str] = None,
                 schema_registry_config: Optional['outputs.GetKafkaKafkaUserConfigSchemaRegistryConfigResult'] = None):
        """
        :param str custom_domain: Serve the web frontend using a custom CNAME pointing to the Aiven DNS name.
        :param Sequence[str] ip_filters: Allow incoming connections from CIDR address block, e.g. '10.20.0.0/16'.
        :param 'GetKafkaKafkaUserConfigKafkaArgs' kafka: Kafka server provided values:
        :param 'GetKafkaKafkaUserConfigKafkaAuthenticationMethodsArgs' kafka_authentication_methods: Kafka authentication methods
        :param str kafka_connect: Enable kafka_connect
        :param 'GetKafkaKafkaUserConfigKafkaConnectConfigArgs' kafka_connect_config: Kafka Connect configuration values
        :param str kafka_rest: Enable kafka_rest
        :param 'GetKafkaKafkaUserConfigKafkaRestConfigArgs' kafka_rest_config: Kafka-REST configuration
        :param str kafka_version: Kafka major version
        :param 'GetKafkaKafkaUserConfigPrivateAccessArgs' private_access: Allow access to selected service ports from private networks
        :param 'GetKafkaKafkaUserConfigPrivatelinkAccessArgs' privatelink_access: Allow access to selected service components through Privatelink
        :param 'GetKafkaKafkaUserConfigPublicAccessArgs' public_access: Allow access to selected service ports from the public Internet
        :param str schema_registry: Enable schema_registry
        :param 'GetKafkaKafkaUserConfigSchemaRegistryConfigArgs' schema_registry_config: Schema Registry configuration
        """
        if custom_domain is not None:
            pulumi.set(__self__, "custom_domain", custom_domain)
        if ip_filters is not None:
            pulumi.set(__self__, "ip_filters", ip_filters)
        if kafka is not None:
            pulumi.set(__self__, "kafka", kafka)
        if kafka_authentication_methods is not None:
            pulumi.set(__self__, "kafka_authentication_methods", kafka_authentication_methods)
        if kafka_connect is not None:
            pulumi.set(__self__, "kafka_connect", kafka_connect)
        if kafka_connect_config is not None:
            pulumi.set(__self__, "kafka_connect_config", kafka_connect_config)
        if kafka_rest is not None:
            pulumi.set(__self__, "kafka_rest", kafka_rest)
        if kafka_rest_config is not None:
            pulumi.set(__self__, "kafka_rest_config", kafka_rest_config)
        if kafka_version is not None:
            pulumi.set(__self__, "kafka_version", kafka_version)
        if private_access is not None:
            pulumi.set(__self__, "private_access", private_access)
        if privatelink_access is not None:
            pulumi.set(__self__, "privatelink_access", privatelink_access)
        if public_access is not None:
            pulumi.set(__self__, "public_access", public_access)
        if schema_registry is not None:
            pulumi.set(__self__, "schema_registry", schema_registry)
        if schema_registry_config is not None:
            pulumi.set(__self__, "schema_registry_config", schema_registry_config)

    @property
    @pulumi.getter(name="customDomain")
    def custom_domain(self) -> Optional[str]:
        """
        Serve the web frontend using a custom CNAME pointing to the Aiven DNS name.
        """
        return pulumi.get(self, "custom_domain")

    @property
    @pulumi.getter(name="ipFilters")
    def ip_filters(self) -> Optional[Sequence[str]]:
        """
        Allow incoming connections from CIDR address block, e.g. '10.20.0.0/16'.
        """
        return pulumi.get(self, "ip_filters")

    @property
    @pulumi.getter
    def kafka(self) -> Optional['outputs.GetKafkaKafkaUserConfigKafkaResult']:
        """
        Kafka server provided values:
        """
        return pulumi.get(self, "kafka")

    @property
    @pulumi.getter(name="kafkaAuthenticationMethods")
    def kafka_authentication_methods(self) -> Optional['outputs.GetKafkaKafkaUserConfigKafkaAuthenticationMethodsResult']:
        """
        Kafka authentication methods
        """
        return pulumi.get(self, "kafka_authentication_methods")

    @property
    @pulumi.getter(name="kafkaConnect")
    def kafka_connect(self) -> Optional[str]:
        """
        Enable kafka_connect
        """
        return pulumi.get(self, "kafka_connect")

    @property
    @pulumi.getter(name="kafkaConnectConfig")
    def kafka_connect_config(self) -> Optional['outputs.GetKafkaKafkaUserConfigKafkaConnectConfigResult']:
        """
        Kafka Connect configuration values
        """
        return pulumi.get(self, "kafka_connect_config")

    @property
    @pulumi.getter(name="kafkaRest")
    def kafka_rest(self) -> Optional[str]:
        """
        Enable kafka_rest
        """
        return pulumi.get(self, "kafka_rest")

    @property
    @pulumi.getter(name="kafkaRestConfig")
    def kafka_rest_config(self) -> Optional['outputs.GetKafkaKafkaUserConfigKafkaRestConfigResult']:
        """
        Kafka-REST configuration
        """
        return pulumi.get(self, "kafka_rest_config")

    @property
    @pulumi.getter(name="kafkaVersion")
    def kafka_version(self) -> Optional[str]:
        """
        Kafka major version
        """
        return pulumi.get(self, "kafka_version")

    @property
    @pulumi.getter(name="privateAccess")
    def private_access(self) -> Optional['outputs.GetKafkaKafkaUserConfigPrivateAccessResult']:
        """
        Allow access to selected service ports from private networks
        """
        return pulumi.get(self, "private_access")

    @property
    @pulumi.getter(name="privatelinkAccess")
    def privatelink_access(self) -> Optional['outputs.GetKafkaKafkaUserConfigPrivatelinkAccessResult']:
        """
        Allow access to selected service components through Privatelink
        """
        return pulumi.get(self, "privatelink_access")

    @property
    @pulumi.getter(name="publicAccess")
    def public_access(self) -> Optional['outputs.GetKafkaKafkaUserConfigPublicAccessResult']:
        """
        Allow access to selected service ports from the public Internet
        """
        return pulumi.get(self, "public_access")

    @property
    @pulumi.getter(name="schemaRegistry")
    def schema_registry(self) -> Optional[str]:
        """
        Enable schema_registry
        """
        return pulumi.get(self, "schema_registry")

    @property
    @pulumi.getter(name="schemaRegistryConfig")
    def schema_registry_config(self) -> Optional['outputs.GetKafkaKafkaUserConfigSchemaRegistryConfigResult']:
        """
        Schema Registry configuration
        """
        return pulumi.get(self, "schema_registry_config")


@pulumi.output_type
class GetKafkaKafkaUserConfigKafkaResult(dict):
    def __init__(__self__, *,
                 auto_create_topics_enable: Optional[str] = None,
                 compression_type: Optional[str] = None,
                 connections_max_idle_ms: Optional[str] = None,
                 default_replication_factor: Optional[str] = None,
                 group_initial_rebalance_delay_ms: Optional[str] = None,
                 group_max_session_timeout_ms: Optional[str] = None,
                 group_min_session_timeout_ms: Optional[str] = None,
                 log_cleaner_delete_retention_ms: Optional[str] = None,
                 log_cleaner_max_compaction_lag_ms: Optional[str] = None,
                 log_cleaner_min_cleanable_ratio: Optional[str] = None,
                 log_cleaner_min_compaction_lag_ms: Optional[str] = None,
                 log_cleanup_policy: Optional[str] = None,
                 log_flush_interval_messages: Optional[str] = None,
                 log_flush_interval_ms: Optional[str] = None,
                 log_index_interval_bytes: Optional[str] = None,
                 log_index_size_max_bytes: Optional[str] = None,
                 log_message_downconversion_enable: Optional[str] = None,
                 log_message_timestamp_difference_max_ms: Optional[str] = None,
                 log_message_timestamp_type: Optional[str] = None,
                 log_preallocate: Optional[str] = None,
                 log_retention_bytes: Optional[str] = None,
                 log_retention_hours: Optional[str] = None,
                 log_retention_ms: Optional[str] = None,
                 log_roll_jitter_ms: Optional[str] = None,
                 log_roll_ms: Optional[str] = None,
                 log_segment_bytes: Optional[str] = None,
                 log_segment_delete_delay_ms: Optional[str] = None,
                 max_connections_per_ip: Optional[str] = None,
                 max_incremental_fetch_session_cache_slots: Optional[str] = None,
                 message_max_bytes: Optional[str] = None,
                 min_insync_replicas: Optional[str] = None,
                 num_partitions: Optional[str] = None,
                 offsets_retention_minutes: Optional[str] = None,
                 producer_purgatory_purge_interval_requests: Optional[str] = None,
                 replica_fetch_max_bytes: Optional[str] = None,
                 replica_fetch_response_max_bytes: Optional[str] = None,
                 socket_request_max_bytes: Optional[str] = None,
                 transaction_remove_expired_transaction_cleanup_interval_ms: Optional[str] = None,
                 transaction_state_log_segment_bytes: Optional[str] = None):
        """
        :param str auto_create_topics_enable: Enable auto creation of topics
        :param str compression_type: Specify the final compression type for a given topic. This 
               configuration accepts the standard compression codecs ('gzip', 'snappy', 'lz4', 'zstd').
               It additionally accepts 'uncompressed' which is equivalent to no compression; and 'producer'
               which means retain the original compression codec set by the producer.
        :param str connections_max_idle_ms: Idle connections timeout: the server socket processor 
               threads close the connections that idle for longer than this.
        :param str default_replication_factor: Replication factor for autocreated topics
        :param str group_initial_rebalance_delay_ms: The amount of time, in milliseconds, the group
               coordinator will wait for more consumers to join a new group before performing the first rebalance.
               A longer delay means potentially fewer rebalances, but increases the time until processing begins.
               The default value for this is 3 seconds. During development and testing it might be desirable to set
               this to 0 in order to not delay test execution time.
        :param str group_max_session_timeout_ms: The maximum allowed session timeout for registered 
               consumers. Longer timeouts give consumers more time to process messages in between heartbeats
               at the cost of a longer time to detect failures.
        :param str group_min_session_timeout_ms: The minimum allowed session timeout for registered 
               consumers. Longer timeouts give consumers more time to process messages in between heartbeats
               at the cost of a longer time to detect failures.
        :param str log_cleaner_max_compaction_lag_ms: The maximum amount of time message will 
               remain uncompacted. Only applicable for logs that are being compacted
        :param str log_cleaner_min_cleanable_ratio: Controls log compactor frequency. Larger 
               value means more frequent compactions but also more space wasted for logs. Consider setting
               log.cleaner.max.compaction.lag.ms to enforce compactions sooner, instead of setting a very
               high value for this option.
        :param str log_cleaner_min_compaction_lag_ms: The minimum time a message will remain 
               uncompacted in the log. Only applicable for logs that are being compacted.
        :param str log_cleanup_policy: The default cleanup policy for segments beyond the retention window.
        :param str log_flush_interval_messages: The number of messages accumulated on a log partition 
               before messages are flushed to disk.
        :param str log_flush_interval_ms: The maximum time in ms that a message in any topic is kept 
               in memory before flushed to disk. If not set, the value in log.flush.scheduler.interval.ms is used.
        :param str log_index_interval_bytes: The interval with which Kafka adds an entry to the offset index.
        :param str log_index_size_max_bytes: The maximum size in bytes of the offset index.
        :param str log_message_downconversion_enable: This configuration controls whether down-conversion 
               of message formats is enabled to satisfy consume requests.
        :param str log_message_timestamp_difference_max_ms: The maximum difference allowed between 
               the timestamp when a broker receives a message and the timestamp specified in the message
        :param str log_message_timestamp_type: Define whether the timestamp in the message is 
               message create time or log append time.
        :param str log_preallocate: Should pre allocate file when create new segment?
        :param str log_retention_bytes: The maximum size of the log before deleting messages
        :param str log_retention_hours: The number of hours to keep a log file before deleting it.
        :param str log_retention_ms: The number of milliseconds to keep a log file before deleting it 
               (in milliseconds), If not set, the value in log.retention.minutes is used. If set to -1, no
               time limit is applied.
        :param str log_roll_jitter_ms: The maximum jitter to subtract from logRollTimeMillis 
               (in milliseconds). If not set, the value in log.roll.jitter.hours is used.
        :param str log_roll_ms: The maximum time before a new log segment is rolled out (in milliseconds).
        :param str log_segment_bytes: The maximum size of a single log file
        :param str log_segment_delete_delay_ms: The amount of time to wait before deleting a file 
               from the filesystem.
        :param str max_connections_per_ip: The maximum number of connections allowed from each ip 
               address (defaults to 2147483647).
        :param str max_incremental_fetch_session_cache_slots: The maximum number of incremental fetch 
               sessions that the broker will maintain.
        :param str message_max_bytes: The maximum size of message that the server can receive.
        :param str min_insync_replicas: When a producer sets acks to 'all' (or '-1'), 
               min.insync.replicas specifies the minimum number of replicas that must acknowledge a write for
               the write to be considered successful.
        :param str num_partitions: Number of partitions for autocreated topics
        :param str offsets_retention_minutes: Log retention window in minutes for offsets topic.
        :param str producer_purgatory_purge_interval_requests: The purge interval (in number of 
               requests) of the producer request purgatory(defaults to 1000).
        :param str replica_fetch_max_bytes: The number of bytes of messages to attempt to fetch 
               for each partition (defaults to 1048576). This is not an absolute maximum, if the first record
               batch in the first non-empty partition of the fetch is larger than this value, the record batch
               will still be returned to ensure that progress can be made.
        :param str replica_fetch_response_max_bytes: Maximum bytes expected for the entire fetch 
               response (defaults to 10485760). Records are fetched in batches, and if the first record batch
               in the first non-empty partition of the fetch is larger than this value, the record batch will
               still be returned to ensure that progress can be made. As such, this is not an absolute maximum.
        :param str socket_request_max_bytes: The maximum number of bytes in a socket request 
               (defaults to 104857600).
        :param str transaction_remove_expired_transaction_cleanup_interval_ms: The interval at which 
               to remove transactions that have expired due to transactional.id.expiration.ms passing (defaults
               to 3600000 (1 hour)).
        :param str transaction_state_log_segment_bytes: The transaction topic segment bytes should 
               be kept relatively small in order to facilitate faster log compaction and cache loads (defaults
               to 104857600 (100 mebibytes)).
        """
        if auto_create_topics_enable is not None:
            pulumi.set(__self__, "auto_create_topics_enable", auto_create_topics_enable)
        if compression_type is not None:
            pulumi.set(__self__, "compression_type", compression_type)
        if connections_max_idle_ms is not None:
            pulumi.set(__self__, "connections_max_idle_ms", connections_max_idle_ms)
        if default_replication_factor is not None:
            pulumi.set(__self__, "default_replication_factor", default_replication_factor)
        if group_initial_rebalance_delay_ms is not None:
            pulumi.set(__self__, "group_initial_rebalance_delay_ms", group_initial_rebalance_delay_ms)
        if group_max_session_timeout_ms is not None:
            pulumi.set(__self__, "group_max_session_timeout_ms", group_max_session_timeout_ms)
        if group_min_session_timeout_ms is not None:
            pulumi.set(__self__, "group_min_session_timeout_ms", group_min_session_timeout_ms)
        if log_cleaner_delete_retention_ms is not None:
            pulumi.set(__self__, "log_cleaner_delete_retention_ms", log_cleaner_delete_retention_ms)
        if log_cleaner_max_compaction_lag_ms is not None:
            pulumi.set(__self__, "log_cleaner_max_compaction_lag_ms", log_cleaner_max_compaction_lag_ms)
        if log_cleaner_min_cleanable_ratio is not None:
            pulumi.set(__self__, "log_cleaner_min_cleanable_ratio", log_cleaner_min_cleanable_ratio)
        if log_cleaner_min_compaction_lag_ms is not None:
            pulumi.set(__self__, "log_cleaner_min_compaction_lag_ms", log_cleaner_min_compaction_lag_ms)
        if log_cleanup_policy is not None:
            pulumi.set(__self__, "log_cleanup_policy", log_cleanup_policy)
        if log_flush_interval_messages is not None:
            pulumi.set(__self__, "log_flush_interval_messages", log_flush_interval_messages)
        if log_flush_interval_ms is not None:
            pulumi.set(__self__, "log_flush_interval_ms", log_flush_interval_ms)
        if log_index_interval_bytes is not None:
            pulumi.set(__self__, "log_index_interval_bytes", log_index_interval_bytes)
        if log_index_size_max_bytes is not None:
            pulumi.set(__self__, "log_index_size_max_bytes", log_index_size_max_bytes)
        if log_message_downconversion_enable is not None:
            pulumi.set(__self__, "log_message_downconversion_enable", log_message_downconversion_enable)
        if log_message_timestamp_difference_max_ms is not None:
            pulumi.set(__self__, "log_message_timestamp_difference_max_ms", log_message_timestamp_difference_max_ms)
        if log_message_timestamp_type is not None:
            pulumi.set(__self__, "log_message_timestamp_type", log_message_timestamp_type)
        if log_preallocate is not None:
            pulumi.set(__self__, "log_preallocate", log_preallocate)
        if log_retention_bytes is not None:
            pulumi.set(__self__, "log_retention_bytes", log_retention_bytes)
        if log_retention_hours is not None:
            pulumi.set(__self__, "log_retention_hours", log_retention_hours)
        if log_retention_ms is not None:
            pulumi.set(__self__, "log_retention_ms", log_retention_ms)
        if log_roll_jitter_ms is not None:
            pulumi.set(__self__, "log_roll_jitter_ms", log_roll_jitter_ms)
        if log_roll_ms is not None:
            pulumi.set(__self__, "log_roll_ms", log_roll_ms)
        if log_segment_bytes is not None:
            pulumi.set(__self__, "log_segment_bytes", log_segment_bytes)
        if log_segment_delete_delay_ms is not None:
            pulumi.set(__self__, "log_segment_delete_delay_ms", log_segment_delete_delay_ms)
        if max_connections_per_ip is not None:
            pulumi.set(__self__, "max_connections_per_ip", max_connections_per_ip)
        if max_incremental_fetch_session_cache_slots is not None:
            pulumi.set(__self__, "max_incremental_fetch_session_cache_slots", max_incremental_fetch_session_cache_slots)
        if message_max_bytes is not None:
            pulumi.set(__self__, "message_max_bytes", message_max_bytes)
        if min_insync_replicas is not None:
            pulumi.set(__self__, "min_insync_replicas", min_insync_replicas)
        if num_partitions is not None:
            pulumi.set(__self__, "num_partitions", num_partitions)
        if offsets_retention_minutes is not None:
            pulumi.set(__self__, "offsets_retention_minutes", offsets_retention_minutes)
        if producer_purgatory_purge_interval_requests is not None:
            pulumi.set(__self__, "producer_purgatory_purge_interval_requests", producer_purgatory_purge_interval_requests)
        if replica_fetch_max_bytes is not None:
            pulumi.set(__self__, "replica_fetch_max_bytes", replica_fetch_max_bytes)
        if replica_fetch_response_max_bytes is not None:
            pulumi.set(__self__, "replica_fetch_response_max_bytes", replica_fetch_response_max_bytes)
        if socket_request_max_bytes is not None:
            pulumi.set(__self__, "socket_request_max_bytes", socket_request_max_bytes)
        if transaction_remove_expired_transaction_cleanup_interval_ms is not None:
            pulumi.set(__self__, "transaction_remove_expired_transaction_cleanup_interval_ms", transaction_remove_expired_transaction_cleanup_interval_ms)
        if transaction_state_log_segment_bytes is not None:
            pulumi.set(__self__, "transaction_state_log_segment_bytes", transaction_state_log_segment_bytes)

    @property
    @pulumi.getter(name="autoCreateTopicsEnable")
    def auto_create_topics_enable(self) -> Optional[str]:
        """
        Enable auto creation of topics
        """
        return pulumi.get(self, "auto_create_topics_enable")

    @property
    @pulumi.getter(name="compressionType")
    def compression_type(self) -> Optional[str]:
        """
        Specify the final compression type for a given topic. This 
        configuration accepts the standard compression codecs ('gzip', 'snappy', 'lz4', 'zstd').
        It additionally accepts 'uncompressed' which is equivalent to no compression; and 'producer'
        which means retain the original compression codec set by the producer.
        """
        return pulumi.get(self, "compression_type")

    @property
    @pulumi.getter(name="connectionsMaxIdleMs")
    def connections_max_idle_ms(self) -> Optional[str]:
        """
        Idle connections timeout: the server socket processor 
        threads close the connections that idle for longer than this.
        """
        return pulumi.get(self, "connections_max_idle_ms")

    @property
    @pulumi.getter(name="defaultReplicationFactor")
    def default_replication_factor(self) -> Optional[str]:
        """
        Replication factor for autocreated topics
        """
        return pulumi.get(self, "default_replication_factor")

    @property
    @pulumi.getter(name="groupInitialRebalanceDelayMs")
    def group_initial_rebalance_delay_ms(self) -> Optional[str]:
        """
        The amount of time, in milliseconds, the group
        coordinator will wait for more consumers to join a new group before performing the first rebalance.
        A longer delay means potentially fewer rebalances, but increases the time until processing begins.
        The default value for this is 3 seconds. During development and testing it might be desirable to set
        this to 0 in order to not delay test execution time.
        """
        return pulumi.get(self, "group_initial_rebalance_delay_ms")

    @property
    @pulumi.getter(name="groupMaxSessionTimeoutMs")
    def group_max_session_timeout_ms(self) -> Optional[str]:
        """
        The maximum allowed session timeout for registered 
        consumers. Longer timeouts give consumers more time to process messages in between heartbeats
        at the cost of a longer time to detect failures.
        """
        return pulumi.get(self, "group_max_session_timeout_ms")

    @property
    @pulumi.getter(name="groupMinSessionTimeoutMs")
    def group_min_session_timeout_ms(self) -> Optional[str]:
        """
        The minimum allowed session timeout for registered 
        consumers. Longer timeouts give consumers more time to process messages in between heartbeats
        at the cost of a longer time to detect failures.
        """
        return pulumi.get(self, "group_min_session_timeout_ms")

    @property
    @pulumi.getter(name="logCleanerDeleteRetentionMs")
    def log_cleaner_delete_retention_ms(self) -> Optional[str]:
        return pulumi.get(self, "log_cleaner_delete_retention_ms")

    @property
    @pulumi.getter(name="logCleanerMaxCompactionLagMs")
    def log_cleaner_max_compaction_lag_ms(self) -> Optional[str]:
        """
        The maximum amount of time message will 
        remain uncompacted. Only applicable for logs that are being compacted
        """
        return pulumi.get(self, "log_cleaner_max_compaction_lag_ms")

    @property
    @pulumi.getter(name="logCleanerMinCleanableRatio")
    def log_cleaner_min_cleanable_ratio(self) -> Optional[str]:
        """
        Controls log compactor frequency. Larger 
        value means more frequent compactions but also more space wasted for logs. Consider setting
        log.cleaner.max.compaction.lag.ms to enforce compactions sooner, instead of setting a very
        high value for this option.
        """
        return pulumi.get(self, "log_cleaner_min_cleanable_ratio")

    @property
    @pulumi.getter(name="logCleanerMinCompactionLagMs")
    def log_cleaner_min_compaction_lag_ms(self) -> Optional[str]:
        """
        The minimum time a message will remain 
        uncompacted in the log. Only applicable for logs that are being compacted.
        """
        return pulumi.get(self, "log_cleaner_min_compaction_lag_ms")

    @property
    @pulumi.getter(name="logCleanupPolicy")
    def log_cleanup_policy(self) -> Optional[str]:
        """
        The default cleanup policy for segments beyond the retention window.
        """
        return pulumi.get(self, "log_cleanup_policy")

    @property
    @pulumi.getter(name="logFlushIntervalMessages")
    def log_flush_interval_messages(self) -> Optional[str]:
        """
        The number of messages accumulated on a log partition 
        before messages are flushed to disk.
        """
        return pulumi.get(self, "log_flush_interval_messages")

    @property
    @pulumi.getter(name="logFlushIntervalMs")
    def log_flush_interval_ms(self) -> Optional[str]:
        """
        The maximum time in ms that a message in any topic is kept 
        in memory before flushed to disk. If not set, the value in log.flush.scheduler.interval.ms is used.
        """
        return pulumi.get(self, "log_flush_interval_ms")

    @property
    @pulumi.getter(name="logIndexIntervalBytes")
    def log_index_interval_bytes(self) -> Optional[str]:
        """
        The interval with which Kafka adds an entry to the offset index.
        """
        return pulumi.get(self, "log_index_interval_bytes")

    @property
    @pulumi.getter(name="logIndexSizeMaxBytes")
    def log_index_size_max_bytes(self) -> Optional[str]:
        """
        The maximum size in bytes of the offset index.
        """
        return pulumi.get(self, "log_index_size_max_bytes")

    @property
    @pulumi.getter(name="logMessageDownconversionEnable")
    def log_message_downconversion_enable(self) -> Optional[str]:
        """
        This configuration controls whether down-conversion 
        of message formats is enabled to satisfy consume requests.
        """
        return pulumi.get(self, "log_message_downconversion_enable")

    @property
    @pulumi.getter(name="logMessageTimestampDifferenceMaxMs")
    def log_message_timestamp_difference_max_ms(self) -> Optional[str]:
        """
        The maximum difference allowed between 
        the timestamp when a broker receives a message and the timestamp specified in the message
        """
        return pulumi.get(self, "log_message_timestamp_difference_max_ms")

    @property
    @pulumi.getter(name="logMessageTimestampType")
    def log_message_timestamp_type(self) -> Optional[str]:
        """
        Define whether the timestamp in the message is 
        message create time or log append time.
        """
        return pulumi.get(self, "log_message_timestamp_type")

    @property
    @pulumi.getter(name="logPreallocate")
    def log_preallocate(self) -> Optional[str]:
        """
        Should pre allocate file when create new segment?
        """
        return pulumi.get(self, "log_preallocate")

    @property
    @pulumi.getter(name="logRetentionBytes")
    def log_retention_bytes(self) -> Optional[str]:
        """
        The maximum size of the log before deleting messages
        """
        return pulumi.get(self, "log_retention_bytes")

    @property
    @pulumi.getter(name="logRetentionHours")
    def log_retention_hours(self) -> Optional[str]:
        """
        The number of hours to keep a log file before deleting it.
        """
        return pulumi.get(self, "log_retention_hours")

    @property
    @pulumi.getter(name="logRetentionMs")
    def log_retention_ms(self) -> Optional[str]:
        """
        The number of milliseconds to keep a log file before deleting it 
        (in milliseconds), If not set, the value in log.retention.minutes is used. If set to -1, no
        time limit is applied.
        """
        return pulumi.get(self, "log_retention_ms")

    @property
    @pulumi.getter(name="logRollJitterMs")
    def log_roll_jitter_ms(self) -> Optional[str]:
        """
        The maximum jitter to subtract from logRollTimeMillis 
        (in milliseconds). If not set, the value in log.roll.jitter.hours is used.
        """
        return pulumi.get(self, "log_roll_jitter_ms")

    @property
    @pulumi.getter(name="logRollMs")
    def log_roll_ms(self) -> Optional[str]:
        """
        The maximum time before a new log segment is rolled out (in milliseconds).
        """
        return pulumi.get(self, "log_roll_ms")

    @property
    @pulumi.getter(name="logSegmentBytes")
    def log_segment_bytes(self) -> Optional[str]:
        """
        The maximum size of a single log file
        """
        return pulumi.get(self, "log_segment_bytes")

    @property
    @pulumi.getter(name="logSegmentDeleteDelayMs")
    def log_segment_delete_delay_ms(self) -> Optional[str]:
        """
        The amount of time to wait before deleting a file 
        from the filesystem.
        """
        return pulumi.get(self, "log_segment_delete_delay_ms")

    @property
    @pulumi.getter(name="maxConnectionsPerIp")
    def max_connections_per_ip(self) -> Optional[str]:
        """
        The maximum number of connections allowed from each ip 
        address (defaults to 2147483647).
        """
        return pulumi.get(self, "max_connections_per_ip")

    @property
    @pulumi.getter(name="maxIncrementalFetchSessionCacheSlots")
    def max_incremental_fetch_session_cache_slots(self) -> Optional[str]:
        """
        The maximum number of incremental fetch 
        sessions that the broker will maintain.
        """
        return pulumi.get(self, "max_incremental_fetch_session_cache_slots")

    @property
    @pulumi.getter(name="messageMaxBytes")
    def message_max_bytes(self) -> Optional[str]:
        """
        The maximum size of message that the server can receive.
        """
        return pulumi.get(self, "message_max_bytes")

    @property
    @pulumi.getter(name="minInsyncReplicas")
    def min_insync_replicas(self) -> Optional[str]:
        """
        When a producer sets acks to 'all' (or '-1'), 
        min.insync.replicas specifies the minimum number of replicas that must acknowledge a write for
        the write to be considered successful.
        """
        return pulumi.get(self, "min_insync_replicas")

    @property
    @pulumi.getter(name="numPartitions")
    def num_partitions(self) -> Optional[str]:
        """
        Number of partitions for autocreated topics
        """
        return pulumi.get(self, "num_partitions")

    @property
    @pulumi.getter(name="offsetsRetentionMinutes")
    def offsets_retention_minutes(self) -> Optional[str]:
        """
        Log retention window in minutes for offsets topic.
        """
        return pulumi.get(self, "offsets_retention_minutes")

    @property
    @pulumi.getter(name="producerPurgatoryPurgeIntervalRequests")
    def producer_purgatory_purge_interval_requests(self) -> Optional[str]:
        """
        The purge interval (in number of 
        requests) of the producer request purgatory(defaults to 1000).
        """
        return pulumi.get(self, "producer_purgatory_purge_interval_requests")

    @property
    @pulumi.getter(name="replicaFetchMaxBytes")
    def replica_fetch_max_bytes(self) -> Optional[str]:
        """
        The number of bytes of messages to attempt to fetch 
        for each partition (defaults to 1048576). This is not an absolute maximum, if the first record
        batch in the first non-empty partition of the fetch is larger than this value, the record batch
        will still be returned to ensure that progress can be made.
        """
        return pulumi.get(self, "replica_fetch_max_bytes")

    @property
    @pulumi.getter(name="replicaFetchResponseMaxBytes")
    def replica_fetch_response_max_bytes(self) -> Optional[str]:
        """
        Maximum bytes expected for the entire fetch 
        response (defaults to 10485760). Records are fetched in batches, and if the first record batch
        in the first non-empty partition of the fetch is larger than this value, the record batch will
        still be returned to ensure that progress can be made. As such, this is not an absolute maximum.
        """
        return pulumi.get(self, "replica_fetch_response_max_bytes")

    @property
    @pulumi.getter(name="socketRequestMaxBytes")
    def socket_request_max_bytes(self) -> Optional[str]:
        """
        The maximum number of bytes in a socket request 
        (defaults to 104857600).
        """
        return pulumi.get(self, "socket_request_max_bytes")

    @property
    @pulumi.getter(name="transactionRemoveExpiredTransactionCleanupIntervalMs")
    def transaction_remove_expired_transaction_cleanup_interval_ms(self) -> Optional[str]:
        """
        The interval at which 
        to remove transactions that have expired due to transactional.id.expiration.ms passing (defaults
        to 3600000 (1 hour)).
        """
        return pulumi.get(self, "transaction_remove_expired_transaction_cleanup_interval_ms")

    @property
    @pulumi.getter(name="transactionStateLogSegmentBytes")
    def transaction_state_log_segment_bytes(self) -> Optional[str]:
        """
        The transaction topic segment bytes should 
        be kept relatively small in order to facilitate faster log compaction and cache loads (defaults
        to 104857600 (100 mebibytes)).
        """
        return pulumi.get(self, "transaction_state_log_segment_bytes")


@pulumi.output_type
class GetKafkaKafkaUserConfigKafkaAuthenticationMethodsResult(dict):
    def __init__(__self__, *,
                 certificate: Optional[str] = None,
                 sasl: Optional[str] = None):
        """
        :param str certificate: Enable certificate/SSL authentication
        :param str sasl: Enable SASL authentication
        """
        if certificate is not None:
            pulumi.set(__self__, "certificate", certificate)
        if sasl is not None:
            pulumi.set(__self__, "sasl", sasl)

    @property
    @pulumi.getter
    def certificate(self) -> Optional[str]:
        """
        Enable certificate/SSL authentication
        """
        return pulumi.get(self, "certificate")

    @property
    @pulumi.getter
    def sasl(self) -> Optional[str]:
        """
        Enable SASL authentication
        """
        return pulumi.get(self, "sasl")


@pulumi.output_type
class GetKafkaKafkaUserConfigKafkaConnectConfigResult(dict):
    def __init__(__self__, *,
                 connector_client_config_override_policy: Optional[str] = None,
                 consumer_auto_offset_reset: Optional[str] = None,
                 consumer_fetch_max_bytes: Optional[str] = None,
                 consumer_isolation_level: Optional[str] = None,
                 consumer_max_partition_fetch_bytes: Optional[str] = None,
                 consumer_max_poll_interval_ms: Optional[str] = None,
                 consumer_max_poll_records: Optional[str] = None,
                 offset_flush_interval_ms: Optional[str] = None,
                 offset_flush_timeout_ms: Optional[str] = None,
                 producer_max_request_size: Optional[str] = None,
                 session_timeout_ms: Optional[str] = None):
        """
        :param str connector_client_config_override_policy: Defines what client configurations can 
               be overridden by the connector. Default is None
        :param str consumer_auto_offset_reset: What to do when there is no initial offset in Kafka or 
               if the current offset does not exist any more on the server. Default is earliest.
        :param str consumer_fetch_max_bytes: Records are fetched in batches by the consumer, and 
               if the first record batch in the first non-empty partition of the fetch is larger than this value,
               the record batch will still be returned to ensure that the consumer can make progress. As such,
               this is not a absolute maximum.
        :param str consumer_isolation_level: Transaction read isolation level. read_uncommitted is 
               the default, but read_committed can be used if consume-exactly-once behavior is desired.
        :param str consumer_max_partition_fetch_bytes: Records are fetched in batches by the consumer.If 
               the first record batch in the first non-empty partition of the fetch is larger than this limit,
               the batch will still be returned to ensure that the consumer can make progress.
        :param str consumer_max_poll_interval_ms: The maximum delay in milliseconds between invocations 
               of poll() when using consumer group management (defaults to 300000).
        :param str consumer_max_poll_records: The maximum number of records returned in a single call 
               to poll() (defaults to 500).
        :param str offset_flush_interval_ms: The interval at which to try committing offsets for 
               tasks (defaults to 60000).
        :param str offset_flush_timeout_ms: Maximum number of milliseconds to wait for records to 
               flush and partition offset data to be committed to offset storage before cancelling the process
               and restoring the offset data to be committed in a future attempt (defaults to 5000).
        :param str producer_max_request_size: This setting will limit the number of record batches 
               the producer will send in a single request to avoid sending huge requests.
        :param str session_timeout_ms: The timeout in milliseconds used to detect failures when 
               using Kafkas group management facilities (defaults to 10000).
        """
        if connector_client_config_override_policy is not None:
            pulumi.set(__self__, "connector_client_config_override_policy", connector_client_config_override_policy)
        if consumer_auto_offset_reset is not None:
            pulumi.set(__self__, "consumer_auto_offset_reset", consumer_auto_offset_reset)
        if consumer_fetch_max_bytes is not None:
            pulumi.set(__self__, "consumer_fetch_max_bytes", consumer_fetch_max_bytes)
        if consumer_isolation_level is not None:
            pulumi.set(__self__, "consumer_isolation_level", consumer_isolation_level)
        if consumer_max_partition_fetch_bytes is not None:
            pulumi.set(__self__, "consumer_max_partition_fetch_bytes", consumer_max_partition_fetch_bytes)
        if consumer_max_poll_interval_ms is not None:
            pulumi.set(__self__, "consumer_max_poll_interval_ms", consumer_max_poll_interval_ms)
        if consumer_max_poll_records is not None:
            pulumi.set(__self__, "consumer_max_poll_records", consumer_max_poll_records)
        if offset_flush_interval_ms is not None:
            pulumi.set(__self__, "offset_flush_interval_ms", offset_flush_interval_ms)
        if offset_flush_timeout_ms is not None:
            pulumi.set(__self__, "offset_flush_timeout_ms", offset_flush_timeout_ms)
        if producer_max_request_size is not None:
            pulumi.set(__self__, "producer_max_request_size", producer_max_request_size)
        if session_timeout_ms is not None:
            pulumi.set(__self__, "session_timeout_ms", session_timeout_ms)

    @property
    @pulumi.getter(name="connectorClientConfigOverridePolicy")
    def connector_client_config_override_policy(self) -> Optional[str]:
        """
        Defines what client configurations can 
        be overridden by the connector. Default is None
        """
        return pulumi.get(self, "connector_client_config_override_policy")

    @property
    @pulumi.getter(name="consumerAutoOffsetReset")
    def consumer_auto_offset_reset(self) -> Optional[str]:
        """
        What to do when there is no initial offset in Kafka or 
        if the current offset does not exist any more on the server. Default is earliest.
        """
        return pulumi.get(self, "consumer_auto_offset_reset")

    @property
    @pulumi.getter(name="consumerFetchMaxBytes")
    def consumer_fetch_max_bytes(self) -> Optional[str]:
        """
        Records are fetched in batches by the consumer, and 
        if the first record batch in the first non-empty partition of the fetch is larger than this value,
        the record batch will still be returned to ensure that the consumer can make progress. As such,
        this is not a absolute maximum.
        """
        return pulumi.get(self, "consumer_fetch_max_bytes")

    @property
    @pulumi.getter(name="consumerIsolationLevel")
    def consumer_isolation_level(self) -> Optional[str]:
        """
        Transaction read isolation level. read_uncommitted is 
        the default, but read_committed can be used if consume-exactly-once behavior is desired.
        """
        return pulumi.get(self, "consumer_isolation_level")

    @property
    @pulumi.getter(name="consumerMaxPartitionFetchBytes")
    def consumer_max_partition_fetch_bytes(self) -> Optional[str]:
        """
        Records are fetched in batches by the consumer.If 
        the first record batch in the first non-empty partition of the fetch is larger than this limit,
        the batch will still be returned to ensure that the consumer can make progress.
        """
        return pulumi.get(self, "consumer_max_partition_fetch_bytes")

    @property
    @pulumi.getter(name="consumerMaxPollIntervalMs")
    def consumer_max_poll_interval_ms(self) -> Optional[str]:
        """
        The maximum delay in milliseconds between invocations 
        of poll() when using consumer group management (defaults to 300000).
        """
        return pulumi.get(self, "consumer_max_poll_interval_ms")

    @property
    @pulumi.getter(name="consumerMaxPollRecords")
    def consumer_max_poll_records(self) -> Optional[str]:
        """
        The maximum number of records returned in a single call 
        to poll() (defaults to 500).
        """
        return pulumi.get(self, "consumer_max_poll_records")

    @property
    @pulumi.getter(name="offsetFlushIntervalMs")
    def offset_flush_interval_ms(self) -> Optional[str]:
        """
        The interval at which to try committing offsets for 
        tasks (defaults to 60000).
        """
        return pulumi.get(self, "offset_flush_interval_ms")

    @property
    @pulumi.getter(name="offsetFlushTimeoutMs")
    def offset_flush_timeout_ms(self) -> Optional[str]:
        """
        Maximum number of milliseconds to wait for records to 
        flush and partition offset data to be committed to offset storage before cancelling the process
        and restoring the offset data to be committed in a future attempt (defaults to 5000).
        """
        return pulumi.get(self, "offset_flush_timeout_ms")

    @property
    @pulumi.getter(name="producerMaxRequestSize")
    def producer_max_request_size(self) -> Optional[str]:
        """
        This setting will limit the number of record batches 
        the producer will send in a single request to avoid sending huge requests.
        """
        return pulumi.get(self, "producer_max_request_size")

    @property
    @pulumi.getter(name="sessionTimeoutMs")
    def session_timeout_ms(self) -> Optional[str]:
        """
        The timeout in milliseconds used to detect failures when 
        using Kafkas group management facilities (defaults to 10000).
        """
        return pulumi.get(self, "session_timeout_ms")


@pulumi.output_type
class GetKafkaKafkaUserConfigKafkaRestConfigResult(dict):
    def __init__(__self__, *,
                 consumer_enable_auto_commit: Optional[str] = None,
                 consumer_request_max_bytes: Optional[str] = None,
                 consumer_request_timeout_ms: Optional[str] = None,
                 producer_acks: Optional[str] = None,
                 producer_linger_ms: Optional[str] = None,
                 simpleconsumer_pool_size_max: Optional[str] = None):
        """
        :param str consumer_enable_auto_commit: If true the consumer's offset will be periodically 
               committed to Kafka in the background
        :param str consumer_request_max_bytes: Maximum number of bytes in unencoded message keys and 
               values by a single request
        :param str consumer_request_timeout_ms: The maximum total time to wait for messages for a 
               request if the maximum number of messages has not yet been reached
        :param str producer_acks: The number of acknowledgments the producer requires the leader to 
               have received before considering a request complete. If set to 'all' or '-1', the leader will wait
               for the full set of in-sync replicas to acknowledge the record.
        :param str producer_linger_ms: Wait for up to the given delay to allow batching records together
        :param str simpleconsumer_pool_size_max: Maximum number of SimpleConsumers that can be 
               instantiated per broker.
        """
        if consumer_enable_auto_commit is not None:
            pulumi.set(__self__, "consumer_enable_auto_commit", consumer_enable_auto_commit)
        if consumer_request_max_bytes is not None:
            pulumi.set(__self__, "consumer_request_max_bytes", consumer_request_max_bytes)
        if consumer_request_timeout_ms is not None:
            pulumi.set(__self__, "consumer_request_timeout_ms", consumer_request_timeout_ms)
        if producer_acks is not None:
            pulumi.set(__self__, "producer_acks", producer_acks)
        if producer_linger_ms is not None:
            pulumi.set(__self__, "producer_linger_ms", producer_linger_ms)
        if simpleconsumer_pool_size_max is not None:
            pulumi.set(__self__, "simpleconsumer_pool_size_max", simpleconsumer_pool_size_max)

    @property
    @pulumi.getter(name="consumerEnableAutoCommit")
    def consumer_enable_auto_commit(self) -> Optional[str]:
        """
        If true the consumer's offset will be periodically 
        committed to Kafka in the background
        """
        return pulumi.get(self, "consumer_enable_auto_commit")

    @property
    @pulumi.getter(name="consumerRequestMaxBytes")
    def consumer_request_max_bytes(self) -> Optional[str]:
        """
        Maximum number of bytes in unencoded message keys and 
        values by a single request
        """
        return pulumi.get(self, "consumer_request_max_bytes")

    @property
    @pulumi.getter(name="consumerRequestTimeoutMs")
    def consumer_request_timeout_ms(self) -> Optional[str]:
        """
        The maximum total time to wait for messages for a 
        request if the maximum number of messages has not yet been reached
        """
        return pulumi.get(self, "consumer_request_timeout_ms")

    @property
    @pulumi.getter(name="producerAcks")
    def producer_acks(self) -> Optional[str]:
        """
        The number of acknowledgments the producer requires the leader to 
        have received before considering a request complete. If set to 'all' or '-1', the leader will wait
        for the full set of in-sync replicas to acknowledge the record.
        """
        return pulumi.get(self, "producer_acks")

    @property
    @pulumi.getter(name="producerLingerMs")
    def producer_linger_ms(self) -> Optional[str]:
        """
        Wait for up to the given delay to allow batching records together
        """
        return pulumi.get(self, "producer_linger_ms")

    @property
    @pulumi.getter(name="simpleconsumerPoolSizeMax")
    def simpleconsumer_pool_size_max(self) -> Optional[str]:
        """
        Maximum number of SimpleConsumers that can be 
        instantiated per broker.
        """
        return pulumi.get(self, "simpleconsumer_pool_size_max")


@pulumi.output_type
class GetKafkaKafkaUserConfigPrivateAccessResult(dict):
    def __init__(__self__, *,
                 prometheus: Optional[str] = None):
        """
        :param str prometheus: Allow clients to connect to prometheus from the public internet for 
               service nodes that are in a project VPC or another type of private network
        """
        if prometheus is not None:
            pulumi.set(__self__, "prometheus", prometheus)

    @property
    @pulumi.getter
    def prometheus(self) -> Optional[str]:
        """
        Allow clients to connect to prometheus from the public internet for 
        service nodes that are in a project VPC or another type of private network
        """
        return pulumi.get(self, "prometheus")


@pulumi.output_type
class GetKafkaKafkaUserConfigPrivatelinkAccessResult(dict):
    def __init__(__self__, *,
                 kafka: Optional[str] = None,
                 kafka_connect: Optional[str] = None,
                 kafka_rest: Optional[str] = None,
                 schema_registry: Optional[str] = None):
        """
        :param str kafka: Kafka server provided values:
        :param str kafka_connect: Enable kafka_connect
        :param str kafka_rest: Enable kafka_rest
        :param str schema_registry: Enable schema_registry
        """
        if kafka is not None:
            pulumi.set(__self__, "kafka", kafka)
        if kafka_connect is not None:
            pulumi.set(__self__, "kafka_connect", kafka_connect)
        if kafka_rest is not None:
            pulumi.set(__self__, "kafka_rest", kafka_rest)
        if schema_registry is not None:
            pulumi.set(__self__, "schema_registry", schema_registry)

    @property
    @pulumi.getter
    def kafka(self) -> Optional[str]:
        """
        Kafka server provided values:
        """
        return pulumi.get(self, "kafka")

    @property
    @pulumi.getter(name="kafkaConnect")
    def kafka_connect(self) -> Optional[str]:
        """
        Enable kafka_connect
        """
        return pulumi.get(self, "kafka_connect")

    @property
    @pulumi.getter(name="kafkaRest")
    def kafka_rest(self) -> Optional[str]:
        """
        Enable kafka_rest
        """
        return pulumi.get(self, "kafka_rest")

    @property
    @pulumi.getter(name="schemaRegistry")
    def schema_registry(self) -> Optional[str]:
        """
        Enable schema_registry
        """
        return pulumi.get(self, "schema_registry")


@pulumi.output_type
class GetKafkaKafkaUserConfigPublicAccessResult(dict):
    def __init__(__self__, *,
                 kafka: Optional[str] = None,
                 kafka_connect: Optional[str] = None,
                 kafka_rest: Optional[str] = None,
                 prometheus: Optional[str] = None,
                 schema_registry: Optional[str] = None):
        """
        :param str kafka: Kafka server provided values:
        :param str kafka_connect: Enable kafka_connect
        :param str kafka_rest: Enable kafka_rest
        :param str prometheus: Allow clients to connect to prometheus from the public internet for 
               service nodes that are in a project VPC or another type of private network
        :param str schema_registry: Enable schema_registry
        """
        if kafka is not None:
            pulumi.set(__self__, "kafka", kafka)
        if kafka_connect is not None:
            pulumi.set(__self__, "kafka_connect", kafka_connect)
        if kafka_rest is not None:
            pulumi.set(__self__, "kafka_rest", kafka_rest)
        if prometheus is not None:
            pulumi.set(__self__, "prometheus", prometheus)
        if schema_registry is not None:
            pulumi.set(__self__, "schema_registry", schema_registry)

    @property
    @pulumi.getter
    def kafka(self) -> Optional[str]:
        """
        Kafka server provided values:
        """
        return pulumi.get(self, "kafka")

    @property
    @pulumi.getter(name="kafkaConnect")
    def kafka_connect(self) -> Optional[str]:
        """
        Enable kafka_connect
        """
        return pulumi.get(self, "kafka_connect")

    @property
    @pulumi.getter(name="kafkaRest")
    def kafka_rest(self) -> Optional[str]:
        """
        Enable kafka_rest
        """
        return pulumi.get(self, "kafka_rest")

    @property
    @pulumi.getter
    def prometheus(self) -> Optional[str]:
        """
        Allow clients to connect to prometheus from the public internet for 
        service nodes that are in a project VPC or another type of private network
        """
        return pulumi.get(self, "prometheus")

    @property
    @pulumi.getter(name="schemaRegistry")
    def schema_registry(self) -> Optional[str]:
        """
        Enable schema_registry
        """
        return pulumi.get(self, "schema_registry")


@pulumi.output_type
class GetKafkaKafkaUserConfigSchemaRegistryConfigResult(dict):
    def __init__(__self__, *,
                 leader_eligibility: Optional[str] = None,
                 topic_name: Optional[str] = None):
        """
        :param str leader_eligibility: If true, Karapace / Schema Registry on the service nodes can 
               participate in leader election. It might be needed to disable this when the schemas topic is replicated
               to a secondary cluster and Karapace / Schema Registry there must not participate in leader election.
               Defaults to 'true'.
        :param str topic_name: The durable single partition topic that acts as the durable log for the 
               data. This topic must be compacted to avoid losing data due to retention policy. Please note that
               changing this configuration in an existing Schema Registry / Karapace setup leads to previous
               schemas being inaccessible, data encoded with them potentially unreadable and schema ID sequence
               put out of order. It's only possible to do the switch while Schema Registry / Karapace is disabled.
               Defaults to '_schemas'.
        """
        if leader_eligibility is not None:
            pulumi.set(__self__, "leader_eligibility", leader_eligibility)
        if topic_name is not None:
            pulumi.set(__self__, "topic_name", topic_name)

    @property
    @pulumi.getter(name="leaderEligibility")
    def leader_eligibility(self) -> Optional[str]:
        """
        If true, Karapace / Schema Registry on the service nodes can 
        participate in leader election. It might be needed to disable this when the schemas topic is replicated
        to a secondary cluster and Karapace / Schema Registry there must not participate in leader election.
        Defaults to 'true'.
        """
        return pulumi.get(self, "leader_eligibility")

    @property
    @pulumi.getter(name="topicName")
    def topic_name(self) -> Optional[str]:
        """
        The durable single partition topic that acts as the durable log for the 
        data. This topic must be compacted to avoid losing data due to retention policy. Please note that
        changing this configuration in an existing Schema Registry / Karapace setup leads to previous
        schemas being inaccessible, data encoded with them potentially unreadable and schema ID sequence
        put out of order. It's only possible to do the switch while Schema Registry / Karapace is disabled.
        Defaults to '_schemas'.
        """
        return pulumi.get(self, "topic_name")


@pulumi.output_type
class GetKafkaMirrorMakerComponentResult(dict):
    def __init__(__self__, *,
                 component: str,
                 host: str,
                 kafka_authentication_method: str,
                 port: int,
                 route: str,
                 ssl: bool,
                 usage: str):
        pulumi.set(__self__, "component", component)
        pulumi.set(__self__, "host", host)
        pulumi.set(__self__, "kafka_authentication_method", kafka_authentication_method)
        pulumi.set(__self__, "port", port)
        pulumi.set(__self__, "route", route)
        pulumi.set(__self__, "ssl", ssl)
        pulumi.set(__self__, "usage", usage)

    @property
    @pulumi.getter
    def component(self) -> str:
        return pulumi.get(self, "component")

    @property
    @pulumi.getter
    def host(self) -> str:
        return pulumi.get(self, "host")

    @property
    @pulumi.getter(name="kafkaAuthenticationMethod")
    def kafka_authentication_method(self) -> str:
        return pulumi.get(self, "kafka_authentication_method")

    @property
    @pulumi.getter
    def port(self) -> int:
        return pulumi.get(self, "port")

    @property
    @pulumi.getter
    def route(self) -> str:
        return pulumi.get(self, "route")

    @property
    @pulumi.getter
    def ssl(self) -> bool:
        return pulumi.get(self, "ssl")

    @property
    @pulumi.getter
    def usage(self) -> str:
        return pulumi.get(self, "usage")


@pulumi.output_type
class GetKafkaMirrorMakerKafkaMirrormakerResult(dict):
    def __init__(__self__):
        pass


@pulumi.output_type
class GetKafkaMirrorMakerKafkaMirrormakerUserConfigResult(dict):
    def __init__(__self__, *,
                 ip_filters: Optional[Sequence[str]] = None,
                 kafka_mirrormaker: Optional['outputs.GetKafkaMirrorMakerKafkaMirrormakerUserConfigKafkaMirrormakerResult'] = None):
        """
        :param Sequence[str] ip_filters: allow incoming connections from CIDR address block, e.g. `10.20.0.0/16`
        :param 'GetKafkaMirrorMakerKafkaMirrormakerUserConfigKafkaMirrormakerArgs' kafka_mirrormaker: Kafka MirrorMaker 2 specific server provided values.
        """
        if ip_filters is not None:
            pulumi.set(__self__, "ip_filters", ip_filters)
        if kafka_mirrormaker is not None:
            pulumi.set(__self__, "kafka_mirrormaker", kafka_mirrormaker)

    @property
    @pulumi.getter(name="ipFilters")
    def ip_filters(self) -> Optional[Sequence[str]]:
        """
        allow incoming connections from CIDR address block, e.g. `10.20.0.0/16`
        """
        return pulumi.get(self, "ip_filters")

    @property
    @pulumi.getter(name="kafkaMirrormaker")
    def kafka_mirrormaker(self) -> Optional['outputs.GetKafkaMirrorMakerKafkaMirrormakerUserConfigKafkaMirrormakerResult']:
        """
        Kafka MirrorMaker 2 specific server provided values.
        """
        return pulumi.get(self, "kafka_mirrormaker")


@pulumi.output_type
class GetKafkaMirrorMakerKafkaMirrormakerUserConfigKafkaMirrormakerResult(dict):
    def __init__(__self__, *,
                 emit_checkpoints_enabled: Optional[str] = None,
                 emit_checkpoints_interval_seconds: Optional[str] = None,
                 refresh_groups_enabled: Optional[str] = None,
                 refresh_groups_interval_seconds: Optional[str] = None,
                 refresh_topics_enabled: Optional[str] = None,
                 refresh_topics_interval_seconds: Optional[str] = None,
                 sync_group_offsets_enabled: Optional[str] = None,
                 sync_group_offsets_interval_seconds: Optional[str] = None):
        """
        :param str emit_checkpoints_enabled: Whether to periodically write the translated offsets
               of replicated consumer groups (in the source cluster) to __consumer_offsets topic in target cluster,
               as long as no active consumers in that group are connected to the target cluster.
        :param str refresh_groups_enabled: Whether to periodically check for new consumer groups. 
               Defaults to 'true'.
        :param str refresh_groups_interval_seconds: Whether to periodically check for new topics and 
               partitions. Defaults to 'true'.
        :param str refresh_topics_interval_seconds: Frequency of topic and partitions refresh in 
               seconds. Defaults to 600 seconds (10 minutes).
        :param str sync_group_offsets_interval_seconds: Frequency at which consumer group offsets
               are synced (default: 60, every minute).
        """
        if emit_checkpoints_enabled is not None:
            pulumi.set(__self__, "emit_checkpoints_enabled", emit_checkpoints_enabled)
        if emit_checkpoints_interval_seconds is not None:
            pulumi.set(__self__, "emit_checkpoints_interval_seconds", emit_checkpoints_interval_seconds)
        if refresh_groups_enabled is not None:
            pulumi.set(__self__, "refresh_groups_enabled", refresh_groups_enabled)
        if refresh_groups_interval_seconds is not None:
            pulumi.set(__self__, "refresh_groups_interval_seconds", refresh_groups_interval_seconds)
        if refresh_topics_enabled is not None:
            pulumi.set(__self__, "refresh_topics_enabled", refresh_topics_enabled)
        if refresh_topics_interval_seconds is not None:
            pulumi.set(__self__, "refresh_topics_interval_seconds", refresh_topics_interval_seconds)
        if sync_group_offsets_enabled is not None:
            pulumi.set(__self__, "sync_group_offsets_enabled", sync_group_offsets_enabled)
        if sync_group_offsets_interval_seconds is not None:
            pulumi.set(__self__, "sync_group_offsets_interval_seconds", sync_group_offsets_interval_seconds)

    @property
    @pulumi.getter(name="emitCheckpointsEnabled")
    def emit_checkpoints_enabled(self) -> Optional[str]:
        """
        Whether to periodically write the translated offsets
        of replicated consumer groups (in the source cluster) to __consumer_offsets topic in target cluster,
        as long as no active consumers in that group are connected to the target cluster.
        """
        return pulumi.get(self, "emit_checkpoints_enabled")

    @property
    @pulumi.getter(name="emitCheckpointsIntervalSeconds")
    def emit_checkpoints_interval_seconds(self) -> Optional[str]:
        return pulumi.get(self, "emit_checkpoints_interval_seconds")

    @property
    @pulumi.getter(name="refreshGroupsEnabled")
    def refresh_groups_enabled(self) -> Optional[str]:
        """
        Whether to periodically check for new consumer groups. 
        Defaults to 'true'.
        """
        return pulumi.get(self, "refresh_groups_enabled")

    @property
    @pulumi.getter(name="refreshGroupsIntervalSeconds")
    def refresh_groups_interval_seconds(self) -> Optional[str]:
        """
        Whether to periodically check for new topics and 
        partitions. Defaults to 'true'.
        """
        return pulumi.get(self, "refresh_groups_interval_seconds")

    @property
    @pulumi.getter(name="refreshTopicsEnabled")
    def refresh_topics_enabled(self) -> Optional[str]:
        return pulumi.get(self, "refresh_topics_enabled")

    @property
    @pulumi.getter(name="refreshTopicsIntervalSeconds")
    def refresh_topics_interval_seconds(self) -> Optional[str]:
        """
        Frequency of topic and partitions refresh in 
        seconds. Defaults to 600 seconds (10 minutes).
        """
        return pulumi.get(self, "refresh_topics_interval_seconds")

    @property
    @pulumi.getter(name="syncGroupOffsetsEnabled")
    def sync_group_offsets_enabled(self) -> Optional[str]:
        return pulumi.get(self, "sync_group_offsets_enabled")

    @property
    @pulumi.getter(name="syncGroupOffsetsIntervalSeconds")
    def sync_group_offsets_interval_seconds(self) -> Optional[str]:
        """
        Frequency at which consumer group offsets
        are synced (default: 60, every minute).
        """
        return pulumi.get(self, "sync_group_offsets_interval_seconds")


@pulumi.output_type
class GetKafkaMirrorMakerServiceIntegrationResult(dict):
    def __init__(__self__, *,
                 integration_type: str,
                 source_service_name: str):
        pulumi.set(__self__, "integration_type", integration_type)
        pulumi.set(__self__, "source_service_name", source_service_name)

    @property
    @pulumi.getter(name="integrationType")
    def integration_type(self) -> str:
        return pulumi.get(self, "integration_type")

    @property
    @pulumi.getter(name="sourceServiceName")
    def source_service_name(self) -> str:
        return pulumi.get(self, "source_service_name")


@pulumi.output_type
class GetKafkaServiceIntegrationResult(dict):
    def __init__(__self__, *,
                 integration_type: str,
                 source_service_name: str):
        pulumi.set(__self__, "integration_type", integration_type)
        pulumi.set(__self__, "source_service_name", source_service_name)

    @property
    @pulumi.getter(name="integrationType")
    def integration_type(self) -> str:
        return pulumi.get(self, "integration_type")

    @property
    @pulumi.getter(name="sourceServiceName")
    def source_service_name(self) -> str:
        return pulumi.get(self, "source_service_name")


@pulumi.output_type
class GetKafkaTopicConfigResult(dict):
    def __init__(__self__, *,
                 cleanup_policy: Optional[str] = None,
                 compression_type: Optional[str] = None,
                 delete_retention_ms: Optional[str] = None,
                 file_delete_delay_ms: Optional[str] = None,
                 flush_messages: Optional[str] = None,
                 flush_ms: Optional[str] = None,
                 index_interval_bytes: Optional[str] = None,
                 max_compaction_lag_ms: Optional[str] = None,
                 max_message_bytes: Optional[str] = None,
                 message_downconversion_enable: Optional[str] = None,
                 message_format_version: Optional[str] = None,
                 message_timestamp_difference_max_ms: Optional[str] = None,
                 message_timestamp_type: Optional[str] = None,
                 min_cleanable_dirty_ratio: Optional[str] = None,
                 min_compaction_lag_ms: Optional[str] = None,
                 min_insync_replicas: Optional[str] = None,
                 preallocate: Optional[str] = None,
                 retention_bytes: Optional[str] = None,
                 retention_ms: Optional[str] = None,
                 segment_bytes: Optional[str] = None,
                 segment_index_bytes: Optional[str] = None,
                 segment_jitter_ms: Optional[str] = None,
                 segment_ms: Optional[str] = None,
                 unclean_leader_election_enable: Optional[str] = None):
        """
        :param str cleanup_policy: cleanup.policy value, can be `create`, `delete` or `compact,delete`
        :param str compression_type: compression.type value
        :param str delete_retention_ms: delete.retention.ms value
        :param str file_delete_delay_ms: file.delete.delay.ms value
        :param str flush_messages: flush.messages value
        :param str flush_ms: flush.ms value
        :param str index_interval_bytes: index.interval.bytes value
        :param str max_compaction_lag_ms: max.compaction.lag.ms value
        :param str max_message_bytes: max.message.bytes value
        :param str message_downconversion_enable: message.downconversion.enable value
        :param str message_format_version: message.format.version value
        :param str message_timestamp_difference_max_ms: message.timestamp.difference.max.ms value
        :param str message_timestamp_type: message.timestamp.type value
        :param str min_cleanable_dirty_ratio: min.cleanable.dirty.ratio value
        :param str min_compaction_lag_ms: min.compaction.lag.ms value
        :param str min_insync_replicas: min.insync.replicas value
        :param str preallocate: preallocate value
        :param str retention_bytes: retention.bytes value
        :param str retention_ms: retention.ms value
        :param str segment_bytes: segment.bytes value
        :param str segment_index_bytes: segment.index.bytes value
        :param str segment_jitter_ms: segment.jitter.ms value
        :param str segment_ms: segment.ms value
        :param str unclean_leader_election_enable: unclean.leader.election.enable value
        """
        if cleanup_policy is not None:
            pulumi.set(__self__, "cleanup_policy", cleanup_policy)
        if compression_type is not None:
            pulumi.set(__self__, "compression_type", compression_type)
        if delete_retention_ms is not None:
            pulumi.set(__self__, "delete_retention_ms", delete_retention_ms)
        if file_delete_delay_ms is not None:
            pulumi.set(__self__, "file_delete_delay_ms", file_delete_delay_ms)
        if flush_messages is not None:
            pulumi.set(__self__, "flush_messages", flush_messages)
        if flush_ms is not None:
            pulumi.set(__self__, "flush_ms", flush_ms)
        if index_interval_bytes is not None:
            pulumi.set(__self__, "index_interval_bytes", index_interval_bytes)
        if max_compaction_lag_ms is not None:
            pulumi.set(__self__, "max_compaction_lag_ms", max_compaction_lag_ms)
        if max_message_bytes is not None:
            pulumi.set(__self__, "max_message_bytes", max_message_bytes)
        if message_downconversion_enable is not None:
            pulumi.set(__self__, "message_downconversion_enable", message_downconversion_enable)
        if message_format_version is not None:
            pulumi.set(__self__, "message_format_version", message_format_version)
        if message_timestamp_difference_max_ms is not None:
            pulumi.set(__self__, "message_timestamp_difference_max_ms", message_timestamp_difference_max_ms)
        if message_timestamp_type is not None:
            pulumi.set(__self__, "message_timestamp_type", message_timestamp_type)
        if min_cleanable_dirty_ratio is not None:
            pulumi.set(__self__, "min_cleanable_dirty_ratio", min_cleanable_dirty_ratio)
        if min_compaction_lag_ms is not None:
            pulumi.set(__self__, "min_compaction_lag_ms", min_compaction_lag_ms)
        if min_insync_replicas is not None:
            pulumi.set(__self__, "min_insync_replicas", min_insync_replicas)
        if preallocate is not None:
            pulumi.set(__self__, "preallocate", preallocate)
        if retention_bytes is not None:
            pulumi.set(__self__, "retention_bytes", retention_bytes)
        if retention_ms is not None:
            pulumi.set(__self__, "retention_ms", retention_ms)
        if segment_bytes is not None:
            pulumi.set(__self__, "segment_bytes", segment_bytes)
        if segment_index_bytes is not None:
            pulumi.set(__self__, "segment_index_bytes", segment_index_bytes)
        if segment_jitter_ms is not None:
            pulumi.set(__self__, "segment_jitter_ms", segment_jitter_ms)
        if segment_ms is not None:
            pulumi.set(__self__, "segment_ms", segment_ms)
        if unclean_leader_election_enable is not None:
            pulumi.set(__self__, "unclean_leader_election_enable", unclean_leader_election_enable)

    @property
    @pulumi.getter(name="cleanupPolicy")
    def cleanup_policy(self) -> Optional[str]:
        """
        cleanup.policy value, can be `create`, `delete` or `compact,delete`
        """
        return pulumi.get(self, "cleanup_policy")

    @property
    @pulumi.getter(name="compressionType")
    def compression_type(self) -> Optional[str]:
        """
        compression.type value
        """
        return pulumi.get(self, "compression_type")

    @property
    @pulumi.getter(name="deleteRetentionMs")
    def delete_retention_ms(self) -> Optional[str]:
        """
        delete.retention.ms value
        """
        return pulumi.get(self, "delete_retention_ms")

    @property
    @pulumi.getter(name="fileDeleteDelayMs")
    def file_delete_delay_ms(self) -> Optional[str]:
        """
        file.delete.delay.ms value
        """
        return pulumi.get(self, "file_delete_delay_ms")

    @property
    @pulumi.getter(name="flushMessages")
    def flush_messages(self) -> Optional[str]:
        """
        flush.messages value
        """
        return pulumi.get(self, "flush_messages")

    @property
    @pulumi.getter(name="flushMs")
    def flush_ms(self) -> Optional[str]:
        """
        flush.ms value
        """
        return pulumi.get(self, "flush_ms")

    @property
    @pulumi.getter(name="indexIntervalBytes")
    def index_interval_bytes(self) -> Optional[str]:
        """
        index.interval.bytes value
        """
        return pulumi.get(self, "index_interval_bytes")

    @property
    @pulumi.getter(name="maxCompactionLagMs")
    def max_compaction_lag_ms(self) -> Optional[str]:
        """
        max.compaction.lag.ms value
        """
        return pulumi.get(self, "max_compaction_lag_ms")

    @property
    @pulumi.getter(name="maxMessageBytes")
    def max_message_bytes(self) -> Optional[str]:
        """
        max.message.bytes value
        """
        return pulumi.get(self, "max_message_bytes")

    @property
    @pulumi.getter(name="messageDownconversionEnable")
    def message_downconversion_enable(self) -> Optional[str]:
        """
        message.downconversion.enable value
        """
        return pulumi.get(self, "message_downconversion_enable")

    @property
    @pulumi.getter(name="messageFormatVersion")
    def message_format_version(self) -> Optional[str]:
        """
        message.format.version value
        """
        return pulumi.get(self, "message_format_version")

    @property
    @pulumi.getter(name="messageTimestampDifferenceMaxMs")
    def message_timestamp_difference_max_ms(self) -> Optional[str]:
        """
        message.timestamp.difference.max.ms value
        """
        return pulumi.get(self, "message_timestamp_difference_max_ms")

    @property
    @pulumi.getter(name="messageTimestampType")
    def message_timestamp_type(self) -> Optional[str]:
        """
        message.timestamp.type value
        """
        return pulumi.get(self, "message_timestamp_type")

    @property
    @pulumi.getter(name="minCleanableDirtyRatio")
    def min_cleanable_dirty_ratio(self) -> Optional[str]:
        """
        min.cleanable.dirty.ratio value
        """
        return pulumi.get(self, "min_cleanable_dirty_ratio")

    @property
    @pulumi.getter(name="minCompactionLagMs")
    def min_compaction_lag_ms(self) -> Optional[str]:
        """
        min.compaction.lag.ms value
        """
        return pulumi.get(self, "min_compaction_lag_ms")

    @property
    @pulumi.getter(name="minInsyncReplicas")
    def min_insync_replicas(self) -> Optional[str]:
        """
        min.insync.replicas value
        """
        return pulumi.get(self, "min_insync_replicas")

    @property
    @pulumi.getter
    def preallocate(self) -> Optional[str]:
        """
        preallocate value
        """
        return pulumi.get(self, "preallocate")

    @property
    @pulumi.getter(name="retentionBytes")
    def retention_bytes(self) -> Optional[str]:
        """
        retention.bytes value
        """
        return pulumi.get(self, "retention_bytes")

    @property
    @pulumi.getter(name="retentionMs")
    def retention_ms(self) -> Optional[str]:
        """
        retention.ms value
        """
        return pulumi.get(self, "retention_ms")

    @property
    @pulumi.getter(name="segmentBytes")
    def segment_bytes(self) -> Optional[str]:
        """
        segment.bytes value
        """
        return pulumi.get(self, "segment_bytes")

    @property
    @pulumi.getter(name="segmentIndexBytes")
    def segment_index_bytes(self) -> Optional[str]:
        """
        segment.index.bytes value
        """
        return pulumi.get(self, "segment_index_bytes")

    @property
    @pulumi.getter(name="segmentJitterMs")
    def segment_jitter_ms(self) -> Optional[str]:
        """
        segment.jitter.ms value
        """
        return pulumi.get(self, "segment_jitter_ms")

    @property
    @pulumi.getter(name="segmentMs")
    def segment_ms(self) -> Optional[str]:
        """
        segment.ms value
        """
        return pulumi.get(self, "segment_ms")

    @property
    @pulumi.getter(name="uncleanLeaderElectionEnable")
    def unclean_leader_election_enable(self) -> Optional[str]:
        """
        unclean.leader.election.enable value
        """
        return pulumi.get(self, "unclean_leader_election_enable")


@pulumi.output_type
class GetKafkaTopicTagResult(dict):
    def __init__(__self__, *,
                 key: str,
                 value: Optional[str] = None):
        pulumi.set(__self__, "key", key)
        if value is not None:
            pulumi.set(__self__, "value", value)

    @property
    @pulumi.getter
    def key(self) -> str:
        return pulumi.get(self, "key")

    @property
    @pulumi.getter
    def value(self) -> Optional[str]:
        return pulumi.get(self, "value")


@pulumi.output_type
class GetM3AggregatorComponentResult(dict):
    def __init__(__self__, *,
                 component: str,
                 host: str,
                 kafka_authentication_method: str,
                 port: int,
                 route: str,
                 ssl: bool,
                 usage: str):
        pulumi.set(__self__, "component", component)
        pulumi.set(__self__, "host", host)
        pulumi.set(__self__, "kafka_authentication_method", kafka_authentication_method)
        pulumi.set(__self__, "port", port)
        pulumi.set(__self__, "route", route)
        pulumi.set(__self__, "ssl", ssl)
        pulumi.set(__self__, "usage", usage)

    @property
    @pulumi.getter
    def component(self) -> str:
        return pulumi.get(self, "component")

    @property
    @pulumi.getter
    def host(self) -> str:
        return pulumi.get(self, "host")

    @property
    @pulumi.getter(name="kafkaAuthenticationMethod")
    def kafka_authentication_method(self) -> str:
        return pulumi.get(self, "kafka_authentication_method")

    @property
    @pulumi.getter
    def port(self) -> int:
        return pulumi.get(self, "port")

    @property
    @pulumi.getter
    def route(self) -> str:
        return pulumi.get(self, "route")

    @property
    @pulumi.getter
    def ssl(self) -> bool:
        return pulumi.get(self, "ssl")

    @property
    @pulumi.getter
    def usage(self) -> str:
        return pulumi.get(self, "usage")


@pulumi.output_type
class GetM3AggregatorM3aggregatorResult(dict):
    def __init__(__self__):
        pass


@pulumi.output_type
class GetM3AggregatorM3aggregatorUserConfigResult(dict):
    def __init__(__self__, *,
                 custom_domain: Optional[str] = None,
                 ip_filters: Optional[Sequence[str]] = None,
                 m3_version: Optional[str] = None,
                 m3aggregator_version: Optional[str] = None):
        """
        :param str custom_domain: Serve the web frontend using a custom CNAME pointing to the Aiven DNS name.
        :param Sequence[str] ip_filters: Allow incoming connections from CIDR address block, e.g. '10.20.0.0/16'
        :param str m3aggregator_version: M3 major version
        """
        if custom_domain is not None:
            pulumi.set(__self__, "custom_domain", custom_domain)
        if ip_filters is not None:
            pulumi.set(__self__, "ip_filters", ip_filters)
        if m3_version is not None:
            pulumi.set(__self__, "m3_version", m3_version)
        if m3aggregator_version is not None:
            pulumi.set(__self__, "m3aggregator_version", m3aggregator_version)

    @property
    @pulumi.getter(name="customDomain")
    def custom_domain(self) -> Optional[str]:
        """
        Serve the web frontend using a custom CNAME pointing to the Aiven DNS name.
        """
        return pulumi.get(self, "custom_domain")

    @property
    @pulumi.getter(name="ipFilters")
    def ip_filters(self) -> Optional[Sequence[str]]:
        """
        Allow incoming connections from CIDR address block, e.g. '10.20.0.0/16'
        """
        return pulumi.get(self, "ip_filters")

    @property
    @pulumi.getter(name="m3Version")
    def m3_version(self) -> Optional[str]:
        return pulumi.get(self, "m3_version")

    @property
    @pulumi.getter(name="m3aggregatorVersion")
    def m3aggregator_version(self) -> Optional[str]:
        """
        M3 major version
        """
        return pulumi.get(self, "m3aggregator_version")


@pulumi.output_type
class GetM3AggregatorServiceIntegrationResult(dict):
    def __init__(__self__, *,
                 integration_type: str,
                 source_service_name: str):
        pulumi.set(__self__, "integration_type", integration_type)
        pulumi.set(__self__, "source_service_name", source_service_name)

    @property
    @pulumi.getter(name="integrationType")
    def integration_type(self) -> str:
        return pulumi.get(self, "integration_type")

    @property
    @pulumi.getter(name="sourceServiceName")
    def source_service_name(self) -> str:
        return pulumi.get(self, "source_service_name")


@pulumi.output_type
class GetM3DbComponentResult(dict):
    def __init__(__self__, *,
                 component: str,
                 host: str,
                 kafka_authentication_method: str,
                 port: int,
                 route: str,
                 ssl: bool,
                 usage: str):
        pulumi.set(__self__, "component", component)
        pulumi.set(__self__, "host", host)
        pulumi.set(__self__, "kafka_authentication_method", kafka_authentication_method)
        pulumi.set(__self__, "port", port)
        pulumi.set(__self__, "route", route)
        pulumi.set(__self__, "ssl", ssl)
        pulumi.set(__self__, "usage", usage)

    @property
    @pulumi.getter
    def component(self) -> str:
        return pulumi.get(self, "component")

    @property
    @pulumi.getter
    def host(self) -> str:
        return pulumi.get(self, "host")

    @property
    @pulumi.getter(name="kafkaAuthenticationMethod")
    def kafka_authentication_method(self) -> str:
        return pulumi.get(self, "kafka_authentication_method")

    @property
    @pulumi.getter
    def port(self) -> int:
        return pulumi.get(self, "port")

    @property
    @pulumi.getter
    def route(self) -> str:
        return pulumi.get(self, "route")

    @property
    @pulumi.getter
    def ssl(self) -> bool:
        return pulumi.get(self, "ssl")

    @property
    @pulumi.getter
    def usage(self) -> str:
        return pulumi.get(self, "usage")


@pulumi.output_type
class GetM3DbM3dbResult(dict):
    def __init__(__self__):
        pass


@pulumi.output_type
class GetM3DbM3dbUserConfigResult(dict):
    def __init__(__self__, *,
                 custom_domain: Optional[str] = None,
                 ip_filters: Optional[Sequence[str]] = None,
                 limits: Optional['outputs.GetM3DbM3dbUserConfigLimitsResult'] = None,
                 m3_version: Optional[str] = None,
                 m3coordinator_enable_graphite_carbon_ingest: Optional[str] = None,
                 m3db_version: Optional[str] = None,
                 namespaces: Optional[Sequence['outputs.GetM3DbM3dbUserConfigNamespaceResult']] = None,
                 private_access: Optional['outputs.GetM3DbM3dbUserConfigPrivateAccessResult'] = None,
                 project_to_fork_from: Optional[str] = None,
                 public_access: Optional['outputs.GetM3DbM3dbUserConfigPublicAccessResult'] = None,
                 rules: Optional['outputs.GetM3DbM3dbUserConfigRulesResult'] = None,
                 service_to_fork_from: Optional[str] = None):
        """
        :param str custom_domain: Serve the web frontend using a custom CNAME pointing to the Aiven DNS name.
        :param Sequence[str] ip_filters: Allow incoming connections from CIDR address block, e.g. '10.20.0.0/16'
        :param 'GetM3DbM3dbUserConfigLimitsArgs' limits: M3 limits
        :param str m3coordinator_enable_graphite_carbon_ingest: Enables access to Graphite Carbon 
               plaintext metrics ingestion. It can be enabled only for services inside VPCs. The
               metrics are written to aggregated namespaces only.
        :param str m3db_version: M3 major version
        :param Sequence['GetM3DbM3dbUserConfigNamespaceArgs'] namespaces: List of M3 namespaces
        :param 'GetM3DbM3dbUserConfigPrivateAccessArgs' private_access: Allow access to selected service ports from private networks.
        :param str project_to_fork_from: Name of another project to fork a service from. This has
               effect only when a new service is being created.
        :param 'GetM3DbM3dbUserConfigPublicAccessArgs' public_access: Allow access to selected service ports from the public Internet.
        :param 'GetM3DbM3dbUserConfigRulesArgs' rules: Mapping rules allow more granular use of aggregation, not simply sending
               everything to a namespace. If mapping rules exist that target a namespace, only data matching mapping
               rules will be sent to it and nothing else.
        :param str service_to_fork_from: Name of another service to fork from. This has effect only 
               when a new service is being created.
        """
        if custom_domain is not None:
            pulumi.set(__self__, "custom_domain", custom_domain)
        if ip_filters is not None:
            pulumi.set(__self__, "ip_filters", ip_filters)
        if limits is not None:
            pulumi.set(__self__, "limits", limits)
        if m3_version is not None:
            pulumi.set(__self__, "m3_version", m3_version)
        if m3coordinator_enable_graphite_carbon_ingest is not None:
            pulumi.set(__self__, "m3coordinator_enable_graphite_carbon_ingest", m3coordinator_enable_graphite_carbon_ingest)
        if m3db_version is not None:
            pulumi.set(__self__, "m3db_version", m3db_version)
        if namespaces is not None:
            pulumi.set(__self__, "namespaces", namespaces)
        if private_access is not None:
            pulumi.set(__self__, "private_access", private_access)
        if project_to_fork_from is not None:
            pulumi.set(__self__, "project_to_fork_from", project_to_fork_from)
        if public_access is not None:
            pulumi.set(__self__, "public_access", public_access)
        if rules is not None:
            pulumi.set(__self__, "rules", rules)
        if service_to_fork_from is not None:
            pulumi.set(__self__, "service_to_fork_from", service_to_fork_from)

    @property
    @pulumi.getter(name="customDomain")
    def custom_domain(self) -> Optional[str]:
        """
        Serve the web frontend using a custom CNAME pointing to the Aiven DNS name.
        """
        return pulumi.get(self, "custom_domain")

    @property
    @pulumi.getter(name="ipFilters")
    def ip_filters(self) -> Optional[Sequence[str]]:
        """
        Allow incoming connections from CIDR address block, e.g. '10.20.0.0/16'
        """
        return pulumi.get(self, "ip_filters")

    @property
    @pulumi.getter
    def limits(self) -> Optional['outputs.GetM3DbM3dbUserConfigLimitsResult']:
        """
        M3 limits
        """
        return pulumi.get(self, "limits")

    @property
    @pulumi.getter(name="m3Version")
    def m3_version(self) -> Optional[str]:
        return pulumi.get(self, "m3_version")

    @property
    @pulumi.getter(name="m3coordinatorEnableGraphiteCarbonIngest")
    def m3coordinator_enable_graphite_carbon_ingest(self) -> Optional[str]:
        """
        Enables access to Graphite Carbon 
        plaintext metrics ingestion. It can be enabled only for services inside VPCs. The
        metrics are written to aggregated namespaces only.
        """
        return pulumi.get(self, "m3coordinator_enable_graphite_carbon_ingest")

    @property
    @pulumi.getter(name="m3dbVersion")
    def m3db_version(self) -> Optional[str]:
        """
        M3 major version
        """
        return pulumi.get(self, "m3db_version")

    @property
    @pulumi.getter
    def namespaces(self) -> Optional[Sequence['outputs.GetM3DbM3dbUserConfigNamespaceResult']]:
        """
        List of M3 namespaces
        """
        return pulumi.get(self, "namespaces")

    @property
    @pulumi.getter(name="privateAccess")
    def private_access(self) -> Optional['outputs.GetM3DbM3dbUserConfigPrivateAccessResult']:
        """
        Allow access to selected service ports from private networks.
        """
        return pulumi.get(self, "private_access")

    @property
    @pulumi.getter(name="projectToForkFrom")
    def project_to_fork_from(self) -> Optional[str]:
        """
        Name of another project to fork a service from. This has
        effect only when a new service is being created.
        """
        return pulumi.get(self, "project_to_fork_from")

    @property
    @pulumi.getter(name="publicAccess")
    def public_access(self) -> Optional['outputs.GetM3DbM3dbUserConfigPublicAccessResult']:
        """
        Allow access to selected service ports from the public Internet.
        """
        return pulumi.get(self, "public_access")

    @property
    @pulumi.getter
    def rules(self) -> Optional['outputs.GetM3DbM3dbUserConfigRulesResult']:
        """
        Mapping rules allow more granular use of aggregation, not simply sending
        everything to a namespace. If mapping rules exist that target a namespace, only data matching mapping
        rules will be sent to it and nothing else.
        """
        return pulumi.get(self, "rules")

    @property
    @pulumi.getter(name="serviceToForkFrom")
    def service_to_fork_from(self) -> Optional[str]:
        """
        Name of another service to fork from. This has effect only 
        when a new service is being created.
        """
        return pulumi.get(self, "service_to_fork_from")


@pulumi.output_type
class GetM3DbM3dbUserConfigLimitsResult(dict):
    def __init__(__self__, *,
                 global_datapoints: Optional[str] = None,
                 query_datapoints: Optional[str] = None,
                 query_require_exhaustive: Optional[str] = None,
                 query_series: Optional[str] = None):
        """
        :param str global_datapoints: The maximum number of data points fetched during request
        :param str query_datapoints: The maximum number of data points fetched in single query
        :param str query_require_exhaustive: When query limits are exceeded, whether to return error 
               (if True) or return partial results (False)
        :param str query_series: The maximum number of series fetched in single query
        """
        if global_datapoints is not None:
            pulumi.set(__self__, "global_datapoints", global_datapoints)
        if query_datapoints is not None:
            pulumi.set(__self__, "query_datapoints", query_datapoints)
        if query_require_exhaustive is not None:
            pulumi.set(__self__, "query_require_exhaustive", query_require_exhaustive)
        if query_series is not None:
            pulumi.set(__self__, "query_series", query_series)

    @property
    @pulumi.getter(name="globalDatapoints")
    def global_datapoints(self) -> Optional[str]:
        """
        The maximum number of data points fetched during request
        """
        return pulumi.get(self, "global_datapoints")

    @property
    @pulumi.getter(name="queryDatapoints")
    def query_datapoints(self) -> Optional[str]:
        """
        The maximum number of data points fetched in single query
        """
        return pulumi.get(self, "query_datapoints")

    @property
    @pulumi.getter(name="queryRequireExhaustive")
    def query_require_exhaustive(self) -> Optional[str]:
        """
        When query limits are exceeded, whether to return error 
        (if True) or return partial results (False)
        """
        return pulumi.get(self, "query_require_exhaustive")

    @property
    @pulumi.getter(name="querySeries")
    def query_series(self) -> Optional[str]:
        """
        The maximum number of series fetched in single query
        """
        return pulumi.get(self, "query_series")


@pulumi.output_type
class GetM3DbM3dbUserConfigNamespaceResult(dict):
    def __init__(__self__, *,
                 name: Optional[str] = None,
                 options: Optional['outputs.GetM3DbM3dbUserConfigNamespaceOptionsResult'] = None,
                 resolution: Optional[str] = None,
                 type: Optional[str] = None):
        """
        :param str name: The name of the namespace
        :param 'GetM3DbM3dbUserConfigNamespaceOptionsArgs' options: Namespace options
        :param str resolution: The resolution for an aggregated namespace
        :param str type: The type of aggregation (aggregated/unaggregated)
        """
        if name is not None:
            pulumi.set(__self__, "name", name)
        if options is not None:
            pulumi.set(__self__, "options", options)
        if resolution is not None:
            pulumi.set(__self__, "resolution", resolution)
        if type is not None:
            pulumi.set(__self__, "type", type)

    @property
    @pulumi.getter
    def name(self) -> Optional[str]:
        """
        The name of the namespace
        """
        return pulumi.get(self, "name")

    @property
    @pulumi.getter
    def options(self) -> Optional['outputs.GetM3DbM3dbUserConfigNamespaceOptionsResult']:
        """
        Namespace options
        """
        return pulumi.get(self, "options")

    @property
    @pulumi.getter
    def resolution(self) -> Optional[str]:
        """
        The resolution for an aggregated namespace
        """
        return pulumi.get(self, "resolution")

    @property
    @pulumi.getter
    def type(self) -> Optional[str]:
        """
        The type of aggregation (aggregated/unaggregated)
        """
        return pulumi.get(self, "type")


@pulumi.output_type
class GetM3DbM3dbUserConfigNamespaceOptionsResult(dict):
    def __init__(__self__, *,
                 retention_options: Optional['outputs.GetM3DbM3dbUserConfigNamespaceOptionsRetentionOptionsResult'] = None,
                 snapshot_enabled: Optional[str] = None,
                 writes_to_commitlog: Optional[str] = None):
        """
        :param 'GetM3DbM3dbUserConfigNamespaceOptionsRetentionOptionsArgs' retention_options: Retention options
        :param str snapshot_enabled: Controls whether M3DB will create snapshot files for 
               this namespace
        :param str writes_to_commitlog: Controls whether M3DB will include writes to this 
               namespace in the commitlog.
        """
        if retention_options is not None:
            pulumi.set(__self__, "retention_options", retention_options)
        if snapshot_enabled is not None:
            pulumi.set(__self__, "snapshot_enabled", snapshot_enabled)
        if writes_to_commitlog is not None:
            pulumi.set(__self__, "writes_to_commitlog", writes_to_commitlog)

    @property
    @pulumi.getter(name="retentionOptions")
    def retention_options(self) -> Optional['outputs.GetM3DbM3dbUserConfigNamespaceOptionsRetentionOptionsResult']:
        """
        Retention options
        """
        return pulumi.get(self, "retention_options")

    @property
    @pulumi.getter(name="snapshotEnabled")
    def snapshot_enabled(self) -> Optional[str]:
        """
        Controls whether M3DB will create snapshot files for 
        this namespace
        """
        return pulumi.get(self, "snapshot_enabled")

    @property
    @pulumi.getter(name="writesToCommitlog")
    def writes_to_commitlog(self) -> Optional[str]:
        """
        Controls whether M3DB will include writes to this 
        namespace in the commitlog.
        """
        return pulumi.get(self, "writes_to_commitlog")


@pulumi.output_type
class GetM3DbM3dbUserConfigNamespaceOptionsRetentionOptionsResult(dict):
    def __init__(__self__, *,
                 block_data_expiry_duration: Optional[str] = None,
                 blocksize_duration: Optional[str] = None,
                 buffer_future_duration: Optional[str] = None,
                 buffer_past_duration: Optional[str] = None,
                 retention_period_duration: Optional[str] = None):
        """
        :param str block_data_expiry_duration: Controls how long we wait before expiring stale data
        :param str blocksize_duration: Controls how long to keep a block in memory before 
               flushing to a fileset on disk
        :param str buffer_future_duration: Controls how far into the future writes to 
               the namespace will be accepted
        :param str buffer_past_duration: Controls how far into the past writes to the 
               namespace will be accepted
        :param str retention_period_duration: Controls the duration of time that M3DB will 
               retain data for the namespace
        """
        if block_data_expiry_duration is not None:
            pulumi.set(__self__, "block_data_expiry_duration", block_data_expiry_duration)
        if blocksize_duration is not None:
            pulumi.set(__self__, "blocksize_duration", blocksize_duration)
        if buffer_future_duration is not None:
            pulumi.set(__self__, "buffer_future_duration", buffer_future_duration)
        if buffer_past_duration is not None:
            pulumi.set(__self__, "buffer_past_duration", buffer_past_duration)
        if retention_period_duration is not None:
            pulumi.set(__self__, "retention_period_duration", retention_period_duration)

    @property
    @pulumi.getter(name="blockDataExpiryDuration")
    def block_data_expiry_duration(self) -> Optional[str]:
        """
        Controls how long we wait before expiring stale data
        """
        return pulumi.get(self, "block_data_expiry_duration")

    @property
    @pulumi.getter(name="blocksizeDuration")
    def blocksize_duration(self) -> Optional[str]:
        """
        Controls how long to keep a block in memory before 
        flushing to a fileset on disk
        """
        return pulumi.get(self, "blocksize_duration")

    @property
    @pulumi.getter(name="bufferFutureDuration")
    def buffer_future_duration(self) -> Optional[str]:
        """
        Controls how far into the future writes to 
        the namespace will be accepted
        """
        return pulumi.get(self, "buffer_future_duration")

    @property
    @pulumi.getter(name="bufferPastDuration")
    def buffer_past_duration(self) -> Optional[str]:
        """
        Controls how far into the past writes to the 
        namespace will be accepted
        """
        return pulumi.get(self, "buffer_past_duration")

    @property
    @pulumi.getter(name="retentionPeriodDuration")
    def retention_period_duration(self) -> Optional[str]:
        """
        Controls the duration of time that M3DB will 
        retain data for the namespace
        """
        return pulumi.get(self, "retention_period_duration")


@pulumi.output_type
class GetM3DbM3dbUserConfigPrivateAccessResult(dict):
    def __init__(__self__, *,
                 m3coordinator: Optional[str] = None):
        """
        :param str m3coordinator: Allow clients to connect to m3coordinator from the public internet 
               for service nodes that are in a project VPC or another type of private network.
        """
        if m3coordinator is not None:
            pulumi.set(__self__, "m3coordinator", m3coordinator)

    @property
    @pulumi.getter
    def m3coordinator(self) -> Optional[str]:
        """
        Allow clients to connect to m3coordinator from the public internet 
        for service nodes that are in a project VPC or another type of private network.
        """
        return pulumi.get(self, "m3coordinator")


@pulumi.output_type
class GetM3DbM3dbUserConfigPublicAccessResult(dict):
    def __init__(__self__, *,
                 m3coordinator: Optional[str] = None):
        """
        :param str m3coordinator: Allow clients to connect to m3coordinator from the public internet 
               for service nodes that are in a project VPC or another type of private network.
        """
        if m3coordinator is not None:
            pulumi.set(__self__, "m3coordinator", m3coordinator)

    @property
    @pulumi.getter
    def m3coordinator(self) -> Optional[str]:
        """
        Allow clients to connect to m3coordinator from the public internet 
        for service nodes that are in a project VPC or another type of private network.
        """
        return pulumi.get(self, "m3coordinator")


@pulumi.output_type
class GetM3DbM3dbUserConfigRulesResult(dict):
    def __init__(__self__, *,
                 mappings: Optional[Sequence['outputs.GetM3DbM3dbUserConfigRulesMappingResult']] = None):
        if mappings is not None:
            pulumi.set(__self__, "mappings", mappings)

    @property
    @pulumi.getter
    def mappings(self) -> Optional[Sequence['outputs.GetM3DbM3dbUserConfigRulesMappingResult']]:
        return pulumi.get(self, "mappings")


@pulumi.output_type
class GetM3DbM3dbUserConfigRulesMappingResult(dict):
    def __init__(__self__, *,
                 aggregations: Optional[Sequence[str]] = None,
                 drop: Optional[str] = None,
                 filter: Optional[str] = None,
                 name: Optional[str] = None,
                 tags: Optional[Sequence['outputs.GetM3DbM3dbUserConfigRulesMappingTagResult']] = None):
        """
        :param Sequence[str] aggregations: List of aggregations to be applied
        :param str drop: Drop the matching metric; Only store the derived metric (as specified in the roll-up rules), if any.
        :param str filter: The metrics to be used with this particular rule; Matching metric names with wildcards (using
               __name__:wildcard) or matching tags and their (optionally wildcarded) values. For value, !
               can be used at start of value for negation, and multiple filters can be supplied using space as separator.
        :param str name: The name of the namespace
        :param Sequence['GetM3DbM3dbUserConfigRulesMappingTagArgs'] tags: List of tags to be appended to matching metrics.
        """
        if aggregations is not None:
            pulumi.set(__self__, "aggregations", aggregations)
        if drop is not None:
            pulumi.set(__self__, "drop", drop)
        if filter is not None:
            pulumi.set(__self__, "filter", filter)
        if name is not None:
            pulumi.set(__self__, "name", name)
        if tags is not None:
            pulumi.set(__self__, "tags", tags)

    @property
    @pulumi.getter
    def aggregations(self) -> Optional[Sequence[str]]:
        """
        List of aggregations to be applied
        """
        return pulumi.get(self, "aggregations")

    @property
    @pulumi.getter
    def drop(self) -> Optional[str]:
        """
        Drop the matching metric; Only store the derived metric (as specified in the roll-up rules), if any.
        """
        return pulumi.get(self, "drop")

    @property
    @pulumi.getter
    def filter(self) -> Optional[str]:
        """
        The metrics to be used with this particular rule; Matching metric names with wildcards (using
        __name__:wildcard) or matching tags and their (optionally wildcarded) values. For value, !
        can be used at start of value for negation, and multiple filters can be supplied using space as separator.
        """
        return pulumi.get(self, "filter")

    @property
    @pulumi.getter
    def name(self) -> Optional[str]:
        """
        The name of the namespace
        """
        return pulumi.get(self, "name")

    @property
    @pulumi.getter
    def tags(self) -> Optional[Sequence['outputs.GetM3DbM3dbUserConfigRulesMappingTagResult']]:
        """
        List of tags to be appended to matching metrics.
        """
        return pulumi.get(self, "tags")


@pulumi.output_type
class GetM3DbM3dbUserConfigRulesMappingTagResult(dict):
    def __init__(__self__, *,
                 name: Optional[str] = None,
                 value: Optional[str] = None):
        """
        :param str name: The name of the namespace
        :param str value: Value of the tag.
        """
        if name is not None:
            pulumi.set(__self__, "name", name)
        if value is not None:
            pulumi.set(__self__, "value", value)

    @property
    @pulumi.getter
    def name(self) -> Optional[str]:
        """
        The name of the namespace
        """
        return pulumi.get(self, "name")

    @property
    @pulumi.getter
    def value(self) -> Optional[str]:
        """
        Value of the tag.
        """
        return pulumi.get(self, "value")


@pulumi.output_type
class GetM3DbServiceIntegrationResult(dict):
    def __init__(__self__, *,
                 integration_type: str,
                 source_service_name: str):
        pulumi.set(__self__, "integration_type", integration_type)
        pulumi.set(__self__, "source_service_name", source_service_name)

    @property
    @pulumi.getter(name="integrationType")
    def integration_type(self) -> str:
        return pulumi.get(self, "integration_type")

    @property
    @pulumi.getter(name="sourceServiceName")
    def source_service_name(self) -> str:
        return pulumi.get(self, "source_service_name")


@pulumi.output_type
class GetMySqlComponentResult(dict):
    def __init__(__self__, *,
                 component: str,
                 host: str,
                 kafka_authentication_method: str,
                 port: int,
                 route: str,
                 ssl: bool,
                 usage: str):
        """
        :param str host: Hostname or IP address of the server where to migrate data from
        :param int port: Port number of the server where to migrate data from
        :param bool ssl: The server where to migrate data from is secured with SSL
        """
        pulumi.set(__self__, "component", component)
        pulumi.set(__self__, "host", host)
        pulumi.set(__self__, "kafka_authentication_method", kafka_authentication_method)
        pulumi.set(__self__, "port", port)
        pulumi.set(__self__, "route", route)
        pulumi.set(__self__, "ssl", ssl)
        pulumi.set(__self__, "usage", usage)

    @property
    @pulumi.getter
    def component(self) -> str:
        return pulumi.get(self, "component")

    @property
    @pulumi.getter
    def host(self) -> str:
        """
        Hostname or IP address of the server where to migrate data from
        """
        return pulumi.get(self, "host")

    @property
    @pulumi.getter(name="kafkaAuthenticationMethod")
    def kafka_authentication_method(self) -> str:
        return pulumi.get(self, "kafka_authentication_method")

    @property
    @pulumi.getter
    def port(self) -> int:
        """
        Port number of the server where to migrate data from
        """
        return pulumi.get(self, "port")

    @property
    @pulumi.getter
    def route(self) -> str:
        return pulumi.get(self, "route")

    @property
    @pulumi.getter
    def ssl(self) -> bool:
        """
        The server where to migrate data from is secured with SSL
        """
        return pulumi.get(self, "ssl")

    @property
    @pulumi.getter
    def usage(self) -> str:
        return pulumi.get(self, "usage")


@pulumi.output_type
class GetMySqlMysqlResult(dict):
    def __init__(__self__):
        pass


@pulumi.output_type
class GetMySqlMysqlUserConfigResult(dict):
    def __init__(__self__, *,
                 admin_password: Optional[str] = None,
                 admin_username: Optional[str] = None,
                 backup_hour: Optional[str] = None,
                 backup_minute: Optional[str] = None,
                 binlog_retention_period: Optional[str] = None,
                 ip_filters: Optional[Sequence[str]] = None,
                 migration: Optional['outputs.GetMySqlMysqlUserConfigMigrationResult'] = None,
                 mysql: Optional['outputs.GetMySqlMysqlUserConfigMysqlResult'] = None,
                 mysql_version: Optional[str] = None,
                 private_access: Optional['outputs.GetMySqlMysqlUserConfigPrivateAccessResult'] = None,
                 privatelink_access: Optional['outputs.GetMySqlMysqlUserConfigPrivatelinkAccessResult'] = None,
                 project_to_fork_from: Optional[str] = None,
                 public_access: Optional['outputs.GetMySqlMysqlUserConfigPublicAccessResult'] = None,
                 recovery_target_time: Optional[str] = None,
                 service_to_fork_from: Optional[str] = None):
        """
        :param str admin_password: Custom password for admin user. Defaults to random string. 
               This must be set only when a new service is being created.
        :param str admin_username: Custom username for admin user. This must be set only when a 
               new service is being created.
        :param str backup_hour: The hour of day (in UTC) when backup for the service is started. 
               New backup is only started if previous backup has already completed.
        :param str backup_minute: The minute of an hour when backup for the service is started. 
               New backup is only started if previous backup has already completed.
        :param str binlog_retention_period: The minimum amount of time in seconds to keep binlog entries
               before deletion. This may be extended for services that require binlog entries for longer than the
               default for example if using the MySQL Debezium Kafka connector.
        :param Sequence[str] ip_filters: Allow incoming connections from CIDR address block, e.g. '10.20.0.0/16'
        :param 'GetMySqlMysqlUserConfigMigrationArgs' migration: Migrate data from existing server
        :param 'GetMySqlMysqlUserConfigMysqlArgs' mysql: MySQL specific server provided values.
        :param str mysql_version: MySQL major version
        :param 'GetMySqlMysqlUserConfigPrivateAccessArgs' private_access: Allow access to selected service ports from private networks
        :param 'GetMySqlMysqlUserConfigPrivatelinkAccessArgs' privatelink_access: Allow access to selected service components through Privatelink
        :param str project_to_fork_from: Name of another project to fork a service from. This has
               effect only when a new service is being created.
        :param 'GetMySqlMysqlUserConfigPublicAccessArgs' public_access: Allow access to selected service ports from the public Internet
        :param str recovery_target_time: Recovery target time when forking a service. This has effect 
               only when a new service is being created.
        :param str service_to_fork_from: Name of another service to fork from. This has effect only when 
               a new service is being created.
        """
        if admin_password is not None:
            pulumi.set(__self__, "admin_password", admin_password)
        if admin_username is not None:
            pulumi.set(__self__, "admin_username", admin_username)
        if backup_hour is not None:
            pulumi.set(__self__, "backup_hour", backup_hour)
        if backup_minute is not None:
            pulumi.set(__self__, "backup_minute", backup_minute)
        if binlog_retention_period is not None:
            pulumi.set(__self__, "binlog_retention_period", binlog_retention_period)
        if ip_filters is not None:
            pulumi.set(__self__, "ip_filters", ip_filters)
        if migration is not None:
            pulumi.set(__self__, "migration", migration)
        if mysql is not None:
            pulumi.set(__self__, "mysql", mysql)
        if mysql_version is not None:
            pulumi.set(__self__, "mysql_version", mysql_version)
        if private_access is not None:
            pulumi.set(__self__, "private_access", private_access)
        if privatelink_access is not None:
            pulumi.set(__self__, "privatelink_access", privatelink_access)
        if project_to_fork_from is not None:
            pulumi.set(__self__, "project_to_fork_from", project_to_fork_from)
        if public_access is not None:
            pulumi.set(__self__, "public_access", public_access)
        if recovery_target_time is not None:
            pulumi.set(__self__, "recovery_target_time", recovery_target_time)
        if service_to_fork_from is not None:
            pulumi.set(__self__, "service_to_fork_from", service_to_fork_from)

    @property
    @pulumi.getter(name="adminPassword")
    def admin_password(self) -> Optional[str]:
        """
        Custom password for admin user. Defaults to random string. 
        This must be set only when a new service is being created.
        """
        return pulumi.get(self, "admin_password")

    @property
    @pulumi.getter(name="adminUsername")
    def admin_username(self) -> Optional[str]:
        """
        Custom username for admin user. This must be set only when a 
        new service is being created.
        """
        return pulumi.get(self, "admin_username")

    @property
    @pulumi.getter(name="backupHour")
    def backup_hour(self) -> Optional[str]:
        """
        The hour of day (in UTC) when backup for the service is started. 
        New backup is only started if previous backup has already completed.
        """
        return pulumi.get(self, "backup_hour")

    @property
    @pulumi.getter(name="backupMinute")
    def backup_minute(self) -> Optional[str]:
        """
        The minute of an hour when backup for the service is started. 
        New backup is only started if previous backup has already completed.
        """
        return pulumi.get(self, "backup_minute")

    @property
    @pulumi.getter(name="binlogRetentionPeriod")
    def binlog_retention_period(self) -> Optional[str]:
        """
        The minimum amount of time in seconds to keep binlog entries
        before deletion. This may be extended for services that require binlog entries for longer than the
        default for example if using the MySQL Debezium Kafka connector.
        """
        return pulumi.get(self, "binlog_retention_period")

    @property
    @pulumi.getter(name="ipFilters")
    def ip_filters(self) -> Optional[Sequence[str]]:
        """
        Allow incoming connections from CIDR address block, e.g. '10.20.0.0/16'
        """
        return pulumi.get(self, "ip_filters")

    @property
    @pulumi.getter
    def migration(self) -> Optional['outputs.GetMySqlMysqlUserConfigMigrationResult']:
        """
        Migrate data from existing server
        """
        return pulumi.get(self, "migration")

    @property
    @pulumi.getter
    def mysql(self) -> Optional['outputs.GetMySqlMysqlUserConfigMysqlResult']:
        """
        MySQL specific server provided values.
        """
        return pulumi.get(self, "mysql")

    @property
    @pulumi.getter(name="mysqlVersion")
    def mysql_version(self) -> Optional[str]:
        """
        MySQL major version
        """
        return pulumi.get(self, "mysql_version")

    @property
    @pulumi.getter(name="privateAccess")
    def private_access(self) -> Optional['outputs.GetMySqlMysqlUserConfigPrivateAccessResult']:
        """
        Allow access to selected service ports from private networks
        """
        return pulumi.get(self, "private_access")

    @property
    @pulumi.getter(name="privatelinkAccess")
    def privatelink_access(self) -> Optional['outputs.GetMySqlMysqlUserConfigPrivatelinkAccessResult']:
        """
        Allow access to selected service components through Privatelink
        """
        return pulumi.get(self, "privatelink_access")

    @property
    @pulumi.getter(name="projectToForkFrom")
    def project_to_fork_from(self) -> Optional[str]:
        """
        Name of another project to fork a service from. This has
        effect only when a new service is being created.
        """
        return pulumi.get(self, "project_to_fork_from")

    @property
    @pulumi.getter(name="publicAccess")
    def public_access(self) -> Optional['outputs.GetMySqlMysqlUserConfigPublicAccessResult']:
        """
        Allow access to selected service ports from the public Internet
        """
        return pulumi.get(self, "public_access")

    @property
    @pulumi.getter(name="recoveryTargetTime")
    def recovery_target_time(self) -> Optional[str]:
        """
        Recovery target time when forking a service. This has effect 
        only when a new service is being created.
        """
        return pulumi.get(self, "recovery_target_time")

    @property
    @pulumi.getter(name="serviceToForkFrom")
    def service_to_fork_from(self) -> Optional[str]:
        """
        Name of another service to fork from. This has effect only when 
        a new service is being created.
        """
        return pulumi.get(self, "service_to_fork_from")


@pulumi.output_type
class GetMySqlMysqlUserConfigMigrationResult(dict):
    def __init__(__self__, *,
                 dbname: Optional[str] = None,
                 host: Optional[str] = None,
                 ignore_dbs: Optional[str] = None,
                 password: Optional[str] = None,
                 port: Optional[str] = None,
                 ssl: Optional[str] = None,
                 username: Optional[str] = None):
        """
        :param str dbname: Database name for bootstrapping the initial connection
        :param str host: Hostname or IP address of the server where to migrate data from
        :param str ignore_dbs: Comma-separated list of databases, which should be ignored
               during migration (supported by MySQL only at the moment)
        :param str password: Password for authentication with the server where to migrate data from
        :param str port: Port number of the server where to migrate data from
        :param str ssl: The server where to migrate data from is secured with SSL
        :param str username: User name for authentication with the server where to migrate data from
        """
        if dbname is not None:
            pulumi.set(__self__, "dbname", dbname)
        if host is not None:
            pulumi.set(__self__, "host", host)
        if ignore_dbs is not None:
            pulumi.set(__self__, "ignore_dbs", ignore_dbs)
        if password is not None:
            pulumi.set(__self__, "password", password)
        if port is not None:
            pulumi.set(__self__, "port", port)
        if ssl is not None:
            pulumi.set(__self__, "ssl", ssl)
        if username is not None:
            pulumi.set(__self__, "username", username)

    @property
    @pulumi.getter
    def dbname(self) -> Optional[str]:
        """
        Database name for bootstrapping the initial connection
        """
        return pulumi.get(self, "dbname")

    @property
    @pulumi.getter
    def host(self) -> Optional[str]:
        """
        Hostname or IP address of the server where to migrate data from
        """
        return pulumi.get(self, "host")

    @property
    @pulumi.getter(name="ignoreDbs")
    def ignore_dbs(self) -> Optional[str]:
        """
        Comma-separated list of databases, which should be ignored
        during migration (supported by MySQL only at the moment)
        """
        return pulumi.get(self, "ignore_dbs")

    @property
    @pulumi.getter
    def password(self) -> Optional[str]:
        """
        Password for authentication with the server where to migrate data from
        """
        return pulumi.get(self, "password")

    @property
    @pulumi.getter
    def port(self) -> Optional[str]:
        """
        Port number of the server where to migrate data from
        """
        return pulumi.get(self, "port")

    @property
    @pulumi.getter
    def ssl(self) -> Optional[str]:
        """
        The server where to migrate data from is secured with SSL
        """
        return pulumi.get(self, "ssl")

    @property
    @pulumi.getter
    def username(self) -> Optional[str]:
        """
        User name for authentication with the server where to migrate data from
        """
        return pulumi.get(self, "username")


@pulumi.output_type
class GetMySqlMysqlUserConfigMysqlResult(dict):
    def __init__(__self__, *,
                 connect_timeout: Optional[str] = None,
                 default_time_zone: Optional[str] = None,
                 group_concat_max_len: Optional[str] = None,
                 information_schema_stats_expiry: Optional[str] = None,
                 innodb_ft_min_token_size: Optional[str] = None,
                 innodb_ft_server_stopword_table: Optional[str] = None,
                 innodb_lock_wait_timeout: Optional[str] = None,
                 innodb_log_buffer_size: Optional[str] = None,
                 innodb_online_alter_log_max_size: Optional[str] = None,
                 innodb_print_all_deadlocks: Optional[str] = None,
                 innodb_rollback_on_timeout: Optional[str] = None,
                 interactive_timeout: Optional[str] = None,
                 long_query_time: Optional[str] = None,
                 max_allowed_packet: Optional[str] = None,
                 max_heap_table_size: Optional[str] = None,
                 net_read_timeout: Optional[str] = None,
                 net_write_timeout: Optional[str] = None,
                 slow_query_log: Optional[str] = None,
                 sort_buffer_size: Optional[str] = None,
                 sql_mode: Optional[str] = None,
                 sql_require_primary_key: Optional[str] = None,
                 tmp_table_size: Optional[str] = None,
                 wait_timeout: Optional[str] = None):
        """
        :param str connect_timeout: The number of seconds that the mysqld server waits for a 
               connect packet before responding with Bad handshake
        :param str default_time_zone: Default server time zone as an offset from UTC 
               (from -12:00 to +12:00), a time zone name, or 'SYSTEM' to use the MySQL server default.
        :param str group_concat_max_len: The maximum permitted result length in bytes for 
               the GROUP_CONCAT() function.
        :param str information_schema_stats_expiry: The time, in seconds, before cached 
               statistics expire
        :param str innodb_ft_min_token_size: Minimum length of words that are stored in 
               an InnoDB FULLTEXT index.
        :param str innodb_ft_server_stopword_table: This option is used to specify your 
               own InnoDB FULLTEXT index stopword list for all InnoDB tables.
        :param str innodb_lock_wait_timeout: The length of time in seconds an InnoDB 
               transaction waits for a row lock before giving up.
        :param str innodb_log_buffer_size: The size in bytes of the buffer that InnoDB 
               uses to write to the log files on disk.
        :param str innodb_online_alter_log_max_size: The upper limit in bytes on the 
               size of the temporary log files used during online DDL operations for InnoDB tables.
        :param str innodb_print_all_deadlocks: When enabled, information about all 
               deadlocks in InnoDB user transactions is recorded in the error log. Disabled by default.
        :param str innodb_rollback_on_timeout: When enabled a transaction timeout 
               causes InnoDB to abort and roll back the entire transaction.
        :param str interactive_timeout: The number of seconds the server waits for 
               activity on an interactive connection before closing it.
        :param str long_query_time: The slow_query_logs work as SQL statements that take
               more than long_query_time seconds to execute. Default is 10s
        :param str max_allowed_packet: Size of the largest message in bytes that can 
               be received by the server. Default is 67108864 (64M)
        :param str max_heap_table_size: Limits the size of internal in-memory tables. 
               Also set tmp_table_size. Default is 16777216 (16M)
        :param str net_read_timeout: The number of seconds to wait for more data from 
               a connection before aborting the read.
        :param str net_write_timeout: The number of seconds to wait for a block to be 
               written to a connection before aborting the write.
        :param str slow_query_log: Slow query log enables capturing of slow queries.
               Setting slow_query_log to false also truncates the mysql.slow_log table. Default is off
        :param str sort_buffer_size: Sort buffer size in bytes for ORDER BY optimization. 
               Default is 262144 (256K)
        :param str sql_mode: Global SQL mode. Set to empty to use MySQL server defaults. 
               When creating a new service and not setting this field Aiven default SQL mode (strict,
               SQL standard compliant) will be assigned.
        :param str sql_require_primary_key: Require primary key to be defined for new 
               tables or old tables modified with ALTER TABLE and fail if missing. It is recommended
               to always have primary keys because various functionality may break if any large table
               is missing them.
        :param str tmp_table_size: Limits the size of internal in-memory tables. Also set 
               max_heap_table_size. Default is 16777216 (16M)
        :param str wait_timeout: The number of seconds the server waits for activity on 
               a noninteractive connection before closing it.
        """
        if connect_timeout is not None:
            pulumi.set(__self__, "connect_timeout", connect_timeout)
        if default_time_zone is not None:
            pulumi.set(__self__, "default_time_zone", default_time_zone)
        if group_concat_max_len is not None:
            pulumi.set(__self__, "group_concat_max_len", group_concat_max_len)
        if information_schema_stats_expiry is not None:
            pulumi.set(__self__, "information_schema_stats_expiry", information_schema_stats_expiry)
        if innodb_ft_min_token_size is not None:
            pulumi.set(__self__, "innodb_ft_min_token_size", innodb_ft_min_token_size)
        if innodb_ft_server_stopword_table is not None:
            pulumi.set(__self__, "innodb_ft_server_stopword_table", innodb_ft_server_stopword_table)
        if innodb_lock_wait_timeout is not None:
            pulumi.set(__self__, "innodb_lock_wait_timeout", innodb_lock_wait_timeout)
        if innodb_log_buffer_size is not None:
            pulumi.set(__self__, "innodb_log_buffer_size", innodb_log_buffer_size)
        if innodb_online_alter_log_max_size is not None:
            pulumi.set(__self__, "innodb_online_alter_log_max_size", innodb_online_alter_log_max_size)
        if innodb_print_all_deadlocks is not None:
            pulumi.set(__self__, "innodb_print_all_deadlocks", innodb_print_all_deadlocks)
        if innodb_rollback_on_timeout is not None:
            pulumi.set(__self__, "innodb_rollback_on_timeout", innodb_rollback_on_timeout)
        if interactive_timeout is not None:
            pulumi.set(__self__, "interactive_timeout", interactive_timeout)
        if long_query_time is not None:
            pulumi.set(__self__, "long_query_time", long_query_time)
        if max_allowed_packet is not None:
            pulumi.set(__self__, "max_allowed_packet", max_allowed_packet)
        if max_heap_table_size is not None:
            pulumi.set(__self__, "max_heap_table_size", max_heap_table_size)
        if net_read_timeout is not None:
            pulumi.set(__self__, "net_read_timeout", net_read_timeout)
        if net_write_timeout is not None:
            pulumi.set(__self__, "net_write_timeout", net_write_timeout)
        if slow_query_log is not None:
            pulumi.set(__self__, "slow_query_log", slow_query_log)
        if sort_buffer_size is not None:
            pulumi.set(__self__, "sort_buffer_size", sort_buffer_size)
        if sql_mode is not None:
            pulumi.set(__self__, "sql_mode", sql_mode)
        if sql_require_primary_key is not None:
            pulumi.set(__self__, "sql_require_primary_key", sql_require_primary_key)
        if tmp_table_size is not None:
            pulumi.set(__self__, "tmp_table_size", tmp_table_size)
        if wait_timeout is not None:
            pulumi.set(__self__, "wait_timeout", wait_timeout)

    @property
    @pulumi.getter(name="connectTimeout")
    def connect_timeout(self) -> Optional[str]:
        """
        The number of seconds that the mysqld server waits for a 
        connect packet before responding with Bad handshake
        """
        return pulumi.get(self, "connect_timeout")

    @property
    @pulumi.getter(name="defaultTimeZone")
    def default_time_zone(self) -> Optional[str]:
        """
        Default server time zone as an offset from UTC 
        (from -12:00 to +12:00), a time zone name, or 'SYSTEM' to use the MySQL server default.
        """
        return pulumi.get(self, "default_time_zone")

    @property
    @pulumi.getter(name="groupConcatMaxLen")
    def group_concat_max_len(self) -> Optional[str]:
        """
        The maximum permitted result length in bytes for 
        the GROUP_CONCAT() function.
        """
        return pulumi.get(self, "group_concat_max_len")

    @property
    @pulumi.getter(name="informationSchemaStatsExpiry")
    def information_schema_stats_expiry(self) -> Optional[str]:
        """
        The time, in seconds, before cached 
        statistics expire
        """
        return pulumi.get(self, "information_schema_stats_expiry")

    @property
    @pulumi.getter(name="innodbFtMinTokenSize")
    def innodb_ft_min_token_size(self) -> Optional[str]:
        """
        Minimum length of words that are stored in 
        an InnoDB FULLTEXT index.
        """
        return pulumi.get(self, "innodb_ft_min_token_size")

    @property
    @pulumi.getter(name="innodbFtServerStopwordTable")
    def innodb_ft_server_stopword_table(self) -> Optional[str]:
        """
        This option is used to specify your 
        own InnoDB FULLTEXT index stopword list for all InnoDB tables.
        """
        return pulumi.get(self, "innodb_ft_server_stopword_table")

    @property
    @pulumi.getter(name="innodbLockWaitTimeout")
    def innodb_lock_wait_timeout(self) -> Optional[str]:
        """
        The length of time in seconds an InnoDB 
        transaction waits for a row lock before giving up.
        """
        return pulumi.get(self, "innodb_lock_wait_timeout")

    @property
    @pulumi.getter(name="innodbLogBufferSize")
    def innodb_log_buffer_size(self) -> Optional[str]:
        """
        The size in bytes of the buffer that InnoDB 
        uses to write to the log files on disk.
        """
        return pulumi.get(self, "innodb_log_buffer_size")

    @property
    @pulumi.getter(name="innodbOnlineAlterLogMaxSize")
    def innodb_online_alter_log_max_size(self) -> Optional[str]:
        """
        The upper limit in bytes on the 
        size of the temporary log files used during online DDL operations for InnoDB tables.
        """
        return pulumi.get(self, "innodb_online_alter_log_max_size")

    @property
    @pulumi.getter(name="innodbPrintAllDeadlocks")
    def innodb_print_all_deadlocks(self) -> Optional[str]:
        """
        When enabled, information about all 
        deadlocks in InnoDB user transactions is recorded in the error log. Disabled by default.
        """
        return pulumi.get(self, "innodb_print_all_deadlocks")

    @property
    @pulumi.getter(name="innodbRollbackOnTimeout")
    def innodb_rollback_on_timeout(self) -> Optional[str]:
        """
        When enabled a transaction timeout 
        causes InnoDB to abort and roll back the entire transaction.
        """
        return pulumi.get(self, "innodb_rollback_on_timeout")

    @property
    @pulumi.getter(name="interactiveTimeout")
    def interactive_timeout(self) -> Optional[str]:
        """
        The number of seconds the server waits for 
        activity on an interactive connection before closing it.
        """
        return pulumi.get(self, "interactive_timeout")

    @property
    @pulumi.getter(name="longQueryTime")
    def long_query_time(self) -> Optional[str]:
        """
        The slow_query_logs work as SQL statements that take
        more than long_query_time seconds to execute. Default is 10s
        """
        return pulumi.get(self, "long_query_time")

    @property
    @pulumi.getter(name="maxAllowedPacket")
    def max_allowed_packet(self) -> Optional[str]:
        """
        Size of the largest message in bytes that can 
        be received by the server. Default is 67108864 (64M)
        """
        return pulumi.get(self, "max_allowed_packet")

    @property
    @pulumi.getter(name="maxHeapTableSize")
    def max_heap_table_size(self) -> Optional[str]:
        """
        Limits the size of internal in-memory tables. 
        Also set tmp_table_size. Default is 16777216 (16M)
        """
        return pulumi.get(self, "max_heap_table_size")

    @property
    @pulumi.getter(name="netReadTimeout")
    def net_read_timeout(self) -> Optional[str]:
        """
        The number of seconds to wait for more data from 
        a connection before aborting the read.
        """
        return pulumi.get(self, "net_read_timeout")

    @property
    @pulumi.getter(name="netWriteTimeout")
    def net_write_timeout(self) -> Optional[str]:
        """
        The number of seconds to wait for a block to be 
        written to a connection before aborting the write.
        """
        return pulumi.get(self, "net_write_timeout")

    @property
    @pulumi.getter(name="slowQueryLog")
    def slow_query_log(self) -> Optional[str]:
        """
        Slow query log enables capturing of slow queries.
        Setting slow_query_log to false also truncates the mysql.slow_log table. Default is off
        """
        return pulumi.get(self, "slow_query_log")

    @property
    @pulumi.getter(name="sortBufferSize")
    def sort_buffer_size(self) -> Optional[str]:
        """
        Sort buffer size in bytes for ORDER BY optimization. 
        Default is 262144 (256K)
        """
        return pulumi.get(self, "sort_buffer_size")

    @property
    @pulumi.getter(name="sqlMode")
    def sql_mode(self) -> Optional[str]:
        """
        Global SQL mode. Set to empty to use MySQL server defaults. 
        When creating a new service and not setting this field Aiven default SQL mode (strict,
        SQL standard compliant) will be assigned.
        """
        return pulumi.get(self, "sql_mode")

    @property
    @pulumi.getter(name="sqlRequirePrimaryKey")
    def sql_require_primary_key(self) -> Optional[str]:
        """
        Require primary key to be defined for new 
        tables or old tables modified with ALTER TABLE and fail if missing. It is recommended
        to always have primary keys because various functionality may break if any large table
        is missing them.
        """
        return pulumi.get(self, "sql_require_primary_key")

    @property
    @pulumi.getter(name="tmpTableSize")
    def tmp_table_size(self) -> Optional[str]:
        """
        Limits the size of internal in-memory tables. Also set 
        max_heap_table_size. Default is 16777216 (16M)
        """
        return pulumi.get(self, "tmp_table_size")

    @property
    @pulumi.getter(name="waitTimeout")
    def wait_timeout(self) -> Optional[str]:
        """
        The number of seconds the server waits for activity on 
        a noninteractive connection before closing it.
        """
        return pulumi.get(self, "wait_timeout")


@pulumi.output_type
class GetMySqlMysqlUserConfigPrivateAccessResult(dict):
    def __init__(__self__, *,
                 mysql: Optional[str] = None,
                 mysqlx: Optional[str] = None,
                 prometheus: Optional[str] = None):
        """
        :param str mysql: MySQL specific server provided values.
        :param str mysqlx: (Optional) Allow clients to connect to mysqlx from the public internet for service
               nodes that are in a project VPC or another type of private network
        :param str prometheus: Allow clients to connect to prometheus from the public internet 
               for service nodes that are in a project VPC or another type of private network
        """
        if mysql is not None:
            pulumi.set(__self__, "mysql", mysql)
        if mysqlx is not None:
            pulumi.set(__self__, "mysqlx", mysqlx)
        if prometheus is not None:
            pulumi.set(__self__, "prometheus", prometheus)

    @property
    @pulumi.getter
    def mysql(self) -> Optional[str]:
        """
        MySQL specific server provided values.
        """
        return pulumi.get(self, "mysql")

    @property
    @pulumi.getter
    def mysqlx(self) -> Optional[str]:
        """
        (Optional) Allow clients to connect to mysqlx from the public internet for service
        nodes that are in a project VPC or another type of private network
        """
        return pulumi.get(self, "mysqlx")

    @property
    @pulumi.getter
    def prometheus(self) -> Optional[str]:
        """
        Allow clients to connect to prometheus from the public internet 
        for service nodes that are in a project VPC or another type of private network
        """
        return pulumi.get(self, "prometheus")


@pulumi.output_type
class GetMySqlMysqlUserConfigPrivatelinkAccessResult(dict):
    def __init__(__self__, *,
                 mysql: Optional[str] = None,
                 mysqlx: Optional[str] = None):
        """
        :param str mysql: MySQL specific server provided values.
        :param str mysqlx: (Optional) Allow clients to connect to mysqlx from the public internet for service
               nodes that are in a project VPC or another type of private network
        """
        if mysql is not None:
            pulumi.set(__self__, "mysql", mysql)
        if mysqlx is not None:
            pulumi.set(__self__, "mysqlx", mysqlx)

    @property
    @pulumi.getter
    def mysql(self) -> Optional[str]:
        """
        MySQL specific server provided values.
        """
        return pulumi.get(self, "mysql")

    @property
    @pulumi.getter
    def mysqlx(self) -> Optional[str]:
        """
        (Optional) Allow clients to connect to mysqlx from the public internet for service
        nodes that are in a project VPC or another type of private network
        """
        return pulumi.get(self, "mysqlx")


@pulumi.output_type
class GetMySqlMysqlUserConfigPublicAccessResult(dict):
    def __init__(__self__, *,
                 mysql: Optional[str] = None,
                 mysqlx: Optional[str] = None,
                 prometheus: Optional[str] = None):
        """
        :param str mysql: MySQL specific server provided values.
        :param str mysqlx: (Optional) Allow clients to connect to mysqlx from the public internet for service
               nodes that are in a project VPC or another type of private network
        :param str prometheus: Allow clients to connect to prometheus from the public internet 
               for service nodes that are in a project VPC or another type of private network
        """
        if mysql is not None:
            pulumi.set(__self__, "mysql", mysql)
        if mysqlx is not None:
            pulumi.set(__self__, "mysqlx", mysqlx)
        if prometheus is not None:
            pulumi.set(__self__, "prometheus", prometheus)

    @property
    @pulumi.getter
    def mysql(self) -> Optional[str]:
        """
        MySQL specific server provided values.
        """
        return pulumi.get(self, "mysql")

    @property
    @pulumi.getter
    def mysqlx(self) -> Optional[str]:
        """
        (Optional) Allow clients to connect to mysqlx from the public internet for service
        nodes that are in a project VPC or another type of private network
        """
        return pulumi.get(self, "mysqlx")

    @property
    @pulumi.getter
    def prometheus(self) -> Optional[str]:
        """
        Allow clients to connect to prometheus from the public internet 
        for service nodes that are in a project VPC or another type of private network
        """
        return pulumi.get(self, "prometheus")


@pulumi.output_type
class GetMySqlServiceIntegrationResult(dict):
    def __init__(__self__, *,
                 integration_type: str,
                 source_service_name: str):
        pulumi.set(__self__, "integration_type", integration_type)
        pulumi.set(__self__, "source_service_name", source_service_name)

    @property
    @pulumi.getter(name="integrationType")
    def integration_type(self) -> str:
        return pulumi.get(self, "integration_type")

    @property
    @pulumi.getter(name="sourceServiceName")
    def source_service_name(self) -> str:
        return pulumi.get(self, "source_service_name")


@pulumi.output_type
class GetPgComponentResult(dict):
    def __init__(__self__, *,
                 component: str,
                 host: str,
                 kafka_authentication_method: str,
                 port: int,
                 route: str,
                 ssl: bool,
                 usage: str):
        """
        :param str host: PostgreSQL master node host IP or name
        :param int port: PostgreSQL port
        :param bool ssl: the server where to migrate data from is secured with SSL.
        """
        pulumi.set(__self__, "component", component)
        pulumi.set(__self__, "host", host)
        pulumi.set(__self__, "kafka_authentication_method", kafka_authentication_method)
        pulumi.set(__self__, "port", port)
        pulumi.set(__self__, "route", route)
        pulumi.set(__self__, "ssl", ssl)
        pulumi.set(__self__, "usage", usage)

    @property
    @pulumi.getter
    def component(self) -> str:
        return pulumi.get(self, "component")

    @property
    @pulumi.getter
    def host(self) -> str:
        """
        PostgreSQL master node host IP or name
        """
        return pulumi.get(self, "host")

    @property
    @pulumi.getter(name="kafkaAuthenticationMethod")
    def kafka_authentication_method(self) -> str:
        return pulumi.get(self, "kafka_authentication_method")

    @property
    @pulumi.getter
    def port(self) -> int:
        """
        PostgreSQL port
        """
        return pulumi.get(self, "port")

    @property
    @pulumi.getter
    def route(self) -> str:
        return pulumi.get(self, "route")

    @property
    @pulumi.getter
    def ssl(self) -> bool:
        """
        the server where to migrate data from is secured with SSL.
        """
        return pulumi.get(self, "ssl")

    @property
    @pulumi.getter
    def usage(self) -> str:
        return pulumi.get(self, "usage")


@pulumi.output_type
class GetPgPgResult(dict):
    def __init__(__self__, *,
                 dbname: str,
                 host: str,
                 password: str,
                 port: int,
                 replica_uri: str,
                 sslmode: str,
                 uri: str,
                 user: str):
        """
        :param str dbname: Primary PostgreSQL database name
        :param str host: PostgreSQL master node host IP or name
        :param str password: PostgreSQL admin user password
        :param int port: PostgreSQL port
        :param str replica_uri: PostgreSQL replica URI for services with a replica
        :param str sslmode: PostgreSQL sslmode setting (currently always `require`)
        :param str uri: PostgreSQL master connection URI
        :param str user: PostgreSQL admin user name
        """
        pulumi.set(__self__, "dbname", dbname)
        pulumi.set(__self__, "host", host)
        pulumi.set(__self__, "password", password)
        pulumi.set(__self__, "port", port)
        pulumi.set(__self__, "replica_uri", replica_uri)
        pulumi.set(__self__, "sslmode", sslmode)
        pulumi.set(__self__, "uri", uri)
        pulumi.set(__self__, "user", user)

    @property
    @pulumi.getter
    def dbname(self) -> str:
        """
        Primary PostgreSQL database name
        """
        return pulumi.get(self, "dbname")

    @property
    @pulumi.getter
    def host(self) -> str:
        """
        PostgreSQL master node host IP or name
        """
        return pulumi.get(self, "host")

    @property
    @pulumi.getter
    def password(self) -> str:
        """
        PostgreSQL admin user password
        """
        return pulumi.get(self, "password")

    @property
    @pulumi.getter
    def port(self) -> int:
        """
        PostgreSQL port
        """
        return pulumi.get(self, "port")

    @property
    @pulumi.getter(name="replicaUri")
    def replica_uri(self) -> str:
        """
        PostgreSQL replica URI for services with a replica
        """
        return pulumi.get(self, "replica_uri")

    @property
    @pulumi.getter
    def sslmode(self) -> str:
        """
        PostgreSQL sslmode setting (currently always `require`)
        """
        return pulumi.get(self, "sslmode")

    @property
    @pulumi.getter
    def uri(self) -> str:
        """
        PostgreSQL master connection URI
        """
        return pulumi.get(self, "uri")

    @property
    @pulumi.getter
    def user(self) -> str:
        """
        PostgreSQL admin user name
        """
        return pulumi.get(self, "user")


@pulumi.output_type
class GetPgPgUserConfigResult(dict):
    def __init__(__self__, *,
                 admin_password: Optional[str] = None,
                 admin_username: Optional[str] = None,
                 backup_hour: Optional[str] = None,
                 backup_minute: Optional[str] = None,
                 ip_filters: Optional[Sequence[str]] = None,
                 migration: Optional['outputs.GetPgPgUserConfigMigrationResult'] = None,
                 pg: Optional['outputs.GetPgPgUserConfigPgResult'] = None,
                 pg_read_replica: Optional[str] = None,
                 pg_service_to_fork_from: Optional[str] = None,
                 pg_version: Optional[str] = None,
                 pgbouncer: Optional['outputs.GetPgPgUserConfigPgbouncerResult'] = None,
                 pglookout: Optional['outputs.GetPgPgUserConfigPglookoutResult'] = None,
                 private_access: Optional['outputs.GetPgPgUserConfigPrivateAccessResult'] = None,
                 privatelink_access: Optional['outputs.GetPgPgUserConfigPrivatelinkAccessResult'] = None,
                 project_to_fork_from: Optional[str] = None,
                 public_access: Optional['outputs.GetPgPgUserConfigPublicAccessResult'] = None,
                 recovery_target_time: Optional[str] = None,
                 service_to_fork_from: Optional[str] = None,
                 shared_buffers_percentage: Optional[str] = None,
                 synchronous_replication: Optional[str] = None,
                 timescaledb: Optional['outputs.GetPgPgUserConfigTimescaledbResult'] = None,
                 variant: Optional[str] = None,
                 work_mem: Optional[str] = None):
        """
        :param str admin_password: custom password for admin user. Defaults to random string. *This must
               be set only when a new service is being created.*
        :param str admin_username: custom username for admin user. *This must be set only when a new service
               is being created.*
        :param str backup_hour: the hour of day (in UTC) when backup for the service is started. New backup 
               is only started if previous backup has already completed.
        :param str backup_minute: the minute of an hour when backup for the service is started. New backup 
               is only started if previous backup has already completed.
        :param Sequence[str] ip_filters: allow incoming connections from CIDR address block, e.g. `10.20.0.0/16`
        :param 'GetPgPgUserConfigMigrationArgs' migration: migrate data from existing server, has the following options:
        :param 'GetPgPgUserConfigPgArgs' pg: PostgreSQL specific server provided values.
        :param str pg_read_replica: This setting is deprecated. Use read-replica service integration instead.
        :param str pg_service_to_fork_from: Name of the PG Service from which to fork (deprecated, use service_to_fork_from). 
               This has effect only when a new service is being created.
        :param str pg_version: PostgreSQL major version.
        :param 'GetPgPgUserConfigPgbouncerArgs' pgbouncer: Enable pgbouncer.
        :param 'GetPgPgUserConfigPglookoutArgs' pglookout: PGLookout settings.
        :param 'GetPgPgUserConfigPrivateAccessArgs' private_access: Allow access to selected service ports from private networks.
        :param 'GetPgPgUserConfigPrivatelinkAccessArgs' privatelink_access: Allow access to selected service components through Privatelink.
        :param str project_to_fork_from: Name of another project to fork a service from. This has
               effect only when a new service is being created.
        :param 'GetPgPgUserConfigPublicAccessArgs' public_access: Allow access to selected service ports from the public Internet
        :param str recovery_target_time: Recovery target time when forking a service. This has effect 
               only when a new service is being created.
        :param str service_to_fork_from: Name of another service to fork from. This has effect only 
               when a new service is being created.
        :param str shared_buffers_percentage: Percentage of total RAM that the database server uses for 
               memory buffers. Valid range is 20-60 (float), which corresponds to 20% - 60%. This setting adjusts
               the shared_buffers configuration value. The absolute maximum is 12 GB.
        :param str synchronous_replication: Synchronous replication type. Note that the service plan 
               also needs to support synchronous replication.
        :param 'GetPgPgUserConfigTimescaledbArgs' timescaledb: TimescaleDB extension configuration values.
        :param str variant: Variant of the PostgreSQL service, may affect the features that are 
               exposed by default. Options: `aiven` or `timescale`.
        :param str work_mem: Sets the maximum amount of memory to be used by a query operation (such 
               as a sort or hash table) before writing to temporary disk files, in MB. Default is 1MB + 0.075% of
               total RAM (up to 32MB).
        """
        if admin_password is not None:
            pulumi.set(__self__, "admin_password", admin_password)
        if admin_username is not None:
            pulumi.set(__self__, "admin_username", admin_username)
        if backup_hour is not None:
            pulumi.set(__self__, "backup_hour", backup_hour)
        if backup_minute is not None:
            pulumi.set(__self__, "backup_minute", backup_minute)
        if ip_filters is not None:
            pulumi.set(__self__, "ip_filters", ip_filters)
        if migration is not None:
            pulumi.set(__self__, "migration", migration)
        if pg is not None:
            pulumi.set(__self__, "pg", pg)
        if pg_read_replica is not None:
            pulumi.set(__self__, "pg_read_replica", pg_read_replica)
        if pg_service_to_fork_from is not None:
            pulumi.set(__self__, "pg_service_to_fork_from", pg_service_to_fork_from)
        if pg_version is not None:
            pulumi.set(__self__, "pg_version", pg_version)
        if pgbouncer is not None:
            pulumi.set(__self__, "pgbouncer", pgbouncer)
        if pglookout is not None:
            pulumi.set(__self__, "pglookout", pglookout)
        if private_access is not None:
            pulumi.set(__self__, "private_access", private_access)
        if privatelink_access is not None:
            pulumi.set(__self__, "privatelink_access", privatelink_access)
        if project_to_fork_from is not None:
            pulumi.set(__self__, "project_to_fork_from", project_to_fork_from)
        if public_access is not None:
            pulumi.set(__self__, "public_access", public_access)
        if recovery_target_time is not None:
            pulumi.set(__self__, "recovery_target_time", recovery_target_time)
        if service_to_fork_from is not None:
            pulumi.set(__self__, "service_to_fork_from", service_to_fork_from)
        if shared_buffers_percentage is not None:
            pulumi.set(__self__, "shared_buffers_percentage", shared_buffers_percentage)
        if synchronous_replication is not None:
            pulumi.set(__self__, "synchronous_replication", synchronous_replication)
        if timescaledb is not None:
            pulumi.set(__self__, "timescaledb", timescaledb)
        if variant is not None:
            pulumi.set(__self__, "variant", variant)
        if work_mem is not None:
            pulumi.set(__self__, "work_mem", work_mem)

    @property
    @pulumi.getter(name="adminPassword")
    def admin_password(self) -> Optional[str]:
        """
        custom password for admin user. Defaults to random string. *This must
        be set only when a new service is being created.*
        """
        return pulumi.get(self, "admin_password")

    @property
    @pulumi.getter(name="adminUsername")
    def admin_username(self) -> Optional[str]:
        """
        custom username for admin user. *This must be set only when a new service
        is being created.*
        """
        return pulumi.get(self, "admin_username")

    @property
    @pulumi.getter(name="backupHour")
    def backup_hour(self) -> Optional[str]:
        """
        the hour of day (in UTC) when backup for the service is started. New backup 
        is only started if previous backup has already completed.
        """
        return pulumi.get(self, "backup_hour")

    @property
    @pulumi.getter(name="backupMinute")
    def backup_minute(self) -> Optional[str]:
        """
        the minute of an hour when backup for the service is started. New backup 
        is only started if previous backup has already completed.
        """
        return pulumi.get(self, "backup_minute")

    @property
    @pulumi.getter(name="ipFilters")
    def ip_filters(self) -> Optional[Sequence[str]]:
        """
        allow incoming connections from CIDR address block, e.g. `10.20.0.0/16`
        """
        return pulumi.get(self, "ip_filters")

    @property
    @pulumi.getter
    def migration(self) -> Optional['outputs.GetPgPgUserConfigMigrationResult']:
        """
        migrate data from existing server, has the following options:
        """
        return pulumi.get(self, "migration")

    @property
    @pulumi.getter
    def pg(self) -> Optional['outputs.GetPgPgUserConfigPgResult']:
        """
        PostgreSQL specific server provided values.
        """
        return pulumi.get(self, "pg")

    @property
    @pulumi.getter(name="pgReadReplica")
    def pg_read_replica(self) -> Optional[str]:
        """
        This setting is deprecated. Use read-replica service integration instead.
        """
        return pulumi.get(self, "pg_read_replica")

    @property
    @pulumi.getter(name="pgServiceToForkFrom")
    def pg_service_to_fork_from(self) -> Optional[str]:
        """
        Name of the PG Service from which to fork (deprecated, use service_to_fork_from). 
        This has effect only when a new service is being created.
        """
        return pulumi.get(self, "pg_service_to_fork_from")

    @property
    @pulumi.getter(name="pgVersion")
    def pg_version(self) -> Optional[str]:
        """
        PostgreSQL major version.
        """
        return pulumi.get(self, "pg_version")

    @property
    @pulumi.getter
    def pgbouncer(self) -> Optional['outputs.GetPgPgUserConfigPgbouncerResult']:
        """
        Enable pgbouncer.
        """
        return pulumi.get(self, "pgbouncer")

    @property
    @pulumi.getter
    def pglookout(self) -> Optional['outputs.GetPgPgUserConfigPglookoutResult']:
        """
        PGLookout settings.
        """
        return pulumi.get(self, "pglookout")

    @property
    @pulumi.getter(name="privateAccess")
    def private_access(self) -> Optional['outputs.GetPgPgUserConfigPrivateAccessResult']:
        """
        Allow access to selected service ports from private networks.
        """
        return pulumi.get(self, "private_access")

    @property
    @pulumi.getter(name="privatelinkAccess")
    def privatelink_access(self) -> Optional['outputs.GetPgPgUserConfigPrivatelinkAccessResult']:
        """
        Allow access to selected service components through Privatelink.
        """
        return pulumi.get(self, "privatelink_access")

    @property
    @pulumi.getter(name="projectToForkFrom")
    def project_to_fork_from(self) -> Optional[str]:
        """
        Name of another project to fork a service from. This has
        effect only when a new service is being created.
        """
        return pulumi.get(self, "project_to_fork_from")

    @property
    @pulumi.getter(name="publicAccess")
    def public_access(self) -> Optional['outputs.GetPgPgUserConfigPublicAccessResult']:
        """
        Allow access to selected service ports from the public Internet
        """
        return pulumi.get(self, "public_access")

    @property
    @pulumi.getter(name="recoveryTargetTime")
    def recovery_target_time(self) -> Optional[str]:
        """
        Recovery target time when forking a service. This has effect 
        only when a new service is being created.
        """
        return pulumi.get(self, "recovery_target_time")

    @property
    @pulumi.getter(name="serviceToForkFrom")
    def service_to_fork_from(self) -> Optional[str]:
        """
        Name of another service to fork from. This has effect only 
        when a new service is being created.
        """
        return pulumi.get(self, "service_to_fork_from")

    @property
    @pulumi.getter(name="sharedBuffersPercentage")
    def shared_buffers_percentage(self) -> Optional[str]:
        """
        Percentage of total RAM that the database server uses for 
        memory buffers. Valid range is 20-60 (float), which corresponds to 20% - 60%. This setting adjusts
        the shared_buffers configuration value. The absolute maximum is 12 GB.
        """
        return pulumi.get(self, "shared_buffers_percentage")

    @property
    @pulumi.getter(name="synchronousReplication")
    def synchronous_replication(self) -> Optional[str]:
        """
        Synchronous replication type. Note that the service plan 
        also needs to support synchronous replication.
        """
        return pulumi.get(self, "synchronous_replication")

    @property
    @pulumi.getter
    def timescaledb(self) -> Optional['outputs.GetPgPgUserConfigTimescaledbResult']:
        """
        TimescaleDB extension configuration values.
        """
        return pulumi.get(self, "timescaledb")

    @property
    @pulumi.getter
    def variant(self) -> Optional[str]:
        """
        Variant of the PostgreSQL service, may affect the features that are 
        exposed by default. Options: `aiven` or `timescale`.
        """
        return pulumi.get(self, "variant")

    @property
    @pulumi.getter(name="workMem")
    def work_mem(self) -> Optional[str]:
        """
        Sets the maximum amount of memory to be used by a query operation (such 
        as a sort or hash table) before writing to temporary disk files, in MB. Default is 1MB + 0.075% of
        total RAM (up to 32MB).
        """
        return pulumi.get(self, "work_mem")


@pulumi.output_type
class GetPgPgUserConfigMigrationResult(dict):
    def __init__(__self__, *,
                 dbname: Optional[str] = None,
                 host: Optional[str] = None,
                 ignore_dbs: Optional[str] = None,
                 password: Optional[str] = None,
                 port: Optional[str] = None,
                 ssl: Optional[str] = None,
                 username: Optional[str] = None):
        """
        :param str dbname: Primary PostgreSQL database name
        :param str host: PostgreSQL master node host IP or name
        :param str ignore_dbs: Comma-separated list of databases, which should be ignored during
               migration (supported by MySQL only at the moment)
        :param str password: PostgreSQL admin user password
        :param str port: PostgreSQL port
        :param str ssl: the server where to migrate data from is secured with SSL.
        :param str username: user name for authentication with the server where to migrate data from.
        """
        if dbname is not None:
            pulumi.set(__self__, "dbname", dbname)
        if host is not None:
            pulumi.set(__self__, "host", host)
        if ignore_dbs is not None:
            pulumi.set(__self__, "ignore_dbs", ignore_dbs)
        if password is not None:
            pulumi.set(__self__, "password", password)
        if port is not None:
            pulumi.set(__self__, "port", port)
        if ssl is not None:
            pulumi.set(__self__, "ssl", ssl)
        if username is not None:
            pulumi.set(__self__, "username", username)

    @property
    @pulumi.getter
    def dbname(self) -> Optional[str]:
        """
        Primary PostgreSQL database name
        """
        return pulumi.get(self, "dbname")

    @property
    @pulumi.getter
    def host(self) -> Optional[str]:
        """
        PostgreSQL master node host IP or name
        """
        return pulumi.get(self, "host")

    @property
    @pulumi.getter(name="ignoreDbs")
    def ignore_dbs(self) -> Optional[str]:
        """
        Comma-separated list of databases, which should be ignored during
        migration (supported by MySQL only at the moment)
        """
        return pulumi.get(self, "ignore_dbs")

    @property
    @pulumi.getter
    def password(self) -> Optional[str]:
        """
        PostgreSQL admin user password
        """
        return pulumi.get(self, "password")

    @property
    @pulumi.getter
    def port(self) -> Optional[str]:
        """
        PostgreSQL port
        """
        return pulumi.get(self, "port")

    @property
    @pulumi.getter
    def ssl(self) -> Optional[str]:
        """
        the server where to migrate data from is secured with SSL.
        """
        return pulumi.get(self, "ssl")

    @property
    @pulumi.getter
    def username(self) -> Optional[str]:
        """
        user name for authentication with the server where to migrate data from.
        """
        return pulumi.get(self, "username")


@pulumi.output_type
class GetPgPgUserConfigPgResult(dict):
    def __init__(__self__, *,
                 autovacuum_analyze_scale_factor: Optional[str] = None,
                 autovacuum_analyze_threshold: Optional[str] = None,
                 autovacuum_freeze_max_age: Optional[str] = None,
                 autovacuum_max_workers: Optional[str] = None,
                 autovacuum_naptime: Optional[str] = None,
                 autovacuum_vacuum_cost_delay: Optional[str] = None,
                 autovacuum_vacuum_cost_limit: Optional[str] = None,
                 autovacuum_vacuum_scale_factor: Optional[str] = None,
                 autovacuum_vacuum_threshold: Optional[str] = None,
                 deadlock_timeout: Optional[str] = None,
                 idle_in_transaction_session_timeout: Optional[str] = None,
                 jit: Optional[str] = None,
                 log_autovacuum_min_duration: Optional[str] = None,
                 log_error_verbosity: Optional[str] = None,
                 log_line_prefix: Optional[str] = None,
                 log_min_duration_statement: Optional[str] = None,
                 max_files_per_process: Optional[str] = None,
                 max_locks_per_transaction: Optional[str] = None,
                 max_logical_replication_workers: Optional[str] = None,
                 max_parallel_workers: Optional[str] = None,
                 max_parallel_workers_per_gather: Optional[str] = None,
                 max_pred_locks_per_transaction: Optional[str] = None,
                 max_prepared_transactions: Optional[str] = None,
                 max_replication_slots: Optional[str] = None,
                 max_stack_depth: Optional[str] = None,
                 max_standby_archive_delay: Optional[str] = None,
                 max_standby_streaming_delay: Optional[str] = None,
                 max_wal_senders: Optional[str] = None,
                 max_worker_processes: Optional[str] = None,
                 pg_partman_bgw_dot_interval: Optional[str] = None,
                 pg_partman_bgw_dot_role: Optional[str] = None,
                 pg_stat_statements_dot_track: Optional[str] = None,
                 temp_file_limit: Optional[str] = None,
                 timezone: Optional[str] = None,
                 track_activity_query_size: Optional[str] = None,
                 track_commit_timestamp: Optional[str] = None,
                 track_functions: Optional[str] = None,
                 track_io_timing: Optional[str] = None,
                 wal_sender_timeout: Optional[str] = None,
                 wal_writer_delay: Optional[str] = None):
        """
        :param str autovacuum_analyze_scale_factor: Specifies a fraction of the table size to add to 
               autovacuum_analyze_threshold when deciding whether to trigger an ANALYZE. The default is 0.2
               (20% of table size).
        :param str autovacuum_analyze_threshold: specifies the minimum number of inserted, updated 
               or deleted tuples needed to trigger an ANALYZE in any one table. The default is 50 tuples.
        :param str autovacuum_freeze_max_age: specifies the maximum age (in transactions) that a table's 
               pg_class.relfrozenxid field can attain before a VACUUM operation is forced to prevent transaction ID
               wraparound within the table. Note that the system will launch autovacuum processes to prevent wraparound
               even when autovacuum is otherwise disabled. This parameter will cause the server to be restarted.
        :param str autovacuum_max_workers: specifies the maximum number of autovacuum processes (other 
               than the autovacuum launcher) that may be running at any one time. The default is three. This parameter
               can only be set at server start.
        :param str autovacuum_naptime: specifies the minimum delay between autovacuum runs on any 
               given database. The delay is measured in seconds, and the default is one minute.
        :param str autovacuum_vacuum_cost_delay: specifies the cost delay value that will be used 
               in automatic VACUUM operations. If -1 is specified, the regular vacuum_cost_delay value will be
               used. The default value is 20 milliseconds.
        :param str autovacuum_vacuum_cost_limit: specifies the cost limit value that will be used in 
               automatic VACUUM operations. If -1 is specified (which is the default), the regular vacuum_cost_limit
               value will be used.
        :param str autovacuum_vacuum_scale_factor: specifies a fraction of the table size to add to 
               autovacuum_vacuum_threshold when deciding whether to trigger a VACUUM. The default is 0.2 (20% of table size).
        :param str autovacuum_vacuum_threshold: specifies the minimum number of updated or deleted tuples 
               needed to trigger a VACUUM in any one table. The default is 50 tuples
        :param str deadlock_timeout: this is the amount of time, in milliseconds, to wait on a lock before 
               checking to see if there is a deadlock condition.
        :param str idle_in_transaction_session_timeout: Time out sessions with open transactions after 
               this number of milliseconds.
        :param str jit: Controls system-wide use of Just-in-Time Compilation (JIT).
        :param str log_autovacuum_min_duration: Causes each action executed by autovacuum to be logged 
               if it ran for at least the specified number of milliseconds. Setting this to zero logs all autovacuum
               actions. Minus-one (the default) disables logging autovacuum actions.
        :param str log_error_verbosity: Controls the amount of detail written in the server log for 
               each message that is logged. Possible values: `TERSE`, `DEFAULT` and `VERBOSE`.
        :param str log_line_prefix: Choose from one of the available log-formats. These can support
               popular log analyzers like pgbadger, pganalyze etc.
        :param str log_min_duration_statement: Log statements that take more than this number of 
               milliseconds to run, -1 disables
        :param str max_files_per_process: PostgreSQL maximum number of files that can be open per process
        :param str max_locks_per_transaction: PostgreSQL maximum locks per transaction
        :param str max_logical_replication_workers: PostgreSQL maximum logical replication workers 
               (taken from the pool of max_parallel_workers)
        :param str max_parallel_workers: Sets the maximum number of workers that the system can 
               support for parallel queries.
        :param str max_parallel_workers_per_gather: Sets the maximum number of workers that can be 
               started by a single Gather or Gather Merge node.
        :param str max_pred_locks_per_transaction: PostgreSQL maximum predicate locks per transaction
        :param str max_prepared_transactions: PostgreSQL maximum prepared transactions
        :param str max_replication_slots: PostgreSQL maximum replication slots
        :param str max_stack_depth: Maximum depth of the stack in bytes
        :param str max_standby_archive_delay: Max standby archive delay in milliseconds
        :param str max_standby_streaming_delay: Max standby streaming delay in milliseconds
        :param str max_wal_senders: PostgreSQL maximum WAL senders
        :param str max_worker_processes: Sets the maximum number of background processes that the system
               can support
               * `pg_partman_bgw.interval` - Sets the time interval to run pg_partman's scheduled tasks
               * `pg_partman_bgw.role` - Controls which role to use for pg_partman's scheduled
               background tasks.
               * `pg_stat_statements.track` - Controls which statements are counted. Specify top
               to track top-level statements (those issued directly by clients), all to also track nested
               statements (such as statements invoked within functions), or none to disable statement statistics
               collection. The default value is top.
        :param str temp_file_limit: PostgreSQL temporary file limit in KiB, -1 for unlimited
        :param str timezone: PostgreSQL service timezone
        :param str track_activity_query_size: Specifies the number of bytes reserved to track the currently 
               executing command for each active session.
        :param str track_commit_timestamp: Record commit time of transactions
        :param str track_functions: Enables tracking of function call counts and time used.
        :param str track_io_timing: Enables timing of database I/O calls. This parameter is off by default,
               because it will repeatedly query the operating system for the current time, which may cause
               significant overhead on some platforms.
        :param str wal_sender_timeout: Terminate replication connections that are inactive for longer than 
               this amount of time, in milliseconds.
        :param str wal_writer_delay: WAL flush interval in milliseconds. Note that setting this value 
               to lower than the default 200ms may negatively impact performance
        """
        if autovacuum_analyze_scale_factor is not None:
            pulumi.set(__self__, "autovacuum_analyze_scale_factor", autovacuum_analyze_scale_factor)
        if autovacuum_analyze_threshold is not None:
            pulumi.set(__self__, "autovacuum_analyze_threshold", autovacuum_analyze_threshold)
        if autovacuum_freeze_max_age is not None:
            pulumi.set(__self__, "autovacuum_freeze_max_age", autovacuum_freeze_max_age)
        if autovacuum_max_workers is not None:
            pulumi.set(__self__, "autovacuum_max_workers", autovacuum_max_workers)
        if autovacuum_naptime is not None:
            pulumi.set(__self__, "autovacuum_naptime", autovacuum_naptime)
        if autovacuum_vacuum_cost_delay is not None:
            pulumi.set(__self__, "autovacuum_vacuum_cost_delay", autovacuum_vacuum_cost_delay)
        if autovacuum_vacuum_cost_limit is not None:
            pulumi.set(__self__, "autovacuum_vacuum_cost_limit", autovacuum_vacuum_cost_limit)
        if autovacuum_vacuum_scale_factor is not None:
            pulumi.set(__self__, "autovacuum_vacuum_scale_factor", autovacuum_vacuum_scale_factor)
        if autovacuum_vacuum_threshold is not None:
            pulumi.set(__self__, "autovacuum_vacuum_threshold", autovacuum_vacuum_threshold)
        if deadlock_timeout is not None:
            pulumi.set(__self__, "deadlock_timeout", deadlock_timeout)
        if idle_in_transaction_session_timeout is not None:
            pulumi.set(__self__, "idle_in_transaction_session_timeout", idle_in_transaction_session_timeout)
        if jit is not None:
            pulumi.set(__self__, "jit", jit)
        if log_autovacuum_min_duration is not None:
            pulumi.set(__self__, "log_autovacuum_min_duration", log_autovacuum_min_duration)
        if log_error_verbosity is not None:
            pulumi.set(__self__, "log_error_verbosity", log_error_verbosity)
        if log_line_prefix is not None:
            pulumi.set(__self__, "log_line_prefix", log_line_prefix)
        if log_min_duration_statement is not None:
            pulumi.set(__self__, "log_min_duration_statement", log_min_duration_statement)
        if max_files_per_process is not None:
            pulumi.set(__self__, "max_files_per_process", max_files_per_process)
        if max_locks_per_transaction is not None:
            pulumi.set(__self__, "max_locks_per_transaction", max_locks_per_transaction)
        if max_logical_replication_workers is not None:
            pulumi.set(__self__, "max_logical_replication_workers", max_logical_replication_workers)
        if max_parallel_workers is not None:
            pulumi.set(__self__, "max_parallel_workers", max_parallel_workers)
        if max_parallel_workers_per_gather is not None:
            pulumi.set(__self__, "max_parallel_workers_per_gather", max_parallel_workers_per_gather)
        if max_pred_locks_per_transaction is not None:
            pulumi.set(__self__, "max_pred_locks_per_transaction", max_pred_locks_per_transaction)
        if max_prepared_transactions is not None:
            pulumi.set(__self__, "max_prepared_transactions", max_prepared_transactions)
        if max_replication_slots is not None:
            pulumi.set(__self__, "max_replication_slots", max_replication_slots)
        if max_stack_depth is not None:
            pulumi.set(__self__, "max_stack_depth", max_stack_depth)
        if max_standby_archive_delay is not None:
            pulumi.set(__self__, "max_standby_archive_delay", max_standby_archive_delay)
        if max_standby_streaming_delay is not None:
            pulumi.set(__self__, "max_standby_streaming_delay", max_standby_streaming_delay)
        if max_wal_senders is not None:
            pulumi.set(__self__, "max_wal_senders", max_wal_senders)
        if max_worker_processes is not None:
            pulumi.set(__self__, "max_worker_processes", max_worker_processes)
        if pg_partman_bgw_dot_interval is not None:
            pulumi.set(__self__, "pg_partman_bgw_dot_interval", pg_partman_bgw_dot_interval)
        if pg_partman_bgw_dot_role is not None:
            pulumi.set(__self__, "pg_partman_bgw_dot_role", pg_partman_bgw_dot_role)
        if pg_stat_statements_dot_track is not None:
            pulumi.set(__self__, "pg_stat_statements_dot_track", pg_stat_statements_dot_track)
        if temp_file_limit is not None:
            pulumi.set(__self__, "temp_file_limit", temp_file_limit)
        if timezone is not None:
            pulumi.set(__self__, "timezone", timezone)
        if track_activity_query_size is not None:
            pulumi.set(__self__, "track_activity_query_size", track_activity_query_size)
        if track_commit_timestamp is not None:
            pulumi.set(__self__, "track_commit_timestamp", track_commit_timestamp)
        if track_functions is not None:
            pulumi.set(__self__, "track_functions", track_functions)
        if track_io_timing is not None:
            pulumi.set(__self__, "track_io_timing", track_io_timing)
        if wal_sender_timeout is not None:
            pulumi.set(__self__, "wal_sender_timeout", wal_sender_timeout)
        if wal_writer_delay is not None:
            pulumi.set(__self__, "wal_writer_delay", wal_writer_delay)

    @property
    @pulumi.getter(name="autovacuumAnalyzeScaleFactor")
    def autovacuum_analyze_scale_factor(self) -> Optional[str]:
        """
        Specifies a fraction of the table size to add to 
        autovacuum_analyze_threshold when deciding whether to trigger an ANALYZE. The default is 0.2
        (20% of table size).
        """
        return pulumi.get(self, "autovacuum_analyze_scale_factor")

    @property
    @pulumi.getter(name="autovacuumAnalyzeThreshold")
    def autovacuum_analyze_threshold(self) -> Optional[str]:
        """
        specifies the minimum number of inserted, updated 
        or deleted tuples needed to trigger an ANALYZE in any one table. The default is 50 tuples.
        """
        return pulumi.get(self, "autovacuum_analyze_threshold")

    @property
    @pulumi.getter(name="autovacuumFreezeMaxAge")
    def autovacuum_freeze_max_age(self) -> Optional[str]:
        """
        specifies the maximum age (in transactions) that a table's 
        pg_class.relfrozenxid field can attain before a VACUUM operation is forced to prevent transaction ID
        wraparound within the table. Note that the system will launch autovacuum processes to prevent wraparound
        even when autovacuum is otherwise disabled. This parameter will cause the server to be restarted.
        """
        return pulumi.get(self, "autovacuum_freeze_max_age")

    @property
    @pulumi.getter(name="autovacuumMaxWorkers")
    def autovacuum_max_workers(self) -> Optional[str]:
        """
        specifies the maximum number of autovacuum processes (other 
        than the autovacuum launcher) that may be running at any one time. The default is three. This parameter
        can only be set at server start.
        """
        return pulumi.get(self, "autovacuum_max_workers")

    @property
    @pulumi.getter(name="autovacuumNaptime")
    def autovacuum_naptime(self) -> Optional[str]:
        """
        specifies the minimum delay between autovacuum runs on any 
        given database. The delay is measured in seconds, and the default is one minute.
        """
        return pulumi.get(self, "autovacuum_naptime")

    @property
    @pulumi.getter(name="autovacuumVacuumCostDelay")
    def autovacuum_vacuum_cost_delay(self) -> Optional[str]:
        """
        specifies the cost delay value that will be used 
        in automatic VACUUM operations. If -1 is specified, the regular vacuum_cost_delay value will be
        used. The default value is 20 milliseconds.
        """
        return pulumi.get(self, "autovacuum_vacuum_cost_delay")

    @property
    @pulumi.getter(name="autovacuumVacuumCostLimit")
    def autovacuum_vacuum_cost_limit(self) -> Optional[str]:
        """
        specifies the cost limit value that will be used in 
        automatic VACUUM operations. If -1 is specified (which is the default), the regular vacuum_cost_limit
        value will be used.
        """
        return pulumi.get(self, "autovacuum_vacuum_cost_limit")

    @property
    @pulumi.getter(name="autovacuumVacuumScaleFactor")
    def autovacuum_vacuum_scale_factor(self) -> Optional[str]:
        """
        specifies a fraction of the table size to add to 
        autovacuum_vacuum_threshold when deciding whether to trigger a VACUUM. The default is 0.2 (20% of table size).
        """
        return pulumi.get(self, "autovacuum_vacuum_scale_factor")

    @property
    @pulumi.getter(name="autovacuumVacuumThreshold")
    def autovacuum_vacuum_threshold(self) -> Optional[str]:
        """
        specifies the minimum number of updated or deleted tuples 
        needed to trigger a VACUUM in any one table. The default is 50 tuples
        """
        return pulumi.get(self, "autovacuum_vacuum_threshold")

    @property
    @pulumi.getter(name="deadlockTimeout")
    def deadlock_timeout(self) -> Optional[str]:
        """
        this is the amount of time, in milliseconds, to wait on a lock before 
        checking to see if there is a deadlock condition.
        """
        return pulumi.get(self, "deadlock_timeout")

    @property
    @pulumi.getter(name="idleInTransactionSessionTimeout")
    def idle_in_transaction_session_timeout(self) -> Optional[str]:
        """
        Time out sessions with open transactions after 
        this number of milliseconds.
        """
        return pulumi.get(self, "idle_in_transaction_session_timeout")

    @property
    @pulumi.getter
    def jit(self) -> Optional[str]:
        """
        Controls system-wide use of Just-in-Time Compilation (JIT).
        """
        return pulumi.get(self, "jit")

    @property
    @pulumi.getter(name="logAutovacuumMinDuration")
    def log_autovacuum_min_duration(self) -> Optional[str]:
        """
        Causes each action executed by autovacuum to be logged 
        if it ran for at least the specified number of milliseconds. Setting this to zero logs all autovacuum
        actions. Minus-one (the default) disables logging autovacuum actions.
        """
        return pulumi.get(self, "log_autovacuum_min_duration")

    @property
    @pulumi.getter(name="logErrorVerbosity")
    def log_error_verbosity(self) -> Optional[str]:
        """
        Controls the amount of detail written in the server log for 
        each message that is logged. Possible values: `TERSE`, `DEFAULT` and `VERBOSE`.
        """
        return pulumi.get(self, "log_error_verbosity")

    @property
    @pulumi.getter(name="logLinePrefix")
    def log_line_prefix(self) -> Optional[str]:
        """
        Choose from one of the available log-formats. These can support
        popular log analyzers like pgbadger, pganalyze etc.
        """
        return pulumi.get(self, "log_line_prefix")

    @property
    @pulumi.getter(name="logMinDurationStatement")
    def log_min_duration_statement(self) -> Optional[str]:
        """
        Log statements that take more than this number of 
        milliseconds to run, -1 disables
        """
        return pulumi.get(self, "log_min_duration_statement")

    @property
    @pulumi.getter(name="maxFilesPerProcess")
    def max_files_per_process(self) -> Optional[str]:
        """
        PostgreSQL maximum number of files that can be open per process
        """
        return pulumi.get(self, "max_files_per_process")

    @property
    @pulumi.getter(name="maxLocksPerTransaction")
    def max_locks_per_transaction(self) -> Optional[str]:
        """
        PostgreSQL maximum locks per transaction
        """
        return pulumi.get(self, "max_locks_per_transaction")

    @property
    @pulumi.getter(name="maxLogicalReplicationWorkers")
    def max_logical_replication_workers(self) -> Optional[str]:
        """
        PostgreSQL maximum logical replication workers 
        (taken from the pool of max_parallel_workers)
        """
        return pulumi.get(self, "max_logical_replication_workers")

    @property
    @pulumi.getter(name="maxParallelWorkers")
    def max_parallel_workers(self) -> Optional[str]:
        """
        Sets the maximum number of workers that the system can 
        support for parallel queries.
        """
        return pulumi.get(self, "max_parallel_workers")

    @property
    @pulumi.getter(name="maxParallelWorkersPerGather")
    def max_parallel_workers_per_gather(self) -> Optional[str]:
        """
        Sets the maximum number of workers that can be 
        started by a single Gather or Gather Merge node.
        """
        return pulumi.get(self, "max_parallel_workers_per_gather")

    @property
    @pulumi.getter(name="maxPredLocksPerTransaction")
    def max_pred_locks_per_transaction(self) -> Optional[str]:
        """
        PostgreSQL maximum predicate locks per transaction
        """
        return pulumi.get(self, "max_pred_locks_per_transaction")

    @property
    @pulumi.getter(name="maxPreparedTransactions")
    def max_prepared_transactions(self) -> Optional[str]:
        """
        PostgreSQL maximum prepared transactions
        """
        return pulumi.get(self, "max_prepared_transactions")

    @property
    @pulumi.getter(name="maxReplicationSlots")
    def max_replication_slots(self) -> Optional[str]:
        """
        PostgreSQL maximum replication slots
        """
        return pulumi.get(self, "max_replication_slots")

    @property
    @pulumi.getter(name="maxStackDepth")
    def max_stack_depth(self) -> Optional[str]:
        """
        Maximum depth of the stack in bytes
        """
        return pulumi.get(self, "max_stack_depth")

    @property
    @pulumi.getter(name="maxStandbyArchiveDelay")
    def max_standby_archive_delay(self) -> Optional[str]:
        """
        Max standby archive delay in milliseconds
        """
        return pulumi.get(self, "max_standby_archive_delay")

    @property
    @pulumi.getter(name="maxStandbyStreamingDelay")
    def max_standby_streaming_delay(self) -> Optional[str]:
        """
        Max standby streaming delay in milliseconds
        """
        return pulumi.get(self, "max_standby_streaming_delay")

    @property
    @pulumi.getter(name="maxWalSenders")
    def max_wal_senders(self) -> Optional[str]:
        """
        PostgreSQL maximum WAL senders
        """
        return pulumi.get(self, "max_wal_senders")

    @property
    @pulumi.getter(name="maxWorkerProcesses")
    def max_worker_processes(self) -> Optional[str]:
        """
        Sets the maximum number of background processes that the system
        can support
        * `pg_partman_bgw.interval` - Sets the time interval to run pg_partman's scheduled tasks
        * `pg_partman_bgw.role` - Controls which role to use for pg_partman's scheduled
        background tasks.
        * `pg_stat_statements.track` - Controls which statements are counted. Specify top
        to track top-level statements (those issued directly by clients), all to also track nested
        statements (such as statements invoked within functions), or none to disable statement statistics
        collection. The default value is top.
        """
        return pulumi.get(self, "max_worker_processes")

    @property
    @pulumi.getter(name="pgPartmanBgwDotInterval")
    def pg_partman_bgw_dot_interval(self) -> Optional[str]:
        return pulumi.get(self, "pg_partman_bgw_dot_interval")

    @property
    @pulumi.getter(name="pgPartmanBgwDotRole")
    def pg_partman_bgw_dot_role(self) -> Optional[str]:
        return pulumi.get(self, "pg_partman_bgw_dot_role")

    @property
    @pulumi.getter(name="pgStatStatementsDotTrack")
    def pg_stat_statements_dot_track(self) -> Optional[str]:
        return pulumi.get(self, "pg_stat_statements_dot_track")

    @property
    @pulumi.getter(name="tempFileLimit")
    def temp_file_limit(self) -> Optional[str]:
        """
        PostgreSQL temporary file limit in KiB, -1 for unlimited
        """
        return pulumi.get(self, "temp_file_limit")

    @property
    @pulumi.getter
    def timezone(self) -> Optional[str]:
        """
        PostgreSQL service timezone
        """
        return pulumi.get(self, "timezone")

    @property
    @pulumi.getter(name="trackActivityQuerySize")
    def track_activity_query_size(self) -> Optional[str]:
        """
        Specifies the number of bytes reserved to track the currently 
        executing command for each active session.
        """
        return pulumi.get(self, "track_activity_query_size")

    @property
    @pulumi.getter(name="trackCommitTimestamp")
    def track_commit_timestamp(self) -> Optional[str]:
        """
        Record commit time of transactions
        """
        return pulumi.get(self, "track_commit_timestamp")

    @property
    @pulumi.getter(name="trackFunctions")
    def track_functions(self) -> Optional[str]:
        """
        Enables tracking of function call counts and time used.
        """
        return pulumi.get(self, "track_functions")

    @property
    @pulumi.getter(name="trackIoTiming")
    def track_io_timing(self) -> Optional[str]:
        """
        Enables timing of database I/O calls. This parameter is off by default,
        because it will repeatedly query the operating system for the current time, which may cause
        significant overhead on some platforms.
        """
        return pulumi.get(self, "track_io_timing")

    @property
    @pulumi.getter(name="walSenderTimeout")
    def wal_sender_timeout(self) -> Optional[str]:
        """
        Terminate replication connections that are inactive for longer than 
        this amount of time, in milliseconds.
        """
        return pulumi.get(self, "wal_sender_timeout")

    @property
    @pulumi.getter(name="walWriterDelay")
    def wal_writer_delay(self) -> Optional[str]:
        """
        WAL flush interval in milliseconds. Note that setting this value 
        to lower than the default 200ms may negatively impact performance
        """
        return pulumi.get(self, "wal_writer_delay")


@pulumi.output_type
class GetPgPgUserConfigPgbouncerResult(dict):
    def __init__(__self__, *,
                 autodb_idle_timeout: Optional[str] = None,
                 autodb_max_db_connections: Optional[str] = None,
                 autodb_pool_mode: Optional[str] = None,
                 autodb_pool_size: Optional[str] = None,
                 ignore_startup_parameters: Optional[Sequence[str]] = None,
                 min_pool_size: Optional[str] = None,
                 server_idle_timeout: Optional[str] = None,
                 server_lifetime: Optional[str] = None,
                 server_reset_query_always: Optional[str] = None):
        """
        :param str autodb_idle_timeout: If the automatically created database pools have been unused this 
               many seconds, they are freed. If 0 then timeout is disabled.
        :param str autodb_max_db_connections: Do not allow more than this many server connections per database 
               (regardless of user). Setting it to 0 means unlimited.
        :param str autodb_pool_mode: PGBouncer pool mode
        :param str autodb_pool_size: If non-zero then create automatically a pool of that size per user 
               when a pool doesn't exist.
        :param Sequence[str] ignore_startup_parameters: Enum of parameters to ignore when given in startup packet.
        :param str min_pool_size: Add more server connections to pool if below this number. Improves 
               behavior when usual load comes suddenly back after period of total inactivity. The value is
               effectively capped at the pool size.
        :param str server_idle_timeout: If a server connection has been idle more than this many seconds 
               it will be dropped. If 0 then timeout is disabled.
        :param str server_lifetime: The pooler will close an unused server connection that has been connected 
               longer than this.
        :param str server_reset_query_always: Run server_reset_query (DISCARD ALL) in all pooling modes.
        """
        if autodb_idle_timeout is not None:
            pulumi.set(__self__, "autodb_idle_timeout", autodb_idle_timeout)
        if autodb_max_db_connections is not None:
            pulumi.set(__self__, "autodb_max_db_connections", autodb_max_db_connections)
        if autodb_pool_mode is not None:
            pulumi.set(__self__, "autodb_pool_mode", autodb_pool_mode)
        if autodb_pool_size is not None:
            pulumi.set(__self__, "autodb_pool_size", autodb_pool_size)
        if ignore_startup_parameters is not None:
            pulumi.set(__self__, "ignore_startup_parameters", ignore_startup_parameters)
        if min_pool_size is not None:
            pulumi.set(__self__, "min_pool_size", min_pool_size)
        if server_idle_timeout is not None:
            pulumi.set(__self__, "server_idle_timeout", server_idle_timeout)
        if server_lifetime is not None:
            pulumi.set(__self__, "server_lifetime", server_lifetime)
        if server_reset_query_always is not None:
            pulumi.set(__self__, "server_reset_query_always", server_reset_query_always)

    @property
    @pulumi.getter(name="autodbIdleTimeout")
    def autodb_idle_timeout(self) -> Optional[str]:
        """
        If the automatically created database pools have been unused this 
        many seconds, they are freed. If 0 then timeout is disabled.
        """
        return pulumi.get(self, "autodb_idle_timeout")

    @property
    @pulumi.getter(name="autodbMaxDbConnections")
    def autodb_max_db_connections(self) -> Optional[str]:
        """
        Do not allow more than this many server connections per database 
        (regardless of user). Setting it to 0 means unlimited.
        """
        return pulumi.get(self, "autodb_max_db_connections")

    @property
    @pulumi.getter(name="autodbPoolMode")
    def autodb_pool_mode(self) -> Optional[str]:
        """
        PGBouncer pool mode
        """
        return pulumi.get(self, "autodb_pool_mode")

    @property
    @pulumi.getter(name="autodbPoolSize")
    def autodb_pool_size(self) -> Optional[str]:
        """
        If non-zero then create automatically a pool of that size per user 
        when a pool doesn't exist.
        """
        return pulumi.get(self, "autodb_pool_size")

    @property
    @pulumi.getter(name="ignoreStartupParameters")
    def ignore_startup_parameters(self) -> Optional[Sequence[str]]:
        """
        Enum of parameters to ignore when given in startup packet.
        """
        return pulumi.get(self, "ignore_startup_parameters")

    @property
    @pulumi.getter(name="minPoolSize")
    def min_pool_size(self) -> Optional[str]:
        """
        Add more server connections to pool if below this number. Improves 
        behavior when usual load comes suddenly back after period of total inactivity. The value is
        effectively capped at the pool size.
        """
        return pulumi.get(self, "min_pool_size")

    @property
    @pulumi.getter(name="serverIdleTimeout")
    def server_idle_timeout(self) -> Optional[str]:
        """
        If a server connection has been idle more than this many seconds 
        it will be dropped. If 0 then timeout is disabled.
        """
        return pulumi.get(self, "server_idle_timeout")

    @property
    @pulumi.getter(name="serverLifetime")
    def server_lifetime(self) -> Optional[str]:
        """
        The pooler will close an unused server connection that has been connected 
        longer than this.
        """
        return pulumi.get(self, "server_lifetime")

    @property
    @pulumi.getter(name="serverResetQueryAlways")
    def server_reset_query_always(self) -> Optional[str]:
        """
        Run server_reset_query (DISCARD ALL) in all pooling modes.
        """
        return pulumi.get(self, "server_reset_query_always")


@pulumi.output_type
class GetPgPgUserConfigPglookoutResult(dict):
    def __init__(__self__, *,
                 max_failover_replication_time_lag: Optional[str] = None):
        """
        :param str max_failover_replication_time_lag: Number of seconds of master unavailability before 
               triggering database failover to standby
        """
        if max_failover_replication_time_lag is not None:
            pulumi.set(__self__, "max_failover_replication_time_lag", max_failover_replication_time_lag)

    @property
    @pulumi.getter(name="maxFailoverReplicationTimeLag")
    def max_failover_replication_time_lag(self) -> Optional[str]:
        """
        Number of seconds of master unavailability before 
        triggering database failover to standby
        """
        return pulumi.get(self, "max_failover_replication_time_lag")


@pulumi.output_type
class GetPgPgUserConfigPrivateAccessResult(dict):
    def __init__(__self__, *,
                 pg: Optional[str] = None,
                 pgbouncer: Optional[str] = None,
                 prometheus: Optional[str] = None):
        """
        :param str pg: PostgreSQL specific server provided values.
        :param str pgbouncer: Enable pgbouncer.
        :param str prometheus: Allow clients to connect to prometheus from the public internet for 
               service nodes that are in a project VPC or another type of private network
        """
        if pg is not None:
            pulumi.set(__self__, "pg", pg)
        if pgbouncer is not None:
            pulumi.set(__self__, "pgbouncer", pgbouncer)
        if prometheus is not None:
            pulumi.set(__self__, "prometheus", prometheus)

    @property
    @pulumi.getter
    def pg(self) -> Optional[str]:
        """
        PostgreSQL specific server provided values.
        """
        return pulumi.get(self, "pg")

    @property
    @pulumi.getter
    def pgbouncer(self) -> Optional[str]:
        """
        Enable pgbouncer.
        """
        return pulumi.get(self, "pgbouncer")

    @property
    @pulumi.getter
    def prometheus(self) -> Optional[str]:
        """
        Allow clients to connect to prometheus from the public internet for 
        service nodes that are in a project VPC or another type of private network
        """
        return pulumi.get(self, "prometheus")


@pulumi.output_type
class GetPgPgUserConfigPrivatelinkAccessResult(dict):
    def __init__(__self__, *,
                 pg: Optional[str] = None,
                 pgbouncer: Optional[str] = None):
        """
        :param str pg: PostgreSQL specific server provided values.
        :param str pgbouncer: Enable pgbouncer.
        """
        if pg is not None:
            pulumi.set(__self__, "pg", pg)
        if pgbouncer is not None:
            pulumi.set(__self__, "pgbouncer", pgbouncer)

    @property
    @pulumi.getter
    def pg(self) -> Optional[str]:
        """
        PostgreSQL specific server provided values.
        """
        return pulumi.get(self, "pg")

    @property
    @pulumi.getter
    def pgbouncer(self) -> Optional[str]:
        """
        Enable pgbouncer.
        """
        return pulumi.get(self, "pgbouncer")


@pulumi.output_type
class GetPgPgUserConfigPublicAccessResult(dict):
    def __init__(__self__, *,
                 pg: Optional[str] = None,
                 pgbouncer: Optional[str] = None,
                 prometheus: Optional[str] = None):
        """
        :param str pg: PostgreSQL specific server provided values.
        :param str pgbouncer: Enable pgbouncer.
        :param str prometheus: Allow clients to connect to prometheus from the public internet for 
               service nodes that are in a project VPC or another type of private network
        """
        if pg is not None:
            pulumi.set(__self__, "pg", pg)
        if pgbouncer is not None:
            pulumi.set(__self__, "pgbouncer", pgbouncer)
        if prometheus is not None:
            pulumi.set(__self__, "prometheus", prometheus)

    @property
    @pulumi.getter
    def pg(self) -> Optional[str]:
        """
        PostgreSQL specific server provided values.
        """
        return pulumi.get(self, "pg")

    @property
    @pulumi.getter
    def pgbouncer(self) -> Optional[str]:
        """
        Enable pgbouncer.
        """
        return pulumi.get(self, "pgbouncer")

    @property
    @pulumi.getter
    def prometheus(self) -> Optional[str]:
        """
        Allow clients to connect to prometheus from the public internet for 
        service nodes that are in a project VPC or another type of private network
        """
        return pulumi.get(self, "prometheus")


@pulumi.output_type
class GetPgPgUserConfigTimescaledbResult(dict):
    def __init__(__self__, *,
                 max_background_workers: Optional[str] = None):
        """
        :param str max_background_workers: The number of background workers for timescaledb 
               operations. You should configure this setting to the sum of your number of databases and the
               total number of concurrent background workers you want running at any given point in time.
        """
        if max_background_workers is not None:
            pulumi.set(__self__, "max_background_workers", max_background_workers)

    @property
    @pulumi.getter(name="maxBackgroundWorkers")
    def max_background_workers(self) -> Optional[str]:
        """
        The number of background workers for timescaledb 
        operations. You should configure this setting to the sum of your number of databases and the
        total number of concurrent background workers you want running at any given point in time.
        """
        return pulumi.get(self, "max_background_workers")


@pulumi.output_type
class GetPgServiceIntegrationResult(dict):
    def __init__(__self__, *,
                 integration_type: str,
                 source_service_name: str):
        pulumi.set(__self__, "integration_type", integration_type)
        pulumi.set(__self__, "source_service_name", source_service_name)

    @property
    @pulumi.getter(name="integrationType")
    def integration_type(self) -> str:
        return pulumi.get(self, "integration_type")

    @property
    @pulumi.getter(name="sourceServiceName")
    def source_service_name(self) -> str:
        return pulumi.get(self, "source_service_name")


@pulumi.output_type
class GetRedisComponentResult(dict):
    def __init__(__self__, *,
                 component: str,
                 host: str,
                 kafka_authentication_method: str,
                 port: int,
                 route: str,
                 ssl: bool,
                 usage: str):
        """
        :param str host: (Required) Hostname or IP address of the server where to migrate data from
        :param int port: (Required) Port number of the server where to migrate data from
        :param bool ssl: The server where to migrate data from is secured with SSL
        """
        pulumi.set(__self__, "component", component)
        pulumi.set(__self__, "host", host)
        pulumi.set(__self__, "kafka_authentication_method", kafka_authentication_method)
        pulumi.set(__self__, "port", port)
        pulumi.set(__self__, "route", route)
        pulumi.set(__self__, "ssl", ssl)
        pulumi.set(__self__, "usage", usage)

    @property
    @pulumi.getter
    def component(self) -> str:
        return pulumi.get(self, "component")

    @property
    @pulumi.getter
    def host(self) -> str:
        """
        (Required) Hostname or IP address of the server where to migrate data from
        """
        return pulumi.get(self, "host")

    @property
    @pulumi.getter(name="kafkaAuthenticationMethod")
    def kafka_authentication_method(self) -> str:
        return pulumi.get(self, "kafka_authentication_method")

    @property
    @pulumi.getter
    def port(self) -> int:
        """
        (Required) Port number of the server where to migrate data from
        """
        return pulumi.get(self, "port")

    @property
    @pulumi.getter
    def route(self) -> str:
        return pulumi.get(self, "route")

    @property
    @pulumi.getter
    def ssl(self) -> bool:
        """
        The server where to migrate data from is secured with SSL
        """
        return pulumi.get(self, "ssl")

    @property
    @pulumi.getter
    def usage(self) -> str:
        return pulumi.get(self, "usage")


@pulumi.output_type
class GetRedisRedisResult(dict):
    def __init__(__self__):
        pass


@pulumi.output_type
class GetRedisRedisUserConfigResult(dict):
    def __init__(__self__, *,
                 ip_filters: Optional[Sequence[str]] = None,
                 migration: Optional['outputs.GetRedisRedisUserConfigMigrationResult'] = None,
                 private_access: Optional['outputs.GetRedisRedisUserConfigPrivateAccessResult'] = None,
                 privatelink_access: Optional['outputs.GetRedisRedisUserConfigPrivatelinkAccessResult'] = None,
                 project_to_fork_from: Optional[str] = None,
                 public_access: Optional['outputs.GetRedisRedisUserConfigPublicAccessResult'] = None,
                 recovery_basebackup_name: Optional[str] = None,
                 redis_io_threads: Optional[str] = None,
                 redis_lfu_decay_time: Optional[str] = None,
                 redis_lfu_log_factor: Optional[str] = None,
                 redis_maxmemory_policy: Optional[str] = None,
                 redis_notify_keyspace_events: Optional[str] = None,
                 redis_ssl: Optional[str] = None,
                 redis_timeout: Optional[str] = None,
                 service_to_fork_from: Optional[str] = None):
        """
        :param Sequence[str] ip_filters: Allow incoming connections from CIDR address block, e.g. `10.20.0.0/16`
        :param 'GetRedisRedisUserConfigMigrationArgs' migration: Migrate data from existing server
        :param 'GetRedisRedisUserConfigPrivateAccessArgs' private_access: Allow access to selected service ports from private networks
        :param 'GetRedisRedisUserConfigPrivatelinkAccessArgs' privatelink_access: Allow access to selected service components through Privatelink
        :param str project_to_fork_from: Name of another project to fork a service from. This has
               effect only when a new service is being created.
        :param 'GetRedisRedisUserConfigPublicAccessArgs' public_access: Allow access to selected service ports from the public Internet
        :param str recovery_basebackup_name: Name of the basebackup to restore in forked service
        :param str redis_io_threads: Redis IO thread count
               * `redis_lfu_decay_time"` - LFU maxmemory-policy counter decay time in minutes
        :param str redis_lfu_log_factor: Counter logarithm factor for volatile-lfu and allkeys-lfu 
               maxmemory-policies
        :param str redis_maxmemory_policy: Redis maxmemory-policy
        :param str redis_notify_keyspace_events: Set notify-keyspace-events option
        :param str redis_ssl: Require SSL to access Redis
        :param str redis_timeout: Redis idle connection timeout
               * `service_to_fork_from"` - Name of another service to fork from. This has effect only
               when a new service is being created.
        """
        if ip_filters is not None:
            pulumi.set(__self__, "ip_filters", ip_filters)
        if migration is not None:
            pulumi.set(__self__, "migration", migration)
        if private_access is not None:
            pulumi.set(__self__, "private_access", private_access)
        if privatelink_access is not None:
            pulumi.set(__self__, "privatelink_access", privatelink_access)
        if project_to_fork_from is not None:
            pulumi.set(__self__, "project_to_fork_from", project_to_fork_from)
        if public_access is not None:
            pulumi.set(__self__, "public_access", public_access)
        if recovery_basebackup_name is not None:
            pulumi.set(__self__, "recovery_basebackup_name", recovery_basebackup_name)
        if redis_io_threads is not None:
            pulumi.set(__self__, "redis_io_threads", redis_io_threads)
        if redis_lfu_decay_time is not None:
            pulumi.set(__self__, "redis_lfu_decay_time", redis_lfu_decay_time)
        if redis_lfu_log_factor is not None:
            pulumi.set(__self__, "redis_lfu_log_factor", redis_lfu_log_factor)
        if redis_maxmemory_policy is not None:
            pulumi.set(__self__, "redis_maxmemory_policy", redis_maxmemory_policy)
        if redis_notify_keyspace_events is not None:
            pulumi.set(__self__, "redis_notify_keyspace_events", redis_notify_keyspace_events)
        if redis_ssl is not None:
            pulumi.set(__self__, "redis_ssl", redis_ssl)
        if redis_timeout is not None:
            pulumi.set(__self__, "redis_timeout", redis_timeout)
        if service_to_fork_from is not None:
            pulumi.set(__self__, "service_to_fork_from", service_to_fork_from)

    @property
    @pulumi.getter(name="ipFilters")
    def ip_filters(self) -> Optional[Sequence[str]]:
        """
        Allow incoming connections from CIDR address block, e.g. `10.20.0.0/16`
        """
        return pulumi.get(self, "ip_filters")

    @property
    @pulumi.getter
    def migration(self) -> Optional['outputs.GetRedisRedisUserConfigMigrationResult']:
        """
        Migrate data from existing server
        """
        return pulumi.get(self, "migration")

    @property
    @pulumi.getter(name="privateAccess")
    def private_access(self) -> Optional['outputs.GetRedisRedisUserConfigPrivateAccessResult']:
        """
        Allow access to selected service ports from private networks
        """
        return pulumi.get(self, "private_access")

    @property
    @pulumi.getter(name="privatelinkAccess")
    def privatelink_access(self) -> Optional['outputs.GetRedisRedisUserConfigPrivatelinkAccessResult']:
        """
        Allow access to selected service components through Privatelink
        """
        return pulumi.get(self, "privatelink_access")

    @property
    @pulumi.getter(name="projectToForkFrom")
    def project_to_fork_from(self) -> Optional[str]:
        """
        Name of another project to fork a service from. This has
        effect only when a new service is being created.
        """
        return pulumi.get(self, "project_to_fork_from")

    @property
    @pulumi.getter(name="publicAccess")
    def public_access(self) -> Optional['outputs.GetRedisRedisUserConfigPublicAccessResult']:
        """
        Allow access to selected service ports from the public Internet
        """
        return pulumi.get(self, "public_access")

    @property
    @pulumi.getter(name="recoveryBasebackupName")
    def recovery_basebackup_name(self) -> Optional[str]:
        """
        Name of the basebackup to restore in forked service
        """
        return pulumi.get(self, "recovery_basebackup_name")

    @property
    @pulumi.getter(name="redisIoThreads")
    def redis_io_threads(self) -> Optional[str]:
        """
        Redis IO thread count
        * `redis_lfu_decay_time"` - LFU maxmemory-policy counter decay time in minutes
        """
        return pulumi.get(self, "redis_io_threads")

    @property
    @pulumi.getter(name="redisLfuDecayTime")
    def redis_lfu_decay_time(self) -> Optional[str]:
        return pulumi.get(self, "redis_lfu_decay_time")

    @property
    @pulumi.getter(name="redisLfuLogFactor")
    def redis_lfu_log_factor(self) -> Optional[str]:
        """
        Counter logarithm factor for volatile-lfu and allkeys-lfu 
        maxmemory-policies
        """
        return pulumi.get(self, "redis_lfu_log_factor")

    @property
    @pulumi.getter(name="redisMaxmemoryPolicy")
    def redis_maxmemory_policy(self) -> Optional[str]:
        """
        Redis maxmemory-policy
        """
        return pulumi.get(self, "redis_maxmemory_policy")

    @property
    @pulumi.getter(name="redisNotifyKeyspaceEvents")
    def redis_notify_keyspace_events(self) -> Optional[str]:
        """
        Set notify-keyspace-events option
        """
        return pulumi.get(self, "redis_notify_keyspace_events")

    @property
    @pulumi.getter(name="redisSsl")
    def redis_ssl(self) -> Optional[str]:
        """
        Require SSL to access Redis
        """
        return pulumi.get(self, "redis_ssl")

    @property
    @pulumi.getter(name="redisTimeout")
    def redis_timeout(self) -> Optional[str]:
        """
        Redis idle connection timeout
        * `service_to_fork_from"` - Name of another service to fork from. This has effect only
        when a new service is being created.
        """
        return pulumi.get(self, "redis_timeout")

    @property
    @pulumi.getter(name="serviceToForkFrom")
    def service_to_fork_from(self) -> Optional[str]:
        return pulumi.get(self, "service_to_fork_from")


@pulumi.output_type
class GetRedisRedisUserConfigMigrationResult(dict):
    def __init__(__self__, *,
                 dbname: Optional[str] = None,
                 host: Optional[str] = None,
                 ignore_dbs: Optional[str] = None,
                 password: Optional[str] = None,
                 port: Optional[str] = None,
                 ssl: Optional[str] = None,
                 username: Optional[str] = None):
        """
        :param str dbname: Database name for bootstrapping the initial connection
        :param str host: (Required) Hostname or IP address of the server where to migrate data from
        :param str ignore_dbs: Comma-separated list of databases, which should be ignored during
               migration (supported by MySQL only at the moment)
        :param str password: Password for authentication with the server where to migrate data from
        :param str port: (Required) Port number of the server where to migrate data from
        :param str ssl: The server where to migrate data from is secured with SSL
        :param str username: User name for authentication with the server where to migrate data from
        """
        if dbname is not None:
            pulumi.set(__self__, "dbname", dbname)
        if host is not None:
            pulumi.set(__self__, "host", host)
        if ignore_dbs is not None:
            pulumi.set(__self__, "ignore_dbs", ignore_dbs)
        if password is not None:
            pulumi.set(__self__, "password", password)
        if port is not None:
            pulumi.set(__self__, "port", port)
        if ssl is not None:
            pulumi.set(__self__, "ssl", ssl)
        if username is not None:
            pulumi.set(__self__, "username", username)

    @property
    @pulumi.getter
    def dbname(self) -> Optional[str]:
        """
        Database name for bootstrapping the initial connection
        """
        return pulumi.get(self, "dbname")

    @property
    @pulumi.getter
    def host(self) -> Optional[str]:
        """
        (Required) Hostname or IP address of the server where to migrate data from
        """
        return pulumi.get(self, "host")

    @property
    @pulumi.getter(name="ignoreDbs")
    def ignore_dbs(self) -> Optional[str]:
        """
        Comma-separated list of databases, which should be ignored during
        migration (supported by MySQL only at the moment)
        """
        return pulumi.get(self, "ignore_dbs")

    @property
    @pulumi.getter
    def password(self) -> Optional[str]:
        """
        Password for authentication with the server where to migrate data from
        """
        return pulumi.get(self, "password")

    @property
    @pulumi.getter
    def port(self) -> Optional[str]:
        """
        (Required) Port number of the server where to migrate data from
        """
        return pulumi.get(self, "port")

    @property
    @pulumi.getter
    def ssl(self) -> Optional[str]:
        """
        The server where to migrate data from is secured with SSL
        """
        return pulumi.get(self, "ssl")

    @property
    @pulumi.getter
    def username(self) -> Optional[str]:
        """
        User name for authentication with the server where to migrate data from
        """
        return pulumi.get(self, "username")


@pulumi.output_type
class GetRedisRedisUserConfigPrivateAccessResult(dict):
    def __init__(__self__, *,
                 prometheus: Optional[str] = None,
                 redis: Optional[str] = None):
        """
        :param str prometheus: Allow clients to connect to prometheus from the public internet 
               for service nodes that are in a project VPC or another type of private network
        :param str redis: Redis specific server provided values.
        """
        if prometheus is not None:
            pulumi.set(__self__, "prometheus", prometheus)
        if redis is not None:
            pulumi.set(__self__, "redis", redis)

    @property
    @pulumi.getter
    def prometheus(self) -> Optional[str]:
        """
        Allow clients to connect to prometheus from the public internet 
        for service nodes that are in a project VPC or another type of private network
        """
        return pulumi.get(self, "prometheus")

    @property
    @pulumi.getter
    def redis(self) -> Optional[str]:
        """
        Redis specific server provided values.
        """
        return pulumi.get(self, "redis")


@pulumi.output_type
class GetRedisRedisUserConfigPrivatelinkAccessResult(dict):
    def __init__(__self__, *,
                 redis: Optional[str] = None):
        """
        :param str redis: Redis specific server provided values.
        """
        if redis is not None:
            pulumi.set(__self__, "redis", redis)

    @property
    @pulumi.getter
    def redis(self) -> Optional[str]:
        """
        Redis specific server provided values.
        """
        return pulumi.get(self, "redis")


@pulumi.output_type
class GetRedisRedisUserConfigPublicAccessResult(dict):
    def __init__(__self__, *,
                 prometheus: Optional[str] = None,
                 redis: Optional[str] = None):
        """
        :param str prometheus: Allow clients to connect to prometheus from the public internet 
               for service nodes that are in a project VPC or another type of private network
        :param str redis: Redis specific server provided values.
        """
        if prometheus is not None:
            pulumi.set(__self__, "prometheus", prometheus)
        if redis is not None:
            pulumi.set(__self__, "redis", redis)

    @property
    @pulumi.getter
    def prometheus(self) -> Optional[str]:
        """
        Allow clients to connect to prometheus from the public internet 
        for service nodes that are in a project VPC or another type of private network
        """
        return pulumi.get(self, "prometheus")

    @property
    @pulumi.getter
    def redis(self) -> Optional[str]:
        """
        Redis specific server provided values.
        """
        return pulumi.get(self, "redis")


@pulumi.output_type
class GetRedisServiceIntegrationResult(dict):
    def __init__(__self__, *,
                 integration_type: str,
                 source_service_name: str):
        pulumi.set(__self__, "integration_type", integration_type)
        pulumi.set(__self__, "source_service_name", source_service_name)

    @property
    @pulumi.getter(name="integrationType")
    def integration_type(self) -> str:
        return pulumi.get(self, "integration_type")

    @property
    @pulumi.getter(name="sourceServiceName")
    def source_service_name(self) -> str:
        return pulumi.get(self, "source_service_name")


@pulumi.output_type
class GetServiceCassandraResult(dict):
    def __init__(__self__):
        pass


@pulumi.output_type
class GetServiceCassandraUserConfigResult(dict):
    def __init__(__self__, *,
                 cassandra: Optional['outputs.GetServiceCassandraUserConfigCassandraResult'] = None,
                 ip_filters: Optional[Sequence[str]] = None,
                 migrate_sstableloader: Optional[str] = None,
                 private_access: Optional['outputs.GetServiceCassandraUserConfigPrivateAccessResult'] = None,
                 project_to_fork_from: Optional[str] = None,
                 public_access: Optional['outputs.GetServiceCassandraUserConfigPublicAccessResult'] = None,
                 service_to_fork_from: Optional[str] = None):
        if cassandra is not None:
            pulumi.set(__self__, "cassandra", cassandra)
        if ip_filters is not None:
            pulumi.set(__self__, "ip_filters", ip_filters)
        if migrate_sstableloader is not None:
            pulumi.set(__self__, "migrate_sstableloader", migrate_sstableloader)
        if private_access is not None:
            pulumi.set(__self__, "private_access", private_access)
        if project_to_fork_from is not None:
            pulumi.set(__self__, "project_to_fork_from", project_to_fork_from)
        if public_access is not None:
            pulumi.set(__self__, "public_access", public_access)
        if service_to_fork_from is not None:
            pulumi.set(__self__, "service_to_fork_from", service_to_fork_from)

    @property
    @pulumi.getter
    def cassandra(self) -> Optional['outputs.GetServiceCassandraUserConfigCassandraResult']:
        return pulumi.get(self, "cassandra")

    @property
    @pulumi.getter(name="ipFilters")
    def ip_filters(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "ip_filters")

    @property
    @pulumi.getter(name="migrateSstableloader")
    def migrate_sstableloader(self) -> Optional[str]:
        return pulumi.get(self, "migrate_sstableloader")

    @property
    @pulumi.getter(name="privateAccess")
    def private_access(self) -> Optional['outputs.GetServiceCassandraUserConfigPrivateAccessResult']:
        return pulumi.get(self, "private_access")

    @property
    @pulumi.getter(name="projectToForkFrom")
    def project_to_fork_from(self) -> Optional[str]:
        return pulumi.get(self, "project_to_fork_from")

    @property
    @pulumi.getter(name="publicAccess")
    def public_access(self) -> Optional['outputs.GetServiceCassandraUserConfigPublicAccessResult']:
        return pulumi.get(self, "public_access")

    @property
    @pulumi.getter(name="serviceToForkFrom")
    def service_to_fork_from(self) -> Optional[str]:
        return pulumi.get(self, "service_to_fork_from")


@pulumi.output_type
class GetServiceCassandraUserConfigCassandraResult(dict):
    def __init__(__self__, *,
                 batch_size_fail_threshold_in_kb: Optional[str] = None,
                 batch_size_warn_threshold_in_kb: Optional[str] = None):
        if batch_size_fail_threshold_in_kb is not None:
            pulumi.set(__self__, "batch_size_fail_threshold_in_kb", batch_size_fail_threshold_in_kb)
        if batch_size_warn_threshold_in_kb is not None:
            pulumi.set(__self__, "batch_size_warn_threshold_in_kb", batch_size_warn_threshold_in_kb)

    @property
    @pulumi.getter(name="batchSizeFailThresholdInKb")
    def batch_size_fail_threshold_in_kb(self) -> Optional[str]:
        return pulumi.get(self, "batch_size_fail_threshold_in_kb")

    @property
    @pulumi.getter(name="batchSizeWarnThresholdInKb")
    def batch_size_warn_threshold_in_kb(self) -> Optional[str]:
        return pulumi.get(self, "batch_size_warn_threshold_in_kb")


@pulumi.output_type
class GetServiceCassandraUserConfigPrivateAccessResult(dict):
    def __init__(__self__, *,
                 prometheus: Optional[str] = None):
        if prometheus is not None:
            pulumi.set(__self__, "prometheus", prometheus)

    @property
    @pulumi.getter
    def prometheus(self) -> Optional[str]:
        return pulumi.get(self, "prometheus")


@pulumi.output_type
class GetServiceCassandraUserConfigPublicAccessResult(dict):
    def __init__(__self__, *,
                 prometheus: Optional[str] = None):
        if prometheus is not None:
            pulumi.set(__self__, "prometheus", prometheus)

    @property
    @pulumi.getter
    def prometheus(self) -> Optional[str]:
        return pulumi.get(self, "prometheus")


@pulumi.output_type
class GetServiceComponentResult(dict):
    def __init__(__self__, *,
                 component: str,
                 host: str,
                 kafka_authentication_method: str,
                 port: int,
                 route: str,
                 ssl: bool,
                 usage: str):
        pulumi.set(__self__, "component", component)
        pulumi.set(__self__, "host", host)
        pulumi.set(__self__, "kafka_authentication_method", kafka_authentication_method)
        pulumi.set(__self__, "port", port)
        pulumi.set(__self__, "route", route)
        pulumi.set(__self__, "ssl", ssl)
        pulumi.set(__self__, "usage", usage)

    @property
    @pulumi.getter
    def component(self) -> str:
        return pulumi.get(self, "component")

    @property
    @pulumi.getter
    def host(self) -> str:
        return pulumi.get(self, "host")

    @property
    @pulumi.getter(name="kafkaAuthenticationMethod")
    def kafka_authentication_method(self) -> str:
        return pulumi.get(self, "kafka_authentication_method")

    @property
    @pulumi.getter
    def port(self) -> int:
        return pulumi.get(self, "port")

    @property
    @pulumi.getter
    def route(self) -> str:
        return pulumi.get(self, "route")

    @property
    @pulumi.getter
    def ssl(self) -> bool:
        return pulumi.get(self, "ssl")

    @property
    @pulumi.getter
    def usage(self) -> str:
        return pulumi.get(self, "usage")


@pulumi.output_type
class GetServiceElasticsearchResult(dict):
    def __init__(__self__, *,
                 kibana_uri: str):
        pulumi.set(__self__, "kibana_uri", kibana_uri)

    @property
    @pulumi.getter(name="kibanaUri")
    def kibana_uri(self) -> str:
        return pulumi.get(self, "kibana_uri")


@pulumi.output_type
class GetServiceElasticsearchUserConfigResult(dict):
    def __init__(__self__, *,
                 custom_domain: Optional[str] = None,
                 disable_replication_factor_adjustment: Optional[str] = None,
                 elasticsearch: Optional['outputs.GetServiceElasticsearchUserConfigElasticsearchResult'] = None,
                 elasticsearch_version: Optional[str] = None,
                 index_patterns: Optional[Sequence['outputs.GetServiceElasticsearchUserConfigIndexPatternResult']] = None,
                 index_template: Optional['outputs.GetServiceElasticsearchUserConfigIndexTemplateResult'] = None,
                 ip_filters: Optional[Sequence[str]] = None,
                 kibana: Optional['outputs.GetServiceElasticsearchUserConfigKibanaResult'] = None,
                 max_index_count: Optional[str] = None,
                 private_access: Optional['outputs.GetServiceElasticsearchUserConfigPrivateAccessResult'] = None,
                 privatelink_access: Optional['outputs.GetServiceElasticsearchUserConfigPrivatelinkAccessResult'] = None,
                 project_to_fork_from: Optional[str] = None,
                 public_access: Optional['outputs.GetServiceElasticsearchUserConfigPublicAccessResult'] = None,
                 recovery_basebackup_name: Optional[str] = None,
                 service_to_fork_from: Optional[str] = None):
        if custom_domain is not None:
            pulumi.set(__self__, "custom_domain", custom_domain)
        if disable_replication_factor_adjustment is not None:
            pulumi.set(__self__, "disable_replication_factor_adjustment", disable_replication_factor_adjustment)
        if elasticsearch is not None:
            pulumi.set(__self__, "elasticsearch", elasticsearch)
        if elasticsearch_version is not None:
            pulumi.set(__self__, "elasticsearch_version", elasticsearch_version)
        if index_patterns is not None:
            pulumi.set(__self__, "index_patterns", index_patterns)
        if index_template is not None:
            pulumi.set(__self__, "index_template", index_template)
        if ip_filters is not None:
            pulumi.set(__self__, "ip_filters", ip_filters)
        if kibana is not None:
            pulumi.set(__self__, "kibana", kibana)
        if max_index_count is not None:
            pulumi.set(__self__, "max_index_count", max_index_count)
        if private_access is not None:
            pulumi.set(__self__, "private_access", private_access)
        if privatelink_access is not None:
            pulumi.set(__self__, "privatelink_access", privatelink_access)
        if project_to_fork_from is not None:
            pulumi.set(__self__, "project_to_fork_from", project_to_fork_from)
        if public_access is not None:
            pulumi.set(__self__, "public_access", public_access)
        if recovery_basebackup_name is not None:
            pulumi.set(__self__, "recovery_basebackup_name", recovery_basebackup_name)
        if service_to_fork_from is not None:
            pulumi.set(__self__, "service_to_fork_from", service_to_fork_from)

    @property
    @pulumi.getter(name="customDomain")
    def custom_domain(self) -> Optional[str]:
        return pulumi.get(self, "custom_domain")

    @property
    @pulumi.getter(name="disableReplicationFactorAdjustment")
    def disable_replication_factor_adjustment(self) -> Optional[str]:
        return pulumi.get(self, "disable_replication_factor_adjustment")

    @property
    @pulumi.getter
    def elasticsearch(self) -> Optional['outputs.GetServiceElasticsearchUserConfigElasticsearchResult']:
        return pulumi.get(self, "elasticsearch")

    @property
    @pulumi.getter(name="elasticsearchVersion")
    def elasticsearch_version(self) -> Optional[str]:
        return pulumi.get(self, "elasticsearch_version")

    @property
    @pulumi.getter(name="indexPatterns")
    def index_patterns(self) -> Optional[Sequence['outputs.GetServiceElasticsearchUserConfigIndexPatternResult']]:
        return pulumi.get(self, "index_patterns")

    @property
    @pulumi.getter(name="indexTemplate")
    def index_template(self) -> Optional['outputs.GetServiceElasticsearchUserConfigIndexTemplateResult']:
        return pulumi.get(self, "index_template")

    @property
    @pulumi.getter(name="ipFilters")
    def ip_filters(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "ip_filters")

    @property
    @pulumi.getter
    def kibana(self) -> Optional['outputs.GetServiceElasticsearchUserConfigKibanaResult']:
        return pulumi.get(self, "kibana")

    @property
    @pulumi.getter(name="maxIndexCount")
    def max_index_count(self) -> Optional[str]:
        return pulumi.get(self, "max_index_count")

    @property
    @pulumi.getter(name="privateAccess")
    def private_access(self) -> Optional['outputs.GetServiceElasticsearchUserConfigPrivateAccessResult']:
        return pulumi.get(self, "private_access")

    @property
    @pulumi.getter(name="privatelinkAccess")
    def privatelink_access(self) -> Optional['outputs.GetServiceElasticsearchUserConfigPrivatelinkAccessResult']:
        return pulumi.get(self, "privatelink_access")

    @property
    @pulumi.getter(name="projectToForkFrom")
    def project_to_fork_from(self) -> Optional[str]:
        return pulumi.get(self, "project_to_fork_from")

    @property
    @pulumi.getter(name="publicAccess")
    def public_access(self) -> Optional['outputs.GetServiceElasticsearchUserConfigPublicAccessResult']:
        return pulumi.get(self, "public_access")

    @property
    @pulumi.getter(name="recoveryBasebackupName")
    def recovery_basebackup_name(self) -> Optional[str]:
        return pulumi.get(self, "recovery_basebackup_name")

    @property
    @pulumi.getter(name="serviceToForkFrom")
    def service_to_fork_from(self) -> Optional[str]:
        return pulumi.get(self, "service_to_fork_from")


@pulumi.output_type
class GetServiceElasticsearchUserConfigElasticsearchResult(dict):
    def __init__(__self__, *,
                 action_auto_create_index_enabled: Optional[str] = None,
                 action_destructive_requires_name: Optional[str] = None,
                 cluster_max_shards_per_node: Optional[str] = None,
                 http_max_content_length: Optional[str] = None,
                 http_max_header_size: Optional[str] = None,
                 http_max_initial_line_length: Optional[str] = None,
                 indices_fielddata_cache_size: Optional[str] = None,
                 indices_memory_index_buffer_size: Optional[str] = None,
                 indices_queries_cache_size: Optional[str] = None,
                 indices_query_bool_max_clause_count: Optional[str] = None,
                 reindex_remote_whitelists: Optional[Sequence[str]] = None,
                 search_max_buckets: Optional[str] = None,
                 thread_pool_analyze_queue_size: Optional[str] = None,
                 thread_pool_analyze_size: Optional[str] = None,
                 thread_pool_force_merge_size: Optional[str] = None,
                 thread_pool_get_queue_size: Optional[str] = None,
                 thread_pool_get_size: Optional[str] = None,
                 thread_pool_index_queue_size: Optional[str] = None,
                 thread_pool_index_size: Optional[str] = None,
                 thread_pool_search_queue_size: Optional[str] = None,
                 thread_pool_search_size: Optional[str] = None,
                 thread_pool_search_throttled_queue_size: Optional[str] = None,
                 thread_pool_search_throttled_size: Optional[str] = None,
                 thread_pool_write_queue_size: Optional[str] = None,
                 thread_pool_write_size: Optional[str] = None):
        if action_auto_create_index_enabled is not None:
            pulumi.set(__self__, "action_auto_create_index_enabled", action_auto_create_index_enabled)
        if action_destructive_requires_name is not None:
            pulumi.set(__self__, "action_destructive_requires_name", action_destructive_requires_name)
        if cluster_max_shards_per_node is not None:
            pulumi.set(__self__, "cluster_max_shards_per_node", cluster_max_shards_per_node)
        if http_max_content_length is not None:
            pulumi.set(__self__, "http_max_content_length", http_max_content_length)
        if http_max_header_size is not None:
            pulumi.set(__self__, "http_max_header_size", http_max_header_size)
        if http_max_initial_line_length is not None:
            pulumi.set(__self__, "http_max_initial_line_length", http_max_initial_line_length)
        if indices_fielddata_cache_size is not None:
            pulumi.set(__self__, "indices_fielddata_cache_size", indices_fielddata_cache_size)
        if indices_memory_index_buffer_size is not None:
            pulumi.set(__self__, "indices_memory_index_buffer_size", indices_memory_index_buffer_size)
        if indices_queries_cache_size is not None:
            pulumi.set(__self__, "indices_queries_cache_size", indices_queries_cache_size)
        if indices_query_bool_max_clause_count is not None:
            pulumi.set(__self__, "indices_query_bool_max_clause_count", indices_query_bool_max_clause_count)
        if reindex_remote_whitelists is not None:
            pulumi.set(__self__, "reindex_remote_whitelists", reindex_remote_whitelists)
        if search_max_buckets is not None:
            pulumi.set(__self__, "search_max_buckets", search_max_buckets)
        if thread_pool_analyze_queue_size is not None:
            pulumi.set(__self__, "thread_pool_analyze_queue_size", thread_pool_analyze_queue_size)
        if thread_pool_analyze_size is not None:
            pulumi.set(__self__, "thread_pool_analyze_size", thread_pool_analyze_size)
        if thread_pool_force_merge_size is not None:
            pulumi.set(__self__, "thread_pool_force_merge_size", thread_pool_force_merge_size)
        if thread_pool_get_queue_size is not None:
            pulumi.set(__self__, "thread_pool_get_queue_size", thread_pool_get_queue_size)
        if thread_pool_get_size is not None:
            pulumi.set(__self__, "thread_pool_get_size", thread_pool_get_size)
        if thread_pool_index_queue_size is not None:
            pulumi.set(__self__, "thread_pool_index_queue_size", thread_pool_index_queue_size)
        if thread_pool_index_size is not None:
            pulumi.set(__self__, "thread_pool_index_size", thread_pool_index_size)
        if thread_pool_search_queue_size is not None:
            pulumi.set(__self__, "thread_pool_search_queue_size", thread_pool_search_queue_size)
        if thread_pool_search_size is not None:
            pulumi.set(__self__, "thread_pool_search_size", thread_pool_search_size)
        if thread_pool_search_throttled_queue_size is not None:
            pulumi.set(__self__, "thread_pool_search_throttled_queue_size", thread_pool_search_throttled_queue_size)
        if thread_pool_search_throttled_size is not None:
            pulumi.set(__self__, "thread_pool_search_throttled_size", thread_pool_search_throttled_size)
        if thread_pool_write_queue_size is not None:
            pulumi.set(__self__, "thread_pool_write_queue_size", thread_pool_write_queue_size)
        if thread_pool_write_size is not None:
            pulumi.set(__self__, "thread_pool_write_size", thread_pool_write_size)

    @property
    @pulumi.getter(name="actionAutoCreateIndexEnabled")
    def action_auto_create_index_enabled(self) -> Optional[str]:
        return pulumi.get(self, "action_auto_create_index_enabled")

    @property
    @pulumi.getter(name="actionDestructiveRequiresName")
    def action_destructive_requires_name(self) -> Optional[str]:
        return pulumi.get(self, "action_destructive_requires_name")

    @property
    @pulumi.getter(name="clusterMaxShardsPerNode")
    def cluster_max_shards_per_node(self) -> Optional[str]:
        return pulumi.get(self, "cluster_max_shards_per_node")

    @property
    @pulumi.getter(name="httpMaxContentLength")
    def http_max_content_length(self) -> Optional[str]:
        return pulumi.get(self, "http_max_content_length")

    @property
    @pulumi.getter(name="httpMaxHeaderSize")
    def http_max_header_size(self) -> Optional[str]:
        return pulumi.get(self, "http_max_header_size")

    @property
    @pulumi.getter(name="httpMaxInitialLineLength")
    def http_max_initial_line_length(self) -> Optional[str]:
        return pulumi.get(self, "http_max_initial_line_length")

    @property
    @pulumi.getter(name="indicesFielddataCacheSize")
    def indices_fielddata_cache_size(self) -> Optional[str]:
        return pulumi.get(self, "indices_fielddata_cache_size")

    @property
    @pulumi.getter(name="indicesMemoryIndexBufferSize")
    def indices_memory_index_buffer_size(self) -> Optional[str]:
        return pulumi.get(self, "indices_memory_index_buffer_size")

    @property
    @pulumi.getter(name="indicesQueriesCacheSize")
    def indices_queries_cache_size(self) -> Optional[str]:
        return pulumi.get(self, "indices_queries_cache_size")

    @property
    @pulumi.getter(name="indicesQueryBoolMaxClauseCount")
    def indices_query_bool_max_clause_count(self) -> Optional[str]:
        return pulumi.get(self, "indices_query_bool_max_clause_count")

    @property
    @pulumi.getter(name="reindexRemoteWhitelists")
    def reindex_remote_whitelists(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "reindex_remote_whitelists")

    @property
    @pulumi.getter(name="searchMaxBuckets")
    def search_max_buckets(self) -> Optional[str]:
        return pulumi.get(self, "search_max_buckets")

    @property
    @pulumi.getter(name="threadPoolAnalyzeQueueSize")
    def thread_pool_analyze_queue_size(self) -> Optional[str]:
        return pulumi.get(self, "thread_pool_analyze_queue_size")

    @property
    @pulumi.getter(name="threadPoolAnalyzeSize")
    def thread_pool_analyze_size(self) -> Optional[str]:
        return pulumi.get(self, "thread_pool_analyze_size")

    @property
    @pulumi.getter(name="threadPoolForceMergeSize")
    def thread_pool_force_merge_size(self) -> Optional[str]:
        return pulumi.get(self, "thread_pool_force_merge_size")

    @property
    @pulumi.getter(name="threadPoolGetQueueSize")
    def thread_pool_get_queue_size(self) -> Optional[str]:
        return pulumi.get(self, "thread_pool_get_queue_size")

    @property
    @pulumi.getter(name="threadPoolGetSize")
    def thread_pool_get_size(self) -> Optional[str]:
        return pulumi.get(self, "thread_pool_get_size")

    @property
    @pulumi.getter(name="threadPoolIndexQueueSize")
    def thread_pool_index_queue_size(self) -> Optional[str]:
        return pulumi.get(self, "thread_pool_index_queue_size")

    @property
    @pulumi.getter(name="threadPoolIndexSize")
    def thread_pool_index_size(self) -> Optional[str]:
        return pulumi.get(self, "thread_pool_index_size")

    @property
    @pulumi.getter(name="threadPoolSearchQueueSize")
    def thread_pool_search_queue_size(self) -> Optional[str]:
        return pulumi.get(self, "thread_pool_search_queue_size")

    @property
    @pulumi.getter(name="threadPoolSearchSize")
    def thread_pool_search_size(self) -> Optional[str]:
        return pulumi.get(self, "thread_pool_search_size")

    @property
    @pulumi.getter(name="threadPoolSearchThrottledQueueSize")
    def thread_pool_search_throttled_queue_size(self) -> Optional[str]:
        return pulumi.get(self, "thread_pool_search_throttled_queue_size")

    @property
    @pulumi.getter(name="threadPoolSearchThrottledSize")
    def thread_pool_search_throttled_size(self) -> Optional[str]:
        return pulumi.get(self, "thread_pool_search_throttled_size")

    @property
    @pulumi.getter(name="threadPoolWriteQueueSize")
    def thread_pool_write_queue_size(self) -> Optional[str]:
        return pulumi.get(self, "thread_pool_write_queue_size")

    @property
    @pulumi.getter(name="threadPoolWriteSize")
    def thread_pool_write_size(self) -> Optional[str]:
        return pulumi.get(self, "thread_pool_write_size")


@pulumi.output_type
class GetServiceElasticsearchUserConfigIndexPatternResult(dict):
    def __init__(__self__, *,
                 max_index_count: Optional[str] = None,
                 pattern: Optional[str] = None,
                 sorting_algorithm: Optional[str] = None):
        if max_index_count is not None:
            pulumi.set(__self__, "max_index_count", max_index_count)
        if pattern is not None:
            pulumi.set(__self__, "pattern", pattern)
        if sorting_algorithm is not None:
            pulumi.set(__self__, "sorting_algorithm", sorting_algorithm)

    @property
    @pulumi.getter(name="maxIndexCount")
    def max_index_count(self) -> Optional[str]:
        return pulumi.get(self, "max_index_count")

    @property
    @pulumi.getter
    def pattern(self) -> Optional[str]:
        return pulumi.get(self, "pattern")

    @property
    @pulumi.getter(name="sortingAlgorithm")
    def sorting_algorithm(self) -> Optional[str]:
        return pulumi.get(self, "sorting_algorithm")


@pulumi.output_type
class GetServiceElasticsearchUserConfigIndexTemplateResult(dict):
    def __init__(__self__, *,
                 mapping_nested_objects_limit: Optional[str] = None,
                 number_of_replicas: Optional[str] = None,
                 number_of_shards: Optional[str] = None):
        if mapping_nested_objects_limit is not None:
            pulumi.set(__self__, "mapping_nested_objects_limit", mapping_nested_objects_limit)
        if number_of_replicas is not None:
            pulumi.set(__self__, "number_of_replicas", number_of_replicas)
        if number_of_shards is not None:
            pulumi.set(__self__, "number_of_shards", number_of_shards)

    @property
    @pulumi.getter(name="mappingNestedObjectsLimit")
    def mapping_nested_objects_limit(self) -> Optional[str]:
        return pulumi.get(self, "mapping_nested_objects_limit")

    @property
    @pulumi.getter(name="numberOfReplicas")
    def number_of_replicas(self) -> Optional[str]:
        return pulumi.get(self, "number_of_replicas")

    @property
    @pulumi.getter(name="numberOfShards")
    def number_of_shards(self) -> Optional[str]:
        return pulumi.get(self, "number_of_shards")


@pulumi.output_type
class GetServiceElasticsearchUserConfigKibanaResult(dict):
    def __init__(__self__, *,
                 elasticsearch_request_timeout: Optional[str] = None,
                 enabled: Optional[str] = None,
                 max_old_space_size: Optional[str] = None):
        if elasticsearch_request_timeout is not None:
            pulumi.set(__self__, "elasticsearch_request_timeout", elasticsearch_request_timeout)
        if enabled is not None:
            pulumi.set(__self__, "enabled", enabled)
        if max_old_space_size is not None:
            pulumi.set(__self__, "max_old_space_size", max_old_space_size)

    @property
    @pulumi.getter(name="elasticsearchRequestTimeout")
    def elasticsearch_request_timeout(self) -> Optional[str]:
        return pulumi.get(self, "elasticsearch_request_timeout")

    @property
    @pulumi.getter
    def enabled(self) -> Optional[str]:
        return pulumi.get(self, "enabled")

    @property
    @pulumi.getter(name="maxOldSpaceSize")
    def max_old_space_size(self) -> Optional[str]:
        return pulumi.get(self, "max_old_space_size")


@pulumi.output_type
class GetServiceElasticsearchUserConfigPrivateAccessResult(dict):
    def __init__(__self__, *,
                 elasticsearch: Optional[str] = None,
                 kibana: Optional[str] = None,
                 prometheus: Optional[str] = None):
        if elasticsearch is not None:
            pulumi.set(__self__, "elasticsearch", elasticsearch)
        if kibana is not None:
            pulumi.set(__self__, "kibana", kibana)
        if prometheus is not None:
            pulumi.set(__self__, "prometheus", prometheus)

    @property
    @pulumi.getter
    def elasticsearch(self) -> Optional[str]:
        return pulumi.get(self, "elasticsearch")

    @property
    @pulumi.getter
    def kibana(self) -> Optional[str]:
        return pulumi.get(self, "kibana")

    @property
    @pulumi.getter
    def prometheus(self) -> Optional[str]:
        return pulumi.get(self, "prometheus")


@pulumi.output_type
class GetServiceElasticsearchUserConfigPrivatelinkAccessResult(dict):
    def __init__(__self__, *,
                 elasticsearch: Optional[str] = None,
                 kibana: Optional[str] = None):
        if elasticsearch is not None:
            pulumi.set(__self__, "elasticsearch", elasticsearch)
        if kibana is not None:
            pulumi.set(__self__, "kibana", kibana)

    @property
    @pulumi.getter
    def elasticsearch(self) -> Optional[str]:
        return pulumi.get(self, "elasticsearch")

    @property
    @pulumi.getter
    def kibana(self) -> Optional[str]:
        return pulumi.get(self, "kibana")


@pulumi.output_type
class GetServiceElasticsearchUserConfigPublicAccessResult(dict):
    def __init__(__self__, *,
                 elasticsearch: Optional[str] = None,
                 kibana: Optional[str] = None,
                 prometheus: Optional[str] = None):
        if elasticsearch is not None:
            pulumi.set(__self__, "elasticsearch", elasticsearch)
        if kibana is not None:
            pulumi.set(__self__, "kibana", kibana)
        if prometheus is not None:
            pulumi.set(__self__, "prometheus", prometheus)

    @property
    @pulumi.getter
    def elasticsearch(self) -> Optional[str]:
        return pulumi.get(self, "elasticsearch")

    @property
    @pulumi.getter
    def kibana(self) -> Optional[str]:
        return pulumi.get(self, "kibana")

    @property
    @pulumi.getter
    def prometheus(self) -> Optional[str]:
        return pulumi.get(self, "prometheus")


@pulumi.output_type
class GetServiceGrafanaResult(dict):
    def __init__(__self__):
        pass


@pulumi.output_type
class GetServiceGrafanaUserConfigResult(dict):
    def __init__(__self__, *,
                 alerting_enabled: Optional[str] = None,
                 alerting_error_or_timeout: Optional[str] = None,
                 alerting_nodata_or_nullvalues: Optional[str] = None,
                 allow_embedding: Optional[str] = None,
                 auth_basic_enabled: Optional[str] = None,
                 auth_generic_oauth: Optional['outputs.GetServiceGrafanaUserConfigAuthGenericOauthResult'] = None,
                 auth_github: Optional['outputs.GetServiceGrafanaUserConfigAuthGithubResult'] = None,
                 auth_gitlab: Optional['outputs.GetServiceGrafanaUserConfigAuthGitlabResult'] = None,
                 auth_google: Optional['outputs.GetServiceGrafanaUserConfigAuthGoogleResult'] = None,
                 cookie_samesite: Optional[str] = None,
                 custom_domain: Optional[str] = None,
                 dashboards_min_refresh_interval: Optional[str] = None,
                 dashboards_versions_to_keep: Optional[str] = None,
                 dataproxy_send_user_header: Optional[str] = None,
                 dataproxy_timeout: Optional[str] = None,
                 disable_gravatar: Optional[str] = None,
                 editors_can_admin: Optional[str] = None,
                 external_image_storage: Optional['outputs.GetServiceGrafanaUserConfigExternalImageStorageResult'] = None,
                 google_analytics_ua_id: Optional[str] = None,
                 ip_filters: Optional[Sequence[str]] = None,
                 metrics_enabled: Optional[str] = None,
                 private_access: Optional['outputs.GetServiceGrafanaUserConfigPrivateAccessResult'] = None,
                 privatelink_access: Optional['outputs.GetServiceGrafanaUserConfigPrivatelinkAccessResult'] = None,
                 project_to_fork_from: Optional[str] = None,
                 public_access: Optional['outputs.GetServiceGrafanaUserConfigPublicAccessResult'] = None,
                 recovery_basebackup_name: Optional[str] = None,
                 service_to_fork_from: Optional[str] = None,
                 smtp_server: Optional['outputs.GetServiceGrafanaUserConfigSmtpServerResult'] = None,
                 user_auto_assign_org: Optional[str] = None,
                 user_auto_assign_org_role: Optional[str] = None,
                 viewers_can_edit: Optional[str] = None):
        if alerting_enabled is not None:
            pulumi.set(__self__, "alerting_enabled", alerting_enabled)
        if alerting_error_or_timeout is not None:
            pulumi.set(__self__, "alerting_error_or_timeout", alerting_error_or_timeout)
        if alerting_nodata_or_nullvalues is not None:
            pulumi.set(__self__, "alerting_nodata_or_nullvalues", alerting_nodata_or_nullvalues)
        if allow_embedding is not None:
            pulumi.set(__self__, "allow_embedding", allow_embedding)
        if auth_basic_enabled is not None:
            pulumi.set(__self__, "auth_basic_enabled", auth_basic_enabled)
        if auth_generic_oauth is not None:
            pulumi.set(__self__, "auth_generic_oauth", auth_generic_oauth)
        if auth_github is not None:
            pulumi.set(__self__, "auth_github", auth_github)
        if auth_gitlab is not None:
            pulumi.set(__self__, "auth_gitlab", auth_gitlab)
        if auth_google is not None:
            pulumi.set(__self__, "auth_google", auth_google)
        if cookie_samesite is not None:
            pulumi.set(__self__, "cookie_samesite", cookie_samesite)
        if custom_domain is not None:
            pulumi.set(__self__, "custom_domain", custom_domain)
        if dashboards_min_refresh_interval is not None:
            pulumi.set(__self__, "dashboards_min_refresh_interval", dashboards_min_refresh_interval)
        if dashboards_versions_to_keep is not None:
            pulumi.set(__self__, "dashboards_versions_to_keep", dashboards_versions_to_keep)
        if dataproxy_send_user_header is not None:
            pulumi.set(__self__, "dataproxy_send_user_header", dataproxy_send_user_header)
        if dataproxy_timeout is not None:
            pulumi.set(__self__, "dataproxy_timeout", dataproxy_timeout)
        if disable_gravatar is not None:
            pulumi.set(__self__, "disable_gravatar", disable_gravatar)
        if editors_can_admin is not None:
            pulumi.set(__self__, "editors_can_admin", editors_can_admin)
        if external_image_storage is not None:
            pulumi.set(__self__, "external_image_storage", external_image_storage)
        if google_analytics_ua_id is not None:
            pulumi.set(__self__, "google_analytics_ua_id", google_analytics_ua_id)
        if ip_filters is not None:
            pulumi.set(__self__, "ip_filters", ip_filters)
        if metrics_enabled is not None:
            pulumi.set(__self__, "metrics_enabled", metrics_enabled)
        if private_access is not None:
            pulumi.set(__self__, "private_access", private_access)
        if privatelink_access is not None:
            pulumi.set(__self__, "privatelink_access", privatelink_access)
        if project_to_fork_from is not None:
            pulumi.set(__self__, "project_to_fork_from", project_to_fork_from)
        if public_access is not None:
            pulumi.set(__self__, "public_access", public_access)
        if recovery_basebackup_name is not None:
            pulumi.set(__self__, "recovery_basebackup_name", recovery_basebackup_name)
        if service_to_fork_from is not None:
            pulumi.set(__self__, "service_to_fork_from", service_to_fork_from)
        if smtp_server is not None:
            pulumi.set(__self__, "smtp_server", smtp_server)
        if user_auto_assign_org is not None:
            pulumi.set(__self__, "user_auto_assign_org", user_auto_assign_org)
        if user_auto_assign_org_role is not None:
            pulumi.set(__self__, "user_auto_assign_org_role", user_auto_assign_org_role)
        if viewers_can_edit is not None:
            pulumi.set(__self__, "viewers_can_edit", viewers_can_edit)

    @property
    @pulumi.getter(name="alertingEnabled")
    def alerting_enabled(self) -> Optional[str]:
        return pulumi.get(self, "alerting_enabled")

    @property
    @pulumi.getter(name="alertingErrorOrTimeout")
    def alerting_error_or_timeout(self) -> Optional[str]:
        return pulumi.get(self, "alerting_error_or_timeout")

    @property
    @pulumi.getter(name="alertingNodataOrNullvalues")
    def alerting_nodata_or_nullvalues(self) -> Optional[str]:
        return pulumi.get(self, "alerting_nodata_or_nullvalues")

    @property
    @pulumi.getter(name="allowEmbedding")
    def allow_embedding(self) -> Optional[str]:
        return pulumi.get(self, "allow_embedding")

    @property
    @pulumi.getter(name="authBasicEnabled")
    def auth_basic_enabled(self) -> Optional[str]:
        return pulumi.get(self, "auth_basic_enabled")

    @property
    @pulumi.getter(name="authGenericOauth")
    def auth_generic_oauth(self) -> Optional['outputs.GetServiceGrafanaUserConfigAuthGenericOauthResult']:
        return pulumi.get(self, "auth_generic_oauth")

    @property
    @pulumi.getter(name="authGithub")
    def auth_github(self) -> Optional['outputs.GetServiceGrafanaUserConfigAuthGithubResult']:
        return pulumi.get(self, "auth_github")

    @property
    @pulumi.getter(name="authGitlab")
    def auth_gitlab(self) -> Optional['outputs.GetServiceGrafanaUserConfigAuthGitlabResult']:
        return pulumi.get(self, "auth_gitlab")

    @property
    @pulumi.getter(name="authGoogle")
    def auth_google(self) -> Optional['outputs.GetServiceGrafanaUserConfigAuthGoogleResult']:
        return pulumi.get(self, "auth_google")

    @property
    @pulumi.getter(name="cookieSamesite")
    def cookie_samesite(self) -> Optional[str]:
        return pulumi.get(self, "cookie_samesite")

    @property
    @pulumi.getter(name="customDomain")
    def custom_domain(self) -> Optional[str]:
        return pulumi.get(self, "custom_domain")

    @property
    @pulumi.getter(name="dashboardsMinRefreshInterval")
    def dashboards_min_refresh_interval(self) -> Optional[str]:
        return pulumi.get(self, "dashboards_min_refresh_interval")

    @property
    @pulumi.getter(name="dashboardsVersionsToKeep")
    def dashboards_versions_to_keep(self) -> Optional[str]:
        return pulumi.get(self, "dashboards_versions_to_keep")

    @property
    @pulumi.getter(name="dataproxySendUserHeader")
    def dataproxy_send_user_header(self) -> Optional[str]:
        return pulumi.get(self, "dataproxy_send_user_header")

    @property
    @pulumi.getter(name="dataproxyTimeout")
    def dataproxy_timeout(self) -> Optional[str]:
        return pulumi.get(self, "dataproxy_timeout")

    @property
    @pulumi.getter(name="disableGravatar")
    def disable_gravatar(self) -> Optional[str]:
        return pulumi.get(self, "disable_gravatar")

    @property
    @pulumi.getter(name="editorsCanAdmin")
    def editors_can_admin(self) -> Optional[str]:
        return pulumi.get(self, "editors_can_admin")

    @property
    @pulumi.getter(name="externalImageStorage")
    def external_image_storage(self) -> Optional['outputs.GetServiceGrafanaUserConfigExternalImageStorageResult']:
        return pulumi.get(self, "external_image_storage")

    @property
    @pulumi.getter(name="googleAnalyticsUaId")
    def google_analytics_ua_id(self) -> Optional[str]:
        return pulumi.get(self, "google_analytics_ua_id")

    @property
    @pulumi.getter(name="ipFilters")
    def ip_filters(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "ip_filters")

    @property
    @pulumi.getter(name="metricsEnabled")
    def metrics_enabled(self) -> Optional[str]:
        return pulumi.get(self, "metrics_enabled")

    @property
    @pulumi.getter(name="privateAccess")
    def private_access(self) -> Optional['outputs.GetServiceGrafanaUserConfigPrivateAccessResult']:
        return pulumi.get(self, "private_access")

    @property
    @pulumi.getter(name="privatelinkAccess")
    def privatelink_access(self) -> Optional['outputs.GetServiceGrafanaUserConfigPrivatelinkAccessResult']:
        return pulumi.get(self, "privatelink_access")

    @property
    @pulumi.getter(name="projectToForkFrom")
    def project_to_fork_from(self) -> Optional[str]:
        return pulumi.get(self, "project_to_fork_from")

    @property
    @pulumi.getter(name="publicAccess")
    def public_access(self) -> Optional['outputs.GetServiceGrafanaUserConfigPublicAccessResult']:
        return pulumi.get(self, "public_access")

    @property
    @pulumi.getter(name="recoveryBasebackupName")
    def recovery_basebackup_name(self) -> Optional[str]:
        return pulumi.get(self, "recovery_basebackup_name")

    @property
    @pulumi.getter(name="serviceToForkFrom")
    def service_to_fork_from(self) -> Optional[str]:
        return pulumi.get(self, "service_to_fork_from")

    @property
    @pulumi.getter(name="smtpServer")
    def smtp_server(self) -> Optional['outputs.GetServiceGrafanaUserConfigSmtpServerResult']:
        return pulumi.get(self, "smtp_server")

    @property
    @pulumi.getter(name="userAutoAssignOrg")
    def user_auto_assign_org(self) -> Optional[str]:
        return pulumi.get(self, "user_auto_assign_org")

    @property
    @pulumi.getter(name="userAutoAssignOrgRole")
    def user_auto_assign_org_role(self) -> Optional[str]:
        return pulumi.get(self, "user_auto_assign_org_role")

    @property
    @pulumi.getter(name="viewersCanEdit")
    def viewers_can_edit(self) -> Optional[str]:
        return pulumi.get(self, "viewers_can_edit")


@pulumi.output_type
class GetServiceGrafanaUserConfigAuthGenericOauthResult(dict):
    def __init__(__self__, *,
                 allow_sign_up: Optional[str] = None,
                 allowed_domains: Optional[Sequence[str]] = None,
                 allowed_organizations: Optional[Sequence[str]] = None,
                 api_url: Optional[str] = None,
                 auth_url: Optional[str] = None,
                 client_id: Optional[str] = None,
                 client_secret: Optional[str] = None,
                 name: Optional[str] = None,
                 scopes: Optional[Sequence[str]] = None,
                 token_url: Optional[str] = None):
        if allow_sign_up is not None:
            pulumi.set(__self__, "allow_sign_up", allow_sign_up)
        if allowed_domains is not None:
            pulumi.set(__self__, "allowed_domains", allowed_domains)
        if allowed_organizations is not None:
            pulumi.set(__self__, "allowed_organizations", allowed_organizations)
        if api_url is not None:
            pulumi.set(__self__, "api_url", api_url)
        if auth_url is not None:
            pulumi.set(__self__, "auth_url", auth_url)
        if client_id is not None:
            pulumi.set(__self__, "client_id", client_id)
        if client_secret is not None:
            pulumi.set(__self__, "client_secret", client_secret)
        if name is not None:
            pulumi.set(__self__, "name", name)
        if scopes is not None:
            pulumi.set(__self__, "scopes", scopes)
        if token_url is not None:
            pulumi.set(__self__, "token_url", token_url)

    @property
    @pulumi.getter(name="allowSignUp")
    def allow_sign_up(self) -> Optional[str]:
        return pulumi.get(self, "allow_sign_up")

    @property
    @pulumi.getter(name="allowedDomains")
    def allowed_domains(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "allowed_domains")

    @property
    @pulumi.getter(name="allowedOrganizations")
    def allowed_organizations(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "allowed_organizations")

    @property
    @pulumi.getter(name="apiUrl")
    def api_url(self) -> Optional[str]:
        return pulumi.get(self, "api_url")

    @property
    @pulumi.getter(name="authUrl")
    def auth_url(self) -> Optional[str]:
        return pulumi.get(self, "auth_url")

    @property
    @pulumi.getter(name="clientId")
    def client_id(self) -> Optional[str]:
        return pulumi.get(self, "client_id")

    @property
    @pulumi.getter(name="clientSecret")
    def client_secret(self) -> Optional[str]:
        return pulumi.get(self, "client_secret")

    @property
    @pulumi.getter
    def name(self) -> Optional[str]:
        return pulumi.get(self, "name")

    @property
    @pulumi.getter
    def scopes(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "scopes")

    @property
    @pulumi.getter(name="tokenUrl")
    def token_url(self) -> Optional[str]:
        return pulumi.get(self, "token_url")


@pulumi.output_type
class GetServiceGrafanaUserConfigAuthGithubResult(dict):
    def __init__(__self__, *,
                 allow_sign_up: Optional[str] = None,
                 allowed_organizations: Optional[Sequence[str]] = None,
                 client_id: Optional[str] = None,
                 client_secret: Optional[str] = None,
                 team_ids: Optional[Sequence[str]] = None):
        if allow_sign_up is not None:
            pulumi.set(__self__, "allow_sign_up", allow_sign_up)
        if allowed_organizations is not None:
            pulumi.set(__self__, "allowed_organizations", allowed_organizations)
        if client_id is not None:
            pulumi.set(__self__, "client_id", client_id)
        if client_secret is not None:
            pulumi.set(__self__, "client_secret", client_secret)
        if team_ids is not None:
            pulumi.set(__self__, "team_ids", team_ids)

    @property
    @pulumi.getter(name="allowSignUp")
    def allow_sign_up(self) -> Optional[str]:
        return pulumi.get(self, "allow_sign_up")

    @property
    @pulumi.getter(name="allowedOrganizations")
    def allowed_organizations(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "allowed_organizations")

    @property
    @pulumi.getter(name="clientId")
    def client_id(self) -> Optional[str]:
        return pulumi.get(self, "client_id")

    @property
    @pulumi.getter(name="clientSecret")
    def client_secret(self) -> Optional[str]:
        return pulumi.get(self, "client_secret")

    @property
    @pulumi.getter(name="teamIds")
    def team_ids(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "team_ids")


@pulumi.output_type
class GetServiceGrafanaUserConfigAuthGitlabResult(dict):
    def __init__(__self__, *,
                 allow_sign_up: Optional[str] = None,
                 allowed_groups: Optional[Sequence[str]] = None,
                 api_url: Optional[str] = None,
                 auth_url: Optional[str] = None,
                 client_id: Optional[str] = None,
                 client_secret: Optional[str] = None,
                 token_url: Optional[str] = None):
        if allow_sign_up is not None:
            pulumi.set(__self__, "allow_sign_up", allow_sign_up)
        if allowed_groups is not None:
            pulumi.set(__self__, "allowed_groups", allowed_groups)
        if api_url is not None:
            pulumi.set(__self__, "api_url", api_url)
        if auth_url is not None:
            pulumi.set(__self__, "auth_url", auth_url)
        if client_id is not None:
            pulumi.set(__self__, "client_id", client_id)
        if client_secret is not None:
            pulumi.set(__self__, "client_secret", client_secret)
        if token_url is not None:
            pulumi.set(__self__, "token_url", token_url)

    @property
    @pulumi.getter(name="allowSignUp")
    def allow_sign_up(self) -> Optional[str]:
        return pulumi.get(self, "allow_sign_up")

    @property
    @pulumi.getter(name="allowedGroups")
    def allowed_groups(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "allowed_groups")

    @property
    @pulumi.getter(name="apiUrl")
    def api_url(self) -> Optional[str]:
        return pulumi.get(self, "api_url")

    @property
    @pulumi.getter(name="authUrl")
    def auth_url(self) -> Optional[str]:
        return pulumi.get(self, "auth_url")

    @property
    @pulumi.getter(name="clientId")
    def client_id(self) -> Optional[str]:
        return pulumi.get(self, "client_id")

    @property
    @pulumi.getter(name="clientSecret")
    def client_secret(self) -> Optional[str]:
        return pulumi.get(self, "client_secret")

    @property
    @pulumi.getter(name="tokenUrl")
    def token_url(self) -> Optional[str]:
        return pulumi.get(self, "token_url")


@pulumi.output_type
class GetServiceGrafanaUserConfigAuthGoogleResult(dict):
    def __init__(__self__, *,
                 allow_sign_up: Optional[str] = None,
                 allowed_domains: Optional[Sequence[str]] = None,
                 client_id: Optional[str] = None,
                 client_secret: Optional[str] = None):
        if allow_sign_up is not None:
            pulumi.set(__self__, "allow_sign_up", allow_sign_up)
        if allowed_domains is not None:
            pulumi.set(__self__, "allowed_domains", allowed_domains)
        if client_id is not None:
            pulumi.set(__self__, "client_id", client_id)
        if client_secret is not None:
            pulumi.set(__self__, "client_secret", client_secret)

    @property
    @pulumi.getter(name="allowSignUp")
    def allow_sign_up(self) -> Optional[str]:
        return pulumi.get(self, "allow_sign_up")

    @property
    @pulumi.getter(name="allowedDomains")
    def allowed_domains(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "allowed_domains")

    @property
    @pulumi.getter(name="clientId")
    def client_id(self) -> Optional[str]:
        return pulumi.get(self, "client_id")

    @property
    @pulumi.getter(name="clientSecret")
    def client_secret(self) -> Optional[str]:
        return pulumi.get(self, "client_secret")


@pulumi.output_type
class GetServiceGrafanaUserConfigExternalImageStorageResult(dict):
    def __init__(__self__, *,
                 access_key: Optional[str] = None,
                 bucket_url: Optional[str] = None,
                 provider: Optional[str] = None,
                 secret_key: Optional[str] = None):
        if access_key is not None:
            pulumi.set(__self__, "access_key", access_key)
        if bucket_url is not None:
            pulumi.set(__self__, "bucket_url", bucket_url)
        if provider is not None:
            pulumi.set(__self__, "provider", provider)
        if secret_key is not None:
            pulumi.set(__self__, "secret_key", secret_key)

    @property
    @pulumi.getter(name="accessKey")
    def access_key(self) -> Optional[str]:
        return pulumi.get(self, "access_key")

    @property
    @pulumi.getter(name="bucketUrl")
    def bucket_url(self) -> Optional[str]:
        return pulumi.get(self, "bucket_url")

    @property
    @pulumi.getter
    def provider(self) -> Optional[str]:
        return pulumi.get(self, "provider")

    @property
    @pulumi.getter(name="secretKey")
    def secret_key(self) -> Optional[str]:
        return pulumi.get(self, "secret_key")


@pulumi.output_type
class GetServiceGrafanaUserConfigPrivateAccessResult(dict):
    def __init__(__self__, *,
                 grafana: Optional[str] = None):
        if grafana is not None:
            pulumi.set(__self__, "grafana", grafana)

    @property
    @pulumi.getter
    def grafana(self) -> Optional[str]:
        return pulumi.get(self, "grafana")


@pulumi.output_type
class GetServiceGrafanaUserConfigPrivatelinkAccessResult(dict):
    def __init__(__self__, *,
                 grafana: Optional[str] = None):
        if grafana is not None:
            pulumi.set(__self__, "grafana", grafana)

    @property
    @pulumi.getter
    def grafana(self) -> Optional[str]:
        return pulumi.get(self, "grafana")


@pulumi.output_type
class GetServiceGrafanaUserConfigPublicAccessResult(dict):
    def __init__(__self__, *,
                 grafana: Optional[str] = None):
        if grafana is not None:
            pulumi.set(__self__, "grafana", grafana)

    @property
    @pulumi.getter
    def grafana(self) -> Optional[str]:
        return pulumi.get(self, "grafana")


@pulumi.output_type
class GetServiceGrafanaUserConfigSmtpServerResult(dict):
    def __init__(__self__, *,
                 from_address: Optional[str] = None,
                 from_name: Optional[str] = None,
                 host: Optional[str] = None,
                 password: Optional[str] = None,
                 port: Optional[str] = None,
                 skip_verify: Optional[str] = None,
                 starttls_policy: Optional[str] = None,
                 username: Optional[str] = None):
        if from_address is not None:
            pulumi.set(__self__, "from_address", from_address)
        if from_name is not None:
            pulumi.set(__self__, "from_name", from_name)
        if host is not None:
            pulumi.set(__self__, "host", host)
        if password is not None:
            pulumi.set(__self__, "password", password)
        if port is not None:
            pulumi.set(__self__, "port", port)
        if skip_verify is not None:
            pulumi.set(__self__, "skip_verify", skip_verify)
        if starttls_policy is not None:
            pulumi.set(__self__, "starttls_policy", starttls_policy)
        if username is not None:
            pulumi.set(__self__, "username", username)

    @property
    @pulumi.getter(name="fromAddress")
    def from_address(self) -> Optional[str]:
        return pulumi.get(self, "from_address")

    @property
    @pulumi.getter(name="fromName")
    def from_name(self) -> Optional[str]:
        return pulumi.get(self, "from_name")

    @property
    @pulumi.getter
    def host(self) -> Optional[str]:
        return pulumi.get(self, "host")

    @property
    @pulumi.getter
    def password(self) -> Optional[str]:
        return pulumi.get(self, "password")

    @property
    @pulumi.getter
    def port(self) -> Optional[str]:
        return pulumi.get(self, "port")

    @property
    @pulumi.getter(name="skipVerify")
    def skip_verify(self) -> Optional[str]:
        return pulumi.get(self, "skip_verify")

    @property
    @pulumi.getter(name="starttlsPolicy")
    def starttls_policy(self) -> Optional[str]:
        return pulumi.get(self, "starttls_policy")

    @property
    @pulumi.getter
    def username(self) -> Optional[str]:
        return pulumi.get(self, "username")


@pulumi.output_type
class GetServiceInfluxdbResult(dict):
    def __init__(__self__, *,
                 database_name: str):
        pulumi.set(__self__, "database_name", database_name)

    @property
    @pulumi.getter(name="databaseName")
    def database_name(self) -> str:
        return pulumi.get(self, "database_name")


@pulumi.output_type
class GetServiceInfluxdbUserConfigResult(dict):
    def __init__(__self__, *,
                 custom_domain: Optional[str] = None,
                 influxdb: Optional['outputs.GetServiceInfluxdbUserConfigInfluxdbResult'] = None,
                 ip_filters: Optional[Sequence[str]] = None,
                 private_access: Optional['outputs.GetServiceInfluxdbUserConfigPrivateAccessResult'] = None,
                 privatelink_access: Optional['outputs.GetServiceInfluxdbUserConfigPrivatelinkAccessResult'] = None,
                 project_to_fork_from: Optional[str] = None,
                 public_access: Optional['outputs.GetServiceInfluxdbUserConfigPublicAccessResult'] = None,
                 recovery_basebackup_name: Optional[str] = None,
                 service_to_fork_from: Optional[str] = None):
        if custom_domain is not None:
            pulumi.set(__self__, "custom_domain", custom_domain)
        if influxdb is not None:
            pulumi.set(__self__, "influxdb", influxdb)
        if ip_filters is not None:
            pulumi.set(__self__, "ip_filters", ip_filters)
        if private_access is not None:
            pulumi.set(__self__, "private_access", private_access)
        if privatelink_access is not None:
            pulumi.set(__self__, "privatelink_access", privatelink_access)
        if project_to_fork_from is not None:
            pulumi.set(__self__, "project_to_fork_from", project_to_fork_from)
        if public_access is not None:
            pulumi.set(__self__, "public_access", public_access)
        if recovery_basebackup_name is not None:
            pulumi.set(__self__, "recovery_basebackup_name", recovery_basebackup_name)
        if service_to_fork_from is not None:
            pulumi.set(__self__, "service_to_fork_from", service_to_fork_from)

    @property
    @pulumi.getter(name="customDomain")
    def custom_domain(self) -> Optional[str]:
        return pulumi.get(self, "custom_domain")

    @property
    @pulumi.getter
    def influxdb(self) -> Optional['outputs.GetServiceInfluxdbUserConfigInfluxdbResult']:
        return pulumi.get(self, "influxdb")

    @property
    @pulumi.getter(name="ipFilters")
    def ip_filters(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "ip_filters")

    @property
    @pulumi.getter(name="privateAccess")
    def private_access(self) -> Optional['outputs.GetServiceInfluxdbUserConfigPrivateAccessResult']:
        return pulumi.get(self, "private_access")

    @property
    @pulumi.getter(name="privatelinkAccess")
    def privatelink_access(self) -> Optional['outputs.GetServiceInfluxdbUserConfigPrivatelinkAccessResult']:
        return pulumi.get(self, "privatelink_access")

    @property
    @pulumi.getter(name="projectToForkFrom")
    def project_to_fork_from(self) -> Optional[str]:
        return pulumi.get(self, "project_to_fork_from")

    @property
    @pulumi.getter(name="publicAccess")
    def public_access(self) -> Optional['outputs.GetServiceInfluxdbUserConfigPublicAccessResult']:
        return pulumi.get(self, "public_access")

    @property
    @pulumi.getter(name="recoveryBasebackupName")
    def recovery_basebackup_name(self) -> Optional[str]:
        return pulumi.get(self, "recovery_basebackup_name")

    @property
    @pulumi.getter(name="serviceToForkFrom")
    def service_to_fork_from(self) -> Optional[str]:
        return pulumi.get(self, "service_to_fork_from")


@pulumi.output_type
class GetServiceInfluxdbUserConfigInfluxdbResult(dict):
    def __init__(__self__, *,
                 log_queries_after: Optional[str] = None,
                 max_row_limit: Optional[str] = None,
                 max_select_buckets: Optional[str] = None,
                 max_select_point: Optional[str] = None,
                 query_timeout: Optional[str] = None):
        if log_queries_after is not None:
            pulumi.set(__self__, "log_queries_after", log_queries_after)
        if max_row_limit is not None:
            pulumi.set(__self__, "max_row_limit", max_row_limit)
        if max_select_buckets is not None:
            pulumi.set(__self__, "max_select_buckets", max_select_buckets)
        if max_select_point is not None:
            pulumi.set(__self__, "max_select_point", max_select_point)
        if query_timeout is not None:
            pulumi.set(__self__, "query_timeout", query_timeout)

    @property
    @pulumi.getter(name="logQueriesAfter")
    def log_queries_after(self) -> Optional[str]:
        return pulumi.get(self, "log_queries_after")

    @property
    @pulumi.getter(name="maxRowLimit")
    def max_row_limit(self) -> Optional[str]:
        return pulumi.get(self, "max_row_limit")

    @property
    @pulumi.getter(name="maxSelectBuckets")
    def max_select_buckets(self) -> Optional[str]:
        return pulumi.get(self, "max_select_buckets")

    @property
    @pulumi.getter(name="maxSelectPoint")
    def max_select_point(self) -> Optional[str]:
        return pulumi.get(self, "max_select_point")

    @property
    @pulumi.getter(name="queryTimeout")
    def query_timeout(self) -> Optional[str]:
        return pulumi.get(self, "query_timeout")


@pulumi.output_type
class GetServiceInfluxdbUserConfigPrivateAccessResult(dict):
    def __init__(__self__, *,
                 influxdb: Optional[str] = None):
        if influxdb is not None:
            pulumi.set(__self__, "influxdb", influxdb)

    @property
    @pulumi.getter
    def influxdb(self) -> Optional[str]:
        return pulumi.get(self, "influxdb")


@pulumi.output_type
class GetServiceInfluxdbUserConfigPrivatelinkAccessResult(dict):
    def __init__(__self__, *,
                 influxdb: Optional[str] = None):
        if influxdb is not None:
            pulumi.set(__self__, "influxdb", influxdb)

    @property
    @pulumi.getter
    def influxdb(self) -> Optional[str]:
        return pulumi.get(self, "influxdb")


@pulumi.output_type
class GetServiceInfluxdbUserConfigPublicAccessResult(dict):
    def __init__(__self__, *,
                 influxdb: Optional[str] = None):
        if influxdb is not None:
            pulumi.set(__self__, "influxdb", influxdb)

    @property
    @pulumi.getter
    def influxdb(self) -> Optional[str]:
        return pulumi.get(self, "influxdb")


@pulumi.output_type
class GetServiceIntegrationDashboardUserConfigResult(dict):
    def __init__(__self__):
        pass


@pulumi.output_type
class GetServiceIntegrationDatadogUserConfigResult(dict):
    def __init__(__self__, *,
                 datadog_tags: Optional[Sequence['outputs.GetServiceIntegrationDatadogUserConfigDatadogTagResult']] = None,
                 exclude_consumer_groups: Optional[Sequence[str]] = None,
                 exclude_topics: Optional[Sequence[str]] = None,
                 include_consumer_groups: Optional[Sequence[str]] = None,
                 include_topics: Optional[Sequence[str]] = None,
                 kafka_custom_metrics: Optional[Sequence[str]] = None,
                 max_jmx_metrics: Optional[str] = None):
        if datadog_tags is not None:
            pulumi.set(__self__, "datadog_tags", datadog_tags)
        if exclude_consumer_groups is not None:
            pulumi.set(__self__, "exclude_consumer_groups", exclude_consumer_groups)
        if exclude_topics is not None:
            pulumi.set(__self__, "exclude_topics", exclude_topics)
        if include_consumer_groups is not None:
            pulumi.set(__self__, "include_consumer_groups", include_consumer_groups)
        if include_topics is not None:
            pulumi.set(__self__, "include_topics", include_topics)
        if kafka_custom_metrics is not None:
            pulumi.set(__self__, "kafka_custom_metrics", kafka_custom_metrics)
        if max_jmx_metrics is not None:
            pulumi.set(__self__, "max_jmx_metrics", max_jmx_metrics)

    @property
    @pulumi.getter(name="datadogTags")
    def datadog_tags(self) -> Optional[Sequence['outputs.GetServiceIntegrationDatadogUserConfigDatadogTagResult']]:
        return pulumi.get(self, "datadog_tags")

    @property
    @pulumi.getter(name="excludeConsumerGroups")
    def exclude_consumer_groups(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "exclude_consumer_groups")

    @property
    @pulumi.getter(name="excludeTopics")
    def exclude_topics(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "exclude_topics")

    @property
    @pulumi.getter(name="includeConsumerGroups")
    def include_consumer_groups(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "include_consumer_groups")

    @property
    @pulumi.getter(name="includeTopics")
    def include_topics(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "include_topics")

    @property
    @pulumi.getter(name="kafkaCustomMetrics")
    def kafka_custom_metrics(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "kafka_custom_metrics")

    @property
    @pulumi.getter(name="maxJmxMetrics")
    def max_jmx_metrics(self) -> Optional[str]:
        return pulumi.get(self, "max_jmx_metrics")


@pulumi.output_type
class GetServiceIntegrationDatadogUserConfigDatadogTagResult(dict):
    def __init__(__self__, *,
                 comment: Optional[str] = None,
                 tag: Optional[str] = None):
        if comment is not None:
            pulumi.set(__self__, "comment", comment)
        if tag is not None:
            pulumi.set(__self__, "tag", tag)

    @property
    @pulumi.getter
    def comment(self) -> Optional[str]:
        return pulumi.get(self, "comment")

    @property
    @pulumi.getter
    def tag(self) -> Optional[str]:
        return pulumi.get(self, "tag")


@pulumi.output_type
class GetServiceIntegrationEndpointDatadogUserConfigResult(dict):
    def __init__(__self__, *,
                 datadog_api_key: Optional[str] = None,
                 datadog_tags: Optional[Sequence['outputs.GetServiceIntegrationEndpointDatadogUserConfigDatadogTagResult']] = None,
                 disable_consumer_stats: Optional[str] = None,
                 max_partition_contexts: Optional[str] = None,
                 site: Optional[str] = None):
        if datadog_api_key is not None:
            pulumi.set(__self__, "datadog_api_key", datadog_api_key)
        if datadog_tags is not None:
            pulumi.set(__self__, "datadog_tags", datadog_tags)
        if disable_consumer_stats is not None:
            pulumi.set(__self__, "disable_consumer_stats", disable_consumer_stats)
        if max_partition_contexts is not None:
            pulumi.set(__self__, "max_partition_contexts", max_partition_contexts)
        if site is not None:
            pulumi.set(__self__, "site", site)

    @property
    @pulumi.getter(name="datadogApiKey")
    def datadog_api_key(self) -> Optional[str]:
        return pulumi.get(self, "datadog_api_key")

    @property
    @pulumi.getter(name="datadogTags")
    def datadog_tags(self) -> Optional[Sequence['outputs.GetServiceIntegrationEndpointDatadogUserConfigDatadogTagResult']]:
        return pulumi.get(self, "datadog_tags")

    @property
    @pulumi.getter(name="disableConsumerStats")
    def disable_consumer_stats(self) -> Optional[str]:
        return pulumi.get(self, "disable_consumer_stats")

    @property
    @pulumi.getter(name="maxPartitionContexts")
    def max_partition_contexts(self) -> Optional[str]:
        return pulumi.get(self, "max_partition_contexts")

    @property
    @pulumi.getter
    def site(self) -> Optional[str]:
        return pulumi.get(self, "site")


@pulumi.output_type
class GetServiceIntegrationEndpointDatadogUserConfigDatadogTagResult(dict):
    def __init__(__self__, *,
                 comment: Optional[str] = None,
                 tag: Optional[str] = None):
        if comment is not None:
            pulumi.set(__self__, "comment", comment)
        if tag is not None:
            pulumi.set(__self__, "tag", tag)

    @property
    @pulumi.getter
    def comment(self) -> Optional[str]:
        return pulumi.get(self, "comment")

    @property
    @pulumi.getter
    def tag(self) -> Optional[str]:
        return pulumi.get(self, "tag")


@pulumi.output_type
class GetServiceIntegrationEndpointExternalAwsCloudwatchLogsUserConfigResult(dict):
    def __init__(__self__, *,
                 access_key: Optional[str] = None,
                 log_group_name: Optional[str] = None,
                 region: Optional[str] = None,
                 secret_key: Optional[str] = None):
        if access_key is not None:
            pulumi.set(__self__, "access_key", access_key)
        if log_group_name is not None:
            pulumi.set(__self__, "log_group_name", log_group_name)
        if region is not None:
            pulumi.set(__self__, "region", region)
        if secret_key is not None:
            pulumi.set(__self__, "secret_key", secret_key)

    @property
    @pulumi.getter(name="accessKey")
    def access_key(self) -> Optional[str]:
        return pulumi.get(self, "access_key")

    @property
    @pulumi.getter(name="logGroupName")
    def log_group_name(self) -> Optional[str]:
        return pulumi.get(self, "log_group_name")

    @property
    @pulumi.getter
    def region(self) -> Optional[str]:
        return pulumi.get(self, "region")

    @property
    @pulumi.getter(name="secretKey")
    def secret_key(self) -> Optional[str]:
        return pulumi.get(self, "secret_key")


@pulumi.output_type
class GetServiceIntegrationEndpointExternalAwsCloudwatchMetricsUserConfigResult(dict):
    def __init__(__self__, *,
                 access_key: Optional[str] = None,
                 namespace: Optional[str] = None,
                 region: Optional[str] = None,
                 secret_key: Optional[str] = None):
        if access_key is not None:
            pulumi.set(__self__, "access_key", access_key)
        if namespace is not None:
            pulumi.set(__self__, "namespace", namespace)
        if region is not None:
            pulumi.set(__self__, "region", region)
        if secret_key is not None:
            pulumi.set(__self__, "secret_key", secret_key)

    @property
    @pulumi.getter(name="accessKey")
    def access_key(self) -> Optional[str]:
        return pulumi.get(self, "access_key")

    @property
    @pulumi.getter
    def namespace(self) -> Optional[str]:
        return pulumi.get(self, "namespace")

    @property
    @pulumi.getter
    def region(self) -> Optional[str]:
        return pulumi.get(self, "region")

    @property
    @pulumi.getter(name="secretKey")
    def secret_key(self) -> Optional[str]:
        return pulumi.get(self, "secret_key")


@pulumi.output_type
class GetServiceIntegrationEndpointExternalElasticsearchLogsUserConfigResult(dict):
    def __init__(__self__, *,
                 ca: Optional[str] = None,
                 index_days_max: Optional[str] = None,
                 index_prefix: Optional[str] = None,
                 timeout: Optional[str] = None,
                 url: Optional[str] = None):
        if ca is not None:
            pulumi.set(__self__, "ca", ca)
        if index_days_max is not None:
            pulumi.set(__self__, "index_days_max", index_days_max)
        if index_prefix is not None:
            pulumi.set(__self__, "index_prefix", index_prefix)
        if timeout is not None:
            pulumi.set(__self__, "timeout", timeout)
        if url is not None:
            pulumi.set(__self__, "url", url)

    @property
    @pulumi.getter
    def ca(self) -> Optional[str]:
        return pulumi.get(self, "ca")

    @property
    @pulumi.getter(name="indexDaysMax")
    def index_days_max(self) -> Optional[str]:
        return pulumi.get(self, "index_days_max")

    @property
    @pulumi.getter(name="indexPrefix")
    def index_prefix(self) -> Optional[str]:
        return pulumi.get(self, "index_prefix")

    @property
    @pulumi.getter
    def timeout(self) -> Optional[str]:
        return pulumi.get(self, "timeout")

    @property
    @pulumi.getter
    def url(self) -> Optional[str]:
        return pulumi.get(self, "url")


@pulumi.output_type
class GetServiceIntegrationEndpointExternalGoogleCloudLoggingUserConfigResult(dict):
    def __init__(__self__, *,
                 log_id: Optional[str] = None,
                 project_id: Optional[str] = None,
                 service_account_credentials: Optional[str] = None):
        if log_id is not None:
            pulumi.set(__self__, "log_id", log_id)
        if project_id is not None:
            pulumi.set(__self__, "project_id", project_id)
        if service_account_credentials is not None:
            pulumi.set(__self__, "service_account_credentials", service_account_credentials)

    @property
    @pulumi.getter(name="logId")
    def log_id(self) -> Optional[str]:
        return pulumi.get(self, "log_id")

    @property
    @pulumi.getter(name="projectId")
    def project_id(self) -> Optional[str]:
        return pulumi.get(self, "project_id")

    @property
    @pulumi.getter(name="serviceAccountCredentials")
    def service_account_credentials(self) -> Optional[str]:
        return pulumi.get(self, "service_account_credentials")


@pulumi.output_type
class GetServiceIntegrationEndpointExternalKafkaUserConfigResult(dict):
    def __init__(__self__, *,
                 bootstrap_servers: Optional[str] = None,
                 sasl_mechanism: Optional[str] = None,
                 sasl_plain_password: Optional[str] = None,
                 sasl_plain_username: Optional[str] = None,
                 security_protocol: Optional[str] = None,
                 ssl_ca_cert: Optional[str] = None,
                 ssl_client_cert: Optional[str] = None,
                 ssl_client_key: Optional[str] = None,
                 ssl_endpoint_identification_algorithm: Optional[str] = None):
        if bootstrap_servers is not None:
            pulumi.set(__self__, "bootstrap_servers", bootstrap_servers)
        if sasl_mechanism is not None:
            pulumi.set(__self__, "sasl_mechanism", sasl_mechanism)
        if sasl_plain_password is not None:
            pulumi.set(__self__, "sasl_plain_password", sasl_plain_password)
        if sasl_plain_username is not None:
            pulumi.set(__self__, "sasl_plain_username", sasl_plain_username)
        if security_protocol is not None:
            pulumi.set(__self__, "security_protocol", security_protocol)
        if ssl_ca_cert is not None:
            pulumi.set(__self__, "ssl_ca_cert", ssl_ca_cert)
        if ssl_client_cert is not None:
            pulumi.set(__self__, "ssl_client_cert", ssl_client_cert)
        if ssl_client_key is not None:
            pulumi.set(__self__, "ssl_client_key", ssl_client_key)
        if ssl_endpoint_identification_algorithm is not None:
            pulumi.set(__self__, "ssl_endpoint_identification_algorithm", ssl_endpoint_identification_algorithm)

    @property
    @pulumi.getter(name="bootstrapServers")
    def bootstrap_servers(self) -> Optional[str]:
        return pulumi.get(self, "bootstrap_servers")

    @property
    @pulumi.getter(name="saslMechanism")
    def sasl_mechanism(self) -> Optional[str]:
        return pulumi.get(self, "sasl_mechanism")

    @property
    @pulumi.getter(name="saslPlainPassword")
    def sasl_plain_password(self) -> Optional[str]:
        return pulumi.get(self, "sasl_plain_password")

    @property
    @pulumi.getter(name="saslPlainUsername")
    def sasl_plain_username(self) -> Optional[str]:
        return pulumi.get(self, "sasl_plain_username")

    @property
    @pulumi.getter(name="securityProtocol")
    def security_protocol(self) -> Optional[str]:
        return pulumi.get(self, "security_protocol")

    @property
    @pulumi.getter(name="sslCaCert")
    def ssl_ca_cert(self) -> Optional[str]:
        return pulumi.get(self, "ssl_ca_cert")

    @property
    @pulumi.getter(name="sslClientCert")
    def ssl_client_cert(self) -> Optional[str]:
        return pulumi.get(self, "ssl_client_cert")

    @property
    @pulumi.getter(name="sslClientKey")
    def ssl_client_key(self) -> Optional[str]:
        return pulumi.get(self, "ssl_client_key")

    @property
    @pulumi.getter(name="sslEndpointIdentificationAlgorithm")
    def ssl_endpoint_identification_algorithm(self) -> Optional[str]:
        return pulumi.get(self, "ssl_endpoint_identification_algorithm")


@pulumi.output_type
class GetServiceIntegrationEndpointExternalSchemaRegistryUserConfigResult(dict):
    def __init__(__self__, *,
                 authentication: Optional[str] = None,
                 basic_auth_password: Optional[str] = None,
                 basic_auth_username: Optional[str] = None,
                 url: Optional[str] = None):
        if authentication is not None:
            pulumi.set(__self__, "authentication", authentication)
        if basic_auth_password is not None:
            pulumi.set(__self__, "basic_auth_password", basic_auth_password)
        if basic_auth_username is not None:
            pulumi.set(__self__, "basic_auth_username", basic_auth_username)
        if url is not None:
            pulumi.set(__self__, "url", url)

    @property
    @pulumi.getter
    def authentication(self) -> Optional[str]:
        return pulumi.get(self, "authentication")

    @property
    @pulumi.getter(name="basicAuthPassword")
    def basic_auth_password(self) -> Optional[str]:
        return pulumi.get(self, "basic_auth_password")

    @property
    @pulumi.getter(name="basicAuthUsername")
    def basic_auth_username(self) -> Optional[str]:
        return pulumi.get(self, "basic_auth_username")

    @property
    @pulumi.getter
    def url(self) -> Optional[str]:
        return pulumi.get(self, "url")


@pulumi.output_type
class GetServiceIntegrationEndpointJolokiaUserConfigResult(dict):
    def __init__(__self__, *,
                 basic_auth_password: Optional[str] = None,
                 basic_auth_username: Optional[str] = None):
        if basic_auth_password is not None:
            pulumi.set(__self__, "basic_auth_password", basic_auth_password)
        if basic_auth_username is not None:
            pulumi.set(__self__, "basic_auth_username", basic_auth_username)

    @property
    @pulumi.getter(name="basicAuthPassword")
    def basic_auth_password(self) -> Optional[str]:
        return pulumi.get(self, "basic_auth_password")

    @property
    @pulumi.getter(name="basicAuthUsername")
    def basic_auth_username(self) -> Optional[str]:
        return pulumi.get(self, "basic_auth_username")


@pulumi.output_type
class GetServiceIntegrationEndpointPrometheusUserConfigResult(dict):
    def __init__(__self__, *,
                 basic_auth_password: Optional[str] = None,
                 basic_auth_username: Optional[str] = None):
        if basic_auth_password is not None:
            pulumi.set(__self__, "basic_auth_password", basic_auth_password)
        if basic_auth_username is not None:
            pulumi.set(__self__, "basic_auth_username", basic_auth_username)

    @property
    @pulumi.getter(name="basicAuthPassword")
    def basic_auth_password(self) -> Optional[str]:
        return pulumi.get(self, "basic_auth_password")

    @property
    @pulumi.getter(name="basicAuthUsername")
    def basic_auth_username(self) -> Optional[str]:
        return pulumi.get(self, "basic_auth_username")


@pulumi.output_type
class GetServiceIntegrationEndpointRsyslogUserConfigResult(dict):
    def __init__(__self__, *,
                 ca: Optional[str] = None,
                 cert: Optional[str] = None,
                 format: Optional[str] = None,
                 key: Optional[str] = None,
                 logline: Optional[str] = None,
                 port: Optional[str] = None,
                 sd: Optional[str] = None,
                 server: Optional[str] = None,
                 tls: Optional[str] = None):
        if ca is not None:
            pulumi.set(__self__, "ca", ca)
        if cert is not None:
            pulumi.set(__self__, "cert", cert)
        if format is not None:
            pulumi.set(__self__, "format", format)
        if key is not None:
            pulumi.set(__self__, "key", key)
        if logline is not None:
            pulumi.set(__self__, "logline", logline)
        if port is not None:
            pulumi.set(__self__, "port", port)
        if sd is not None:
            pulumi.set(__self__, "sd", sd)
        if server is not None:
            pulumi.set(__self__, "server", server)
        if tls is not None:
            pulumi.set(__self__, "tls", tls)

    @property
    @pulumi.getter
    def ca(self) -> Optional[str]:
        return pulumi.get(self, "ca")

    @property
    @pulumi.getter
    def cert(self) -> Optional[str]:
        return pulumi.get(self, "cert")

    @property
    @pulumi.getter
    def format(self) -> Optional[str]:
        return pulumi.get(self, "format")

    @property
    @pulumi.getter
    def key(self) -> Optional[str]:
        return pulumi.get(self, "key")

    @property
    @pulumi.getter
    def logline(self) -> Optional[str]:
        return pulumi.get(self, "logline")

    @property
    @pulumi.getter
    def port(self) -> Optional[str]:
        return pulumi.get(self, "port")

    @property
    @pulumi.getter
    def sd(self) -> Optional[str]:
        return pulumi.get(self, "sd")

    @property
    @pulumi.getter
    def server(self) -> Optional[str]:
        return pulumi.get(self, "server")

    @property
    @pulumi.getter
    def tls(self) -> Optional[str]:
        return pulumi.get(self, "tls")


@pulumi.output_type
class GetServiceIntegrationEndpointSignalfxUserConfigResult(dict):
    def __init__(__self__, *,
                 enabled_metrics: Optional[Sequence[str]] = None,
                 signalfx_api_key: Optional[str] = None,
                 signalfx_realm: Optional[str] = None):
        if enabled_metrics is not None:
            pulumi.set(__self__, "enabled_metrics", enabled_metrics)
        if signalfx_api_key is not None:
            pulumi.set(__self__, "signalfx_api_key", signalfx_api_key)
        if signalfx_realm is not None:
            pulumi.set(__self__, "signalfx_realm", signalfx_realm)

    @property
    @pulumi.getter(name="enabledMetrics")
    def enabled_metrics(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "enabled_metrics")

    @property
    @pulumi.getter(name="signalfxApiKey")
    def signalfx_api_key(self) -> Optional[str]:
        return pulumi.get(self, "signalfx_api_key")

    @property
    @pulumi.getter(name="signalfxRealm")
    def signalfx_realm(self) -> Optional[str]:
        return pulumi.get(self, "signalfx_realm")


@pulumi.output_type
class GetServiceIntegrationExternalAwsCloudwatchLogsUserConfigResult(dict):
    def __init__(__self__):
        pass


@pulumi.output_type
class GetServiceIntegrationExternalAwsCloudwatchMetricsUserConfigResult(dict):
    def __init__(__self__, *,
                 dropped_metrics: Optional[Sequence['outputs.GetServiceIntegrationExternalAwsCloudwatchMetricsUserConfigDroppedMetricResult']] = None,
                 extra_metrics: Optional[Sequence['outputs.GetServiceIntegrationExternalAwsCloudwatchMetricsUserConfigExtraMetricResult']] = None):
        if dropped_metrics is not None:
            pulumi.set(__self__, "dropped_metrics", dropped_metrics)
        if extra_metrics is not None:
            pulumi.set(__self__, "extra_metrics", extra_metrics)

    @property
    @pulumi.getter(name="droppedMetrics")
    def dropped_metrics(self) -> Optional[Sequence['outputs.GetServiceIntegrationExternalAwsCloudwatchMetricsUserConfigDroppedMetricResult']]:
        return pulumi.get(self, "dropped_metrics")

    @property
    @pulumi.getter(name="extraMetrics")
    def extra_metrics(self) -> Optional[Sequence['outputs.GetServiceIntegrationExternalAwsCloudwatchMetricsUserConfigExtraMetricResult']]:
        return pulumi.get(self, "extra_metrics")


@pulumi.output_type
class GetServiceIntegrationExternalAwsCloudwatchMetricsUserConfigDroppedMetricResult(dict):
    def __init__(__self__, *,
                 field: Optional[str] = None,
                 metric: Optional[str] = None):
        if field is not None:
            pulumi.set(__self__, "field", field)
        if metric is not None:
            pulumi.set(__self__, "metric", metric)

    @property
    @pulumi.getter
    def field(self) -> Optional[str]:
        return pulumi.get(self, "field")

    @property
    @pulumi.getter
    def metric(self) -> Optional[str]:
        return pulumi.get(self, "metric")


@pulumi.output_type
class GetServiceIntegrationExternalAwsCloudwatchMetricsUserConfigExtraMetricResult(dict):
    def __init__(__self__, *,
                 field: Optional[str] = None,
                 metric: Optional[str] = None):
        if field is not None:
            pulumi.set(__self__, "field", field)
        if metric is not None:
            pulumi.set(__self__, "metric", metric)

    @property
    @pulumi.getter
    def field(self) -> Optional[str]:
        return pulumi.get(self, "field")

    @property
    @pulumi.getter
    def metric(self) -> Optional[str]:
        return pulumi.get(self, "metric")


@pulumi.output_type
class GetServiceIntegrationExternalElasticsearchLogsUserConfigResult(dict):
    def __init__(__self__):
        pass


@pulumi.output_type
class GetServiceIntegrationExternalGoogleCloudLoggingUserConfigResult(dict):
    def __init__(__self__):
        pass


@pulumi.output_type
class GetServiceIntegrationKafkaConnectUserConfigResult(dict):
    def __init__(__self__, *,
                 kafka_connect: Optional['outputs.GetServiceIntegrationKafkaConnectUserConfigKafkaConnectResult'] = None):
        if kafka_connect is not None:
            pulumi.set(__self__, "kafka_connect", kafka_connect)

    @property
    @pulumi.getter(name="kafkaConnect")
    def kafka_connect(self) -> Optional['outputs.GetServiceIntegrationKafkaConnectUserConfigKafkaConnectResult']:
        return pulumi.get(self, "kafka_connect")


@pulumi.output_type
class GetServiceIntegrationKafkaConnectUserConfigKafkaConnectResult(dict):
    def __init__(__self__, *,
                 config_storage_topic: Optional[str] = None,
                 group_id: Optional[str] = None,
                 offset_storage_topic: Optional[str] = None,
                 status_storage_topic: Optional[str] = None):
        if config_storage_topic is not None:
            pulumi.set(__self__, "config_storage_topic", config_storage_topic)
        if group_id is not None:
            pulumi.set(__self__, "group_id", group_id)
        if offset_storage_topic is not None:
            pulumi.set(__self__, "offset_storage_topic", offset_storage_topic)
        if status_storage_topic is not None:
            pulumi.set(__self__, "status_storage_topic", status_storage_topic)

    @property
    @pulumi.getter(name="configStorageTopic")
    def config_storage_topic(self) -> Optional[str]:
        return pulumi.get(self, "config_storage_topic")

    @property
    @pulumi.getter(name="groupId")
    def group_id(self) -> Optional[str]:
        return pulumi.get(self, "group_id")

    @property
    @pulumi.getter(name="offsetStorageTopic")
    def offset_storage_topic(self) -> Optional[str]:
        return pulumi.get(self, "offset_storage_topic")

    @property
    @pulumi.getter(name="statusStorageTopic")
    def status_storage_topic(self) -> Optional[str]:
        return pulumi.get(self, "status_storage_topic")


@pulumi.output_type
class GetServiceIntegrationKafkaLogsUserConfigResult(dict):
    def __init__(__self__, *,
                 kafka_topic: Optional[str] = None):
        if kafka_topic is not None:
            pulumi.set(__self__, "kafka_topic", kafka_topic)

    @property
    @pulumi.getter(name="kafkaTopic")
    def kafka_topic(self) -> Optional[str]:
        return pulumi.get(self, "kafka_topic")


@pulumi.output_type
class GetServiceIntegrationKafkaMirrormakerUserConfigResult(dict):
    def __init__(__self__, *,
                 cluster_alias: Optional[str] = None):
        if cluster_alias is not None:
            pulumi.set(__self__, "cluster_alias", cluster_alias)

    @property
    @pulumi.getter(name="clusterAlias")
    def cluster_alias(self) -> Optional[str]:
        return pulumi.get(self, "cluster_alias")


@pulumi.output_type
class GetServiceIntegrationLogsUserConfigResult(dict):
    def __init__(__self__, *,
                 elasticsearch_index_days_max: Optional[str] = None,
                 elasticsearch_index_prefix: Optional[str] = None):
        if elasticsearch_index_days_max is not None:
            pulumi.set(__self__, "elasticsearch_index_days_max", elasticsearch_index_days_max)
        if elasticsearch_index_prefix is not None:
            pulumi.set(__self__, "elasticsearch_index_prefix", elasticsearch_index_prefix)

    @property
    @pulumi.getter(name="elasticsearchIndexDaysMax")
    def elasticsearch_index_days_max(self) -> Optional[str]:
        return pulumi.get(self, "elasticsearch_index_days_max")

    @property
    @pulumi.getter(name="elasticsearchIndexPrefix")
    def elasticsearch_index_prefix(self) -> Optional[str]:
        return pulumi.get(self, "elasticsearch_index_prefix")


@pulumi.output_type
class GetServiceIntegrationM3aggregatorUserConfigResult(dict):
    def __init__(__self__):
        pass


@pulumi.output_type
class GetServiceIntegrationM3coordinatorUserConfigResult(dict):
    def __init__(__self__):
        pass


@pulumi.output_type
class GetServiceIntegrationMetricsUserConfigResult(dict):
    def __init__(__self__, *,
                 database: Optional[str] = None,
                 retention_days: Optional[str] = None,
                 ro_username: Optional[str] = None,
                 source_mysql: Optional['outputs.GetServiceIntegrationMetricsUserConfigSourceMysqlResult'] = None,
                 username: Optional[str] = None):
        if database is not None:
            pulumi.set(__self__, "database", database)
        if retention_days is not None:
            pulumi.set(__self__, "retention_days", retention_days)
        if ro_username is not None:
            pulumi.set(__self__, "ro_username", ro_username)
        if source_mysql is not None:
            pulumi.set(__self__, "source_mysql", source_mysql)
        if username is not None:
            pulumi.set(__self__, "username", username)

    @property
    @pulumi.getter
    def database(self) -> Optional[str]:
        return pulumi.get(self, "database")

    @property
    @pulumi.getter(name="retentionDays")
    def retention_days(self) -> Optional[str]:
        return pulumi.get(self, "retention_days")

    @property
    @pulumi.getter(name="roUsername")
    def ro_username(self) -> Optional[str]:
        return pulumi.get(self, "ro_username")

    @property
    @pulumi.getter(name="sourceMysql")
    def source_mysql(self) -> Optional['outputs.GetServiceIntegrationMetricsUserConfigSourceMysqlResult']:
        return pulumi.get(self, "source_mysql")

    @property
    @pulumi.getter
    def username(self) -> Optional[str]:
        return pulumi.get(self, "username")


@pulumi.output_type
class GetServiceIntegrationMetricsUserConfigSourceMysqlResult(dict):
    def __init__(__self__, *,
                 telegraf: Optional['outputs.GetServiceIntegrationMetricsUserConfigSourceMysqlTelegrafResult'] = None):
        if telegraf is not None:
            pulumi.set(__self__, "telegraf", telegraf)

    @property
    @pulumi.getter
    def telegraf(self) -> Optional['outputs.GetServiceIntegrationMetricsUserConfigSourceMysqlTelegrafResult']:
        return pulumi.get(self, "telegraf")


@pulumi.output_type
class GetServiceIntegrationMetricsUserConfigSourceMysqlTelegrafResult(dict):
    def __init__(__self__, *,
                 gather_event_waits: Optional[str] = None,
                 gather_file_events_stats: Optional[str] = None,
                 gather_index_io_waits: Optional[str] = None,
                 gather_info_schema_auto_inc: Optional[str] = None,
                 gather_innodb_metrics: Optional[str] = None,
                 gather_perf_events_statements: Optional[str] = None,
                 gather_process_list: Optional[str] = None,
                 gather_slave_status: Optional[str] = None,
                 gather_table_io_waits: Optional[str] = None,
                 gather_table_lock_waits: Optional[str] = None,
                 gather_table_schema: Optional[str] = None,
                 perf_events_statements_digest_text_limit: Optional[str] = None,
                 perf_events_statements_limit: Optional[str] = None,
                 perf_events_statements_time_limit: Optional[str] = None):
        if gather_event_waits is not None:
            pulumi.set(__self__, "gather_event_waits", gather_event_waits)
        if gather_file_events_stats is not None:
            pulumi.set(__self__, "gather_file_events_stats", gather_file_events_stats)
        if gather_index_io_waits is not None:
            pulumi.set(__self__, "gather_index_io_waits", gather_index_io_waits)
        if gather_info_schema_auto_inc is not None:
            pulumi.set(__self__, "gather_info_schema_auto_inc", gather_info_schema_auto_inc)
        if gather_innodb_metrics is not None:
            pulumi.set(__self__, "gather_innodb_metrics", gather_innodb_metrics)
        if gather_perf_events_statements is not None:
            pulumi.set(__self__, "gather_perf_events_statements", gather_perf_events_statements)
        if gather_process_list is not None:
            pulumi.set(__self__, "gather_process_list", gather_process_list)
        if gather_slave_status is not None:
            pulumi.set(__self__, "gather_slave_status", gather_slave_status)
        if gather_table_io_waits is not None:
            pulumi.set(__self__, "gather_table_io_waits", gather_table_io_waits)
        if gather_table_lock_waits is not None:
            pulumi.set(__self__, "gather_table_lock_waits", gather_table_lock_waits)
        if gather_table_schema is not None:
            pulumi.set(__self__, "gather_table_schema", gather_table_schema)
        if perf_events_statements_digest_text_limit is not None:
            pulumi.set(__self__, "perf_events_statements_digest_text_limit", perf_events_statements_digest_text_limit)
        if perf_events_statements_limit is not None:
            pulumi.set(__self__, "perf_events_statements_limit", perf_events_statements_limit)
        if perf_events_statements_time_limit is not None:
            pulumi.set(__self__, "perf_events_statements_time_limit", perf_events_statements_time_limit)

    @property
    @pulumi.getter(name="gatherEventWaits")
    def gather_event_waits(self) -> Optional[str]:
        return pulumi.get(self, "gather_event_waits")

    @property
    @pulumi.getter(name="gatherFileEventsStats")
    def gather_file_events_stats(self) -> Optional[str]:
        return pulumi.get(self, "gather_file_events_stats")

    @property
    @pulumi.getter(name="gatherIndexIoWaits")
    def gather_index_io_waits(self) -> Optional[str]:
        return pulumi.get(self, "gather_index_io_waits")

    @property
    @pulumi.getter(name="gatherInfoSchemaAutoInc")
    def gather_info_schema_auto_inc(self) -> Optional[str]:
        return pulumi.get(self, "gather_info_schema_auto_inc")

    @property
    @pulumi.getter(name="gatherInnodbMetrics")
    def gather_innodb_metrics(self) -> Optional[str]:
        return pulumi.get(self, "gather_innodb_metrics")

    @property
    @pulumi.getter(name="gatherPerfEventsStatements")
    def gather_perf_events_statements(self) -> Optional[str]:
        return pulumi.get(self, "gather_perf_events_statements")

    @property
    @pulumi.getter(name="gatherProcessList")
    def gather_process_list(self) -> Optional[str]:
        return pulumi.get(self, "gather_process_list")

    @property
    @pulumi.getter(name="gatherSlaveStatus")
    def gather_slave_status(self) -> Optional[str]:
        return pulumi.get(self, "gather_slave_status")

    @property
    @pulumi.getter(name="gatherTableIoWaits")
    def gather_table_io_waits(self) -> Optional[str]:
        return pulumi.get(self, "gather_table_io_waits")

    @property
    @pulumi.getter(name="gatherTableLockWaits")
    def gather_table_lock_waits(self) -> Optional[str]:
        return pulumi.get(self, "gather_table_lock_waits")

    @property
    @pulumi.getter(name="gatherTableSchema")
    def gather_table_schema(self) -> Optional[str]:
        return pulumi.get(self, "gather_table_schema")

    @property
    @pulumi.getter(name="perfEventsStatementsDigestTextLimit")
    def perf_events_statements_digest_text_limit(self) -> Optional[str]:
        return pulumi.get(self, "perf_events_statements_digest_text_limit")

    @property
    @pulumi.getter(name="perfEventsStatementsLimit")
    def perf_events_statements_limit(self) -> Optional[str]:
        return pulumi.get(self, "perf_events_statements_limit")

    @property
    @pulumi.getter(name="perfEventsStatementsTimeLimit")
    def perf_events_statements_time_limit(self) -> Optional[str]:
        return pulumi.get(self, "perf_events_statements_time_limit")


@pulumi.output_type
class GetServiceIntegrationMirrormakerUserConfigResult(dict):
    def __init__(__self__, *,
                 mirrormaker_whitelist: Optional[str] = None):
        if mirrormaker_whitelist is not None:
            pulumi.set(__self__, "mirrormaker_whitelist", mirrormaker_whitelist)

    @property
    @pulumi.getter(name="mirrormakerWhitelist")
    def mirrormaker_whitelist(self) -> Optional[str]:
        return pulumi.get(self, "mirrormaker_whitelist")


@pulumi.output_type
class GetServiceIntegrationPrometheusUserConfigResult(dict):
    def __init__(__self__, *,
                 source_mysql: Optional['outputs.GetServiceIntegrationPrometheusUserConfigSourceMysqlResult'] = None):
        if source_mysql is not None:
            pulumi.set(__self__, "source_mysql", source_mysql)

    @property
    @pulumi.getter(name="sourceMysql")
    def source_mysql(self) -> Optional['outputs.GetServiceIntegrationPrometheusUserConfigSourceMysqlResult']:
        return pulumi.get(self, "source_mysql")


@pulumi.output_type
class GetServiceIntegrationPrometheusUserConfigSourceMysqlResult(dict):
    def __init__(__self__, *,
                 telegraf: Optional['outputs.GetServiceIntegrationPrometheusUserConfigSourceMysqlTelegrafResult'] = None):
        if telegraf is not None:
            pulumi.set(__self__, "telegraf", telegraf)

    @property
    @pulumi.getter
    def telegraf(self) -> Optional['outputs.GetServiceIntegrationPrometheusUserConfigSourceMysqlTelegrafResult']:
        return pulumi.get(self, "telegraf")


@pulumi.output_type
class GetServiceIntegrationPrometheusUserConfigSourceMysqlTelegrafResult(dict):
    def __init__(__self__, *,
                 gather_event_waits: Optional[str] = None,
                 gather_file_events_stats: Optional[str] = None,
                 gather_index_io_waits: Optional[str] = None,
                 gather_info_schema_auto_inc: Optional[str] = None,
                 gather_innodb_metrics: Optional[str] = None,
                 gather_perf_events_statements: Optional[str] = None,
                 gather_process_list: Optional[str] = None,
                 gather_slave_status: Optional[str] = None,
                 gather_table_io_waits: Optional[str] = None,
                 gather_table_lock_waits: Optional[str] = None,
                 gather_table_schema: Optional[str] = None,
                 perf_events_statements_digest_text_limit: Optional[str] = None,
                 perf_events_statements_limit: Optional[str] = None,
                 perf_events_statements_time_limit: Optional[str] = None):
        if gather_event_waits is not None:
            pulumi.set(__self__, "gather_event_waits", gather_event_waits)
        if gather_file_events_stats is not None:
            pulumi.set(__self__, "gather_file_events_stats", gather_file_events_stats)
        if gather_index_io_waits is not None:
            pulumi.set(__self__, "gather_index_io_waits", gather_index_io_waits)
        if gather_info_schema_auto_inc is not None:
            pulumi.set(__self__, "gather_info_schema_auto_inc", gather_info_schema_auto_inc)
        if gather_innodb_metrics is not None:
            pulumi.set(__self__, "gather_innodb_metrics", gather_innodb_metrics)
        if gather_perf_events_statements is not None:
            pulumi.set(__self__, "gather_perf_events_statements", gather_perf_events_statements)
        if gather_process_list is not None:
            pulumi.set(__self__, "gather_process_list", gather_process_list)
        if gather_slave_status is not None:
            pulumi.set(__self__, "gather_slave_status", gather_slave_status)
        if gather_table_io_waits is not None:
            pulumi.set(__self__, "gather_table_io_waits", gather_table_io_waits)
        if gather_table_lock_waits is not None:
            pulumi.set(__self__, "gather_table_lock_waits", gather_table_lock_waits)
        if gather_table_schema is not None:
            pulumi.set(__self__, "gather_table_schema", gather_table_schema)
        if perf_events_statements_digest_text_limit is not None:
            pulumi.set(__self__, "perf_events_statements_digest_text_limit", perf_events_statements_digest_text_limit)
        if perf_events_statements_limit is not None:
            pulumi.set(__self__, "perf_events_statements_limit", perf_events_statements_limit)
        if perf_events_statements_time_limit is not None:
            pulumi.set(__self__, "perf_events_statements_time_limit", perf_events_statements_time_limit)

    @property
    @pulumi.getter(name="gatherEventWaits")
    def gather_event_waits(self) -> Optional[str]:
        return pulumi.get(self, "gather_event_waits")

    @property
    @pulumi.getter(name="gatherFileEventsStats")
    def gather_file_events_stats(self) -> Optional[str]:
        return pulumi.get(self, "gather_file_events_stats")

    @property
    @pulumi.getter(name="gatherIndexIoWaits")
    def gather_index_io_waits(self) -> Optional[str]:
        return pulumi.get(self, "gather_index_io_waits")

    @property
    @pulumi.getter(name="gatherInfoSchemaAutoInc")
    def gather_info_schema_auto_inc(self) -> Optional[str]:
        return pulumi.get(self, "gather_info_schema_auto_inc")

    @property
    @pulumi.getter(name="gatherInnodbMetrics")
    def gather_innodb_metrics(self) -> Optional[str]:
        return pulumi.get(self, "gather_innodb_metrics")

    @property
    @pulumi.getter(name="gatherPerfEventsStatements")
    def gather_perf_events_statements(self) -> Optional[str]:
        return pulumi.get(self, "gather_perf_events_statements")

    @property
    @pulumi.getter(name="gatherProcessList")
    def gather_process_list(self) -> Optional[str]:
        return pulumi.get(self, "gather_process_list")

    @property
    @pulumi.getter(name="gatherSlaveStatus")
    def gather_slave_status(self) -> Optional[str]:
        return pulumi.get(self, "gather_slave_status")

    @property
    @pulumi.getter(name="gatherTableIoWaits")
    def gather_table_io_waits(self) -> Optional[str]:
        return pulumi.get(self, "gather_table_io_waits")

    @property
    @pulumi.getter(name="gatherTableLockWaits")
    def gather_table_lock_waits(self) -> Optional[str]:
        return pulumi.get(self, "gather_table_lock_waits")

    @property
    @pulumi.getter(name="gatherTableSchema")
    def gather_table_schema(self) -> Optional[str]:
        return pulumi.get(self, "gather_table_schema")

    @property
    @pulumi.getter(name="perfEventsStatementsDigestTextLimit")
    def perf_events_statements_digest_text_limit(self) -> Optional[str]:
        return pulumi.get(self, "perf_events_statements_digest_text_limit")

    @property
    @pulumi.getter(name="perfEventsStatementsLimit")
    def perf_events_statements_limit(self) -> Optional[str]:
        return pulumi.get(self, "perf_events_statements_limit")

    @property
    @pulumi.getter(name="perfEventsStatementsTimeLimit")
    def perf_events_statements_time_limit(self) -> Optional[str]:
        return pulumi.get(self, "perf_events_statements_time_limit")


@pulumi.output_type
class GetServiceIntegrationReadReplicaUserConfigResult(dict):
    def __init__(__self__):
        pass


@pulumi.output_type
class GetServiceIntegrationRsyslogUserConfigResult(dict):
    def __init__(__self__):
        pass


@pulumi.output_type
class GetServiceIntegrationSchemaRegistryProxyUserConfigResult(dict):
    def __init__(__self__):
        pass


@pulumi.output_type
class GetServiceIntegrationSignalfxUserConfigResult(dict):
    def __init__(__self__):
        pass


@pulumi.output_type
class GetServiceKafkaResult(dict):
    def __init__(__self__, *,
                 access_cert: str,
                 access_key: str,
                 connect_uri: str,
                 rest_uri: str,
                 schema_registry_uri: str):
        pulumi.set(__self__, "access_cert", access_cert)
        pulumi.set(__self__, "access_key", access_key)
        pulumi.set(__self__, "connect_uri", connect_uri)
        pulumi.set(__self__, "rest_uri", rest_uri)
        pulumi.set(__self__, "schema_registry_uri", schema_registry_uri)

    @property
    @pulumi.getter(name="accessCert")
    def access_cert(self) -> str:
        return pulumi.get(self, "access_cert")

    @property
    @pulumi.getter(name="accessKey")
    def access_key(self) -> str:
        return pulumi.get(self, "access_key")

    @property
    @pulumi.getter(name="connectUri")
    def connect_uri(self) -> str:
        return pulumi.get(self, "connect_uri")

    @property
    @pulumi.getter(name="restUri")
    def rest_uri(self) -> str:
        return pulumi.get(self, "rest_uri")

    @property
    @pulumi.getter(name="schemaRegistryUri")
    def schema_registry_uri(self) -> str:
        return pulumi.get(self, "schema_registry_uri")


@pulumi.output_type
class GetServiceKafkaConnectResult(dict):
    def __init__(__self__):
        pass


@pulumi.output_type
class GetServiceKafkaConnectUserConfigResult(dict):
    def __init__(__self__, *,
                 ip_filters: Optional[Sequence[str]] = None,
                 kafka_connect: Optional['outputs.GetServiceKafkaConnectUserConfigKafkaConnectResult'] = None,
                 private_access: Optional['outputs.GetServiceKafkaConnectUserConfigPrivateAccessResult'] = None,
                 privatelink_access: Optional['outputs.GetServiceKafkaConnectUserConfigPrivatelinkAccessResult'] = None,
                 public_access: Optional['outputs.GetServiceKafkaConnectUserConfigPublicAccessResult'] = None):
        if ip_filters is not None:
            pulumi.set(__self__, "ip_filters", ip_filters)
        if kafka_connect is not None:
            pulumi.set(__self__, "kafka_connect", kafka_connect)
        if private_access is not None:
            pulumi.set(__self__, "private_access", private_access)
        if privatelink_access is not None:
            pulumi.set(__self__, "privatelink_access", privatelink_access)
        if public_access is not None:
            pulumi.set(__self__, "public_access", public_access)

    @property
    @pulumi.getter(name="ipFilters")
    def ip_filters(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "ip_filters")

    @property
    @pulumi.getter(name="kafkaConnect")
    def kafka_connect(self) -> Optional['outputs.GetServiceKafkaConnectUserConfigKafkaConnectResult']:
        return pulumi.get(self, "kafka_connect")

    @property
    @pulumi.getter(name="privateAccess")
    def private_access(self) -> Optional['outputs.GetServiceKafkaConnectUserConfigPrivateAccessResult']:
        return pulumi.get(self, "private_access")

    @property
    @pulumi.getter(name="privatelinkAccess")
    def privatelink_access(self) -> Optional['outputs.GetServiceKafkaConnectUserConfigPrivatelinkAccessResult']:
        return pulumi.get(self, "privatelink_access")

    @property
    @pulumi.getter(name="publicAccess")
    def public_access(self) -> Optional['outputs.GetServiceKafkaConnectUserConfigPublicAccessResult']:
        return pulumi.get(self, "public_access")


@pulumi.output_type
class GetServiceKafkaConnectUserConfigKafkaConnectResult(dict):
    def __init__(__self__, *,
                 connector_client_config_override_policy: Optional[str] = None,
                 consumer_auto_offset_reset: Optional[str] = None,
                 consumer_fetch_max_bytes: Optional[str] = None,
                 consumer_isolation_level: Optional[str] = None,
                 consumer_max_partition_fetch_bytes: Optional[str] = None,
                 consumer_max_poll_interval_ms: Optional[str] = None,
                 consumer_max_poll_records: Optional[str] = None,
                 offset_flush_interval_ms: Optional[str] = None,
                 offset_flush_timeout_ms: Optional[str] = None,
                 producer_max_request_size: Optional[str] = None,
                 session_timeout_ms: Optional[str] = None):
        if connector_client_config_override_policy is not None:
            pulumi.set(__self__, "connector_client_config_override_policy", connector_client_config_override_policy)
        if consumer_auto_offset_reset is not None:
            pulumi.set(__self__, "consumer_auto_offset_reset", consumer_auto_offset_reset)
        if consumer_fetch_max_bytes is not None:
            pulumi.set(__self__, "consumer_fetch_max_bytes", consumer_fetch_max_bytes)
        if consumer_isolation_level is not None:
            pulumi.set(__self__, "consumer_isolation_level", consumer_isolation_level)
        if consumer_max_partition_fetch_bytes is not None:
            pulumi.set(__self__, "consumer_max_partition_fetch_bytes", consumer_max_partition_fetch_bytes)
        if consumer_max_poll_interval_ms is not None:
            pulumi.set(__self__, "consumer_max_poll_interval_ms", consumer_max_poll_interval_ms)
        if consumer_max_poll_records is not None:
            pulumi.set(__self__, "consumer_max_poll_records", consumer_max_poll_records)
        if offset_flush_interval_ms is not None:
            pulumi.set(__self__, "offset_flush_interval_ms", offset_flush_interval_ms)
        if offset_flush_timeout_ms is not None:
            pulumi.set(__self__, "offset_flush_timeout_ms", offset_flush_timeout_ms)
        if producer_max_request_size is not None:
            pulumi.set(__self__, "producer_max_request_size", producer_max_request_size)
        if session_timeout_ms is not None:
            pulumi.set(__self__, "session_timeout_ms", session_timeout_ms)

    @property
    @pulumi.getter(name="connectorClientConfigOverridePolicy")
    def connector_client_config_override_policy(self) -> Optional[str]:
        return pulumi.get(self, "connector_client_config_override_policy")

    @property
    @pulumi.getter(name="consumerAutoOffsetReset")
    def consumer_auto_offset_reset(self) -> Optional[str]:
        return pulumi.get(self, "consumer_auto_offset_reset")

    @property
    @pulumi.getter(name="consumerFetchMaxBytes")
    def consumer_fetch_max_bytes(self) -> Optional[str]:
        return pulumi.get(self, "consumer_fetch_max_bytes")

    @property
    @pulumi.getter(name="consumerIsolationLevel")
    def consumer_isolation_level(self) -> Optional[str]:
        return pulumi.get(self, "consumer_isolation_level")

    @property
    @pulumi.getter(name="consumerMaxPartitionFetchBytes")
    def consumer_max_partition_fetch_bytes(self) -> Optional[str]:
        return pulumi.get(self, "consumer_max_partition_fetch_bytes")

    @property
    @pulumi.getter(name="consumerMaxPollIntervalMs")
    def consumer_max_poll_interval_ms(self) -> Optional[str]:
        return pulumi.get(self, "consumer_max_poll_interval_ms")

    @property
    @pulumi.getter(name="consumerMaxPollRecords")
    def consumer_max_poll_records(self) -> Optional[str]:
        return pulumi.get(self, "consumer_max_poll_records")

    @property
    @pulumi.getter(name="offsetFlushIntervalMs")
    def offset_flush_interval_ms(self) -> Optional[str]:
        return pulumi.get(self, "offset_flush_interval_ms")

    @property
    @pulumi.getter(name="offsetFlushTimeoutMs")
    def offset_flush_timeout_ms(self) -> Optional[str]:
        return pulumi.get(self, "offset_flush_timeout_ms")

    @property
    @pulumi.getter(name="producerMaxRequestSize")
    def producer_max_request_size(self) -> Optional[str]:
        return pulumi.get(self, "producer_max_request_size")

    @property
    @pulumi.getter(name="sessionTimeoutMs")
    def session_timeout_ms(self) -> Optional[str]:
        return pulumi.get(self, "session_timeout_ms")


@pulumi.output_type
class GetServiceKafkaConnectUserConfigPrivateAccessResult(dict):
    def __init__(__self__, *,
                 kafka_connect: Optional[str] = None,
                 prometheus: Optional[str] = None):
        if kafka_connect is not None:
            pulumi.set(__self__, "kafka_connect", kafka_connect)
        if prometheus is not None:
            pulumi.set(__self__, "prometheus", prometheus)

    @property
    @pulumi.getter(name="kafkaConnect")
    def kafka_connect(self) -> Optional[str]:
        return pulumi.get(self, "kafka_connect")

    @property
    @pulumi.getter
    def prometheus(self) -> Optional[str]:
        return pulumi.get(self, "prometheus")


@pulumi.output_type
class GetServiceKafkaConnectUserConfigPrivatelinkAccessResult(dict):
    def __init__(__self__, *,
                 kafka_connect: Optional[str] = None):
        if kafka_connect is not None:
            pulumi.set(__self__, "kafka_connect", kafka_connect)

    @property
    @pulumi.getter(name="kafkaConnect")
    def kafka_connect(self) -> Optional[str]:
        return pulumi.get(self, "kafka_connect")


@pulumi.output_type
class GetServiceKafkaConnectUserConfigPublicAccessResult(dict):
    def __init__(__self__, *,
                 kafka_connect: Optional[str] = None,
                 prometheus: Optional[str] = None):
        if kafka_connect is not None:
            pulumi.set(__self__, "kafka_connect", kafka_connect)
        if prometheus is not None:
            pulumi.set(__self__, "prometheus", prometheus)

    @property
    @pulumi.getter(name="kafkaConnect")
    def kafka_connect(self) -> Optional[str]:
        return pulumi.get(self, "kafka_connect")

    @property
    @pulumi.getter
    def prometheus(self) -> Optional[str]:
        return pulumi.get(self, "prometheus")


@pulumi.output_type
class GetServiceKafkaMirrormakerResult(dict):
    def __init__(__self__):
        pass


@pulumi.output_type
class GetServiceKafkaMirrormakerUserConfigResult(dict):
    def __init__(__self__, *,
                 ip_filters: Optional[Sequence[str]] = None,
                 kafka_mirrormaker: Optional['outputs.GetServiceKafkaMirrormakerUserConfigKafkaMirrormakerResult'] = None):
        if ip_filters is not None:
            pulumi.set(__self__, "ip_filters", ip_filters)
        if kafka_mirrormaker is not None:
            pulumi.set(__self__, "kafka_mirrormaker", kafka_mirrormaker)

    @property
    @pulumi.getter(name="ipFilters")
    def ip_filters(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "ip_filters")

    @property
    @pulumi.getter(name="kafkaMirrormaker")
    def kafka_mirrormaker(self) -> Optional['outputs.GetServiceKafkaMirrormakerUserConfigKafkaMirrormakerResult']:
        return pulumi.get(self, "kafka_mirrormaker")


@pulumi.output_type
class GetServiceKafkaMirrormakerUserConfigKafkaMirrormakerResult(dict):
    def __init__(__self__, *,
                 emit_checkpoints_enabled: Optional[str] = None,
                 emit_checkpoints_interval_seconds: Optional[str] = None,
                 refresh_groups_enabled: Optional[str] = None,
                 refresh_groups_interval_seconds: Optional[str] = None,
                 refresh_topics_enabled: Optional[str] = None,
                 refresh_topics_interval_seconds: Optional[str] = None,
                 sync_group_offsets_enabled: Optional[str] = None,
                 sync_group_offsets_interval_seconds: Optional[str] = None):
        if emit_checkpoints_enabled is not None:
            pulumi.set(__self__, "emit_checkpoints_enabled", emit_checkpoints_enabled)
        if emit_checkpoints_interval_seconds is not None:
            pulumi.set(__self__, "emit_checkpoints_interval_seconds", emit_checkpoints_interval_seconds)
        if refresh_groups_enabled is not None:
            pulumi.set(__self__, "refresh_groups_enabled", refresh_groups_enabled)
        if refresh_groups_interval_seconds is not None:
            pulumi.set(__self__, "refresh_groups_interval_seconds", refresh_groups_interval_seconds)
        if refresh_topics_enabled is not None:
            pulumi.set(__self__, "refresh_topics_enabled", refresh_topics_enabled)
        if refresh_topics_interval_seconds is not None:
            pulumi.set(__self__, "refresh_topics_interval_seconds", refresh_topics_interval_seconds)
        if sync_group_offsets_enabled is not None:
            pulumi.set(__self__, "sync_group_offsets_enabled", sync_group_offsets_enabled)
        if sync_group_offsets_interval_seconds is not None:
            pulumi.set(__self__, "sync_group_offsets_interval_seconds", sync_group_offsets_interval_seconds)

    @property
    @pulumi.getter(name="emitCheckpointsEnabled")
    def emit_checkpoints_enabled(self) -> Optional[str]:
        return pulumi.get(self, "emit_checkpoints_enabled")

    @property
    @pulumi.getter(name="emitCheckpointsIntervalSeconds")
    def emit_checkpoints_interval_seconds(self) -> Optional[str]:
        return pulumi.get(self, "emit_checkpoints_interval_seconds")

    @property
    @pulumi.getter(name="refreshGroupsEnabled")
    def refresh_groups_enabled(self) -> Optional[str]:
        return pulumi.get(self, "refresh_groups_enabled")

    @property
    @pulumi.getter(name="refreshGroupsIntervalSeconds")
    def refresh_groups_interval_seconds(self) -> Optional[str]:
        return pulumi.get(self, "refresh_groups_interval_seconds")

    @property
    @pulumi.getter(name="refreshTopicsEnabled")
    def refresh_topics_enabled(self) -> Optional[str]:
        return pulumi.get(self, "refresh_topics_enabled")

    @property
    @pulumi.getter(name="refreshTopicsIntervalSeconds")
    def refresh_topics_interval_seconds(self) -> Optional[str]:
        return pulumi.get(self, "refresh_topics_interval_seconds")

    @property
    @pulumi.getter(name="syncGroupOffsetsEnabled")
    def sync_group_offsets_enabled(self) -> Optional[str]:
        return pulumi.get(self, "sync_group_offsets_enabled")

    @property
    @pulumi.getter(name="syncGroupOffsetsIntervalSeconds")
    def sync_group_offsets_interval_seconds(self) -> Optional[str]:
        return pulumi.get(self, "sync_group_offsets_interval_seconds")


@pulumi.output_type
class GetServiceKafkaUserConfigResult(dict):
    def __init__(__self__, *,
                 custom_domain: Optional[str] = None,
                 ip_filters: Optional[Sequence[str]] = None,
                 kafka: Optional['outputs.GetServiceKafkaUserConfigKafkaResult'] = None,
                 kafka_authentication_methods: Optional['outputs.GetServiceKafkaUserConfigKafkaAuthenticationMethodsResult'] = None,
                 kafka_connect: Optional[str] = None,
                 kafka_connect_config: Optional['outputs.GetServiceKafkaUserConfigKafkaConnectConfigResult'] = None,
                 kafka_rest: Optional[str] = None,
                 kafka_rest_config: Optional['outputs.GetServiceKafkaUserConfigKafkaRestConfigResult'] = None,
                 kafka_version: Optional[str] = None,
                 private_access: Optional['outputs.GetServiceKafkaUserConfigPrivateAccessResult'] = None,
                 privatelink_access: Optional['outputs.GetServiceKafkaUserConfigPrivatelinkAccessResult'] = None,
                 public_access: Optional['outputs.GetServiceKafkaUserConfigPublicAccessResult'] = None,
                 schema_registry: Optional[str] = None,
                 schema_registry_config: Optional['outputs.GetServiceKafkaUserConfigSchemaRegistryConfigResult'] = None):
        if custom_domain is not None:
            pulumi.set(__self__, "custom_domain", custom_domain)
        if ip_filters is not None:
            pulumi.set(__self__, "ip_filters", ip_filters)
        if kafka is not None:
            pulumi.set(__self__, "kafka", kafka)
        if kafka_authentication_methods is not None:
            pulumi.set(__self__, "kafka_authentication_methods", kafka_authentication_methods)
        if kafka_connect is not None:
            pulumi.set(__self__, "kafka_connect", kafka_connect)
        if kafka_connect_config is not None:
            pulumi.set(__self__, "kafka_connect_config", kafka_connect_config)
        if kafka_rest is not None:
            pulumi.set(__self__, "kafka_rest", kafka_rest)
        if kafka_rest_config is not None:
            pulumi.set(__self__, "kafka_rest_config", kafka_rest_config)
        if kafka_version is not None:
            pulumi.set(__self__, "kafka_version", kafka_version)
        if private_access is not None:
            pulumi.set(__self__, "private_access", private_access)
        if privatelink_access is not None:
            pulumi.set(__self__, "privatelink_access", privatelink_access)
        if public_access is not None:
            pulumi.set(__self__, "public_access", public_access)
        if schema_registry is not None:
            pulumi.set(__self__, "schema_registry", schema_registry)
        if schema_registry_config is not None:
            pulumi.set(__self__, "schema_registry_config", schema_registry_config)

    @property
    @pulumi.getter(name="customDomain")
    def custom_domain(self) -> Optional[str]:
        return pulumi.get(self, "custom_domain")

    @property
    @pulumi.getter(name="ipFilters")
    def ip_filters(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "ip_filters")

    @property
    @pulumi.getter
    def kafka(self) -> Optional['outputs.GetServiceKafkaUserConfigKafkaResult']:
        return pulumi.get(self, "kafka")

    @property
    @pulumi.getter(name="kafkaAuthenticationMethods")
    def kafka_authentication_methods(self) -> Optional['outputs.GetServiceKafkaUserConfigKafkaAuthenticationMethodsResult']:
        return pulumi.get(self, "kafka_authentication_methods")

    @property
    @pulumi.getter(name="kafkaConnect")
    def kafka_connect(self) -> Optional[str]:
        return pulumi.get(self, "kafka_connect")

    @property
    @pulumi.getter(name="kafkaConnectConfig")
    def kafka_connect_config(self) -> Optional['outputs.GetServiceKafkaUserConfigKafkaConnectConfigResult']:
        return pulumi.get(self, "kafka_connect_config")

    @property
    @pulumi.getter(name="kafkaRest")
    def kafka_rest(self) -> Optional[str]:
        return pulumi.get(self, "kafka_rest")

    @property
    @pulumi.getter(name="kafkaRestConfig")
    def kafka_rest_config(self) -> Optional['outputs.GetServiceKafkaUserConfigKafkaRestConfigResult']:
        return pulumi.get(self, "kafka_rest_config")

    @property
    @pulumi.getter(name="kafkaVersion")
    def kafka_version(self) -> Optional[str]:
        return pulumi.get(self, "kafka_version")

    @property
    @pulumi.getter(name="privateAccess")
    def private_access(self) -> Optional['outputs.GetServiceKafkaUserConfigPrivateAccessResult']:
        return pulumi.get(self, "private_access")

    @property
    @pulumi.getter(name="privatelinkAccess")
    def privatelink_access(self) -> Optional['outputs.GetServiceKafkaUserConfigPrivatelinkAccessResult']:
        return pulumi.get(self, "privatelink_access")

    @property
    @pulumi.getter(name="publicAccess")
    def public_access(self) -> Optional['outputs.GetServiceKafkaUserConfigPublicAccessResult']:
        return pulumi.get(self, "public_access")

    @property
    @pulumi.getter(name="schemaRegistry")
    def schema_registry(self) -> Optional[str]:
        return pulumi.get(self, "schema_registry")

    @property
    @pulumi.getter(name="schemaRegistryConfig")
    def schema_registry_config(self) -> Optional['outputs.GetServiceKafkaUserConfigSchemaRegistryConfigResult']:
        return pulumi.get(self, "schema_registry_config")


@pulumi.output_type
class GetServiceKafkaUserConfigKafkaResult(dict):
    def __init__(__self__, *,
                 auto_create_topics_enable: Optional[str] = None,
                 compression_type: Optional[str] = None,
                 connections_max_idle_ms: Optional[str] = None,
                 default_replication_factor: Optional[str] = None,
                 group_initial_rebalance_delay_ms: Optional[str] = None,
                 group_max_session_timeout_ms: Optional[str] = None,
                 group_min_session_timeout_ms: Optional[str] = None,
                 log_cleaner_delete_retention_ms: Optional[str] = None,
                 log_cleaner_max_compaction_lag_ms: Optional[str] = None,
                 log_cleaner_min_cleanable_ratio: Optional[str] = None,
                 log_cleaner_min_compaction_lag_ms: Optional[str] = None,
                 log_cleanup_policy: Optional[str] = None,
                 log_flush_interval_messages: Optional[str] = None,
                 log_flush_interval_ms: Optional[str] = None,
                 log_index_interval_bytes: Optional[str] = None,
                 log_index_size_max_bytes: Optional[str] = None,
                 log_message_downconversion_enable: Optional[str] = None,
                 log_message_timestamp_difference_max_ms: Optional[str] = None,
                 log_message_timestamp_type: Optional[str] = None,
                 log_preallocate: Optional[str] = None,
                 log_retention_bytes: Optional[str] = None,
                 log_retention_hours: Optional[str] = None,
                 log_retention_ms: Optional[str] = None,
                 log_roll_jitter_ms: Optional[str] = None,
                 log_roll_ms: Optional[str] = None,
                 log_segment_bytes: Optional[str] = None,
                 log_segment_delete_delay_ms: Optional[str] = None,
                 max_connections_per_ip: Optional[str] = None,
                 max_incremental_fetch_session_cache_slots: Optional[str] = None,
                 message_max_bytes: Optional[str] = None,
                 min_insync_replicas: Optional[str] = None,
                 num_partitions: Optional[str] = None,
                 offsets_retention_minutes: Optional[str] = None,
                 producer_purgatory_purge_interval_requests: Optional[str] = None,
                 replica_fetch_max_bytes: Optional[str] = None,
                 replica_fetch_response_max_bytes: Optional[str] = None,
                 socket_request_max_bytes: Optional[str] = None,
                 transaction_remove_expired_transaction_cleanup_interval_ms: Optional[str] = None,
                 transaction_state_log_segment_bytes: Optional[str] = None):
        if auto_create_topics_enable is not None:
            pulumi.set(__self__, "auto_create_topics_enable", auto_create_topics_enable)
        if compression_type is not None:
            pulumi.set(__self__, "compression_type", compression_type)
        if connections_max_idle_ms is not None:
            pulumi.set(__self__, "connections_max_idle_ms", connections_max_idle_ms)
        if default_replication_factor is not None:
            pulumi.set(__self__, "default_replication_factor", default_replication_factor)
        if group_initial_rebalance_delay_ms is not None:
            pulumi.set(__self__, "group_initial_rebalance_delay_ms", group_initial_rebalance_delay_ms)
        if group_max_session_timeout_ms is not None:
            pulumi.set(__self__, "group_max_session_timeout_ms", group_max_session_timeout_ms)
        if group_min_session_timeout_ms is not None:
            pulumi.set(__self__, "group_min_session_timeout_ms", group_min_session_timeout_ms)
        if log_cleaner_delete_retention_ms is not None:
            pulumi.set(__self__, "log_cleaner_delete_retention_ms", log_cleaner_delete_retention_ms)
        if log_cleaner_max_compaction_lag_ms is not None:
            pulumi.set(__self__, "log_cleaner_max_compaction_lag_ms", log_cleaner_max_compaction_lag_ms)
        if log_cleaner_min_cleanable_ratio is not None:
            pulumi.set(__self__, "log_cleaner_min_cleanable_ratio", log_cleaner_min_cleanable_ratio)
        if log_cleaner_min_compaction_lag_ms is not None:
            pulumi.set(__self__, "log_cleaner_min_compaction_lag_ms", log_cleaner_min_compaction_lag_ms)
        if log_cleanup_policy is not None:
            pulumi.set(__self__, "log_cleanup_policy", log_cleanup_policy)
        if log_flush_interval_messages is not None:
            pulumi.set(__self__, "log_flush_interval_messages", log_flush_interval_messages)
        if log_flush_interval_ms is not None:
            pulumi.set(__self__, "log_flush_interval_ms", log_flush_interval_ms)
        if log_index_interval_bytes is not None:
            pulumi.set(__self__, "log_index_interval_bytes", log_index_interval_bytes)
        if log_index_size_max_bytes is not None:
            pulumi.set(__self__, "log_index_size_max_bytes", log_index_size_max_bytes)
        if log_message_downconversion_enable is not None:
            pulumi.set(__self__, "log_message_downconversion_enable", log_message_downconversion_enable)
        if log_message_timestamp_difference_max_ms is not None:
            pulumi.set(__self__, "log_message_timestamp_difference_max_ms", log_message_timestamp_difference_max_ms)
        if log_message_timestamp_type is not None:
            pulumi.set(__self__, "log_message_timestamp_type", log_message_timestamp_type)
        if log_preallocate is not None:
            pulumi.set(__self__, "log_preallocate", log_preallocate)
        if log_retention_bytes is not None:
            pulumi.set(__self__, "log_retention_bytes", log_retention_bytes)
        if log_retention_hours is not None:
            pulumi.set(__self__, "log_retention_hours", log_retention_hours)
        if log_retention_ms is not None:
            pulumi.set(__self__, "log_retention_ms", log_retention_ms)
        if log_roll_jitter_ms is not None:
            pulumi.set(__self__, "log_roll_jitter_ms", log_roll_jitter_ms)
        if log_roll_ms is not None:
            pulumi.set(__self__, "log_roll_ms", log_roll_ms)
        if log_segment_bytes is not None:
            pulumi.set(__self__, "log_segment_bytes", log_segment_bytes)
        if log_segment_delete_delay_ms is not None:
            pulumi.set(__self__, "log_segment_delete_delay_ms", log_segment_delete_delay_ms)
        if max_connections_per_ip is not None:
            pulumi.set(__self__, "max_connections_per_ip", max_connections_per_ip)
        if max_incremental_fetch_session_cache_slots is not None:
            pulumi.set(__self__, "max_incremental_fetch_session_cache_slots", max_incremental_fetch_session_cache_slots)
        if message_max_bytes is not None:
            pulumi.set(__self__, "message_max_bytes", message_max_bytes)
        if min_insync_replicas is not None:
            pulumi.set(__self__, "min_insync_replicas", min_insync_replicas)
        if num_partitions is not None:
            pulumi.set(__self__, "num_partitions", num_partitions)
        if offsets_retention_minutes is not None:
            pulumi.set(__self__, "offsets_retention_minutes", offsets_retention_minutes)
        if producer_purgatory_purge_interval_requests is not None:
            pulumi.set(__self__, "producer_purgatory_purge_interval_requests", producer_purgatory_purge_interval_requests)
        if replica_fetch_max_bytes is not None:
            pulumi.set(__self__, "replica_fetch_max_bytes", replica_fetch_max_bytes)
        if replica_fetch_response_max_bytes is not None:
            pulumi.set(__self__, "replica_fetch_response_max_bytes", replica_fetch_response_max_bytes)
        if socket_request_max_bytes is not None:
            pulumi.set(__self__, "socket_request_max_bytes", socket_request_max_bytes)
        if transaction_remove_expired_transaction_cleanup_interval_ms is not None:
            pulumi.set(__self__, "transaction_remove_expired_transaction_cleanup_interval_ms", transaction_remove_expired_transaction_cleanup_interval_ms)
        if transaction_state_log_segment_bytes is not None:
            pulumi.set(__self__, "transaction_state_log_segment_bytes", transaction_state_log_segment_bytes)

    @property
    @pulumi.getter(name="autoCreateTopicsEnable")
    def auto_create_topics_enable(self) -> Optional[str]:
        return pulumi.get(self, "auto_create_topics_enable")

    @property
    @pulumi.getter(name="compressionType")
    def compression_type(self) -> Optional[str]:
        return pulumi.get(self, "compression_type")

    @property
    @pulumi.getter(name="connectionsMaxIdleMs")
    def connections_max_idle_ms(self) -> Optional[str]:
        return pulumi.get(self, "connections_max_idle_ms")

    @property
    @pulumi.getter(name="defaultReplicationFactor")
    def default_replication_factor(self) -> Optional[str]:
        return pulumi.get(self, "default_replication_factor")

    @property
    @pulumi.getter(name="groupInitialRebalanceDelayMs")
    def group_initial_rebalance_delay_ms(self) -> Optional[str]:
        return pulumi.get(self, "group_initial_rebalance_delay_ms")

    @property
    @pulumi.getter(name="groupMaxSessionTimeoutMs")
    def group_max_session_timeout_ms(self) -> Optional[str]:
        return pulumi.get(self, "group_max_session_timeout_ms")

    @property
    @pulumi.getter(name="groupMinSessionTimeoutMs")
    def group_min_session_timeout_ms(self) -> Optional[str]:
        return pulumi.get(self, "group_min_session_timeout_ms")

    @property
    @pulumi.getter(name="logCleanerDeleteRetentionMs")
    def log_cleaner_delete_retention_ms(self) -> Optional[str]:
        return pulumi.get(self, "log_cleaner_delete_retention_ms")

    @property
    @pulumi.getter(name="logCleanerMaxCompactionLagMs")
    def log_cleaner_max_compaction_lag_ms(self) -> Optional[str]:
        return pulumi.get(self, "log_cleaner_max_compaction_lag_ms")

    @property
    @pulumi.getter(name="logCleanerMinCleanableRatio")
    def log_cleaner_min_cleanable_ratio(self) -> Optional[str]:
        return pulumi.get(self, "log_cleaner_min_cleanable_ratio")

    @property
    @pulumi.getter(name="logCleanerMinCompactionLagMs")
    def log_cleaner_min_compaction_lag_ms(self) -> Optional[str]:
        return pulumi.get(self, "log_cleaner_min_compaction_lag_ms")

    @property
    @pulumi.getter(name="logCleanupPolicy")
    def log_cleanup_policy(self) -> Optional[str]:
        return pulumi.get(self, "log_cleanup_policy")

    @property
    @pulumi.getter(name="logFlushIntervalMessages")
    def log_flush_interval_messages(self) -> Optional[str]:
        return pulumi.get(self, "log_flush_interval_messages")

    @property
    @pulumi.getter(name="logFlushIntervalMs")
    def log_flush_interval_ms(self) -> Optional[str]:
        return pulumi.get(self, "log_flush_interval_ms")

    @property
    @pulumi.getter(name="logIndexIntervalBytes")
    def log_index_interval_bytes(self) -> Optional[str]:
        return pulumi.get(self, "log_index_interval_bytes")

    @property
    @pulumi.getter(name="logIndexSizeMaxBytes")
    def log_index_size_max_bytes(self) -> Optional[str]:
        return pulumi.get(self, "log_index_size_max_bytes")

    @property
    @pulumi.getter(name="logMessageDownconversionEnable")
    def log_message_downconversion_enable(self) -> Optional[str]:
        return pulumi.get(self, "log_message_downconversion_enable")

    @property
    @pulumi.getter(name="logMessageTimestampDifferenceMaxMs")
    def log_message_timestamp_difference_max_ms(self) -> Optional[str]:
        return pulumi.get(self, "log_message_timestamp_difference_max_ms")

    @property
    @pulumi.getter(name="logMessageTimestampType")
    def log_message_timestamp_type(self) -> Optional[str]:
        return pulumi.get(self, "log_message_timestamp_type")

    @property
    @pulumi.getter(name="logPreallocate")
    def log_preallocate(self) -> Optional[str]:
        return pulumi.get(self, "log_preallocate")

    @property
    @pulumi.getter(name="logRetentionBytes")
    def log_retention_bytes(self) -> Optional[str]:
        return pulumi.get(self, "log_retention_bytes")

    @property
    @pulumi.getter(name="logRetentionHours")
    def log_retention_hours(self) -> Optional[str]:
        return pulumi.get(self, "log_retention_hours")

    @property
    @pulumi.getter(name="logRetentionMs")
    def log_retention_ms(self) -> Optional[str]:
        return pulumi.get(self, "log_retention_ms")

    @property
    @pulumi.getter(name="logRollJitterMs")
    def log_roll_jitter_ms(self) -> Optional[str]:
        return pulumi.get(self, "log_roll_jitter_ms")

    @property
    @pulumi.getter(name="logRollMs")
    def log_roll_ms(self) -> Optional[str]:
        return pulumi.get(self, "log_roll_ms")

    @property
    @pulumi.getter(name="logSegmentBytes")
    def log_segment_bytes(self) -> Optional[str]:
        return pulumi.get(self, "log_segment_bytes")

    @property
    @pulumi.getter(name="logSegmentDeleteDelayMs")
    def log_segment_delete_delay_ms(self) -> Optional[str]:
        return pulumi.get(self, "log_segment_delete_delay_ms")

    @property
    @pulumi.getter(name="maxConnectionsPerIp")
    def max_connections_per_ip(self) -> Optional[str]:
        return pulumi.get(self, "max_connections_per_ip")

    @property
    @pulumi.getter(name="maxIncrementalFetchSessionCacheSlots")
    def max_incremental_fetch_session_cache_slots(self) -> Optional[str]:
        return pulumi.get(self, "max_incremental_fetch_session_cache_slots")

    @property
    @pulumi.getter(name="messageMaxBytes")
    def message_max_bytes(self) -> Optional[str]:
        return pulumi.get(self, "message_max_bytes")

    @property
    @pulumi.getter(name="minInsyncReplicas")
    def min_insync_replicas(self) -> Optional[str]:
        return pulumi.get(self, "min_insync_replicas")

    @property
    @pulumi.getter(name="numPartitions")
    def num_partitions(self) -> Optional[str]:
        return pulumi.get(self, "num_partitions")

    @property
    @pulumi.getter(name="offsetsRetentionMinutes")
    def offsets_retention_minutes(self) -> Optional[str]:
        return pulumi.get(self, "offsets_retention_minutes")

    @property
    @pulumi.getter(name="producerPurgatoryPurgeIntervalRequests")
    def producer_purgatory_purge_interval_requests(self) -> Optional[str]:
        return pulumi.get(self, "producer_purgatory_purge_interval_requests")

    @property
    @pulumi.getter(name="replicaFetchMaxBytes")
    def replica_fetch_max_bytes(self) -> Optional[str]:
        return pulumi.get(self, "replica_fetch_max_bytes")

    @property
    @pulumi.getter(name="replicaFetchResponseMaxBytes")
    def replica_fetch_response_max_bytes(self) -> Optional[str]:
        return pulumi.get(self, "replica_fetch_response_max_bytes")

    @property
    @pulumi.getter(name="socketRequestMaxBytes")
    def socket_request_max_bytes(self) -> Optional[str]:
        return pulumi.get(self, "socket_request_max_bytes")

    @property
    @pulumi.getter(name="transactionRemoveExpiredTransactionCleanupIntervalMs")
    def transaction_remove_expired_transaction_cleanup_interval_ms(self) -> Optional[str]:
        return pulumi.get(self, "transaction_remove_expired_transaction_cleanup_interval_ms")

    @property
    @pulumi.getter(name="transactionStateLogSegmentBytes")
    def transaction_state_log_segment_bytes(self) -> Optional[str]:
        return pulumi.get(self, "transaction_state_log_segment_bytes")


@pulumi.output_type
class GetServiceKafkaUserConfigKafkaAuthenticationMethodsResult(dict):
    def __init__(__self__, *,
                 certificate: Optional[str] = None,
                 sasl: Optional[str] = None):
        if certificate is not None:
            pulumi.set(__self__, "certificate", certificate)
        if sasl is not None:
            pulumi.set(__self__, "sasl", sasl)

    @property
    @pulumi.getter
    def certificate(self) -> Optional[str]:
        return pulumi.get(self, "certificate")

    @property
    @pulumi.getter
    def sasl(self) -> Optional[str]:
        return pulumi.get(self, "sasl")


@pulumi.output_type
class GetServiceKafkaUserConfigKafkaConnectConfigResult(dict):
    def __init__(__self__, *,
                 connector_client_config_override_policy: Optional[str] = None,
                 consumer_auto_offset_reset: Optional[str] = None,
                 consumer_fetch_max_bytes: Optional[str] = None,
                 consumer_isolation_level: Optional[str] = None,
                 consumer_max_partition_fetch_bytes: Optional[str] = None,
                 consumer_max_poll_interval_ms: Optional[str] = None,
                 consumer_max_poll_records: Optional[str] = None,
                 offset_flush_interval_ms: Optional[str] = None,
                 offset_flush_timeout_ms: Optional[str] = None,
                 producer_max_request_size: Optional[str] = None,
                 session_timeout_ms: Optional[str] = None):
        if connector_client_config_override_policy is not None:
            pulumi.set(__self__, "connector_client_config_override_policy", connector_client_config_override_policy)
        if consumer_auto_offset_reset is not None:
            pulumi.set(__self__, "consumer_auto_offset_reset", consumer_auto_offset_reset)
        if consumer_fetch_max_bytes is not None:
            pulumi.set(__self__, "consumer_fetch_max_bytes", consumer_fetch_max_bytes)
        if consumer_isolation_level is not None:
            pulumi.set(__self__, "consumer_isolation_level", consumer_isolation_level)
        if consumer_max_partition_fetch_bytes is not None:
            pulumi.set(__self__, "consumer_max_partition_fetch_bytes", consumer_max_partition_fetch_bytes)
        if consumer_max_poll_interval_ms is not None:
            pulumi.set(__self__, "consumer_max_poll_interval_ms", consumer_max_poll_interval_ms)
        if consumer_max_poll_records is not None:
            pulumi.set(__self__, "consumer_max_poll_records", consumer_max_poll_records)
        if offset_flush_interval_ms is not None:
            pulumi.set(__self__, "offset_flush_interval_ms", offset_flush_interval_ms)
        if offset_flush_timeout_ms is not None:
            pulumi.set(__self__, "offset_flush_timeout_ms", offset_flush_timeout_ms)
        if producer_max_request_size is not None:
            pulumi.set(__self__, "producer_max_request_size", producer_max_request_size)
        if session_timeout_ms is not None:
            pulumi.set(__self__, "session_timeout_ms", session_timeout_ms)

    @property
    @pulumi.getter(name="connectorClientConfigOverridePolicy")
    def connector_client_config_override_policy(self) -> Optional[str]:
        return pulumi.get(self, "connector_client_config_override_policy")

    @property
    @pulumi.getter(name="consumerAutoOffsetReset")
    def consumer_auto_offset_reset(self) -> Optional[str]:
        return pulumi.get(self, "consumer_auto_offset_reset")

    @property
    @pulumi.getter(name="consumerFetchMaxBytes")
    def consumer_fetch_max_bytes(self) -> Optional[str]:
        return pulumi.get(self, "consumer_fetch_max_bytes")

    @property
    @pulumi.getter(name="consumerIsolationLevel")
    def consumer_isolation_level(self) -> Optional[str]:
        return pulumi.get(self, "consumer_isolation_level")

    @property
    @pulumi.getter(name="consumerMaxPartitionFetchBytes")
    def consumer_max_partition_fetch_bytes(self) -> Optional[str]:
        return pulumi.get(self, "consumer_max_partition_fetch_bytes")

    @property
    @pulumi.getter(name="consumerMaxPollIntervalMs")
    def consumer_max_poll_interval_ms(self) -> Optional[str]:
        return pulumi.get(self, "consumer_max_poll_interval_ms")

    @property
    @pulumi.getter(name="consumerMaxPollRecords")
    def consumer_max_poll_records(self) -> Optional[str]:
        return pulumi.get(self, "consumer_max_poll_records")

    @property
    @pulumi.getter(name="offsetFlushIntervalMs")
    def offset_flush_interval_ms(self) -> Optional[str]:
        return pulumi.get(self, "offset_flush_interval_ms")

    @property
    @pulumi.getter(name="offsetFlushTimeoutMs")
    def offset_flush_timeout_ms(self) -> Optional[str]:
        return pulumi.get(self, "offset_flush_timeout_ms")

    @property
    @pulumi.getter(name="producerMaxRequestSize")
    def producer_max_request_size(self) -> Optional[str]:
        return pulumi.get(self, "producer_max_request_size")

    @property
    @pulumi.getter(name="sessionTimeoutMs")
    def session_timeout_ms(self) -> Optional[str]:
        return pulumi.get(self, "session_timeout_ms")


@pulumi.output_type
class GetServiceKafkaUserConfigKafkaRestConfigResult(dict):
    def __init__(__self__, *,
                 consumer_enable_auto_commit: Optional[str] = None,
                 consumer_request_max_bytes: Optional[str] = None,
                 consumer_request_timeout_ms: Optional[str] = None,
                 producer_acks: Optional[str] = None,
                 producer_linger_ms: Optional[str] = None,
                 simpleconsumer_pool_size_max: Optional[str] = None):
        if consumer_enable_auto_commit is not None:
            pulumi.set(__self__, "consumer_enable_auto_commit", consumer_enable_auto_commit)
        if consumer_request_max_bytes is not None:
            pulumi.set(__self__, "consumer_request_max_bytes", consumer_request_max_bytes)
        if consumer_request_timeout_ms is not None:
            pulumi.set(__self__, "consumer_request_timeout_ms", consumer_request_timeout_ms)
        if producer_acks is not None:
            pulumi.set(__self__, "producer_acks", producer_acks)
        if producer_linger_ms is not None:
            pulumi.set(__self__, "producer_linger_ms", producer_linger_ms)
        if simpleconsumer_pool_size_max is not None:
            pulumi.set(__self__, "simpleconsumer_pool_size_max", simpleconsumer_pool_size_max)

    @property
    @pulumi.getter(name="consumerEnableAutoCommit")
    def consumer_enable_auto_commit(self) -> Optional[str]:
        return pulumi.get(self, "consumer_enable_auto_commit")

    @property
    @pulumi.getter(name="consumerRequestMaxBytes")
    def consumer_request_max_bytes(self) -> Optional[str]:
        return pulumi.get(self, "consumer_request_max_bytes")

    @property
    @pulumi.getter(name="consumerRequestTimeoutMs")
    def consumer_request_timeout_ms(self) -> Optional[str]:
        return pulumi.get(self, "consumer_request_timeout_ms")

    @property
    @pulumi.getter(name="producerAcks")
    def producer_acks(self) -> Optional[str]:
        return pulumi.get(self, "producer_acks")

    @property
    @pulumi.getter(name="producerLingerMs")
    def producer_linger_ms(self) -> Optional[str]:
        return pulumi.get(self, "producer_linger_ms")

    @property
    @pulumi.getter(name="simpleconsumerPoolSizeMax")
    def simpleconsumer_pool_size_max(self) -> Optional[str]:
        return pulumi.get(self, "simpleconsumer_pool_size_max")


@pulumi.output_type
class GetServiceKafkaUserConfigPrivateAccessResult(dict):
    def __init__(__self__, *,
                 prometheus: Optional[str] = None):
        if prometheus is not None:
            pulumi.set(__self__, "prometheus", prometheus)

    @property
    @pulumi.getter
    def prometheus(self) -> Optional[str]:
        return pulumi.get(self, "prometheus")


@pulumi.output_type
class GetServiceKafkaUserConfigPrivatelinkAccessResult(dict):
    def __init__(__self__, *,
                 kafka: Optional[str] = None,
                 kafka_connect: Optional[str] = None,
                 kafka_rest: Optional[str] = None,
                 schema_registry: Optional[str] = None):
        if kafka is not None:
            pulumi.set(__self__, "kafka", kafka)
        if kafka_connect is not None:
            pulumi.set(__self__, "kafka_connect", kafka_connect)
        if kafka_rest is not None:
            pulumi.set(__self__, "kafka_rest", kafka_rest)
        if schema_registry is not None:
            pulumi.set(__self__, "schema_registry", schema_registry)

    @property
    @pulumi.getter
    def kafka(self) -> Optional[str]:
        return pulumi.get(self, "kafka")

    @property
    @pulumi.getter(name="kafkaConnect")
    def kafka_connect(self) -> Optional[str]:
        return pulumi.get(self, "kafka_connect")

    @property
    @pulumi.getter(name="kafkaRest")
    def kafka_rest(self) -> Optional[str]:
        return pulumi.get(self, "kafka_rest")

    @property
    @pulumi.getter(name="schemaRegistry")
    def schema_registry(self) -> Optional[str]:
        return pulumi.get(self, "schema_registry")


@pulumi.output_type
class GetServiceKafkaUserConfigPublicAccessResult(dict):
    def __init__(__self__, *,
                 kafka: Optional[str] = None,
                 kafka_connect: Optional[str] = None,
                 kafka_rest: Optional[str] = None,
                 prometheus: Optional[str] = None,
                 schema_registry: Optional[str] = None):
        if kafka is not None:
            pulumi.set(__self__, "kafka", kafka)
        if kafka_connect is not None:
            pulumi.set(__self__, "kafka_connect", kafka_connect)
        if kafka_rest is not None:
            pulumi.set(__self__, "kafka_rest", kafka_rest)
        if prometheus is not None:
            pulumi.set(__self__, "prometheus", prometheus)
        if schema_registry is not None:
            pulumi.set(__self__, "schema_registry", schema_registry)

    @property
    @pulumi.getter
    def kafka(self) -> Optional[str]:
        return pulumi.get(self, "kafka")

    @property
    @pulumi.getter(name="kafkaConnect")
    def kafka_connect(self) -> Optional[str]:
        return pulumi.get(self, "kafka_connect")

    @property
    @pulumi.getter(name="kafkaRest")
    def kafka_rest(self) -> Optional[str]:
        return pulumi.get(self, "kafka_rest")

    @property
    @pulumi.getter
    def prometheus(self) -> Optional[str]:
        return pulumi.get(self, "prometheus")

    @property
    @pulumi.getter(name="schemaRegistry")
    def schema_registry(self) -> Optional[str]:
        return pulumi.get(self, "schema_registry")


@pulumi.output_type
class GetServiceKafkaUserConfigSchemaRegistryConfigResult(dict):
    def __init__(__self__, *,
                 leader_eligibility: Optional[str] = None,
                 topic_name: Optional[str] = None):
        if leader_eligibility is not None:
            pulumi.set(__self__, "leader_eligibility", leader_eligibility)
        if topic_name is not None:
            pulumi.set(__self__, "topic_name", topic_name)

    @property
    @pulumi.getter(name="leaderEligibility")
    def leader_eligibility(self) -> Optional[str]:
        return pulumi.get(self, "leader_eligibility")

    @property
    @pulumi.getter(name="topicName")
    def topic_name(self) -> Optional[str]:
        return pulumi.get(self, "topic_name")


@pulumi.output_type
class GetServiceMysqlResult(dict):
    def __init__(__self__):
        pass


@pulumi.output_type
class GetServiceMysqlUserConfigResult(dict):
    def __init__(__self__, *,
                 admin_password: Optional[str] = None,
                 admin_username: Optional[str] = None,
                 backup_hour: Optional[str] = None,
                 backup_minute: Optional[str] = None,
                 binlog_retention_period: Optional[str] = None,
                 ip_filters: Optional[Sequence[str]] = None,
                 migration: Optional['outputs.GetServiceMysqlUserConfigMigrationResult'] = None,
                 mysql: Optional['outputs.GetServiceMysqlUserConfigMysqlResult'] = None,
                 mysql_version: Optional[str] = None,
                 private_access: Optional['outputs.GetServiceMysqlUserConfigPrivateAccessResult'] = None,
                 privatelink_access: Optional['outputs.GetServiceMysqlUserConfigPrivatelinkAccessResult'] = None,
                 project_to_fork_from: Optional[str] = None,
                 public_access: Optional['outputs.GetServiceMysqlUserConfigPublicAccessResult'] = None,
                 recovery_target_time: Optional[str] = None,
                 service_to_fork_from: Optional[str] = None):
        if admin_password is not None:
            pulumi.set(__self__, "admin_password", admin_password)
        if admin_username is not None:
            pulumi.set(__self__, "admin_username", admin_username)
        if backup_hour is not None:
            pulumi.set(__self__, "backup_hour", backup_hour)
        if backup_minute is not None:
            pulumi.set(__self__, "backup_minute", backup_minute)
        if binlog_retention_period is not None:
            pulumi.set(__self__, "binlog_retention_period", binlog_retention_period)
        if ip_filters is not None:
            pulumi.set(__self__, "ip_filters", ip_filters)
        if migration is not None:
            pulumi.set(__self__, "migration", migration)
        if mysql is not None:
            pulumi.set(__self__, "mysql", mysql)
        if mysql_version is not None:
            pulumi.set(__self__, "mysql_version", mysql_version)
        if private_access is not None:
            pulumi.set(__self__, "private_access", private_access)
        if privatelink_access is not None:
            pulumi.set(__self__, "privatelink_access", privatelink_access)
        if project_to_fork_from is not None:
            pulumi.set(__self__, "project_to_fork_from", project_to_fork_from)
        if public_access is not None:
            pulumi.set(__self__, "public_access", public_access)
        if recovery_target_time is not None:
            pulumi.set(__self__, "recovery_target_time", recovery_target_time)
        if service_to_fork_from is not None:
            pulumi.set(__self__, "service_to_fork_from", service_to_fork_from)

    @property
    @pulumi.getter(name="adminPassword")
    def admin_password(self) -> Optional[str]:
        return pulumi.get(self, "admin_password")

    @property
    @pulumi.getter(name="adminUsername")
    def admin_username(self) -> Optional[str]:
        return pulumi.get(self, "admin_username")

    @property
    @pulumi.getter(name="backupHour")
    def backup_hour(self) -> Optional[str]:
        return pulumi.get(self, "backup_hour")

    @property
    @pulumi.getter(name="backupMinute")
    def backup_minute(self) -> Optional[str]:
        return pulumi.get(self, "backup_minute")

    @property
    @pulumi.getter(name="binlogRetentionPeriod")
    def binlog_retention_period(self) -> Optional[str]:
        return pulumi.get(self, "binlog_retention_period")

    @property
    @pulumi.getter(name="ipFilters")
    def ip_filters(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "ip_filters")

    @property
    @pulumi.getter
    def migration(self) -> Optional['outputs.GetServiceMysqlUserConfigMigrationResult']:
        return pulumi.get(self, "migration")

    @property
    @pulumi.getter
    def mysql(self) -> Optional['outputs.GetServiceMysqlUserConfigMysqlResult']:
        return pulumi.get(self, "mysql")

    @property
    @pulumi.getter(name="mysqlVersion")
    def mysql_version(self) -> Optional[str]:
        return pulumi.get(self, "mysql_version")

    @property
    @pulumi.getter(name="privateAccess")
    def private_access(self) -> Optional['outputs.GetServiceMysqlUserConfigPrivateAccessResult']:
        return pulumi.get(self, "private_access")

    @property
    @pulumi.getter(name="privatelinkAccess")
    def privatelink_access(self) -> Optional['outputs.GetServiceMysqlUserConfigPrivatelinkAccessResult']:
        return pulumi.get(self, "privatelink_access")

    @property
    @pulumi.getter(name="projectToForkFrom")
    def project_to_fork_from(self) -> Optional[str]:
        return pulumi.get(self, "project_to_fork_from")

    @property
    @pulumi.getter(name="publicAccess")
    def public_access(self) -> Optional['outputs.GetServiceMysqlUserConfigPublicAccessResult']:
        return pulumi.get(self, "public_access")

    @property
    @pulumi.getter(name="recoveryTargetTime")
    def recovery_target_time(self) -> Optional[str]:
        return pulumi.get(self, "recovery_target_time")

    @property
    @pulumi.getter(name="serviceToForkFrom")
    def service_to_fork_from(self) -> Optional[str]:
        return pulumi.get(self, "service_to_fork_from")


@pulumi.output_type
class GetServiceMysqlUserConfigMigrationResult(dict):
    def __init__(__self__, *,
                 dbname: Optional[str] = None,
                 host: Optional[str] = None,
                 ignore_dbs: Optional[str] = None,
                 password: Optional[str] = None,
                 port: Optional[str] = None,
                 ssl: Optional[str] = None,
                 username: Optional[str] = None):
        if dbname is not None:
            pulumi.set(__self__, "dbname", dbname)
        if host is not None:
            pulumi.set(__self__, "host", host)
        if ignore_dbs is not None:
            pulumi.set(__self__, "ignore_dbs", ignore_dbs)
        if password is not None:
            pulumi.set(__self__, "password", password)
        if port is not None:
            pulumi.set(__self__, "port", port)
        if ssl is not None:
            pulumi.set(__self__, "ssl", ssl)
        if username is not None:
            pulumi.set(__self__, "username", username)

    @property
    @pulumi.getter
    def dbname(self) -> Optional[str]:
        return pulumi.get(self, "dbname")

    @property
    @pulumi.getter
    def host(self) -> Optional[str]:
        return pulumi.get(self, "host")

    @property
    @pulumi.getter(name="ignoreDbs")
    def ignore_dbs(self) -> Optional[str]:
        return pulumi.get(self, "ignore_dbs")

    @property
    @pulumi.getter
    def password(self) -> Optional[str]:
        return pulumi.get(self, "password")

    @property
    @pulumi.getter
    def port(self) -> Optional[str]:
        return pulumi.get(self, "port")

    @property
    @pulumi.getter
    def ssl(self) -> Optional[str]:
        return pulumi.get(self, "ssl")

    @property
    @pulumi.getter
    def username(self) -> Optional[str]:
        return pulumi.get(self, "username")


@pulumi.output_type
class GetServiceMysqlUserConfigMysqlResult(dict):
    def __init__(__self__, *,
                 connect_timeout: Optional[str] = None,
                 default_time_zone: Optional[str] = None,
                 group_concat_max_len: Optional[str] = None,
                 information_schema_stats_expiry: Optional[str] = None,
                 innodb_ft_min_token_size: Optional[str] = None,
                 innodb_ft_server_stopword_table: Optional[str] = None,
                 innodb_lock_wait_timeout: Optional[str] = None,
                 innodb_log_buffer_size: Optional[str] = None,
                 innodb_online_alter_log_max_size: Optional[str] = None,
                 innodb_print_all_deadlocks: Optional[str] = None,
                 innodb_rollback_on_timeout: Optional[str] = None,
                 interactive_timeout: Optional[str] = None,
                 long_query_time: Optional[str] = None,
                 max_allowed_packet: Optional[str] = None,
                 max_heap_table_size: Optional[str] = None,
                 net_read_timeout: Optional[str] = None,
                 net_write_timeout: Optional[str] = None,
                 slow_query_log: Optional[str] = None,
                 sort_buffer_size: Optional[str] = None,
                 sql_mode: Optional[str] = None,
                 sql_require_primary_key: Optional[str] = None,
                 tmp_table_size: Optional[str] = None,
                 wait_timeout: Optional[str] = None):
        if connect_timeout is not None:
            pulumi.set(__self__, "connect_timeout", connect_timeout)
        if default_time_zone is not None:
            pulumi.set(__self__, "default_time_zone", default_time_zone)
        if group_concat_max_len is not None:
            pulumi.set(__self__, "group_concat_max_len", group_concat_max_len)
        if information_schema_stats_expiry is not None:
            pulumi.set(__self__, "information_schema_stats_expiry", information_schema_stats_expiry)
        if innodb_ft_min_token_size is not None:
            pulumi.set(__self__, "innodb_ft_min_token_size", innodb_ft_min_token_size)
        if innodb_ft_server_stopword_table is not None:
            pulumi.set(__self__, "innodb_ft_server_stopword_table", innodb_ft_server_stopword_table)
        if innodb_lock_wait_timeout is not None:
            pulumi.set(__self__, "innodb_lock_wait_timeout", innodb_lock_wait_timeout)
        if innodb_log_buffer_size is not None:
            pulumi.set(__self__, "innodb_log_buffer_size", innodb_log_buffer_size)
        if innodb_online_alter_log_max_size is not None:
            pulumi.set(__self__, "innodb_online_alter_log_max_size", innodb_online_alter_log_max_size)
        if innodb_print_all_deadlocks is not None:
            pulumi.set(__self__, "innodb_print_all_deadlocks", innodb_print_all_deadlocks)
        if innodb_rollback_on_timeout is not None:
            pulumi.set(__self__, "innodb_rollback_on_timeout", innodb_rollback_on_timeout)
        if interactive_timeout is not None:
            pulumi.set(__self__, "interactive_timeout", interactive_timeout)
        if long_query_time is not None:
            pulumi.set(__self__, "long_query_time", long_query_time)
        if max_allowed_packet is not None:
            pulumi.set(__self__, "max_allowed_packet", max_allowed_packet)
        if max_heap_table_size is not None:
            pulumi.set(__self__, "max_heap_table_size", max_heap_table_size)
        if net_read_timeout is not None:
            pulumi.set(__self__, "net_read_timeout", net_read_timeout)
        if net_write_timeout is not None:
            pulumi.set(__self__, "net_write_timeout", net_write_timeout)
        if slow_query_log is not None:
            pulumi.set(__self__, "slow_query_log", slow_query_log)
        if sort_buffer_size is not None:
            pulumi.set(__self__, "sort_buffer_size", sort_buffer_size)
        if sql_mode is not None:
            pulumi.set(__self__, "sql_mode", sql_mode)
        if sql_require_primary_key is not None:
            pulumi.set(__self__, "sql_require_primary_key", sql_require_primary_key)
        if tmp_table_size is not None:
            pulumi.set(__self__, "tmp_table_size", tmp_table_size)
        if wait_timeout is not None:
            pulumi.set(__self__, "wait_timeout", wait_timeout)

    @property
    @pulumi.getter(name="connectTimeout")
    def connect_timeout(self) -> Optional[str]:
        return pulumi.get(self, "connect_timeout")

    @property
    @pulumi.getter(name="defaultTimeZone")
    def default_time_zone(self) -> Optional[str]:
        return pulumi.get(self, "default_time_zone")

    @property
    @pulumi.getter(name="groupConcatMaxLen")
    def group_concat_max_len(self) -> Optional[str]:
        return pulumi.get(self, "group_concat_max_len")

    @property
    @pulumi.getter(name="informationSchemaStatsExpiry")
    def information_schema_stats_expiry(self) -> Optional[str]:
        return pulumi.get(self, "information_schema_stats_expiry")

    @property
    @pulumi.getter(name="innodbFtMinTokenSize")
    def innodb_ft_min_token_size(self) -> Optional[str]:
        return pulumi.get(self, "innodb_ft_min_token_size")

    @property
    @pulumi.getter(name="innodbFtServerStopwordTable")
    def innodb_ft_server_stopword_table(self) -> Optional[str]:
        return pulumi.get(self, "innodb_ft_server_stopword_table")

    @property
    @pulumi.getter(name="innodbLockWaitTimeout")
    def innodb_lock_wait_timeout(self) -> Optional[str]:
        return pulumi.get(self, "innodb_lock_wait_timeout")

    @property
    @pulumi.getter(name="innodbLogBufferSize")
    def innodb_log_buffer_size(self) -> Optional[str]:
        return pulumi.get(self, "innodb_log_buffer_size")

    @property
    @pulumi.getter(name="innodbOnlineAlterLogMaxSize")
    def innodb_online_alter_log_max_size(self) -> Optional[str]:
        return pulumi.get(self, "innodb_online_alter_log_max_size")

    @property
    @pulumi.getter(name="innodbPrintAllDeadlocks")
    def innodb_print_all_deadlocks(self) -> Optional[str]:
        return pulumi.get(self, "innodb_print_all_deadlocks")

    @property
    @pulumi.getter(name="innodbRollbackOnTimeout")
    def innodb_rollback_on_timeout(self) -> Optional[str]:
        return pulumi.get(self, "innodb_rollback_on_timeout")

    @property
    @pulumi.getter(name="interactiveTimeout")
    def interactive_timeout(self) -> Optional[str]:
        return pulumi.get(self, "interactive_timeout")

    @property
    @pulumi.getter(name="longQueryTime")
    def long_query_time(self) -> Optional[str]:
        return pulumi.get(self, "long_query_time")

    @property
    @pulumi.getter(name="maxAllowedPacket")
    def max_allowed_packet(self) -> Optional[str]:
        return pulumi.get(self, "max_allowed_packet")

    @property
    @pulumi.getter(name="maxHeapTableSize")
    def max_heap_table_size(self) -> Optional[str]:
        return pulumi.get(self, "max_heap_table_size")

    @property
    @pulumi.getter(name="netReadTimeout")
    def net_read_timeout(self) -> Optional[str]:
        return pulumi.get(self, "net_read_timeout")

    @property
    @pulumi.getter(name="netWriteTimeout")
    def net_write_timeout(self) -> Optional[str]:
        return pulumi.get(self, "net_write_timeout")

    @property
    @pulumi.getter(name="slowQueryLog")
    def slow_query_log(self) -> Optional[str]:
        return pulumi.get(self, "slow_query_log")

    @property
    @pulumi.getter(name="sortBufferSize")
    def sort_buffer_size(self) -> Optional[str]:
        return pulumi.get(self, "sort_buffer_size")

    @property
    @pulumi.getter(name="sqlMode")
    def sql_mode(self) -> Optional[str]:
        return pulumi.get(self, "sql_mode")

    @property
    @pulumi.getter(name="sqlRequirePrimaryKey")
    def sql_require_primary_key(self) -> Optional[str]:
        return pulumi.get(self, "sql_require_primary_key")

    @property
    @pulumi.getter(name="tmpTableSize")
    def tmp_table_size(self) -> Optional[str]:
        return pulumi.get(self, "tmp_table_size")

    @property
    @pulumi.getter(name="waitTimeout")
    def wait_timeout(self) -> Optional[str]:
        return pulumi.get(self, "wait_timeout")


@pulumi.output_type
class GetServiceMysqlUserConfigPrivateAccessResult(dict):
    def __init__(__self__, *,
                 mysql: Optional[str] = None,
                 mysqlx: Optional[str] = None,
                 prometheus: Optional[str] = None):
        if mysql is not None:
            pulumi.set(__self__, "mysql", mysql)
        if mysqlx is not None:
            pulumi.set(__self__, "mysqlx", mysqlx)
        if prometheus is not None:
            pulumi.set(__self__, "prometheus", prometheus)

    @property
    @pulumi.getter
    def mysql(self) -> Optional[str]:
        return pulumi.get(self, "mysql")

    @property
    @pulumi.getter
    def mysqlx(self) -> Optional[str]:
        return pulumi.get(self, "mysqlx")

    @property
    @pulumi.getter
    def prometheus(self) -> Optional[str]:
        return pulumi.get(self, "prometheus")


@pulumi.output_type
class GetServiceMysqlUserConfigPrivatelinkAccessResult(dict):
    def __init__(__self__, *,
                 mysql: Optional[str] = None,
                 mysqlx: Optional[str] = None):
        if mysql is not None:
            pulumi.set(__self__, "mysql", mysql)
        if mysqlx is not None:
            pulumi.set(__self__, "mysqlx", mysqlx)

    @property
    @pulumi.getter
    def mysql(self) -> Optional[str]:
        return pulumi.get(self, "mysql")

    @property
    @pulumi.getter
    def mysqlx(self) -> Optional[str]:
        return pulumi.get(self, "mysqlx")


@pulumi.output_type
class GetServiceMysqlUserConfigPublicAccessResult(dict):
    def __init__(__self__, *,
                 mysql: Optional[str] = None,
                 mysqlx: Optional[str] = None,
                 prometheus: Optional[str] = None):
        if mysql is not None:
            pulumi.set(__self__, "mysql", mysql)
        if mysqlx is not None:
            pulumi.set(__self__, "mysqlx", mysqlx)
        if prometheus is not None:
            pulumi.set(__self__, "prometheus", prometheus)

    @property
    @pulumi.getter
    def mysql(self) -> Optional[str]:
        return pulumi.get(self, "mysql")

    @property
    @pulumi.getter
    def mysqlx(self) -> Optional[str]:
        return pulumi.get(self, "mysqlx")

    @property
    @pulumi.getter
    def prometheus(self) -> Optional[str]:
        return pulumi.get(self, "prometheus")


@pulumi.output_type
class GetServicePgResult(dict):
    def __init__(__self__, *,
                 dbname: str,
                 host: str,
                 password: str,
                 port: int,
                 replica_uri: str,
                 sslmode: str,
                 uri: str,
                 user: str):
        pulumi.set(__self__, "dbname", dbname)
        pulumi.set(__self__, "host", host)
        pulumi.set(__self__, "password", password)
        pulumi.set(__self__, "port", port)
        pulumi.set(__self__, "replica_uri", replica_uri)
        pulumi.set(__self__, "sslmode", sslmode)
        pulumi.set(__self__, "uri", uri)
        pulumi.set(__self__, "user", user)

    @property
    @pulumi.getter
    def dbname(self) -> str:
        return pulumi.get(self, "dbname")

    @property
    @pulumi.getter
    def host(self) -> str:
        return pulumi.get(self, "host")

    @property
    @pulumi.getter
    def password(self) -> str:
        return pulumi.get(self, "password")

    @property
    @pulumi.getter
    def port(self) -> int:
        return pulumi.get(self, "port")

    @property
    @pulumi.getter(name="replicaUri")
    def replica_uri(self) -> str:
        return pulumi.get(self, "replica_uri")

    @property
    @pulumi.getter
    def sslmode(self) -> str:
        return pulumi.get(self, "sslmode")

    @property
    @pulumi.getter
    def uri(self) -> str:
        return pulumi.get(self, "uri")

    @property
    @pulumi.getter
    def user(self) -> str:
        return pulumi.get(self, "user")


@pulumi.output_type
class GetServicePgUserConfigResult(dict):
    def __init__(__self__, *,
                 admin_password: Optional[str] = None,
                 admin_username: Optional[str] = None,
                 backup_hour: Optional[str] = None,
                 backup_minute: Optional[str] = None,
                 ip_filters: Optional[Sequence[str]] = None,
                 migration: Optional['outputs.GetServicePgUserConfigMigrationResult'] = None,
                 pg: Optional['outputs.GetServicePgUserConfigPgResult'] = None,
                 pg_read_replica: Optional[str] = None,
                 pg_service_to_fork_from: Optional[str] = None,
                 pg_version: Optional[str] = None,
                 pgbouncer: Optional['outputs.GetServicePgUserConfigPgbouncerResult'] = None,
                 pglookout: Optional['outputs.GetServicePgUserConfigPglookoutResult'] = None,
                 private_access: Optional['outputs.GetServicePgUserConfigPrivateAccessResult'] = None,
                 privatelink_access: Optional['outputs.GetServicePgUserConfigPrivatelinkAccessResult'] = None,
                 project_to_fork_from: Optional[str] = None,
                 public_access: Optional['outputs.GetServicePgUserConfigPublicAccessResult'] = None,
                 recovery_target_time: Optional[str] = None,
                 service_to_fork_from: Optional[str] = None,
                 shared_buffers_percentage: Optional[str] = None,
                 synchronous_replication: Optional[str] = None,
                 timescaledb: Optional['outputs.GetServicePgUserConfigTimescaledbResult'] = None,
                 variant: Optional[str] = None,
                 work_mem: Optional[str] = None):
        if admin_password is not None:
            pulumi.set(__self__, "admin_password", admin_password)
        if admin_username is not None:
            pulumi.set(__self__, "admin_username", admin_username)
        if backup_hour is not None:
            pulumi.set(__self__, "backup_hour", backup_hour)
        if backup_minute is not None:
            pulumi.set(__self__, "backup_minute", backup_minute)
        if ip_filters is not None:
            pulumi.set(__self__, "ip_filters", ip_filters)
        if migration is not None:
            pulumi.set(__self__, "migration", migration)
        if pg is not None:
            pulumi.set(__self__, "pg", pg)
        if pg_read_replica is not None:
            pulumi.set(__self__, "pg_read_replica", pg_read_replica)
        if pg_service_to_fork_from is not None:
            pulumi.set(__self__, "pg_service_to_fork_from", pg_service_to_fork_from)
        if pg_version is not None:
            pulumi.set(__self__, "pg_version", pg_version)
        if pgbouncer is not None:
            pulumi.set(__self__, "pgbouncer", pgbouncer)
        if pglookout is not None:
            pulumi.set(__self__, "pglookout", pglookout)
        if private_access is not None:
            pulumi.set(__self__, "private_access", private_access)
        if privatelink_access is not None:
            pulumi.set(__self__, "privatelink_access", privatelink_access)
        if project_to_fork_from is not None:
            pulumi.set(__self__, "project_to_fork_from", project_to_fork_from)
        if public_access is not None:
            pulumi.set(__self__, "public_access", public_access)
        if recovery_target_time is not None:
            pulumi.set(__self__, "recovery_target_time", recovery_target_time)
        if service_to_fork_from is not None:
            pulumi.set(__self__, "service_to_fork_from", service_to_fork_from)
        if shared_buffers_percentage is not None:
            pulumi.set(__self__, "shared_buffers_percentage", shared_buffers_percentage)
        if synchronous_replication is not None:
            pulumi.set(__self__, "synchronous_replication", synchronous_replication)
        if timescaledb is not None:
            pulumi.set(__self__, "timescaledb", timescaledb)
        if variant is not None:
            pulumi.set(__self__, "variant", variant)
        if work_mem is not None:
            pulumi.set(__self__, "work_mem", work_mem)

    @property
    @pulumi.getter(name="adminPassword")
    def admin_password(self) -> Optional[str]:
        return pulumi.get(self, "admin_password")

    @property
    @pulumi.getter(name="adminUsername")
    def admin_username(self) -> Optional[str]:
        return pulumi.get(self, "admin_username")

    @property
    @pulumi.getter(name="backupHour")
    def backup_hour(self) -> Optional[str]:
        return pulumi.get(self, "backup_hour")

    @property
    @pulumi.getter(name="backupMinute")
    def backup_minute(self) -> Optional[str]:
        return pulumi.get(self, "backup_minute")

    @property
    @pulumi.getter(name="ipFilters")
    def ip_filters(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "ip_filters")

    @property
    @pulumi.getter
    def migration(self) -> Optional['outputs.GetServicePgUserConfigMigrationResult']:
        return pulumi.get(self, "migration")

    @property
    @pulumi.getter
    def pg(self) -> Optional['outputs.GetServicePgUserConfigPgResult']:
        return pulumi.get(self, "pg")

    @property
    @pulumi.getter(name="pgReadReplica")
    def pg_read_replica(self) -> Optional[str]:
        return pulumi.get(self, "pg_read_replica")

    @property
    @pulumi.getter(name="pgServiceToForkFrom")
    def pg_service_to_fork_from(self) -> Optional[str]:
        return pulumi.get(self, "pg_service_to_fork_from")

    @property
    @pulumi.getter(name="pgVersion")
    def pg_version(self) -> Optional[str]:
        return pulumi.get(self, "pg_version")

    @property
    @pulumi.getter
    def pgbouncer(self) -> Optional['outputs.GetServicePgUserConfigPgbouncerResult']:
        return pulumi.get(self, "pgbouncer")

    @property
    @pulumi.getter
    def pglookout(self) -> Optional['outputs.GetServicePgUserConfigPglookoutResult']:
        return pulumi.get(self, "pglookout")

    @property
    @pulumi.getter(name="privateAccess")
    def private_access(self) -> Optional['outputs.GetServicePgUserConfigPrivateAccessResult']:
        return pulumi.get(self, "private_access")

    @property
    @pulumi.getter(name="privatelinkAccess")
    def privatelink_access(self) -> Optional['outputs.GetServicePgUserConfigPrivatelinkAccessResult']:
        return pulumi.get(self, "privatelink_access")

    @property
    @pulumi.getter(name="projectToForkFrom")
    def project_to_fork_from(self) -> Optional[str]:
        return pulumi.get(self, "project_to_fork_from")

    @property
    @pulumi.getter(name="publicAccess")
    def public_access(self) -> Optional['outputs.GetServicePgUserConfigPublicAccessResult']:
        return pulumi.get(self, "public_access")

    @property
    @pulumi.getter(name="recoveryTargetTime")
    def recovery_target_time(self) -> Optional[str]:
        return pulumi.get(self, "recovery_target_time")

    @property
    @pulumi.getter(name="serviceToForkFrom")
    def service_to_fork_from(self) -> Optional[str]:
        return pulumi.get(self, "service_to_fork_from")

    @property
    @pulumi.getter(name="sharedBuffersPercentage")
    def shared_buffers_percentage(self) -> Optional[str]:
        return pulumi.get(self, "shared_buffers_percentage")

    @property
    @pulumi.getter(name="synchronousReplication")
    def synchronous_replication(self) -> Optional[str]:
        return pulumi.get(self, "synchronous_replication")

    @property
    @pulumi.getter
    def timescaledb(self) -> Optional['outputs.GetServicePgUserConfigTimescaledbResult']:
        return pulumi.get(self, "timescaledb")

    @property
    @pulumi.getter
    def variant(self) -> Optional[str]:
        return pulumi.get(self, "variant")

    @property
    @pulumi.getter(name="workMem")
    def work_mem(self) -> Optional[str]:
        return pulumi.get(self, "work_mem")


@pulumi.output_type
class GetServicePgUserConfigMigrationResult(dict):
    def __init__(__self__, *,
                 dbname: Optional[str] = None,
                 host: Optional[str] = None,
                 ignore_dbs: Optional[str] = None,
                 password: Optional[str] = None,
                 port: Optional[str] = None,
                 ssl: Optional[str] = None,
                 username: Optional[str] = None):
        if dbname is not None:
            pulumi.set(__self__, "dbname", dbname)
        if host is not None:
            pulumi.set(__self__, "host", host)
        if ignore_dbs is not None:
            pulumi.set(__self__, "ignore_dbs", ignore_dbs)
        if password is not None:
            pulumi.set(__self__, "password", password)
        if port is not None:
            pulumi.set(__self__, "port", port)
        if ssl is not None:
            pulumi.set(__self__, "ssl", ssl)
        if username is not None:
            pulumi.set(__self__, "username", username)

    @property
    @pulumi.getter
    def dbname(self) -> Optional[str]:
        return pulumi.get(self, "dbname")

    @property
    @pulumi.getter
    def host(self) -> Optional[str]:
        return pulumi.get(self, "host")

    @property
    @pulumi.getter(name="ignoreDbs")
    def ignore_dbs(self) -> Optional[str]:
        return pulumi.get(self, "ignore_dbs")

    @property
    @pulumi.getter
    def password(self) -> Optional[str]:
        return pulumi.get(self, "password")

    @property
    @pulumi.getter
    def port(self) -> Optional[str]:
        return pulumi.get(self, "port")

    @property
    @pulumi.getter
    def ssl(self) -> Optional[str]:
        return pulumi.get(self, "ssl")

    @property
    @pulumi.getter
    def username(self) -> Optional[str]:
        return pulumi.get(self, "username")


@pulumi.output_type
class GetServicePgUserConfigPgResult(dict):
    def __init__(__self__, *,
                 autovacuum_analyze_scale_factor: Optional[str] = None,
                 autovacuum_analyze_threshold: Optional[str] = None,
                 autovacuum_freeze_max_age: Optional[str] = None,
                 autovacuum_max_workers: Optional[str] = None,
                 autovacuum_naptime: Optional[str] = None,
                 autovacuum_vacuum_cost_delay: Optional[str] = None,
                 autovacuum_vacuum_cost_limit: Optional[str] = None,
                 autovacuum_vacuum_scale_factor: Optional[str] = None,
                 autovacuum_vacuum_threshold: Optional[str] = None,
                 deadlock_timeout: Optional[str] = None,
                 idle_in_transaction_session_timeout: Optional[str] = None,
                 jit: Optional[str] = None,
                 log_autovacuum_min_duration: Optional[str] = None,
                 log_error_verbosity: Optional[str] = None,
                 log_line_prefix: Optional[str] = None,
                 log_min_duration_statement: Optional[str] = None,
                 max_files_per_process: Optional[str] = None,
                 max_locks_per_transaction: Optional[str] = None,
                 max_logical_replication_workers: Optional[str] = None,
                 max_parallel_workers: Optional[str] = None,
                 max_parallel_workers_per_gather: Optional[str] = None,
                 max_pred_locks_per_transaction: Optional[str] = None,
                 max_prepared_transactions: Optional[str] = None,
                 max_replication_slots: Optional[str] = None,
                 max_stack_depth: Optional[str] = None,
                 max_standby_archive_delay: Optional[str] = None,
                 max_standby_streaming_delay: Optional[str] = None,
                 max_wal_senders: Optional[str] = None,
                 max_worker_processes: Optional[str] = None,
                 pg_partman_bgw_interval: Optional[str] = None,
                 pg_partman_bgw_role: Optional[str] = None,
                 pg_stat_statements_track: Optional[str] = None,
                 temp_file_limit: Optional[str] = None,
                 timezone: Optional[str] = None,
                 track_activity_query_size: Optional[str] = None,
                 track_commit_timestamp: Optional[str] = None,
                 track_functions: Optional[str] = None,
                 track_io_timing: Optional[str] = None,
                 wal_sender_timeout: Optional[str] = None,
                 wal_writer_delay: Optional[str] = None):
        if autovacuum_analyze_scale_factor is not None:
            pulumi.set(__self__, "autovacuum_analyze_scale_factor", autovacuum_analyze_scale_factor)
        if autovacuum_analyze_threshold is not None:
            pulumi.set(__self__, "autovacuum_analyze_threshold", autovacuum_analyze_threshold)
        if autovacuum_freeze_max_age is not None:
            pulumi.set(__self__, "autovacuum_freeze_max_age", autovacuum_freeze_max_age)
        if autovacuum_max_workers is not None:
            pulumi.set(__self__, "autovacuum_max_workers", autovacuum_max_workers)
        if autovacuum_naptime is not None:
            pulumi.set(__self__, "autovacuum_naptime", autovacuum_naptime)
        if autovacuum_vacuum_cost_delay is not None:
            pulumi.set(__self__, "autovacuum_vacuum_cost_delay", autovacuum_vacuum_cost_delay)
        if autovacuum_vacuum_cost_limit is not None:
            pulumi.set(__self__, "autovacuum_vacuum_cost_limit", autovacuum_vacuum_cost_limit)
        if autovacuum_vacuum_scale_factor is not None:
            pulumi.set(__self__, "autovacuum_vacuum_scale_factor", autovacuum_vacuum_scale_factor)
        if autovacuum_vacuum_threshold is not None:
            pulumi.set(__self__, "autovacuum_vacuum_threshold", autovacuum_vacuum_threshold)
        if deadlock_timeout is not None:
            pulumi.set(__self__, "deadlock_timeout", deadlock_timeout)
        if idle_in_transaction_session_timeout is not None:
            pulumi.set(__self__, "idle_in_transaction_session_timeout", idle_in_transaction_session_timeout)
        if jit is not None:
            pulumi.set(__self__, "jit", jit)
        if log_autovacuum_min_duration is not None:
            pulumi.set(__self__, "log_autovacuum_min_duration", log_autovacuum_min_duration)
        if log_error_verbosity is not None:
            pulumi.set(__self__, "log_error_verbosity", log_error_verbosity)
        if log_line_prefix is not None:
            pulumi.set(__self__, "log_line_prefix", log_line_prefix)
        if log_min_duration_statement is not None:
            pulumi.set(__self__, "log_min_duration_statement", log_min_duration_statement)
        if max_files_per_process is not None:
            pulumi.set(__self__, "max_files_per_process", max_files_per_process)
        if max_locks_per_transaction is not None:
            pulumi.set(__self__, "max_locks_per_transaction", max_locks_per_transaction)
        if max_logical_replication_workers is not None:
            pulumi.set(__self__, "max_logical_replication_workers", max_logical_replication_workers)
        if max_parallel_workers is not None:
            pulumi.set(__self__, "max_parallel_workers", max_parallel_workers)
        if max_parallel_workers_per_gather is not None:
            pulumi.set(__self__, "max_parallel_workers_per_gather", max_parallel_workers_per_gather)
        if max_pred_locks_per_transaction is not None:
            pulumi.set(__self__, "max_pred_locks_per_transaction", max_pred_locks_per_transaction)
        if max_prepared_transactions is not None:
            pulumi.set(__self__, "max_prepared_transactions", max_prepared_transactions)
        if max_replication_slots is not None:
            pulumi.set(__self__, "max_replication_slots", max_replication_slots)
        if max_stack_depth is not None:
            pulumi.set(__self__, "max_stack_depth", max_stack_depth)
        if max_standby_archive_delay is not None:
            pulumi.set(__self__, "max_standby_archive_delay", max_standby_archive_delay)
        if max_standby_streaming_delay is not None:
            pulumi.set(__self__, "max_standby_streaming_delay", max_standby_streaming_delay)
        if max_wal_senders is not None:
            pulumi.set(__self__, "max_wal_senders", max_wal_senders)
        if max_worker_processes is not None:
            pulumi.set(__self__, "max_worker_processes", max_worker_processes)
        if pg_partman_bgw_interval is not None:
            pulumi.set(__self__, "pg_partman_bgw_interval", pg_partman_bgw_interval)
        if pg_partman_bgw_role is not None:
            pulumi.set(__self__, "pg_partman_bgw_role", pg_partman_bgw_role)
        if pg_stat_statements_track is not None:
            pulumi.set(__self__, "pg_stat_statements_track", pg_stat_statements_track)
        if temp_file_limit is not None:
            pulumi.set(__self__, "temp_file_limit", temp_file_limit)
        if timezone is not None:
            pulumi.set(__self__, "timezone", timezone)
        if track_activity_query_size is not None:
            pulumi.set(__self__, "track_activity_query_size", track_activity_query_size)
        if track_commit_timestamp is not None:
            pulumi.set(__self__, "track_commit_timestamp", track_commit_timestamp)
        if track_functions is not None:
            pulumi.set(__self__, "track_functions", track_functions)
        if track_io_timing is not None:
            pulumi.set(__self__, "track_io_timing", track_io_timing)
        if wal_sender_timeout is not None:
            pulumi.set(__self__, "wal_sender_timeout", wal_sender_timeout)
        if wal_writer_delay is not None:
            pulumi.set(__self__, "wal_writer_delay", wal_writer_delay)

    @property
    @pulumi.getter(name="autovacuumAnalyzeScaleFactor")
    def autovacuum_analyze_scale_factor(self) -> Optional[str]:
        return pulumi.get(self, "autovacuum_analyze_scale_factor")

    @property
    @pulumi.getter(name="autovacuumAnalyzeThreshold")
    def autovacuum_analyze_threshold(self) -> Optional[str]:
        return pulumi.get(self, "autovacuum_analyze_threshold")

    @property
    @pulumi.getter(name="autovacuumFreezeMaxAge")
    def autovacuum_freeze_max_age(self) -> Optional[str]:
        return pulumi.get(self, "autovacuum_freeze_max_age")

    @property
    @pulumi.getter(name="autovacuumMaxWorkers")
    def autovacuum_max_workers(self) -> Optional[str]:
        return pulumi.get(self, "autovacuum_max_workers")

    @property
    @pulumi.getter(name="autovacuumNaptime")
    def autovacuum_naptime(self) -> Optional[str]:
        return pulumi.get(self, "autovacuum_naptime")

    @property
    @pulumi.getter(name="autovacuumVacuumCostDelay")
    def autovacuum_vacuum_cost_delay(self) -> Optional[str]:
        return pulumi.get(self, "autovacuum_vacuum_cost_delay")

    @property
    @pulumi.getter(name="autovacuumVacuumCostLimit")
    def autovacuum_vacuum_cost_limit(self) -> Optional[str]:
        return pulumi.get(self, "autovacuum_vacuum_cost_limit")

    @property
    @pulumi.getter(name="autovacuumVacuumScaleFactor")
    def autovacuum_vacuum_scale_factor(self) -> Optional[str]:
        return pulumi.get(self, "autovacuum_vacuum_scale_factor")

    @property
    @pulumi.getter(name="autovacuumVacuumThreshold")
    def autovacuum_vacuum_threshold(self) -> Optional[str]:
        return pulumi.get(self, "autovacuum_vacuum_threshold")

    @property
    @pulumi.getter(name="deadlockTimeout")
    def deadlock_timeout(self) -> Optional[str]:
        return pulumi.get(self, "deadlock_timeout")

    @property
    @pulumi.getter(name="idleInTransactionSessionTimeout")
    def idle_in_transaction_session_timeout(self) -> Optional[str]:
        return pulumi.get(self, "idle_in_transaction_session_timeout")

    @property
    @pulumi.getter
    def jit(self) -> Optional[str]:
        return pulumi.get(self, "jit")

    @property
    @pulumi.getter(name="logAutovacuumMinDuration")
    def log_autovacuum_min_duration(self) -> Optional[str]:
        return pulumi.get(self, "log_autovacuum_min_duration")

    @property
    @pulumi.getter(name="logErrorVerbosity")
    def log_error_verbosity(self) -> Optional[str]:
        return pulumi.get(self, "log_error_verbosity")

    @property
    @pulumi.getter(name="logLinePrefix")
    def log_line_prefix(self) -> Optional[str]:
        return pulumi.get(self, "log_line_prefix")

    @property
    @pulumi.getter(name="logMinDurationStatement")
    def log_min_duration_statement(self) -> Optional[str]:
        return pulumi.get(self, "log_min_duration_statement")

    @property
    @pulumi.getter(name="maxFilesPerProcess")
    def max_files_per_process(self) -> Optional[str]:
        return pulumi.get(self, "max_files_per_process")

    @property
    @pulumi.getter(name="maxLocksPerTransaction")
    def max_locks_per_transaction(self) -> Optional[str]:
        return pulumi.get(self, "max_locks_per_transaction")

    @property
    @pulumi.getter(name="maxLogicalReplicationWorkers")
    def max_logical_replication_workers(self) -> Optional[str]:
        return pulumi.get(self, "max_logical_replication_workers")

    @property
    @pulumi.getter(name="maxParallelWorkers")
    def max_parallel_workers(self) -> Optional[str]:
        return pulumi.get(self, "max_parallel_workers")

    @property
    @pulumi.getter(name="maxParallelWorkersPerGather")
    def max_parallel_workers_per_gather(self) -> Optional[str]:
        return pulumi.get(self, "max_parallel_workers_per_gather")

    @property
    @pulumi.getter(name="maxPredLocksPerTransaction")
    def max_pred_locks_per_transaction(self) -> Optional[str]:
        return pulumi.get(self, "max_pred_locks_per_transaction")

    @property
    @pulumi.getter(name="maxPreparedTransactions")
    def max_prepared_transactions(self) -> Optional[str]:
        return pulumi.get(self, "max_prepared_transactions")

    @property
    @pulumi.getter(name="maxReplicationSlots")
    def max_replication_slots(self) -> Optional[str]:
        return pulumi.get(self, "max_replication_slots")

    @property
    @pulumi.getter(name="maxStackDepth")
    def max_stack_depth(self) -> Optional[str]:
        return pulumi.get(self, "max_stack_depth")

    @property
    @pulumi.getter(name="maxStandbyArchiveDelay")
    def max_standby_archive_delay(self) -> Optional[str]:
        return pulumi.get(self, "max_standby_archive_delay")

    @property
    @pulumi.getter(name="maxStandbyStreamingDelay")
    def max_standby_streaming_delay(self) -> Optional[str]:
        return pulumi.get(self, "max_standby_streaming_delay")

    @property
    @pulumi.getter(name="maxWalSenders")
    def max_wal_senders(self) -> Optional[str]:
        return pulumi.get(self, "max_wal_senders")

    @property
    @pulumi.getter(name="maxWorkerProcesses")
    def max_worker_processes(self) -> Optional[str]:
        return pulumi.get(self, "max_worker_processes")

    @property
    @pulumi.getter(name="pgPartmanBgwInterval")
    def pg_partman_bgw_interval(self) -> Optional[str]:
        return pulumi.get(self, "pg_partman_bgw_interval")

    @property
    @pulumi.getter(name="pgPartmanBgwRole")
    def pg_partman_bgw_role(self) -> Optional[str]:
        return pulumi.get(self, "pg_partman_bgw_role")

    @property
    @pulumi.getter(name="pgStatStatementsTrack")
    def pg_stat_statements_track(self) -> Optional[str]:
        return pulumi.get(self, "pg_stat_statements_track")

    @property
    @pulumi.getter(name="tempFileLimit")
    def temp_file_limit(self) -> Optional[str]:
        return pulumi.get(self, "temp_file_limit")

    @property
    @pulumi.getter
    def timezone(self) -> Optional[str]:
        return pulumi.get(self, "timezone")

    @property
    @pulumi.getter(name="trackActivityQuerySize")
    def track_activity_query_size(self) -> Optional[str]:
        return pulumi.get(self, "track_activity_query_size")

    @property
    @pulumi.getter(name="trackCommitTimestamp")
    def track_commit_timestamp(self) -> Optional[str]:
        return pulumi.get(self, "track_commit_timestamp")

    @property
    @pulumi.getter(name="trackFunctions")
    def track_functions(self) -> Optional[str]:
        return pulumi.get(self, "track_functions")

    @property
    @pulumi.getter(name="trackIoTiming")
    def track_io_timing(self) -> Optional[str]:
        return pulumi.get(self, "track_io_timing")

    @property
    @pulumi.getter(name="walSenderTimeout")
    def wal_sender_timeout(self) -> Optional[str]:
        return pulumi.get(self, "wal_sender_timeout")

    @property
    @pulumi.getter(name="walWriterDelay")
    def wal_writer_delay(self) -> Optional[str]:
        return pulumi.get(self, "wal_writer_delay")


@pulumi.output_type
class GetServicePgUserConfigPgbouncerResult(dict):
    def __init__(__self__, *,
                 autodb_idle_timeout: Optional[str] = None,
                 autodb_max_db_connections: Optional[str] = None,
                 autodb_pool_mode: Optional[str] = None,
                 autodb_pool_size: Optional[str] = None,
                 ignore_startup_parameters: Optional[Sequence[str]] = None,
                 min_pool_size: Optional[str] = None,
                 server_idle_timeout: Optional[str] = None,
                 server_lifetime: Optional[str] = None,
                 server_reset_query_always: Optional[str] = None):
        if autodb_idle_timeout is not None:
            pulumi.set(__self__, "autodb_idle_timeout", autodb_idle_timeout)
        if autodb_max_db_connections is not None:
            pulumi.set(__self__, "autodb_max_db_connections", autodb_max_db_connections)
        if autodb_pool_mode is not None:
            pulumi.set(__self__, "autodb_pool_mode", autodb_pool_mode)
        if autodb_pool_size is not None:
            pulumi.set(__self__, "autodb_pool_size", autodb_pool_size)
        if ignore_startup_parameters is not None:
            pulumi.set(__self__, "ignore_startup_parameters", ignore_startup_parameters)
        if min_pool_size is not None:
            pulumi.set(__self__, "min_pool_size", min_pool_size)
        if server_idle_timeout is not None:
            pulumi.set(__self__, "server_idle_timeout", server_idle_timeout)
        if server_lifetime is not None:
            pulumi.set(__self__, "server_lifetime", server_lifetime)
        if server_reset_query_always is not None:
            pulumi.set(__self__, "server_reset_query_always", server_reset_query_always)

    @property
    @pulumi.getter(name="autodbIdleTimeout")
    def autodb_idle_timeout(self) -> Optional[str]:
        return pulumi.get(self, "autodb_idle_timeout")

    @property
    @pulumi.getter(name="autodbMaxDbConnections")
    def autodb_max_db_connections(self) -> Optional[str]:
        return pulumi.get(self, "autodb_max_db_connections")

    @property
    @pulumi.getter(name="autodbPoolMode")
    def autodb_pool_mode(self) -> Optional[str]:
        return pulumi.get(self, "autodb_pool_mode")

    @property
    @pulumi.getter(name="autodbPoolSize")
    def autodb_pool_size(self) -> Optional[str]:
        return pulumi.get(self, "autodb_pool_size")

    @property
    @pulumi.getter(name="ignoreStartupParameters")
    def ignore_startup_parameters(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "ignore_startup_parameters")

    @property
    @pulumi.getter(name="minPoolSize")
    def min_pool_size(self) -> Optional[str]:
        return pulumi.get(self, "min_pool_size")

    @property
    @pulumi.getter(name="serverIdleTimeout")
    def server_idle_timeout(self) -> Optional[str]:
        return pulumi.get(self, "server_idle_timeout")

    @property
    @pulumi.getter(name="serverLifetime")
    def server_lifetime(self) -> Optional[str]:
        return pulumi.get(self, "server_lifetime")

    @property
    @pulumi.getter(name="serverResetQueryAlways")
    def server_reset_query_always(self) -> Optional[str]:
        return pulumi.get(self, "server_reset_query_always")


@pulumi.output_type
class GetServicePgUserConfigPglookoutResult(dict):
    def __init__(__self__, *,
                 max_failover_replication_time_lag: Optional[str] = None):
        if max_failover_replication_time_lag is not None:
            pulumi.set(__self__, "max_failover_replication_time_lag", max_failover_replication_time_lag)

    @property
    @pulumi.getter(name="maxFailoverReplicationTimeLag")
    def max_failover_replication_time_lag(self) -> Optional[str]:
        return pulumi.get(self, "max_failover_replication_time_lag")


@pulumi.output_type
class GetServicePgUserConfigPrivateAccessResult(dict):
    def __init__(__self__, *,
                 pg: Optional[str] = None,
                 pgbouncer: Optional[str] = None,
                 prometheus: Optional[str] = None):
        if pg is not None:
            pulumi.set(__self__, "pg", pg)
        if pgbouncer is not None:
            pulumi.set(__self__, "pgbouncer", pgbouncer)
        if prometheus is not None:
            pulumi.set(__self__, "prometheus", prometheus)

    @property
    @pulumi.getter
    def pg(self) -> Optional[str]:
        return pulumi.get(self, "pg")

    @property
    @pulumi.getter
    def pgbouncer(self) -> Optional[str]:
        return pulumi.get(self, "pgbouncer")

    @property
    @pulumi.getter
    def prometheus(self) -> Optional[str]:
        return pulumi.get(self, "prometheus")


@pulumi.output_type
class GetServicePgUserConfigPrivatelinkAccessResult(dict):
    def __init__(__self__, *,
                 pg: Optional[str] = None,
                 pgbouncer: Optional[str] = None):
        if pg is not None:
            pulumi.set(__self__, "pg", pg)
        if pgbouncer is not None:
            pulumi.set(__self__, "pgbouncer", pgbouncer)

    @property
    @pulumi.getter
    def pg(self) -> Optional[str]:
        return pulumi.get(self, "pg")

    @property
    @pulumi.getter
    def pgbouncer(self) -> Optional[str]:
        return pulumi.get(self, "pgbouncer")


@pulumi.output_type
class GetServicePgUserConfigPublicAccessResult(dict):
    def __init__(__self__, *,
                 pg: Optional[str] = None,
                 pgbouncer: Optional[str] = None,
                 prometheus: Optional[str] = None):
        if pg is not None:
            pulumi.set(__self__, "pg", pg)
        if pgbouncer is not None:
            pulumi.set(__self__, "pgbouncer", pgbouncer)
        if prometheus is not None:
            pulumi.set(__self__, "prometheus", prometheus)

    @property
    @pulumi.getter
    def pg(self) -> Optional[str]:
        return pulumi.get(self, "pg")

    @property
    @pulumi.getter
    def pgbouncer(self) -> Optional[str]:
        return pulumi.get(self, "pgbouncer")

    @property
    @pulumi.getter
    def prometheus(self) -> Optional[str]:
        return pulumi.get(self, "prometheus")


@pulumi.output_type
class GetServicePgUserConfigTimescaledbResult(dict):
    def __init__(__self__, *,
                 max_background_workers: Optional[str] = None):
        if max_background_workers is not None:
            pulumi.set(__self__, "max_background_workers", max_background_workers)

    @property
    @pulumi.getter(name="maxBackgroundWorkers")
    def max_background_workers(self) -> Optional[str]:
        return pulumi.get(self, "max_background_workers")


@pulumi.output_type
class GetServiceRedisResult(dict):
    def __init__(__self__):
        pass


@pulumi.output_type
class GetServiceRedisUserConfigResult(dict):
    def __init__(__self__, *,
                 ip_filters: Optional[Sequence[str]] = None,
                 migration: Optional['outputs.GetServiceRedisUserConfigMigrationResult'] = None,
                 private_access: Optional['outputs.GetServiceRedisUserConfigPrivateAccessResult'] = None,
                 privatelink_access: Optional['outputs.GetServiceRedisUserConfigPrivatelinkAccessResult'] = None,
                 project_to_fork_from: Optional[str] = None,
                 public_access: Optional['outputs.GetServiceRedisUserConfigPublicAccessResult'] = None,
                 recovery_basebackup_name: Optional[str] = None,
                 redis_io_threads: Optional[str] = None,
                 redis_lfu_decay_time: Optional[str] = None,
                 redis_lfu_log_factor: Optional[str] = None,
                 redis_maxmemory_policy: Optional[str] = None,
                 redis_notify_keyspace_events: Optional[str] = None,
                 redis_ssl: Optional[str] = None,
                 redis_timeout: Optional[str] = None,
                 service_to_fork_from: Optional[str] = None):
        if ip_filters is not None:
            pulumi.set(__self__, "ip_filters", ip_filters)
        if migration is not None:
            pulumi.set(__self__, "migration", migration)
        if private_access is not None:
            pulumi.set(__self__, "private_access", private_access)
        if privatelink_access is not None:
            pulumi.set(__self__, "privatelink_access", privatelink_access)
        if project_to_fork_from is not None:
            pulumi.set(__self__, "project_to_fork_from", project_to_fork_from)
        if public_access is not None:
            pulumi.set(__self__, "public_access", public_access)
        if recovery_basebackup_name is not None:
            pulumi.set(__self__, "recovery_basebackup_name", recovery_basebackup_name)
        if redis_io_threads is not None:
            pulumi.set(__self__, "redis_io_threads", redis_io_threads)
        if redis_lfu_decay_time is not None:
            pulumi.set(__self__, "redis_lfu_decay_time", redis_lfu_decay_time)
        if redis_lfu_log_factor is not None:
            pulumi.set(__self__, "redis_lfu_log_factor", redis_lfu_log_factor)
        if redis_maxmemory_policy is not None:
            pulumi.set(__self__, "redis_maxmemory_policy", redis_maxmemory_policy)
        if redis_notify_keyspace_events is not None:
            pulumi.set(__self__, "redis_notify_keyspace_events", redis_notify_keyspace_events)
        if redis_ssl is not None:
            pulumi.set(__self__, "redis_ssl", redis_ssl)
        if redis_timeout is not None:
            pulumi.set(__self__, "redis_timeout", redis_timeout)
        if service_to_fork_from is not None:
            pulumi.set(__self__, "service_to_fork_from", service_to_fork_from)

    @property
    @pulumi.getter(name="ipFilters")
    def ip_filters(self) -> Optional[Sequence[str]]:
        return pulumi.get(self, "ip_filters")

    @property
    @pulumi.getter
    def migration(self) -> Optional['outputs.GetServiceRedisUserConfigMigrationResult']:
        return pulumi.get(self, "migration")

    @property
    @pulumi.getter(name="privateAccess")
    def private_access(self) -> Optional['outputs.GetServiceRedisUserConfigPrivateAccessResult']:
        return pulumi.get(self, "private_access")

    @property
    @pulumi.getter(name="privatelinkAccess")
    def privatelink_access(self) -> Optional['outputs.GetServiceRedisUserConfigPrivatelinkAccessResult']:
        return pulumi.get(self, "privatelink_access")

    @property
    @pulumi.getter(name="projectToForkFrom")
    def project_to_fork_from(self) -> Optional[str]:
        return pulumi.get(self, "project_to_fork_from")

    @property
    @pulumi.getter(name="publicAccess")
    def public_access(self) -> Optional['outputs.GetServiceRedisUserConfigPublicAccessResult']:
        return pulumi.get(self, "public_access")

    @property
    @pulumi.getter(name="recoveryBasebackupName")
    def recovery_basebackup_name(self) -> Optional[str]:
        return pulumi.get(self, "recovery_basebackup_name")

    @property
    @pulumi.getter(name="redisIoThreads")
    def redis_io_threads(self) -> Optional[str]:
        return pulumi.get(self, "redis_io_threads")

    @property
    @pulumi.getter(name="redisLfuDecayTime")
    def redis_lfu_decay_time(self) -> Optional[str]:
        return pulumi.get(self, "redis_lfu_decay_time")

    @property
    @pulumi.getter(name="redisLfuLogFactor")
    def redis_lfu_log_factor(self) -> Optional[str]:
        return pulumi.get(self, "redis_lfu_log_factor")

    @property
    @pulumi.getter(name="redisMaxmemoryPolicy")
    def redis_maxmemory_policy(self) -> Optional[str]:
        return pulumi.get(self, "redis_maxmemory_policy")

    @property
    @pulumi.getter(name="redisNotifyKeyspaceEvents")
    def redis_notify_keyspace_events(self) -> Optional[str]:
        return pulumi.get(self, "redis_notify_keyspace_events")

    @property
    @pulumi.getter(name="redisSsl")
    def redis_ssl(self) -> Optional[str]:
        return pulumi.get(self, "redis_ssl")

    @property
    @pulumi.getter(name="redisTimeout")
    def redis_timeout(self) -> Optional[str]:
        return pulumi.get(self, "redis_timeout")

    @property
    @pulumi.getter(name="serviceToForkFrom")
    def service_to_fork_from(self) -> Optional[str]:
        return pulumi.get(self, "service_to_fork_from")


@pulumi.output_type
class GetServiceRedisUserConfigMigrationResult(dict):
    def __init__(__self__, *,
                 dbname: Optional[str] = None,
                 host: Optional[str] = None,
                 ignore_dbs: Optional[str] = None,
                 password: Optional[str] = None,
                 port: Optional[str] = None,
                 ssl: Optional[str] = None,
                 username: Optional[str] = None):
        if dbname is not None:
            pulumi.set(__self__, "dbname", dbname)
        if host is not None:
            pulumi.set(__self__, "host", host)
        if ignore_dbs is not None:
            pulumi.set(__self__, "ignore_dbs", ignore_dbs)
        if password is not None:
            pulumi.set(__self__, "password", password)
        if port is not None:
            pulumi.set(__self__, "port", port)
        if ssl is not None:
            pulumi.set(__self__, "ssl", ssl)
        if username is not None:
            pulumi.set(__self__, "username", username)

    @property
    @pulumi.getter
    def dbname(self) -> Optional[str]:
        return pulumi.get(self, "dbname")

    @property
    @pulumi.getter
    def host(self) -> Optional[str]:
        return pulumi.get(self, "host")

    @property
    @pulumi.getter(name="ignoreDbs")
    def ignore_dbs(self) -> Optional[str]:
        return pulumi.get(self, "ignore_dbs")

    @property
    @pulumi.getter
    def password(self) -> Optional[str]:
        return pulumi.get(self, "password")

    @property
    @pulumi.getter
    def port(self) -> Optional[str]:
        return pulumi.get(self, "port")

    @property
    @pulumi.getter
    def ssl(self) -> Optional[str]:
        return pulumi.get(self, "ssl")

    @property
    @pulumi.getter
    def username(self) -> Optional[str]:
        return pulumi.get(self, "username")


@pulumi.output_type
class GetServiceRedisUserConfigPrivateAccessResult(dict):
    def __init__(__self__, *,
                 prometheus: Optional[str] = None,
                 redis: Optional[str] = None):
        if prometheus is not None:
            pulumi.set(__self__, "prometheus", prometheus)
        if redis is not None:
            pulumi.set(__self__, "redis", redis)

    @property
    @pulumi.getter
    def prometheus(self) -> Optional[str]:
        return pulumi.get(self, "prometheus")

    @property
    @pulumi.getter
    def redis(self) -> Optional[str]:
        return pulumi.get(self, "redis")


@pulumi.output_type
class GetServiceRedisUserConfigPrivatelinkAccessResult(dict):
    def __init__(__self__, *,
                 redis: Optional[str] = None):
        if redis is not None:
            pulumi.set(__self__, "redis", redis)

    @property
    @pulumi.getter
    def redis(self) -> Optional[str]:
        return pulumi.get(self, "redis")


@pulumi.output_type
class GetServiceRedisUserConfigPublicAccessResult(dict):
    def __init__(__self__, *,
                 prometheus: Optional[str] = None,
                 redis: Optional[str] = None):
        if prometheus is not None:
            pulumi.set(__self__, "prometheus", prometheus)
        if redis is not None:
            pulumi.set(__self__, "redis", redis)

    @property
    @pulumi.getter
    def prometheus(self) -> Optional[str]:
        return pulumi.get(self, "prometheus")

    @property
    @pulumi.getter
    def redis(self) -> Optional[str]:
        return pulumi.get(self, "redis")


@pulumi.output_type
class GetServiceServiceIntegrationResult(dict):
    def __init__(__self__, *,
                 integration_type: str,
                 source_service_name: str):
        pulumi.set(__self__, "integration_type", integration_type)
        pulumi.set(__self__, "source_service_name", source_service_name)

    @property
    @pulumi.getter(name="integrationType")
    def integration_type(self) -> str:
        return pulumi.get(self, "integration_type")

    @property
    @pulumi.getter(name="sourceServiceName")
    def source_service_name(self) -> str:
        return pulumi.get(self, "source_service_name")


