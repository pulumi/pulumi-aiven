// *** WARNING: this file was generated by pulumi-language-dotnet. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

using System;
using System.Collections.Generic;
using System.Collections.Immutable;
using System.Threading.Tasks;
using Pulumi.Serialization;

namespace Pulumi.Aiven.Outputs
{

    [OutputType]
    public sealed class ServiceIntegrationClickhouseKafkaUserConfigTable
    {
        /// <summary>
        /// Enum: `beginning`, `earliest`, `end`, `largest`, `latest`, `smallest`. Action to take when there is no initial offset in offset store or the desired offset is out of range. Default: `earliest`.
        /// </summary>
        public readonly string? AutoOffsetReset;
        /// <summary>
        /// Table columns
        /// </summary>
        public readonly ImmutableArray<Outputs.ServiceIntegrationClickhouseKafkaUserConfigTableColumn> Columns;
        /// <summary>
        /// Enum: `Avro`, `AvroConfluent`, `CSV`, `JSONAsString`, `JSONCompactEachRow`, `JSONCompactStringsEachRow`, `JSONEachRow`, `JSONStringsEachRow`, `MsgPack`, `Parquet`, `RawBLOB`, `TSKV`, `TSV`, `TabSeparated`. Message data format. Default: `JSONEachRow`.
        /// </summary>
        public readonly string DataFormat;
        /// <summary>
        /// Enum: `basic`, `best_effort`, `best_effort_us`. Method to read DateTime from text input formats. Default: `basic`.
        /// </summary>
        public readonly string? DateTimeInputFormat;
        /// <summary>
        /// Kafka consumers group. Default: `clickhouse`.
        /// </summary>
        public readonly string GroupName;
        /// <summary>
        /// Enum: `default`, `stream`. How to handle errors for Kafka engine. Default: `default`.
        /// </summary>
        public readonly string? HandleErrorMode;
        /// <summary>
        /// Number of row collected by poll(s) for flushing data from Kafka. Default: `0`.
        /// </summary>
        public readonly int? MaxBlockSize;
        /// <summary>
        /// The maximum number of rows produced in one kafka message for row-based formats. Default: `1`.
        /// </summary>
        public readonly int? MaxRowsPerMessage;
        /// <summary>
        /// Name of the table. Example: `events`.
        /// </summary>
        public readonly string Name;
        /// <summary>
        /// The number of consumers per table per replica. Default: `1`.
        /// </summary>
        public readonly int? NumConsumers;
        /// <summary>
        /// Maximum amount of messages to be polled in a single Kafka poll. Default: `0`.
        /// </summary>
        public readonly int? PollMaxBatchSize;
        /// <summary>
        /// Timeout in milliseconds for a single poll from Kafka. Takes the value of the stream*flush*interval_ms server setting by default (500ms). Default: `0`.
        /// </summary>
        public readonly int? PollMaxTimeoutMs;
        /// <summary>
        /// Skip at least this number of broken messages from Kafka topic per block. Default: `0`.
        /// </summary>
        public readonly int? SkipBrokenMessages;
        /// <summary>
        /// Provide an independent thread for each consumer. All consumers run in the same thread by default. Default: `false`.
        /// </summary>
        public readonly bool? ThreadPerConsumer;
        /// <summary>
        /// Kafka topics
        /// </summary>
        public readonly ImmutableArray<Outputs.ServiceIntegrationClickhouseKafkaUserConfigTableTopic> Topics;

        [OutputConstructor]
        private ServiceIntegrationClickhouseKafkaUserConfigTable(
            string? autoOffsetReset,

            ImmutableArray<Outputs.ServiceIntegrationClickhouseKafkaUserConfigTableColumn> columns,

            string dataFormat,

            string? dateTimeInputFormat,

            string groupName,

            string? handleErrorMode,

            int? maxBlockSize,

            int? maxRowsPerMessage,

            string name,

            int? numConsumers,

            int? pollMaxBatchSize,

            int? pollMaxTimeoutMs,

            int? skipBrokenMessages,

            bool? threadPerConsumer,

            ImmutableArray<Outputs.ServiceIntegrationClickhouseKafkaUserConfigTableTopic> topics)
        {
            AutoOffsetReset = autoOffsetReset;
            Columns = columns;
            DataFormat = dataFormat;
            DateTimeInputFormat = dateTimeInputFormat;
            GroupName = groupName;
            HandleErrorMode = handleErrorMode;
            MaxBlockSize = maxBlockSize;
            MaxRowsPerMessage = maxRowsPerMessage;
            Name = name;
            NumConsumers = numConsumers;
            PollMaxBatchSize = pollMaxBatchSize;
            PollMaxTimeoutMs = pollMaxTimeoutMs;
            SkipBrokenMessages = skipBrokenMessages;
            ThreadPerConsumer = threadPerConsumer;
            Topics = topics;
        }
    }
}
