// *** WARNING: this file was generated by pulumi-language-dotnet. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

using System;
using System.Collections.Generic;
using System.Collections.Immutable;
using System.Threading.Tasks;
using Pulumi.Serialization;

namespace Pulumi.Aiven.Inputs
{

    public sealed class GetKafkaTopicListTopicInputArgs : global::Pulumi.ResourceArgs
    {
        /// <summary>
        /// The retention policy to use on old segments. Possible values include 'delete', 'compact', or a comma-separated list of them. The default policy ('delete') will discard old segments when their retention time or size limit has been reached. The 'compact' setting will enable log compaction on the topic.
        /// </summary>
        [Input("cleanupPolicy", required: true)]
        public Input<string> CleanupPolicy { get; set; } = null!;

        /// <summary>
        /// Indicates whether diskless should be enabled. This is only available for BYOC services with Diskless feature enabled.
        /// </summary>
        [Input("disklessEnable", required: true)]
        public Input<bool> DisklessEnable { get; set; } = null!;

        /// <summary>
        /// When a producer sets acks to 'all' (or '-1'), this configuration specifies the minimum number of replicas that must acknowledge a write for the write to be considered successful. If this minimum cannot be met, then the producer will raise an exception (either NotEnoughReplicas or NotEnoughReplicasAfterAppend). When used together, min.insync.replicas and acks allow you to enforce greater durability guarantees. A typical scenario would be to create a topic with a replication factor of 3, set min.insync.replicas to 2, and produce with acks of 'all'. This will ensure that the producer raises an exception if a majority of replicas do not receive a write.
        /// </summary>
        [Input("minInsyncReplicas", required: true)]
        public Input<int> MinInsyncReplicas { get; set; } = null!;

        /// <summary>
        /// The user group that owns this topic.
        /// </summary>
        [Input("ownerUserGroupId", required: true)]
        public Input<string> OwnerUserGroupId { get; set; } = null!;

        /// <summary>
        /// Number of partitions.
        /// </summary>
        [Input("partitions", required: true)]
        public Input<int> Partitions { get; set; } = null!;

        /// <summary>
        /// Indicates whether tiered storage should be enabled. This is only available for services with Tiered Storage feature enabled.
        /// </summary>
        [Input("remoteStorageEnable", required: true)]
        public Input<bool> RemoteStorageEnable { get; set; } = null!;

        /// <summary>
        /// Number of replicas.
        /// </summary>
        [Input("replication", required: true)]
        public Input<int> Replication { get; set; } = null!;

        /// <summary>
        /// This configuration controls the maximum size a partition (which consists of log segments) can grow to before we will discard old log segments to free up space if we are using the 'delete' retention policy. By default there is no size limit only a time limit. Since this limit is enforced at the partition level, multiply it by the number of partitions to compute the topic retention in bytes.
        /// </summary>
        [Input("retentionBytes", required: true)]
        public Input<int> RetentionBytes { get; set; } = null!;

        /// <summary>
        /// Retention period (hours).
        /// </summary>
        [Input("retentionHours", required: true)]
        public Input<int> RetentionHours { get; set; } = null!;

        /// <summary>
        /// Topic state. The possible values are `ACTIVE`, `CONFIGURING` and `DELETING`.
        /// </summary>
        [Input("state", required: true)]
        public Input<string> State { get; set; } = null!;

        [Input("tags")]
        private InputList<Inputs.GetKafkaTopicListTopicTagInputArgs>? _tags;

        /// <summary>
        /// Topic tags.
        /// </summary>
        public InputList<Inputs.GetKafkaTopicListTopicTagInputArgs> Tags
        {
            get => _tags ?? (_tags = new InputList<Inputs.GetKafkaTopicListTopicTagInputArgs>());
            set => _tags = value;
        }

        /// <summary>
        /// Topic description.
        /// </summary>
        [Input("topicDescription", required: true)]
        public Input<string> TopicDescription { get; set; } = null!;

        /// <summary>
        /// Topic name.
        /// </summary>
        [Input("topicName", required: true)]
        public Input<string> TopicName { get; set; } = null!;

        public GetKafkaTopicListTopicInputArgs()
        {
        }
        public static new GetKafkaTopicListTopicInputArgs Empty => new GetKafkaTopicListTopicInputArgs();
    }
}
