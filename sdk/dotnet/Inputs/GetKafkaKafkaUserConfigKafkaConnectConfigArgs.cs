// *** WARNING: this file was generated by the Pulumi Terraform Bridge (tfgen) Tool. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

using System;
using System.Collections.Generic;
using System.Collections.Immutable;
using System.Threading.Tasks;
using Pulumi.Serialization;

namespace Pulumi.Aiven.Inputs
{

    public sealed class GetKafkaKafkaUserConfigKafkaConnectConfigInputArgs : Pulumi.ResourceArgs
    {
        /// <summary>
        /// Defines what client configurations can 
        /// be overridden by the connector. Default is None
        /// </summary>
        [Input("connectorClientConfigOverridePolicy")]
        public Input<string>? ConnectorClientConfigOverridePolicy { get; set; }

        /// <summary>
        /// What to do when there is no initial offset in Kafka or 
        /// if the current offset does not exist any more on the server. Default is earliest.
        /// </summary>
        [Input("consumerAutoOffsetReset")]
        public Input<string>? ConsumerAutoOffsetReset { get; set; }

        /// <summary>
        /// Records are fetched in batches by the consumer, and 
        /// if the first record batch in the first non-empty partition of the fetch is larger than this value,
        /// the record batch will still be returned to ensure that the consumer can make progress. As such,
        /// this is not a absolute maximum.
        /// </summary>
        [Input("consumerFetchMaxBytes")]
        public Input<string>? ConsumerFetchMaxBytes { get; set; }

        /// <summary>
        /// Transaction read isolation level. read_uncommitted is 
        /// the default, but read_committed can be used if consume-exactly-once behavior is desired.
        /// </summary>
        [Input("consumerIsolationLevel")]
        public Input<string>? ConsumerIsolationLevel { get; set; }

        /// <summary>
        /// Records are fetched in batches by the consumer.If 
        /// the first record batch in the first non-empty partition of the fetch is larger than this limit,
        /// the batch will still be returned to ensure that the consumer can make progress.
        /// </summary>
        [Input("consumerMaxPartitionFetchBytes")]
        public Input<string>? ConsumerMaxPartitionFetchBytes { get; set; }

        /// <summary>
        /// The maximum delay in milliseconds between invocations 
        /// of poll() when using consumer group management (defaults to 300000).
        /// </summary>
        [Input("consumerMaxPollIntervalMs")]
        public Input<string>? ConsumerMaxPollIntervalMs { get; set; }

        /// <summary>
        /// The maximum number of records returned in a single call 
        /// to poll() (defaults to 500).
        /// </summary>
        [Input("consumerMaxPollRecords")]
        public Input<string>? ConsumerMaxPollRecords { get; set; }

        /// <summary>
        /// The interval at which to try committing offsets for 
        /// tasks (defaults to 60000).
        /// </summary>
        [Input("offsetFlushIntervalMs")]
        public Input<string>? OffsetFlushIntervalMs { get; set; }

        /// <summary>
        /// Maximum number of milliseconds to wait for records to 
        /// flush and partition offset data to be committed to offset storage before cancelling the process
        /// and restoring the offset data to be committed in a future attempt (defaults to 5000).
        /// </summary>
        [Input("offsetFlushTimeoutMs")]
        public Input<string>? OffsetFlushTimeoutMs { get; set; }

        /// <summary>
        /// This setting will limit the number of record batches 
        /// the producer will send in a single request to avoid sending huge requests.
        /// </summary>
        [Input("producerMaxRequestSize")]
        public Input<string>? ProducerMaxRequestSize { get; set; }

        /// <summary>
        /// The timeout in milliseconds used to detect failures when 
        /// using Kafkaâ€™s group management facilities (defaults to 10000).
        /// </summary>
        [Input("sessionTimeoutMs")]
        public Input<string>? SessionTimeoutMs { get; set; }

        public GetKafkaKafkaUserConfigKafkaConnectConfigInputArgs()
        {
        }
    }
}
