// *** WARNING: this file was generated by pulumi-language-dotnet. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

using System;
using System.Collections.Generic;
using System.Collections.Immutable;
using System.Threading.Tasks;
using Pulumi.Serialization;

namespace Pulumi.Aiven.Inputs
{

    public sealed class KafkaKafkaUserConfigArgs : global::Pulumi.ResourceArgs
    {
        /// <summary>
        /// Additional Cloud Regions for Backup Replication.
        /// </summary>
        [Input("additionalBackupRegions")]
        public Input<string>? AdditionalBackupRegions { get; set; }

        /// <summary>
        /// Allow access to read Kafka topic messages in the Aiven Console and REST API.
        /// </summary>
        [Input("aivenKafkaTopicMessages")]
        public Input<bool>? AivenKafkaTopicMessages { get; set; }

        /// <summary>
        /// Interval in hours between automatic backups. Minimum value is 3 hours. Must be a divisor of 24 (3, 4, 6, 8, 12, 24). (Applicable to ACU plans only). Example: `24`.
        /// </summary>
        [Input("backupIntervalHours")]
        public Input<int>? BackupIntervalHours { get; set; }

        /// <summary>
        /// Number of days to retain automatic backups. Backups older than this value will be automatically deleted. (Applicable to ACU plans only). Example: `7`.
        /// </summary>
        [Input("backupRetentionDays")]
        public Input<int>? BackupRetentionDays { get; set; }

        /// <summary>
        /// Serve the web frontend using a custom CNAME pointing to the Aiven DNS name. When you set a custom domain for a service deployed in a VPC, the service certificate is only created for the public-* hostname and the custom domain. Example: `grafana.example.org`.
        /// </summary>
        [Input("customDomain")]
        public Input<string>? CustomDomain { get; set; }

        /// <summary>
        /// Enable follower fetching
        /// </summary>
        [Input("followerFetching")]
        public Input<Inputs.KafkaKafkaUserConfigFollowerFetchingArgs>? FollowerFetching { get; set; }

        [Input("ipFilterObjects")]
        private InputList<Inputs.KafkaKafkaUserConfigIpFilterObjectArgs>? _ipFilterObjects;

        /// <summary>
        /// Allow incoming connections from CIDR address block, e.g. `10.20.0.0/16`
        /// </summary>
        public InputList<Inputs.KafkaKafkaUserConfigIpFilterObjectArgs> IpFilterObjects
        {
            get => _ipFilterObjects ?? (_ipFilterObjects = new InputList<Inputs.KafkaKafkaUserConfigIpFilterObjectArgs>());
            set => _ipFilterObjects = value;
        }

        [Input("ipFilterStrings")]
        private InputList<string>? _ipFilterStrings;

        /// <summary>
        /// Allow incoming connections from CIDR address block, e.g. `10.20.0.0/16`.
        /// </summary>
        public InputList<string> IpFilterStrings
        {
            get => _ipFilterStrings ?? (_ipFilterStrings = new InputList<string>());
            set => _ipFilterStrings = value;
        }

        [Input("ipFilters")]
        private InputList<string>? _ipFilters;

        /// <summary>
        /// Allow incoming connections from CIDR address block, e.g. `10.20.0.0/16`.
        /// </summary>
        [Obsolete(@"Deprecated. Use `IpFilterString` instead.")]
        public InputList<string> IpFilters
        {
            get => _ipFilters ?? (_ipFilters = new InputList<string>());
            set => _ipFilters = value;
        }

        /// <summary>
        /// Kafka broker configuration values
        /// </summary>
        [Input("kafka")]
        public Input<Inputs.KafkaKafkaUserConfigKafkaArgs>? Kafka { get; set; }

        /// <summary>
        /// Kafka authentication methods
        /// </summary>
        [Input("kafkaAuthenticationMethods")]
        public Input<Inputs.KafkaKafkaUserConfigKafkaAuthenticationMethodsArgs>? KafkaAuthenticationMethods { get; set; }

        /// <summary>
        /// Enable Kafka Connect service. Default: `False`.
        /// </summary>
        [Input("kafkaConnect")]
        public Input<bool>? KafkaConnect { get; set; }

        /// <summary>
        /// Kafka Connect configuration values
        /// </summary>
        [Input("kafkaConnectConfig")]
        public Input<Inputs.KafkaKafkaUserConfigKafkaConnectConfigArgs>? KafkaConnectConfig { get; set; }

        [Input("kafkaConnectPluginVersions")]
        private InputList<Inputs.KafkaKafkaUserConfigKafkaConnectPluginVersionArgs>? _kafkaConnectPluginVersions;

        /// <summary>
        /// The plugin selected by the user
        /// </summary>
        public InputList<Inputs.KafkaKafkaUserConfigKafkaConnectPluginVersionArgs> KafkaConnectPluginVersions
        {
            get => _kafkaConnectPluginVersions ?? (_kafkaConnectPluginVersions = new InputList<Inputs.KafkaKafkaUserConfigKafkaConnectPluginVersionArgs>());
            set => _kafkaConnectPluginVersions = value;
        }

        [Input("kafkaConnectSecretProviders")]
        private InputList<Inputs.KafkaKafkaUserConfigKafkaConnectSecretProviderArgs>? _kafkaConnectSecretProviders;

        /// <summary>
        /// Configure external secret providers in order to reference external secrets in connector configuration. Currently Hashicorp Vault (provider: vault, auth*method: token) and AWS Secrets Manager (provider: aws, auth*method: credentials) are supported. Secrets can be referenced in connector config with ${\n\n:\n\n:\n\n}
        /// </summary>
        public InputList<Inputs.KafkaKafkaUserConfigKafkaConnectSecretProviderArgs> KafkaConnectSecretProviders
        {
            get => _kafkaConnectSecretProviders ?? (_kafkaConnectSecretProviders = new InputList<Inputs.KafkaKafkaUserConfigKafkaConnectSecretProviderArgs>());
            set => _kafkaConnectSecretProviders = value;
        }

        /// <summary>
        /// Kafka Diskless configuration values
        /// </summary>
        [Input("kafkaDiskless")]
        public Input<Inputs.KafkaKafkaUserConfigKafkaDisklessArgs>? KafkaDiskless { get; set; }

        /// <summary>
        /// Enable Kafka-REST service. Default: `False`.
        /// </summary>
        [Input("kafkaRest")]
        public Input<bool>? KafkaRest { get; set; }

        /// <summary>
        /// Enable authorization in Kafka-REST service.
        /// </summary>
        [Input("kafkaRestAuthorization")]
        public Input<bool>? KafkaRestAuthorization { get; set; }

        /// <summary>
        /// Kafka REST configuration
        /// </summary>
        [Input("kafkaRestConfig")]
        public Input<Inputs.KafkaKafkaUserConfigKafkaRestConfigArgs>? KafkaRestConfig { get; set; }

        /// <summary>
        /// Kafka SASL mechanisms
        /// </summary>
        [Input("kafkaSaslMechanisms")]
        public Input<Inputs.KafkaKafkaUserConfigKafkaSaslMechanismsArgs>? KafkaSaslMechanisms { get; set; }

        /// <summary>
        /// Enum: `3.1`, `3.2`, `3.3`, `3.4`, `3.5`, `3.6`, `3.7`, `3.8`, `3.9`, `4.0`, `4.1`, and newer. Kafka major version.
        /// </summary>
        [Input("kafkaVersion")]
        public Input<string>? KafkaVersion { get; set; }

        /// <summary>
        /// Use a Let's Encrypt certificate authority (CA) for Kafka SASL authentication. (Default: False).
        /// </summary>
        [Input("letsencryptSasl")]
        public Input<bool>? LetsencryptSasl { get; set; }

        /// <summary>
        /// Use a Let's Encrypt certificate authority (CA) for Kafka SASL authentication via Privatelink. (Default: False).
        /// </summary>
        [Input("letsencryptSaslPrivatelink")]
        public Input<bool>? LetsencryptSaslPrivatelink { get; set; }

        /// <summary>
        /// Allow access to selected service ports from private networks
        /// </summary>
        [Input("privateAccess")]
        public Input<Inputs.KafkaKafkaUserConfigPrivateAccessArgs>? PrivateAccess { get; set; }

        /// <summary>
        /// Allow access to selected service components through Privatelink
        /// </summary>
        [Input("privatelinkAccess")]
        public Input<Inputs.KafkaKafkaUserConfigPrivatelinkAccessArgs>? PrivatelinkAccess { get; set; }

        /// <summary>
        /// Allow access to selected service ports from the public Internet
        /// </summary>
        [Input("publicAccess")]
        public Input<Inputs.KafkaKafkaUserConfigPublicAccessArgs>? PublicAccess { get; set; }

        [Input("saslOauthbearerAllowedUrls")]
        private InputList<string>? _saslOauthbearerAllowedUrls;

        /// <summary>
        /// List of allowed URLs for SASL OAUTHBEARER authentication. Only HTTPS URLs are allowed for security reasons.
        /// </summary>
        public InputList<string> SaslOauthbearerAllowedUrls
        {
            get => _saslOauthbearerAllowedUrls ?? (_saslOauthbearerAllowedUrls = new InputList<string>());
            set => _saslOauthbearerAllowedUrls = value;
        }

        /// <summary>
        /// Enable Schema-Registry service. Default: `False`.
        /// </summary>
        [Input("schemaRegistry")]
        public Input<bool>? SchemaRegistry { get; set; }

        /// <summary>
        /// Schema Registry configuration
        /// </summary>
        [Input("schemaRegistryConfig")]
        public Input<Inputs.KafkaKafkaUserConfigSchemaRegistryConfigArgs>? SchemaRegistryConfig { get; set; }

        /// <summary>
        /// Store logs for the service so that they are available in the HTTP API and console.
        /// </summary>
        [Input("serviceLog")]
        public Input<bool>? ServiceLog { get; set; }

        /// <summary>
        /// Single-zone configuration
        /// </summary>
        [Input("singleZone")]
        public Input<Inputs.KafkaKafkaUserConfigSingleZoneArgs>? SingleZone { get; set; }

        /// <summary>
        /// Use static public IP addresses.
        /// </summary>
        [Input("staticIps")]
        public Input<bool>? StaticIps { get; set; }

        /// <summary>
        /// Tiered storage configuration
        /// </summary>
        [Input("tieredStorage")]
        public Input<Inputs.KafkaKafkaUserConfigTieredStorageArgs>? TieredStorage { get; set; }

        public KafkaKafkaUserConfigArgs()
        {
        }
        public static new KafkaKafkaUserConfigArgs Empty => new KafkaKafkaUserConfigArgs();
    }
}
